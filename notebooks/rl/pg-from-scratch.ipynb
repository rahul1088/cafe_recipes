{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pg-from-scratch.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahul1088/wired/blob/master/notebooks/rl/pg-from-scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "0l9hHvTk6ec8"
      },
      "cell_type": "markdown",
      "source": [
        "# Policy Gradient\n",
        "\n",
        "* http://karpathy.github.io/2016/05/31/rl/\n",
        "* https://gist.github.com/karpathy/a4166c7fe253700972fcbc77e4ea32c5\n",
        "* https://github.com/gameofdimension/policy-gradient-pong\n",
        "* https://www.youtube.com/watch?v=tqrcjHuNdmQ\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "mqkOdLyN9Ylm"
      },
      "cell_type": "markdown",
      "source": [
        "## Step 1: Installation for Colab - just execute these cells and do not worry too much\n",
        "\n",
        "* http://nbviewer.jupyter.org/github/patrickmineault/xcorr-notebooks/blob/master/Render%20OpenAI%20gym%20as%20GIF.ipynb \n",
        "* https://docs.microsoft.com/en-us/message-passing-interface/microsoft-mpi\n",
        "* https://nyu-cds.github.io/python-mpi/setup/\n",
        "* https://medium.com/@kaleajit27/reinforcement-learning-on-google-colab-9cb2e1ef51e\n"
      ]
    },
    {
      "metadata": {
        "id": "uF9MAVI16huj",
        "outputId": "137200ea-a049-4c1f-b0b4-743f8c4ec75b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "!apt-get install python-opengl -y  >/dev/null\n",
        "!apt install xvfb -y >/dev/null"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "fSC11TfN6p69"
      },
      "cell_type": "code",
      "source": [
        "!pip install pyvirtualdisplay >/dev/null\n",
        "!pip install piglet >/dev/null"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "metadata": {
        "id": "caiHE2hy6xrf",
        "outputId": "785016dc-bc31-4225-df1a-8f387687ee12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "cell_type": "code",
      "source": [
        "# from pyvirtualdisplay import Display\n",
        "# display = Display(visible=0, size=(1400, 900))\n",
        "# display.start()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Display cmd_param=['Xvfb', '-br', '-nolisten', 'tcp', '-screen', '0', '1400x900x24', ':1005'] cmd=['Xvfb', '-br', '-nolisten', 'tcp', '-screen', '0', '1400x900x24', ':1005'] oserror=None return_code=None stdout=\"None\" stderr=\"None\" timeout_happened=False>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "cWACPRL869I4"
      },
      "cell_type": "code",
      "source": [
        "!pip install gym >/dev/null"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2Os6feRY6ec_"
      },
      "cell_type": "code",
      "source": [
        "!pip install JSAnimation >/dev/null"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wotUOa_e6edP"
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "from JSAnimation.IPython_display import display_animation\n",
        "from matplotlib import animation\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import HTML\n",
        "\n",
        "def display_frames_as_gif(frames):\n",
        "    \"\"\"\n",
        "    Displays a list of frames as a gif, with controls\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(frames[0].shape[1] / 72.0, frames[0].shape[0] / 72.0), dpi = 144)\n",
        "    patch = plt.imshow(frames[0])\n",
        "    plt.axis('off')\n",
        "\n",
        "    def animate(i):\n",
        "        patch.set_data(frames[i])\n",
        "\n",
        "    anim = animation.FuncAnimation(plt.gcf(), animate, frames = len(frames), interval=50)\n",
        "    HTML(anim.to_jshtml())"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "metadata": {
        "id": "R66_INeZ9nYX"
      },
      "cell_type": "markdown",
      "source": [
        "## Step 2: Playing Pong"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -U gym>=0.21.0\n",
        "%pip install -U gym[atari,accept-rom-license]"
      ],
      "metadata": {
        "id": "Dz9Z_1D5hTVW",
        "outputId": "5615fc86-3c48-4e71-e935-53b9666d5c46",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gym[accept-rom-license,atari] in /usr/local/lib/python3.7/dist-packages (0.25.1)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.7/dist-packages (from gym[accept-rom-license,atari]) (0.0.8)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym[accept-rom-license,atari]) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.7/dist-packages (from gym[accept-rom-license,atari]) (1.21.6)\n",
            "Requirement already satisfied: importlib-metadata>=4.8.0 in /usr/local/lib/python3.7/dist-packages (from gym[accept-rom-license,atari]) (4.12.0)\n",
            "Collecting autorom[accept-rom-license]~=0.4.2\n",
            "  Downloading AutoROM-0.4.2-py3-none-any.whl (16 kB)\n",
            "Collecting ale-py~=0.7.5\n",
            "  Downloading ale_py-0.7.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 33.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from ale-py~=0.7.5->gym[accept-rom-license,atari]) (5.9.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (4.64.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (2.23.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (7.1.2)\n",
            "Collecting AutoROM.accept-rom-license\n",
            "  Downloading AutoROM.accept-rom-license-0.4.2.tar.gz (9.8 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.8.0->gym[accept-rom-license,atari]) (3.8.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.8.0->gym[accept-rom-license,atari]) (4.1.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (1.24.3)\n",
            "Building wheels for collected packages: AutoROM.accept-rom-license\n",
            "  Building wheel for AutoROM.accept-rom-license (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for AutoROM.accept-rom-license: filename=AutoROM.accept_rom_license-0.4.2-py3-none-any.whl size=441027 sha256=2e78cbe4d8c88263743928c390b3b8a8b2c6a85f03b414367db11f427720cff0\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/67/2e/6147e7912fe37f5408b80d07527dab807c1d25f5c403a9538a\n",
            "Successfully built AutoROM.accept-rom-license\n",
            "Installing collected packages: AutoROM.accept-rom-license, autorom, ale-py\n",
            "Successfully installed AutoROM.accept-rom-license-0.4.2 ale-py-0.7.5 autorom-0.4.2\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "MtT2GyK_6edc",
        "outputId": "0edd6efc-1cf7-4041-f60a-2f75cba2bd4f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "import gym\n",
        "env = gym.make('Pong-v0')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gym/envs/registration.py:594: UserWarning: \u001b[33mWARN: The environment Pong-v0 is out of date. You should consider upgrading to version `v4`.\u001b[0m\n",
            "  f\"The environment {id} is out of date. You should consider \"\n",
            "/usr/local/lib/python3.7/dist-packages/gym/core.py:330: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  \"Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\"\n",
            "/usr/local/lib/python3.7/dist-packages/gym/wrappers/step_api_compatibility.py:40: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  \"Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\"\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "oRE6WmXQJ1Z0",
        "outputId": "5d2f2aab-9faf-4fd6-8d7c-b67ccea02afb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "env.action_space"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Discrete(6)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "yl_9d4HFJ31W",
        "outputId": "ba44b54d-9a2b-4508-eec2-8925d27f12bd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "env.observation_space"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Box(0, 255, (210, 160, 3), uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "trwRXI-h6eeI",
        "outputId": "079777c9-af76-4cc6-ac26-0297266093dd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "# Run a demo of the environment\n",
        "observation = env.reset()\n",
        "cumulated_reward = 0\n",
        "\n",
        "frames = []\n",
        "for t in range(1000):\n",
        "#     print(observation)\n",
        "    frames.append(env.render(mode = 'rgb_array'))\n",
        "    # very stupid agent, just makes a random action within the allowd action space\n",
        "    action = env.action_space.sample()\n",
        "#     print(\"Action: {}\".format(t+1))    \n",
        "    observation, reward, done, info = env.step(action)\n",
        "#     print(reward)\n",
        "    cumulated_reward += reward\n",
        "    if done:\n",
        "        print(\"Episode finished after {} timesteps, accumulated reward = {}\".format(t+1, cumulated_reward))\n",
        "        break\n",
        "print(\"Episode finished without success, accumulated reward = {}\".format(cumulated_reward))\n",
        "\n",
        "env.close()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gym/core.py:52: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
            "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
            "  \"The argument mode in render method is deprecated; \"\n",
            "/usr/local/lib/python3.7/dist-packages/gym/utils/passive_env_checker.py:298: UserWarning: \u001b[33mWARN: No render fps was declared in the environment (env.metadata['render_fps'] is None or not defined), rendering may occur at inconsistent fps.\u001b[0m\n",
            "  \"No render fps was declared in the environment (env.metadata['render_fps'] is None or not defined), rendering may occur at inconsistent fps.\"\n",
            "/usr/local/lib/python3.7/dist-packages/gym/utils/passive_env_checker.py:228: DeprecationWarning: \u001b[33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. \u001b[0m\n",
            "  \"Core environment is written in old step API which returns one bool instead of two. \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode finished without success, accumulated reward = -17.0\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "qUNldrqa6eeM",
        "outputId": "f703c4cf-8c23-4884-8c6c-c18303803b89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        }
      },
      "cell_type": "code",
      "source": [
        "display_frames_as_gif(frames)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 320x420 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQ4AAAFZCAYAAABpOsHqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAWJQAAFiUBSVIk8AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAGtUlEQVR4nO3dz25cZx2A4TOt2yS2kzixA8VUBChQRJd0mxUbeiksUK+CLRJcRm+glwBLxKZIlYgqEfLPduokjuO20rApEu2U4vfY4Yyd51l+9nfmZ8l+Nd+RfGY2n88HgOKVqQcAzh7hADLhADLhADLhADLhADLhADLhADLhADLhADLhADLhADLhALKVsRt//ZNLx/632ldmw3Dr5oVh9bUX16k3tjaH1YuXFtbv7+4OB4eHx77O5sbV4er65RPP8/jg6bDz6NMTX4fTt39zazj43rUTX2f1/v6wcfvBKUw0nfc/3JuN2Tc6HO/9dPGPdEpv3Lgx3Li2+MtwcHgYw7Ex3NzePvE8/7h3XziW1P4PvzM8+OWPTnydrb9+cubDMZajCpAJB5AJB5AJB5CNvjl6Xj16/GSYDXeP/f2X19eGa1euvMCJ+H9Zu/toWLu7eEP72XevDk+/f32CiZaXcHzNw7294eHe3rG//+b2tnCcE1dvPxy2//zxwvq9d38sHF/jqAJkwgFkwgFkwgFkwgFkwgFkwgFkwgFkwgFkwgFkwgFkwgFkwgFkwgFkwgFkwgFkHuQDXzq6ujo8/sHmwvrzjbUJplluwgFf2n3nzWH3nTenHuNMcFQBMuEAMuEAMuEAsnNzc/TZ4eGwv7L443z+xRcv9HWPPvts2H/yZGH98Oj5C31dxrvw5PAbPz8lX2f/+B9mft7M5vP5qI1/eO/6uI0wsdP8xZ2d4rWm8P6He6N+hHPzjgOO66z/sS8D9ziATDiAbPRR5dZv/3iacwBnyOibo7u7u26Owhm3ubk56paPowqQCQeQCQeQCQeQCQeQCQeQCQeQCQeQCQeQCQeQCQeQCQeQCQeQjf63+r988PvTnAOYwK9+87tR+zxzFF5iY5856qgCZMIBZMIBZMIBZMIBZMIBZMIBZMIBZMIBZMIBZMIBZMIBZMIBZMIBZMIBZMIBZMIBZMIBZMIBZMIBZMIBZMIBZMIBZMIBZMIBZMIBZMIBZMIBZMIBZMIBZMIBZMIBZMIBZMIBZMIBZMIBZMIBZMIBZMIBZMIBZMIBZMIBZMIBZMIBZMIBZMIBZMIBZMIBZMIBZMIBZMIBZMIBZMIBZMIBZMIBZMIBZMIBZMIBZMIBZMIBZMIBZMIBZMIBZMIBZMIBZMIBZMIBZMIBZMIBZMIBZMIBZMIBZMIBZMIBZMIBZMIBZMIBZMIBZMIBZMIBZMIBZMIBZMIBZMIBZMIBZMIBZMIBZMIBZMIBZMIBZMIBZMIBZMIBZMIBZMIBZMIBZMIBZMIBZMIBZMIBZMIBZMIBZMIBZMIBZMIBZMIBZMIBZMIBZMIBZMIBZCtTDwAvu6PLF4e9t7cX1l8/OBquf3RnmE0w0/8iHDCxo4214c6tnw/D7KuJWLv76XD9ozsTTfXtHFWATDiATDiATDiATDiATDiATDiATDiATDiATDiATDiATDiATDiATDiATDiATDiATDiATDiAbGkfHfiLt94a1i5dWlj/2+2/D08Onk0wEfBvSxuOy2urw5X19a+szefzYeXVpR0ZXhqOKkAmHEDmfT9M7NWjz4f1O48W1i/uPZ1gmuMRDpjY6oPHw9sf/Okbv7aMH8Y0DMIBk1vWOHwb9ziATDiATDiATDiATDiATDiATDiATDiATDiATDiATDiATDiATDiATDiATDiATDiATDiAbGmfAPbJP+8OF15/bWH92fPnE0wD/KelDce9nZ2pRwD+C0cVIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIFsZu/HGz949zTmAM2Q2n89HbdzZ2Rm3EVgaW1tbszH7Rr/jmM1GvR5wDrjHAWTCAWTCAWTCAWTCAWTCAWTCAWTCAWTCAWTCAWTCAWTCAWTCAWTCAWTCAWTCAWTCAWTCAWTCAWTCAWTCAWTCAWSjP1cFeHl5xwFkwgFkwgFkwgFkwgFkwgFkwgFkwgFkwgFkwgFkwgFkwgFkwgFk/wJ1c6tzPkO9eAAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "3zZTecVWLLes"
      },
      "cell_type": "code",
      "source": [
        "def sigmoid(x): \n",
        "  return 1.0 / (1.0 + np.exp(-x)) # sigmoid \"squashing\" function to interval [0,1]\n",
        "\n",
        "def prepro(I):\n",
        "  \"\"\" prepro 210x160x3 uint8 frame into 6400 (80x80) 1D float vector \"\"\"\n",
        "  I = I[35:195] # crop\n",
        "  I = I[::2,::2,0] # downsample by factor of 2\n",
        "  I[I == 144] = 0 # erase background (background type 1)\n",
        "  I[I == 109] = 0 # erase background (background type 2)\n",
        "  I[I != 0] = 1 # everything else (paddles, ball) just set to 1\n",
        "  return I.astype(np.float).ravel()\n",
        "\n",
        "def policy_forward(x):\n",
        "  h = np.dot(model['W1'], x)\n",
        "  h[h<0] = 0 # ReLU nonlinearity\n",
        "  logp = np.dot(model['W2'], h)\n",
        "  p = sigmoid(logp)\n",
        "  return p, h # return probability of taking action 2, and hidden state\n",
        "\n",
        "def model_step(model, observation, prev_x):\n",
        "  # preprocess the observation, set input to network to be difference image\n",
        "  cur_x = prepro(observation)\n",
        "  x = cur_x - prev_x if prev_x is not None else np.zeros(D)\n",
        "  prev_x = cur_x\n",
        "  \n",
        "  # forward the policy network and sample an action from the returned probability\n",
        "  aprob, _ = policy_forward(x)\n",
        "  action = 2 if aprob >= 0.5 else 3 # roll the dice!\n",
        "  \n",
        "  return action, prev_x\n",
        "\n",
        "def play_game(env, model):\n",
        "  observation = env.reset()\n",
        "\n",
        "  frames = []\n",
        "  cumulated_reward = 0\n",
        "\n",
        "  prev_x = None # used in computing the difference frame\n",
        "\n",
        "  for t in range(1000):\n",
        "      frames.append(env.render(mode = 'rgb_array'))\n",
        "      action, prev_x = model_step(model, observation, prev_x)\n",
        "      observation, reward, done, info = env.step(action)\n",
        "      cumulated_reward += reward\n",
        "      if done:\n",
        "          print(\"Episode finished after {} timesteps, accumulated reward = {}\".format(t+1, cumulated_reward))\n",
        "          break\n",
        "  print(\"Episode finished without success, accumulated reward = {}\".format(cumulated_reward))\n",
        "  display_frames_as_gif(frames)\n",
        "  env.close()\n",
        "  "
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6gWvZQ7AQLQt"
      },
      "cell_type": "markdown",
      "source": [
        "## Step 3: Policy Gradient from Scratch"
      ]
    },
    {
      "metadata": {
        "id": "eqFm7hqcItWl"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# model initialization\n",
        "H = 200 # number of hidden layer neurons\n",
        "D = 80 * 80 # input dimensionality: 80x80 grid\n",
        "model = {}\n",
        "model['W1'] = np.random.randn(H,D) / np.sqrt(D) # \"Xavier\" initialization\n",
        "model['W2'] = np.random.randn(H) / np.sqrt(H)\n",
        "\n",
        "# import pickle\n",
        "# model = pickle.load(open('model.pkl', 'rb'))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IJ4SeY8tPxvn",
        "outputId": "5a2255fa-c8c1-4a0d-cb1a-eab4b9cc28eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        }
      },
      "cell_type": "code",
      "source": [
        "# random init model\n",
        "play_game(env, model)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gym/core.py:52: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
            "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
            "  \"The argument mode in render method is deprecated; \"\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode finished without success, accumulated reward = -17.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 320x420 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "TwjiwKisQM19"
      },
      "cell_type": "code",
      "source": [
        "# hyperparameters\n",
        "batch_size = 10 # every how many episodes to do a param update?\n",
        "# learning_rate = 1e-4\n",
        "learning_rate = 1e-4\n",
        " \n",
        "gamma = 0.99 # discount factor for reward\n",
        "decay_rate = 0.99 # decay factor for RMSProp leaky sum of grad^2\n",
        "  \n",
        "grad_buffer = { k : np.zeros_like(v) for k,v in model.items() } # update buffers that add up gradients over a batch\n",
        "rmsprop_cache = { k : np.zeros_like(v) for k,v in model.items() } # rmsprop memory\n",
        "\n",
        "def discount_rewards(r):\n",
        "  \"\"\" take 1D float array of rewards and compute discounted reward \"\"\"\n",
        "  discounted_r = np.zeros_like(r, dtype=np.float32)\n",
        "  running_add = 0\n",
        "  for t in reversed(range(0, r.size)):\n",
        "    if r[t] != 0: running_add = 0 # reset the sum, since this was a game boundary (pong specific!)\n",
        "    running_add = running_add * gamma + r[t]\n",
        "    discounted_r[t] = running_add\n",
        "  return discounted_r\n",
        "\n",
        "def policy_backward(epx, eph, epdlogp):\n",
        "  \"\"\" backward pass. (eph is array of intermediate hidden states) \"\"\"\n",
        "  dW2 = np.dot(eph.T, epdlogp).ravel()\n",
        "  dh = np.outer(epdlogp, model['W2'])\n",
        "  dh[eph <= 0] = 0 # backpro prelu\n",
        "  dW1 = np.dot(dh.T, epx)\n",
        "  return {'W1':dW1, 'W2':dW2}\n",
        "\n",
        "def train_model(env, model, total_episodes = 100):\n",
        "  hist = []\n",
        "  observation = env.reset()\n",
        "\n",
        "  prev_x = None # used in computing the difference frame\n",
        "  xs,hs,dlogps,drs = [],[],[],[]\n",
        "  running_reward = None\n",
        "  reward_sum = 0\n",
        "  episode_number = 0\n",
        "\n",
        "  while True:\n",
        "    # preprocess the observation, set input to network to be difference image\n",
        "    cur_x = prepro(observation)\n",
        "    x = cur_x - prev_x if prev_x is not None else np.zeros(D)\n",
        "    prev_x = cur_x\n",
        "\n",
        "    # forward the policy network and sample an action from the returned probability\n",
        "    aprob, h = policy_forward(x)\n",
        "    action = 2 if np.random.uniform() < aprob else 3 # roll the dice!\n",
        "\n",
        "    # record various intermediates (needed later for backprop)\n",
        "    xs.append(x) # observation\n",
        "    hs.append(h) # hidden state\n",
        "    y = 1 if action == 2 else 0 # a \"fake label\"\n",
        "    dlogps.append(y - aprob) # grad that encourages the action that was taken to be taken (see http://cs231n.github.io/neural-networks-2/#losses if confused)\n",
        "\n",
        "    # step the environment and get new measurements\n",
        "    observation, reward, done, info = env.step(action)\n",
        "    reward_sum += reward\n",
        "\n",
        "    drs.append(reward) # record reward (has to be done after we call step() to get reward for previous action)\n",
        "\n",
        "    if done: # an episode finished\n",
        "      episode_number += 1\n",
        "\n",
        "      # stack together all inputs, hidden states, action gradients, and rewards for this episode\n",
        "      epx = np.vstack(xs)\n",
        "      eph = np.vstack(hs)\n",
        "      epdlogp = np.vstack(dlogps)\n",
        "      epr = np.vstack(drs)\n",
        "      xs,hs,dlogps,drs = [],[],[],[] # reset array memory\n",
        "\n",
        "      # compute the discounted reward backwards through time\n",
        "      discounted_epr = discount_rewards(epr)\n",
        "      # standardize the rewards to be unit normal (helps control the gradient estimator variance)\n",
        "      discounted_epr -= np.mean(discounted_epr)\n",
        "      discounted_epr /= np.std(discounted_epr)\n",
        "\n",
        "      epdlogp *= discounted_epr # modulate the gradient with advantage (PG magic happens right here.)\n",
        "      grad = policy_backward(epx, eph, epdlogp)\n",
        "      for k in model: grad_buffer[k] += grad[k] # accumulate grad over batch\n",
        "\n",
        "      # perform rmsprop parameter update every batch_size episodes\n",
        "      if episode_number % batch_size == 0:\n",
        "        for k,v in model.items():\n",
        "          g = grad_buffer[k] # gradient\n",
        "          rmsprop_cache[k] = decay_rate * rmsprop_cache[k] + (1 - decay_rate) * g**2\n",
        "          model[k] += learning_rate * g / (np.sqrt(rmsprop_cache[k]) + 1e-5)\n",
        "          grad_buffer[k] = np.zeros_like(v) # reset batch gradient buffer\n",
        "\n",
        "      # boring book-keeping\n",
        "      running_reward = reward_sum if running_reward is None else running_reward * 0.99 + reward_sum * 0.01\n",
        "      hist.append((episode_number, reward_sum, running_reward))\n",
        "      print ('resetting env. episode %f, reward total was %f. running mean: %f' % (episode_number, reward_sum, running_reward))\n",
        "      reward_sum = 0\n",
        "      observation = env.reset() # reset env\n",
        "      prev_x = None\n",
        "      if episode_number == total_episodes: return hist\n",
        "\n",
        "  #   if reward != 0: # Pong has either +1 or -1 reward exactly when game ends.\n",
        "  #     print (('ep %d: game finished, reward: %f' % (episode_number, reward)) + ('' if reward == -1 else ' !!!!!!!!'))"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G6Ka_5Vl9Orm",
        "outputId": "dccbc8b9-2dae-445a-abcd-e26f76d1bf7c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "%time hist1 = train_model(env, model, total_episodes=500)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "resetting env. episode 1.000000, reward total was -20.000000. running mean: -20.000000\n",
            "resetting env. episode 2.000000, reward total was -21.000000. running mean: -20.010000\n",
            "resetting env. episode 3.000000, reward total was -20.000000. running mean: -20.009900\n",
            "resetting env. episode 4.000000, reward total was -21.000000. running mean: -20.019801\n",
            "resetting env. episode 5.000000, reward total was -20.000000. running mean: -20.019603\n",
            "resetting env. episode 6.000000, reward total was -21.000000. running mean: -20.029407\n",
            "resetting env. episode 7.000000, reward total was -18.000000. running mean: -20.009113\n",
            "resetting env. episode 8.000000, reward total was -20.000000. running mean: -20.009022\n",
            "resetting env. episode 9.000000, reward total was -19.000000. running mean: -19.998932\n",
            "resetting env. episode 10.000000, reward total was -19.000000. running mean: -19.988942\n",
            "resetting env. episode 11.000000, reward total was -21.000000. running mean: -19.999053\n",
            "resetting env. episode 12.000000, reward total was -20.000000. running mean: -19.999062\n",
            "resetting env. episode 13.000000, reward total was -19.000000. running mean: -19.989072\n",
            "resetting env. episode 14.000000, reward total was -21.000000. running mean: -19.999181\n",
            "resetting env. episode 15.000000, reward total was -21.000000. running mean: -20.009189\n",
            "resetting env. episode 16.000000, reward total was -19.000000. running mean: -19.999097\n",
            "resetting env. episode 17.000000, reward total was -21.000000. running mean: -20.009106\n",
            "resetting env. episode 18.000000, reward total was -21.000000. running mean: -20.019015\n",
            "resetting env. episode 19.000000, reward total was -21.000000. running mean: -20.028825\n",
            "resetting env. episode 20.000000, reward total was -21.000000. running mean: -20.038537\n",
            "resetting env. episode 21.000000, reward total was -19.000000. running mean: -20.028151\n",
            "resetting env. episode 22.000000, reward total was -21.000000. running mean: -20.037870\n",
            "resetting env. episode 23.000000, reward total was -21.000000. running mean: -20.047491\n",
            "resetting env. episode 24.000000, reward total was -20.000000. running mean: -20.047016\n",
            "resetting env. episode 25.000000, reward total was -21.000000. running mean: -20.056546\n",
            "resetting env. episode 26.000000, reward total was -21.000000. running mean: -20.065981\n",
            "resetting env. episode 27.000000, reward total was -21.000000. running mean: -20.075321\n",
            "resetting env. episode 28.000000, reward total was -21.000000. running mean: -20.084568\n",
            "resetting env. episode 29.000000, reward total was -19.000000. running mean: -20.073722\n",
            "resetting env. episode 30.000000, reward total was -21.000000. running mean: -20.082985\n",
            "resetting env. episode 31.000000, reward total was -21.000000. running mean: -20.092155\n",
            "resetting env. episode 32.000000, reward total was -20.000000. running mean: -20.091233\n",
            "resetting env. episode 33.000000, reward total was -21.000000. running mean: -20.100321\n",
            "resetting env. episode 34.000000, reward total was -20.000000. running mean: -20.099318\n",
            "resetting env. episode 35.000000, reward total was -21.000000. running mean: -20.108325\n",
            "resetting env. episode 36.000000, reward total was -21.000000. running mean: -20.117241\n",
            "resetting env. episode 37.000000, reward total was -21.000000. running mean: -20.126069\n",
            "resetting env. episode 38.000000, reward total was -20.000000. running mean: -20.124808\n",
            "resetting env. episode 39.000000, reward total was -20.000000. running mean: -20.123560\n",
            "resetting env. episode 40.000000, reward total was -20.000000. running mean: -20.122325\n",
            "resetting env. episode 41.000000, reward total was -20.000000. running mean: -20.121101\n",
            "resetting env. episode 42.000000, reward total was -20.000000. running mean: -20.119890\n",
            "resetting env. episode 43.000000, reward total was -21.000000. running mean: -20.128691\n",
            "resetting env. episode 44.000000, reward total was -19.000000. running mean: -20.117405\n",
            "resetting env. episode 45.000000, reward total was -20.000000. running mean: -20.116230\n",
            "resetting env. episode 46.000000, reward total was -21.000000. running mean: -20.125068\n",
            "resetting env. episode 47.000000, reward total was -21.000000. running mean: -20.133818\n",
            "resetting env. episode 48.000000, reward total was -20.000000. running mean: -20.132479\n",
            "resetting env. episode 49.000000, reward total was -20.000000. running mean: -20.131155\n",
            "resetting env. episode 50.000000, reward total was -19.000000. running mean: -20.119843\n",
            "resetting env. episode 51.000000, reward total was -20.000000. running mean: -20.118645\n",
            "resetting env. episode 52.000000, reward total was -19.000000. running mean: -20.107458\n",
            "resetting env. episode 53.000000, reward total was -19.000000. running mean: -20.096384\n",
            "resetting env. episode 54.000000, reward total was -20.000000. running mean: -20.095420\n",
            "resetting env. episode 55.000000, reward total was -21.000000. running mean: -20.104466\n",
            "resetting env. episode 56.000000, reward total was -21.000000. running mean: -20.113421\n",
            "resetting env. episode 57.000000, reward total was -21.000000. running mean: -20.122287\n",
            "resetting env. episode 58.000000, reward total was -19.000000. running mean: -20.111064\n",
            "resetting env. episode 59.000000, reward total was -21.000000. running mean: -20.119953\n",
            "resetting env. episode 60.000000, reward total was -21.000000. running mean: -20.128754\n",
            "resetting env. episode 61.000000, reward total was -21.000000. running mean: -20.137466\n",
            "resetting env. episode 62.000000, reward total was -21.000000. running mean: -20.146091\n",
            "resetting env. episode 63.000000, reward total was -21.000000. running mean: -20.154630\n",
            "resetting env. episode 64.000000, reward total was -20.000000. running mean: -20.153084\n",
            "resetting env. episode 65.000000, reward total was -20.000000. running mean: -20.151553\n",
            "resetting env. episode 66.000000, reward total was -21.000000. running mean: -20.160038\n",
            "resetting env. episode 67.000000, reward total was -21.000000. running mean: -20.168437\n",
            "resetting env. episode 68.000000, reward total was -19.000000. running mean: -20.156753\n",
            "resetting env. episode 69.000000, reward total was -18.000000. running mean: -20.135186\n",
            "resetting env. episode 70.000000, reward total was -19.000000. running mean: -20.123834\n",
            "resetting env. episode 71.000000, reward total was -20.000000. running mean: -20.122595\n",
            "resetting env. episode 72.000000, reward total was -21.000000. running mean: -20.131369\n",
            "resetting env. episode 73.000000, reward total was -21.000000. running mean: -20.140056\n",
            "resetting env. episode 74.000000, reward total was -21.000000. running mean: -20.148655\n",
            "resetting env. episode 75.000000, reward total was -21.000000. running mean: -20.157169\n",
            "resetting env. episode 76.000000, reward total was -21.000000. running mean: -20.165597\n",
            "resetting env. episode 77.000000, reward total was -19.000000. running mean: -20.153941\n",
            "resetting env. episode 78.000000, reward total was -21.000000. running mean: -20.162402\n",
            "resetting env. episode 79.000000, reward total was -21.000000. running mean: -20.170778\n",
            "resetting env. episode 80.000000, reward total was -21.000000. running mean: -20.179070\n",
            "resetting env. episode 81.000000, reward total was -19.000000. running mean: -20.167279\n",
            "resetting env. episode 82.000000, reward total was -21.000000. running mean: -20.175606\n",
            "resetting env. episode 83.000000, reward total was -21.000000. running mean: -20.183850\n",
            "resetting env. episode 84.000000, reward total was -21.000000. running mean: -20.192012\n",
            "resetting env. episode 85.000000, reward total was -21.000000. running mean: -20.200092\n",
            "resetting env. episode 86.000000, reward total was -21.000000. running mean: -20.208091\n",
            "resetting env. episode 87.000000, reward total was -21.000000. running mean: -20.216010\n",
            "resetting env. episode 88.000000, reward total was -20.000000. running mean: -20.213850\n",
            "resetting env. episode 89.000000, reward total was -21.000000. running mean: -20.221711\n",
            "resetting env. episode 90.000000, reward total was -21.000000. running mean: -20.229494\n",
            "resetting env. episode 91.000000, reward total was -21.000000. running mean: -20.237199\n",
            "resetting env. episode 92.000000, reward total was -20.000000. running mean: -20.234827\n",
            "resetting env. episode 93.000000, reward total was -20.000000. running mean: -20.232479\n",
            "resetting env. episode 94.000000, reward total was -20.000000. running mean: -20.230154\n",
            "resetting env. episode 95.000000, reward total was -19.000000. running mean: -20.217853\n",
            "resetting env. episode 96.000000, reward total was -21.000000. running mean: -20.225674\n",
            "resetting env. episode 97.000000, reward total was -21.000000. running mean: -20.233417\n",
            "resetting env. episode 98.000000, reward total was -21.000000. running mean: -20.241083\n",
            "resetting env. episode 99.000000, reward total was -21.000000. running mean: -20.248672\n",
            "resetting env. episode 100.000000, reward total was -21.000000. running mean: -20.256186\n",
            "resetting env. episode 101.000000, reward total was -19.000000. running mean: -20.243624\n",
            "resetting env. episode 102.000000, reward total was -18.000000. running mean: -20.221187\n",
            "resetting env. episode 103.000000, reward total was -20.000000. running mean: -20.218976\n",
            "resetting env. episode 104.000000, reward total was -21.000000. running mean: -20.226786\n",
            "resetting env. episode 105.000000, reward total was -21.000000. running mean: -20.234518\n",
            "resetting env. episode 106.000000, reward total was -21.000000. running mean: -20.242173\n",
            "resetting env. episode 107.000000, reward total was -20.000000. running mean: -20.239751\n",
            "resetting env. episode 108.000000, reward total was -20.000000. running mean: -20.237354\n",
            "resetting env. episode 109.000000, reward total was -20.000000. running mean: -20.234980\n",
            "resetting env. episode 110.000000, reward total was -21.000000. running mean: -20.242630\n",
            "resetting env. episode 111.000000, reward total was -20.000000. running mean: -20.240204\n",
            "resetting env. episode 112.000000, reward total was -20.000000. running mean: -20.237802\n",
            "resetting env. episode 113.000000, reward total was -21.000000. running mean: -20.245424\n",
            "resetting env. episode 114.000000, reward total was -21.000000. running mean: -20.252970\n",
            "resetting env. episode 115.000000, reward total was -21.000000. running mean: -20.260440\n",
            "resetting env. episode 116.000000, reward total was -21.000000. running mean: -20.267835\n",
            "resetting env. episode 117.000000, reward total was -19.000000. running mean: -20.255157\n",
            "resetting env. episode 118.000000, reward total was -21.000000. running mean: -20.262606\n",
            "resetting env. episode 119.000000, reward total was -21.000000. running mean: -20.269980\n",
            "resetting env. episode 120.000000, reward total was -20.000000. running mean: -20.267280\n",
            "resetting env. episode 121.000000, reward total was -20.000000. running mean: -20.264607\n",
            "resetting env. episode 122.000000, reward total was -21.000000. running mean: -20.271961\n",
            "resetting env. episode 123.000000, reward total was -20.000000. running mean: -20.269241\n",
            "resetting env. episode 124.000000, reward total was -20.000000. running mean: -20.266549\n",
            "resetting env. episode 125.000000, reward total was -19.000000. running mean: -20.253883\n",
            "resetting env. episode 126.000000, reward total was -20.000000. running mean: -20.251345\n",
            "resetting env. episode 127.000000, reward total was -21.000000. running mean: -20.258831\n",
            "resetting env. episode 128.000000, reward total was -21.000000. running mean: -20.266243\n",
            "resetting env. episode 129.000000, reward total was -21.000000. running mean: -20.273580\n",
            "resetting env. episode 130.000000, reward total was -20.000000. running mean: -20.270845\n",
            "resetting env. episode 131.000000, reward total was -20.000000. running mean: -20.268136\n",
            "resetting env. episode 132.000000, reward total was -20.000000. running mean: -20.265455\n",
            "resetting env. episode 133.000000, reward total was -20.000000. running mean: -20.262800\n",
            "resetting env. episode 134.000000, reward total was -21.000000. running mean: -20.270172\n",
            "resetting env. episode 135.000000, reward total was -20.000000. running mean: -20.267470\n",
            "resetting env. episode 136.000000, reward total was -21.000000. running mean: -20.274796\n",
            "resetting env. episode 137.000000, reward total was -21.000000. running mean: -20.282048\n",
            "resetting env. episode 138.000000, reward total was -21.000000. running mean: -20.289227\n",
            "resetting env. episode 139.000000, reward total was -20.000000. running mean: -20.286335\n",
            "resetting env. episode 140.000000, reward total was -21.000000. running mean: -20.293472\n",
            "resetting env. episode 141.000000, reward total was -21.000000. running mean: -20.300537\n",
            "resetting env. episode 142.000000, reward total was -18.000000. running mean: -20.277532\n",
            "resetting env. episode 143.000000, reward total was -21.000000. running mean: -20.284756\n",
            "resetting env. episode 144.000000, reward total was -21.000000. running mean: -20.291909\n",
            "resetting env. episode 145.000000, reward total was -20.000000. running mean: -20.288990\n",
            "resetting env. episode 146.000000, reward total was -20.000000. running mean: -20.286100\n",
            "resetting env. episode 147.000000, reward total was -21.000000. running mean: -20.293239\n",
            "resetting env. episode 148.000000, reward total was -19.000000. running mean: -20.280306\n",
            "resetting env. episode 149.000000, reward total was -21.000000. running mean: -20.287503\n",
            "resetting env. episode 150.000000, reward total was -20.000000. running mean: -20.284628\n",
            "resetting env. episode 151.000000, reward total was -20.000000. running mean: -20.281782\n",
            "resetting env. episode 152.000000, reward total was -19.000000. running mean: -20.268964\n",
            "resetting env. episode 153.000000, reward total was -20.000000. running mean: -20.266275\n",
            "resetting env. episode 154.000000, reward total was -21.000000. running mean: -20.273612\n",
            "resetting env. episode 155.000000, reward total was -20.000000. running mean: -20.270876\n",
            "resetting env. episode 156.000000, reward total was -21.000000. running mean: -20.278167\n",
            "resetting env. episode 157.000000, reward total was -19.000000. running mean: -20.265385\n",
            "resetting env. episode 158.000000, reward total was -21.000000. running mean: -20.272731\n",
            "resetting env. episode 159.000000, reward total was -21.000000. running mean: -20.280004\n",
            "resetting env. episode 160.000000, reward total was -20.000000. running mean: -20.277204\n",
            "resetting env. episode 161.000000, reward total was -19.000000. running mean: -20.264432\n",
            "resetting env. episode 162.000000, reward total was -19.000000. running mean: -20.251788\n",
            "resetting env. episode 163.000000, reward total was -21.000000. running mean: -20.259270\n",
            "resetting env. episode 164.000000, reward total was -21.000000. running mean: -20.266677\n",
            "resetting env. episode 165.000000, reward total was -21.000000. running mean: -20.274010\n",
            "resetting env. episode 166.000000, reward total was -21.000000. running mean: -20.281270\n",
            "resetting env. episode 167.000000, reward total was -21.000000. running mean: -20.288458\n",
            "resetting env. episode 168.000000, reward total was -21.000000. running mean: -20.295573\n",
            "resetting env. episode 169.000000, reward total was -21.000000. running mean: -20.302617\n",
            "resetting env. episode 170.000000, reward total was -21.000000. running mean: -20.309591\n",
            "resetting env. episode 171.000000, reward total was -21.000000. running mean: -20.316495\n",
            "resetting env. episode 172.000000, reward total was -18.000000. running mean: -20.293330\n",
            "resetting env. episode 173.000000, reward total was -20.000000. running mean: -20.290397\n",
            "resetting env. episode 174.000000, reward total was -21.000000. running mean: -20.297493\n",
            "resetting env. episode 175.000000, reward total was -21.000000. running mean: -20.304518\n",
            "resetting env. episode 176.000000, reward total was -19.000000. running mean: -20.291473\n",
            "resetting env. episode 177.000000, reward total was -21.000000. running mean: -20.298558\n",
            "resetting env. episode 178.000000, reward total was -21.000000. running mean: -20.305572\n",
            "resetting env. episode 179.000000, reward total was -21.000000. running mean: -20.312517\n",
            "resetting env. episode 180.000000, reward total was -21.000000. running mean: -20.319392\n",
            "resetting env. episode 181.000000, reward total was -20.000000. running mean: -20.316198\n",
            "resetting env. episode 182.000000, reward total was -21.000000. running mean: -20.323036\n",
            "resetting env. episode 183.000000, reward total was -21.000000. running mean: -20.329805\n",
            "resetting env. episode 184.000000, reward total was -21.000000. running mean: -20.336507\n",
            "resetting env. episode 185.000000, reward total was -20.000000. running mean: -20.333142\n",
            "resetting env. episode 186.000000, reward total was -21.000000. running mean: -20.339811\n",
            "resetting env. episode 187.000000, reward total was -20.000000. running mean: -20.336413\n",
            "resetting env. episode 188.000000, reward total was -19.000000. running mean: -20.323049\n",
            "resetting env. episode 189.000000, reward total was -20.000000. running mean: -20.319818\n",
            "resetting env. episode 190.000000, reward total was -19.000000. running mean: -20.306620\n",
            "resetting env. episode 191.000000, reward total was -21.000000. running mean: -20.313554\n",
            "resetting env. episode 192.000000, reward total was -21.000000. running mean: -20.320418\n",
            "resetting env. episode 193.000000, reward total was -21.000000. running mean: -20.327214\n",
            "resetting env. episode 194.000000, reward total was -21.000000. running mean: -20.333942\n",
            "resetting env. episode 195.000000, reward total was -21.000000. running mean: -20.340602\n",
            "resetting env. episode 196.000000, reward total was -18.000000. running mean: -20.317196\n",
            "resetting env. episode 197.000000, reward total was -21.000000. running mean: -20.324024\n",
            "resetting env. episode 198.000000, reward total was -19.000000. running mean: -20.310784\n",
            "resetting env. episode 199.000000, reward total was -21.000000. running mean: -20.317676\n",
            "resetting env. episode 200.000000, reward total was -21.000000. running mean: -20.324500\n",
            "resetting env. episode 201.000000, reward total was -21.000000. running mean: -20.331255\n",
            "resetting env. episode 202.000000, reward total was -19.000000. running mean: -20.317942\n",
            "resetting env. episode 203.000000, reward total was -20.000000. running mean: -20.314763\n",
            "resetting env. episode 204.000000, reward total was -19.000000. running mean: -20.301615\n",
            "resetting env. episode 205.000000, reward total was -21.000000. running mean: -20.308599\n",
            "resetting env. episode 206.000000, reward total was -20.000000. running mean: -20.305513\n",
            "resetting env. episode 207.000000, reward total was -21.000000. running mean: -20.312458\n",
            "resetting env. episode 208.000000, reward total was -20.000000. running mean: -20.309333\n",
            "resetting env. episode 209.000000, reward total was -21.000000. running mean: -20.316240\n",
            "resetting env. episode 210.000000, reward total was -21.000000. running mean: -20.323077\n",
            "resetting env. episode 211.000000, reward total was -21.000000. running mean: -20.329847\n",
            "resetting env. episode 212.000000, reward total was -21.000000. running mean: -20.336548\n",
            "resetting env. episode 213.000000, reward total was -20.000000. running mean: -20.333183\n",
            "resetting env. episode 214.000000, reward total was -21.000000. running mean: -20.339851\n",
            "resetting env. episode 215.000000, reward total was -20.000000. running mean: -20.336452\n",
            "resetting env. episode 216.000000, reward total was -21.000000. running mean: -20.343088\n",
            "resetting env. episode 217.000000, reward total was -20.000000. running mean: -20.339657\n",
            "resetting env. episode 218.000000, reward total was -21.000000. running mean: -20.346260\n",
            "resetting env. episode 219.000000, reward total was -18.000000. running mean: -20.322798\n",
            "resetting env. episode 220.000000, reward total was -20.000000. running mean: -20.319570\n",
            "resetting env. episode 221.000000, reward total was -21.000000. running mean: -20.326374\n",
            "resetting env. episode 222.000000, reward total was -21.000000. running mean: -20.333110\n",
            "resetting env. episode 223.000000, reward total was -20.000000. running mean: -20.329779\n",
            "resetting env. episode 224.000000, reward total was -21.000000. running mean: -20.336481\n",
            "resetting env. episode 225.000000, reward total was -20.000000. running mean: -20.333117\n",
            "resetting env. episode 226.000000, reward total was -21.000000. running mean: -20.339785\n",
            "resetting env. episode 227.000000, reward total was -21.000000. running mean: -20.346388\n",
            "resetting env. episode 228.000000, reward total was -21.000000. running mean: -20.352924\n",
            "resetting env. episode 229.000000, reward total was -21.000000. running mean: -20.359395\n",
            "resetting env. episode 230.000000, reward total was -20.000000. running mean: -20.355801\n",
            "resetting env. episode 231.000000, reward total was -21.000000. running mean: -20.362243\n",
            "resetting env. episode 232.000000, reward total was -20.000000. running mean: -20.358620\n",
            "resetting env. episode 233.000000, reward total was -20.000000. running mean: -20.355034\n",
            "resetting env. episode 234.000000, reward total was -19.000000. running mean: -20.341484\n",
            "resetting env. episode 235.000000, reward total was -21.000000. running mean: -20.348069\n",
            "resetting env. episode 236.000000, reward total was -21.000000. running mean: -20.354588\n",
            "resetting env. episode 237.000000, reward total was -21.000000. running mean: -20.361042\n",
            "resetting env. episode 238.000000, reward total was -21.000000. running mean: -20.367432\n",
            "resetting env. episode 239.000000, reward total was -21.000000. running mean: -20.373757\n",
            "resetting env. episode 240.000000, reward total was -21.000000. running mean: -20.380020\n",
            "resetting env. episode 241.000000, reward total was -21.000000. running mean: -20.386220\n",
            "resetting env. episode 242.000000, reward total was -18.000000. running mean: -20.362357\n",
            "resetting env. episode 243.000000, reward total was -20.000000. running mean: -20.358734\n",
            "resetting env. episode 244.000000, reward total was -20.000000. running mean: -20.355147\n",
            "resetting env. episode 245.000000, reward total was -21.000000. running mean: -20.361595\n",
            "resetting env. episode 246.000000, reward total was -19.000000. running mean: -20.347979\n",
            "resetting env. episode 247.000000, reward total was -21.000000. running mean: -20.354499\n",
            "resetting env. episode 248.000000, reward total was -21.000000. running mean: -20.360954\n",
            "resetting env. episode 249.000000, reward total was -21.000000. running mean: -20.367345\n",
            "resetting env. episode 250.000000, reward total was -20.000000. running mean: -20.363671\n",
            "resetting env. episode 251.000000, reward total was -21.000000. running mean: -20.370035\n",
            "resetting env. episode 252.000000, reward total was -21.000000. running mean: -20.376334\n",
            "resetting env. episode 253.000000, reward total was -21.000000. running mean: -20.382571\n",
            "resetting env. episode 254.000000, reward total was -21.000000. running mean: -20.388745\n",
            "resetting env. episode 255.000000, reward total was -21.000000. running mean: -20.394858\n",
            "resetting env. episode 256.000000, reward total was -20.000000. running mean: -20.390909\n",
            "resetting env. episode 257.000000, reward total was -21.000000. running mean: -20.397000\n",
            "resetting env. episode 258.000000, reward total was -21.000000. running mean: -20.403030\n",
            "resetting env. episode 259.000000, reward total was -20.000000. running mean: -20.399000\n",
            "resetting env. episode 260.000000, reward total was -19.000000. running mean: -20.385010\n",
            "resetting env. episode 261.000000, reward total was -17.000000. running mean: -20.351160\n",
            "resetting env. episode 262.000000, reward total was -20.000000. running mean: -20.347648\n",
            "resetting env. episode 263.000000, reward total was -21.000000. running mean: -20.354172\n",
            "resetting env. episode 264.000000, reward total was -19.000000. running mean: -20.340630\n",
            "resetting env. episode 265.000000, reward total was -19.000000. running mean: -20.327224\n",
            "resetting env. episode 266.000000, reward total was -21.000000. running mean: -20.333951\n",
            "resetting env. episode 267.000000, reward total was -20.000000. running mean: -20.330612\n",
            "resetting env. episode 268.000000, reward total was -21.000000. running mean: -20.337306\n",
            "resetting env. episode 269.000000, reward total was -21.000000. running mean: -20.343933\n",
            "resetting env. episode 270.000000, reward total was -18.000000. running mean: -20.320493\n",
            "resetting env. episode 271.000000, reward total was -20.000000. running mean: -20.317288\n",
            "resetting env. episode 272.000000, reward total was -19.000000. running mean: -20.304116\n",
            "resetting env. episode 273.000000, reward total was -16.000000. running mean: -20.261074\n",
            "resetting env. episode 274.000000, reward total was -19.000000. running mean: -20.248464\n",
            "resetting env. episode 275.000000, reward total was -20.000000. running mean: -20.245979\n",
            "resetting env. episode 276.000000, reward total was -20.000000. running mean: -20.243519\n",
            "resetting env. episode 277.000000, reward total was -21.000000. running mean: -20.251084\n",
            "resetting env. episode 278.000000, reward total was -21.000000. running mean: -20.258573\n",
            "resetting env. episode 279.000000, reward total was -19.000000. running mean: -20.245987\n",
            "resetting env. episode 280.000000, reward total was -20.000000. running mean: -20.243528\n",
            "resetting env. episode 281.000000, reward total was -19.000000. running mean: -20.231092\n",
            "resetting env. episode 282.000000, reward total was -19.000000. running mean: -20.218781\n",
            "resetting env. episode 283.000000, reward total was -20.000000. running mean: -20.216594\n",
            "resetting env. episode 284.000000, reward total was -20.000000. running mean: -20.214428\n",
            "resetting env. episode 285.000000, reward total was -19.000000. running mean: -20.202283\n",
            "resetting env. episode 286.000000, reward total was -21.000000. running mean: -20.210261\n",
            "resetting env. episode 287.000000, reward total was -20.000000. running mean: -20.208158\n",
            "resetting env. episode 288.000000, reward total was -20.000000. running mean: -20.206076\n",
            "resetting env. episode 289.000000, reward total was -21.000000. running mean: -20.214016\n",
            "resetting env. episode 290.000000, reward total was -21.000000. running mean: -20.221875\n",
            "resetting env. episode 291.000000, reward total was -21.000000. running mean: -20.229657\n",
            "resetting env. episode 292.000000, reward total was -21.000000. running mean: -20.237360\n",
            "resetting env. episode 293.000000, reward total was -21.000000. running mean: -20.244987\n",
            "resetting env. episode 294.000000, reward total was -21.000000. running mean: -20.252537\n",
            "resetting env. episode 295.000000, reward total was -20.000000. running mean: -20.250011\n",
            "resetting env. episode 296.000000, reward total was -20.000000. running mean: -20.247511\n",
            "resetting env. episode 297.000000, reward total was -21.000000. running mean: -20.255036\n",
            "resetting env. episode 298.000000, reward total was -21.000000. running mean: -20.262486\n",
            "resetting env. episode 299.000000, reward total was -20.000000. running mean: -20.259861\n",
            "resetting env. episode 300.000000, reward total was -19.000000. running mean: -20.247262\n",
            "resetting env. episode 301.000000, reward total was -21.000000. running mean: -20.254790\n",
            "resetting env. episode 302.000000, reward total was -20.000000. running mean: -20.252242\n",
            "resetting env. episode 303.000000, reward total was -21.000000. running mean: -20.259719\n",
            "resetting env. episode 304.000000, reward total was -21.000000. running mean: -20.267122\n",
            "resetting env. episode 305.000000, reward total was -19.000000. running mean: -20.254451\n",
            "resetting env. episode 306.000000, reward total was -21.000000. running mean: -20.261906\n",
            "resetting env. episode 307.000000, reward total was -20.000000. running mean: -20.259287\n",
            "resetting env. episode 308.000000, reward total was -21.000000. running mean: -20.266694\n",
            "resetting env. episode 309.000000, reward total was -19.000000. running mean: -20.254027\n",
            "resetting env. episode 310.000000, reward total was -20.000000. running mean: -20.251487\n",
            "resetting env. episode 311.000000, reward total was -21.000000. running mean: -20.258972\n",
            "resetting env. episode 312.000000, reward total was -20.000000. running mean: -20.256383\n",
            "resetting env. episode 313.000000, reward total was -20.000000. running mean: -20.253819\n",
            "resetting env. episode 314.000000, reward total was -20.000000. running mean: -20.251281\n",
            "resetting env. episode 315.000000, reward total was -21.000000. running mean: -20.258768\n",
            "resetting env. episode 316.000000, reward total was -20.000000. running mean: -20.256180\n",
            "resetting env. episode 317.000000, reward total was -21.000000. running mean: -20.263618\n",
            "resetting env. episode 318.000000, reward total was -21.000000. running mean: -20.270982\n",
            "resetting env. episode 319.000000, reward total was -21.000000. running mean: -20.278272\n",
            "resetting env. episode 320.000000, reward total was -21.000000. running mean: -20.285490\n",
            "resetting env. episode 321.000000, reward total was -21.000000. running mean: -20.292635\n",
            "resetting env. episode 322.000000, reward total was -21.000000. running mean: -20.299708\n",
            "resetting env. episode 323.000000, reward total was -21.000000. running mean: -20.306711\n",
            "resetting env. episode 324.000000, reward total was -20.000000. running mean: -20.303644\n",
            "resetting env. episode 325.000000, reward total was -20.000000. running mean: -20.300608\n",
            "resetting env. episode 326.000000, reward total was -19.000000. running mean: -20.287602\n",
            "resetting env. episode 327.000000, reward total was -21.000000. running mean: -20.294726\n",
            "resetting env. episode 328.000000, reward total was -21.000000. running mean: -20.301778\n",
            "resetting env. episode 329.000000, reward total was -21.000000. running mean: -20.308761\n",
            "resetting env. episode 330.000000, reward total was -20.000000. running mean: -20.305673\n",
            "resetting env. episode 331.000000, reward total was -21.000000. running mean: -20.312616\n",
            "resetting env. episode 332.000000, reward total was -21.000000. running mean: -20.319490\n",
            "resetting env. episode 333.000000, reward total was -20.000000. running mean: -20.316295\n",
            "resetting env. episode 334.000000, reward total was -21.000000. running mean: -20.323132\n",
            "resetting env. episode 335.000000, reward total was -21.000000. running mean: -20.329901\n",
            "resetting env. episode 336.000000, reward total was -20.000000. running mean: -20.326602\n",
            "resetting env. episode 337.000000, reward total was -21.000000. running mean: -20.333336\n",
            "resetting env. episode 338.000000, reward total was -20.000000. running mean: -20.330003\n",
            "resetting env. episode 339.000000, reward total was -21.000000. running mean: -20.336702\n",
            "resetting env. episode 340.000000, reward total was -21.000000. running mean: -20.343335\n",
            "resetting env. episode 341.000000, reward total was -21.000000. running mean: -20.349902\n",
            "resetting env. episode 342.000000, reward total was -21.000000. running mean: -20.356403\n",
            "resetting env. episode 343.000000, reward total was -21.000000. running mean: -20.362839\n",
            "resetting env. episode 344.000000, reward total was -20.000000. running mean: -20.359211\n",
            "resetting env. episode 345.000000, reward total was -21.000000. running mean: -20.365619\n",
            "resetting env. episode 346.000000, reward total was -19.000000. running mean: -20.351962\n",
            "resetting env. episode 347.000000, reward total was -19.000000. running mean: -20.338443\n",
            "resetting env. episode 348.000000, reward total was -21.000000. running mean: -20.345058\n",
            "resetting env. episode 349.000000, reward total was -21.000000. running mean: -20.351608\n",
            "resetting env. episode 350.000000, reward total was -18.000000. running mean: -20.328092\n",
            "resetting env. episode 351.000000, reward total was -21.000000. running mean: -20.334811\n",
            "resetting env. episode 352.000000, reward total was -21.000000. running mean: -20.341463\n",
            "resetting env. episode 353.000000, reward total was -21.000000. running mean: -20.348048\n",
            "resetting env. episode 354.000000, reward total was -21.000000. running mean: -20.354568\n",
            "resetting env. episode 355.000000, reward total was -21.000000. running mean: -20.361022\n",
            "resetting env. episode 356.000000, reward total was -21.000000. running mean: -20.367412\n",
            "resetting env. episode 357.000000, reward total was -20.000000. running mean: -20.363738\n",
            "resetting env. episode 358.000000, reward total was -20.000000. running mean: -20.360100\n",
            "resetting env. episode 359.000000, reward total was -20.000000. running mean: -20.356499\n",
            "resetting env. episode 360.000000, reward total was -21.000000. running mean: -20.362934\n",
            "resetting env. episode 361.000000, reward total was -21.000000. running mean: -20.369305\n",
            "resetting env. episode 362.000000, reward total was -21.000000. running mean: -20.375612\n",
            "resetting env. episode 363.000000, reward total was -20.000000. running mean: -20.371856\n",
            "resetting env. episode 364.000000, reward total was -20.000000. running mean: -20.368137\n",
            "resetting env. episode 365.000000, reward total was -20.000000. running mean: -20.364456\n",
            "resetting env. episode 366.000000, reward total was -21.000000. running mean: -20.370811\n",
            "resetting env. episode 367.000000, reward total was -20.000000. running mean: -20.367103\n",
            "resetting env. episode 368.000000, reward total was -21.000000. running mean: -20.373432\n",
            "resetting env. episode 369.000000, reward total was -21.000000. running mean: -20.379698\n",
            "resetting env. episode 370.000000, reward total was -20.000000. running mean: -20.375901\n",
            "resetting env. episode 371.000000, reward total was -21.000000. running mean: -20.382142\n",
            "resetting env. episode 372.000000, reward total was -21.000000. running mean: -20.388320\n",
            "resetting env. episode 373.000000, reward total was -20.000000. running mean: -20.384437\n",
            "resetting env. episode 374.000000, reward total was -20.000000. running mean: -20.380593\n",
            "resetting env. episode 375.000000, reward total was -19.000000. running mean: -20.366787\n",
            "resetting env. episode 376.000000, reward total was -21.000000. running mean: -20.373119\n",
            "resetting env. episode 377.000000, reward total was -21.000000. running mean: -20.379388\n",
            "resetting env. episode 378.000000, reward total was -21.000000. running mean: -20.385594\n",
            "resetting env. episode 379.000000, reward total was -21.000000. running mean: -20.391738\n",
            "resetting env. episode 380.000000, reward total was -19.000000. running mean: -20.377821\n",
            "resetting env. episode 381.000000, reward total was -21.000000. running mean: -20.384042\n",
            "resetting env. episode 382.000000, reward total was -21.000000. running mean: -20.390202\n",
            "resetting env. episode 383.000000, reward total was -21.000000. running mean: -20.396300\n",
            "resetting env. episode 384.000000, reward total was -19.000000. running mean: -20.382337\n",
            "resetting env. episode 385.000000, reward total was -20.000000. running mean: -20.378514\n",
            "resetting env. episode 386.000000, reward total was -20.000000. running mean: -20.374728\n",
            "resetting env. episode 387.000000, reward total was -21.000000. running mean: -20.380981\n",
            "resetting env. episode 388.000000, reward total was -21.000000. running mean: -20.387171\n",
            "resetting env. episode 389.000000, reward total was -21.000000. running mean: -20.393300\n",
            "resetting env. episode 390.000000, reward total was -21.000000. running mean: -20.399367\n",
            "resetting env. episode 391.000000, reward total was -20.000000. running mean: -20.395373\n",
            "resetting env. episode 392.000000, reward total was -20.000000. running mean: -20.391419\n",
            "resetting env. episode 393.000000, reward total was -19.000000. running mean: -20.377505\n",
            "resetting env. episode 394.000000, reward total was -20.000000. running mean: -20.373730\n",
            "resetting env. episode 395.000000, reward total was -19.000000. running mean: -20.359993\n",
            "resetting env. episode 396.000000, reward total was -21.000000. running mean: -20.366393\n",
            "resetting env. episode 397.000000, reward total was -20.000000. running mean: -20.362729\n",
            "resetting env. episode 398.000000, reward total was -21.000000. running mean: -20.369102\n",
            "resetting env. episode 399.000000, reward total was -20.000000. running mean: -20.365411\n",
            "resetting env. episode 400.000000, reward total was -21.000000. running mean: -20.371756\n",
            "resetting env. episode 401.000000, reward total was -17.000000. running mean: -20.338039\n",
            "resetting env. episode 402.000000, reward total was -20.000000. running mean: -20.334658\n",
            "resetting env. episode 403.000000, reward total was -21.000000. running mean: -20.341312\n",
            "resetting env. episode 404.000000, reward total was -20.000000. running mean: -20.337899\n",
            "resetting env. episode 405.000000, reward total was -21.000000. running mean: -20.344520\n",
            "resetting env. episode 406.000000, reward total was -20.000000. running mean: -20.341075\n",
            "resetting env. episode 407.000000, reward total was -20.000000. running mean: -20.337664\n",
            "resetting env. episode 408.000000, reward total was -19.000000. running mean: -20.324287\n",
            "resetting env. episode 409.000000, reward total was -21.000000. running mean: -20.331044\n",
            "resetting env. episode 410.000000, reward total was -21.000000. running mean: -20.337734\n",
            "resetting env. episode 411.000000, reward total was -20.000000. running mean: -20.334357\n",
            "resetting env. episode 412.000000, reward total was -21.000000. running mean: -20.341013\n",
            "resetting env. episode 413.000000, reward total was -18.000000. running mean: -20.317603\n",
            "resetting env. episode 414.000000, reward total was -21.000000. running mean: -20.324427\n",
            "resetting env. episode 415.000000, reward total was -21.000000. running mean: -20.331183\n",
            "resetting env. episode 416.000000, reward total was -21.000000. running mean: -20.337871\n",
            "resetting env. episode 417.000000, reward total was -20.000000. running mean: -20.334492\n",
            "resetting env. episode 418.000000, reward total was -21.000000. running mean: -20.341147\n",
            "resetting env. episode 419.000000, reward total was -20.000000. running mean: -20.337736\n",
            "resetting env. episode 420.000000, reward total was -20.000000. running mean: -20.334358\n",
            "resetting env. episode 421.000000, reward total was -21.000000. running mean: -20.341015\n",
            "resetting env. episode 422.000000, reward total was -18.000000. running mean: -20.317605\n",
            "resetting env. episode 423.000000, reward total was -21.000000. running mean: -20.324428\n",
            "resetting env. episode 424.000000, reward total was -20.000000. running mean: -20.321184\n",
            "resetting env. episode 425.000000, reward total was -20.000000. running mean: -20.317972\n",
            "resetting env. episode 426.000000, reward total was -21.000000. running mean: -20.324793\n",
            "resetting env. episode 427.000000, reward total was -20.000000. running mean: -20.321545\n",
            "resetting env. episode 428.000000, reward total was -20.000000. running mean: -20.318329\n",
            "resetting env. episode 429.000000, reward total was -20.000000. running mean: -20.315146\n",
            "resetting env. episode 430.000000, reward total was -21.000000. running mean: -20.321994\n",
            "resetting env. episode 431.000000, reward total was -19.000000. running mean: -20.308775\n",
            "resetting env. episode 432.000000, reward total was -21.000000. running mean: -20.315687\n",
            "resetting env. episode 433.000000, reward total was -21.000000. running mean: -20.322530\n",
            "resetting env. episode 434.000000, reward total was -19.000000. running mean: -20.309305\n",
            "resetting env. episode 435.000000, reward total was -19.000000. running mean: -20.296212\n",
            "resetting env. episode 436.000000, reward total was -20.000000. running mean: -20.293249\n",
            "resetting env. episode 437.000000, reward total was -21.000000. running mean: -20.300317\n",
            "resetting env. episode 438.000000, reward total was -20.000000. running mean: -20.297314\n",
            "resetting env. episode 439.000000, reward total was -21.000000. running mean: -20.304341\n",
            "resetting env. episode 440.000000, reward total was -20.000000. running mean: -20.301297\n",
            "resetting env. episode 441.000000, reward total was -21.000000. running mean: -20.308284\n",
            "resetting env. episode 442.000000, reward total was -20.000000. running mean: -20.305201\n",
            "resetting env. episode 443.000000, reward total was -20.000000. running mean: -20.302149\n",
            "resetting env. episode 444.000000, reward total was -17.000000. running mean: -20.269128\n",
            "resetting env. episode 445.000000, reward total was -20.000000. running mean: -20.266437\n",
            "resetting env. episode 446.000000, reward total was -20.000000. running mean: -20.263772\n",
            "resetting env. episode 447.000000, reward total was -21.000000. running mean: -20.271135\n",
            "resetting env. episode 448.000000, reward total was -20.000000. running mean: -20.268423\n",
            "resetting env. episode 449.000000, reward total was -20.000000. running mean: -20.265739\n",
            "resetting env. episode 450.000000, reward total was -21.000000. running mean: -20.273082\n",
            "resetting env. episode 451.000000, reward total was -20.000000. running mean: -20.270351\n",
            "resetting env. episode 452.000000, reward total was -18.000000. running mean: -20.247647\n",
            "resetting env. episode 453.000000, reward total was -20.000000. running mean: -20.245171\n",
            "resetting env. episode 454.000000, reward total was -21.000000. running mean: -20.252719\n",
            "resetting env. episode 455.000000, reward total was -21.000000. running mean: -20.260192\n",
            "resetting env. episode 456.000000, reward total was -20.000000. running mean: -20.257590\n",
            "resetting env. episode 457.000000, reward total was -21.000000. running mean: -20.265014\n",
            "resetting env. episode 458.000000, reward total was -21.000000. running mean: -20.272364\n",
            "resetting env. episode 459.000000, reward total was -21.000000. running mean: -20.279640\n",
            "resetting env. episode 460.000000, reward total was -21.000000. running mean: -20.286844\n",
            "resetting env. episode 461.000000, reward total was -21.000000. running mean: -20.293975\n",
            "resetting env. episode 462.000000, reward total was -21.000000. running mean: -20.301036\n",
            "resetting env. episode 463.000000, reward total was -20.000000. running mean: -20.298025\n",
            "resetting env. episode 464.000000, reward total was -21.000000. running mean: -20.305045\n",
            "resetting env. episode 465.000000, reward total was -21.000000. running mean: -20.311995\n",
            "resetting env. episode 466.000000, reward total was -21.000000. running mean: -20.318875\n",
            "resetting env. episode 467.000000, reward total was -21.000000. running mean: -20.325686\n",
            "resetting env. episode 468.000000, reward total was -21.000000. running mean: -20.332429\n",
            "resetting env. episode 469.000000, reward total was -21.000000. running mean: -20.339105\n",
            "resetting env. episode 470.000000, reward total was -21.000000. running mean: -20.345714\n",
            "resetting env. episode 471.000000, reward total was -21.000000. running mean: -20.352257\n",
            "resetting env. episode 472.000000, reward total was -20.000000. running mean: -20.348734\n",
            "resetting env. episode 473.000000, reward total was -21.000000. running mean: -20.355247\n",
            "resetting env. episode 474.000000, reward total was -21.000000. running mean: -20.361694\n",
            "resetting env. episode 475.000000, reward total was -21.000000. running mean: -20.368077\n",
            "resetting env. episode 476.000000, reward total was -20.000000. running mean: -20.364397\n",
            "resetting env. episode 477.000000, reward total was -18.000000. running mean: -20.340753\n",
            "resetting env. episode 478.000000, reward total was -20.000000. running mean: -20.337345\n",
            "resetting env. episode 479.000000, reward total was -19.000000. running mean: -20.323972\n",
            "resetting env. episode 480.000000, reward total was -21.000000. running mean: -20.330732\n",
            "resetting env. episode 481.000000, reward total was -21.000000. running mean: -20.337425\n",
            "resetting env. episode 482.000000, reward total was -21.000000. running mean: -20.344050\n",
            "resetting env. episode 483.000000, reward total was -21.000000. running mean: -20.350610\n",
            "resetting env. episode 484.000000, reward total was -21.000000. running mean: -20.357104\n",
            "resetting env. episode 485.000000, reward total was -20.000000. running mean: -20.353533\n",
            "resetting env. episode 486.000000, reward total was -21.000000. running mean: -20.359997\n",
            "resetting env. episode 487.000000, reward total was -20.000000. running mean: -20.356397\n",
            "resetting env. episode 488.000000, reward total was -21.000000. running mean: -20.362833\n",
            "resetting env. episode 489.000000, reward total was -20.000000. running mean: -20.359205\n",
            "resetting env. episode 490.000000, reward total was -21.000000. running mean: -20.365613\n",
            "resetting env. episode 491.000000, reward total was -21.000000. running mean: -20.371957\n",
            "resetting env. episode 492.000000, reward total was -20.000000. running mean: -20.368237\n",
            "resetting env. episode 493.000000, reward total was -20.000000. running mean: -20.364555\n",
            "resetting env. episode 494.000000, reward total was -21.000000. running mean: -20.370909\n",
            "resetting env. episode 495.000000, reward total was -21.000000. running mean: -20.377200\n",
            "resetting env. episode 496.000000, reward total was -20.000000. running mean: -20.373428\n",
            "resetting env. episode 497.000000, reward total was -21.000000. running mean: -20.379694\n",
            "resetting env. episode 498.000000, reward total was -20.000000. running mean: -20.375897\n",
            "resetting env. episode 499.000000, reward total was -20.000000. running mean: -20.372138\n",
            "resetting env. episode 500.000000, reward total was -19.000000. running mean: -20.358417\n",
            "CPU times: user 23min 3s, sys: 10min 40s, total: 33min 43s\n",
            "Wall time: 17min 29s\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "ZJUybWUALvQz",
        "outputId": "6750f51a-a44f-4080-de83-6f1910048546",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        }
      },
      "cell_type": "code",
      "source": [
        "play_game(env, model)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gym/core.py:52: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
            "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
            "  \"The argument mode in render method is deprecated; \"\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode finished without success, accumulated reward = -8.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 320x420 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "cHYCDYwhlVLV",
        "outputId": "39a8081f-78ab-4d24-9d0b-9ea30f625718",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "%time hist2 = train_model(env, model, total_episodes=500)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "resetting env. episode 1.000000, reward total was -20.000000. running mean: -20.000000\n",
            "resetting env. episode 2.000000, reward total was -21.000000. running mean: -20.010000\n",
            "resetting env. episode 3.000000, reward total was -21.000000. running mean: -20.019900\n",
            "resetting env. episode 4.000000, reward total was -21.000000. running mean: -20.029701\n",
            "resetting env. episode 5.000000, reward total was -21.000000. running mean: -20.039404\n",
            "resetting env. episode 6.000000, reward total was -21.000000. running mean: -20.049010\n",
            "resetting env. episode 7.000000, reward total was -21.000000. running mean: -20.058520\n",
            "resetting env. episode 8.000000, reward total was -20.000000. running mean: -20.057935\n",
            "resetting env. episode 9.000000, reward total was -21.000000. running mean: -20.067355\n",
            "resetting env. episode 10.000000, reward total was -20.000000. running mean: -20.066682\n",
            "resetting env. episode 11.000000, reward total was -20.000000. running mean: -20.066015\n",
            "resetting env. episode 12.000000, reward total was -21.000000. running mean: -20.075355\n",
            "resetting env. episode 13.000000, reward total was -21.000000. running mean: -20.084601\n",
            "resetting env. episode 14.000000, reward total was -15.000000. running mean: -20.033755\n",
            "resetting env. episode 15.000000, reward total was -21.000000. running mean: -20.043418\n",
            "resetting env. episode 16.000000, reward total was -21.000000. running mean: -20.052983\n",
            "resetting env. episode 17.000000, reward total was -21.000000. running mean: -20.062454\n",
            "resetting env. episode 18.000000, reward total was -21.000000. running mean: -20.071829\n",
            "resetting env. episode 19.000000, reward total was -21.000000. running mean: -20.081111\n",
            "resetting env. episode 20.000000, reward total was -20.000000. running mean: -20.080300\n",
            "resetting env. episode 21.000000, reward total was -21.000000. running mean: -20.089497\n",
            "resetting env. episode 22.000000, reward total was -21.000000. running mean: -20.098602\n",
            "resetting env. episode 23.000000, reward total was -19.000000. running mean: -20.087616\n",
            "resetting env. episode 24.000000, reward total was -20.000000. running mean: -20.086740\n",
            "resetting env. episode 25.000000, reward total was -21.000000. running mean: -20.095872\n",
            "resetting env. episode 26.000000, reward total was -21.000000. running mean: -20.104913\n",
            "resetting env. episode 27.000000, reward total was -18.000000. running mean: -20.083864\n",
            "resetting env. episode 28.000000, reward total was -20.000000. running mean: -20.083026\n",
            "resetting env. episode 29.000000, reward total was -21.000000. running mean: -20.092195\n",
            "resetting env. episode 30.000000, reward total was -19.000000. running mean: -20.081273\n",
            "resetting env. episode 31.000000, reward total was -21.000000. running mean: -20.090461\n",
            "resetting env. episode 32.000000, reward total was -20.000000. running mean: -20.089556\n",
            "resetting env. episode 33.000000, reward total was -21.000000. running mean: -20.098661\n",
            "resetting env. episode 34.000000, reward total was -20.000000. running mean: -20.097674\n",
            "resetting env. episode 35.000000, reward total was -21.000000. running mean: -20.106697\n",
            "resetting env. episode 36.000000, reward total was -20.000000. running mean: -20.105630\n",
            "resetting env. episode 37.000000, reward total was -21.000000. running mean: -20.114574\n",
            "resetting env. episode 38.000000, reward total was -18.000000. running mean: -20.093428\n",
            "resetting env. episode 39.000000, reward total was -20.000000. running mean: -20.092494\n",
            "resetting env. episode 40.000000, reward total was -21.000000. running mean: -20.101569\n",
            "resetting env. episode 41.000000, reward total was -21.000000. running mean: -20.110553\n",
            "resetting env. episode 42.000000, reward total was -20.000000. running mean: -20.109448\n",
            "resetting env. episode 43.000000, reward total was -20.000000. running mean: -20.108353\n",
            "resetting env. episode 44.000000, reward total was -20.000000. running mean: -20.107270\n",
            "resetting env. episode 45.000000, reward total was -20.000000. running mean: -20.106197\n",
            "resetting env. episode 46.000000, reward total was -21.000000. running mean: -20.115135\n",
            "resetting env. episode 47.000000, reward total was -20.000000. running mean: -20.113984\n",
            "resetting env. episode 48.000000, reward total was -19.000000. running mean: -20.102844\n",
            "resetting env. episode 49.000000, reward total was -21.000000. running mean: -20.111815\n",
            "resetting env. episode 50.000000, reward total was -20.000000. running mean: -20.110697\n",
            "resetting env. episode 51.000000, reward total was -21.000000. running mean: -20.119590\n",
            "resetting env. episode 52.000000, reward total was -19.000000. running mean: -20.108394\n",
            "resetting env. episode 53.000000, reward total was -21.000000. running mean: -20.117310\n",
            "resetting env. episode 54.000000, reward total was -21.000000. running mean: -20.126137\n",
            "resetting env. episode 55.000000, reward total was -21.000000. running mean: -20.134876\n",
            "resetting env. episode 56.000000, reward total was -21.000000. running mean: -20.143527\n",
            "resetting env. episode 57.000000, reward total was -21.000000. running mean: -20.152092\n",
            "resetting env. episode 58.000000, reward total was -21.000000. running mean: -20.160571\n",
            "resetting env. episode 59.000000, reward total was -21.000000. running mean: -20.168965\n",
            "resetting env. episode 60.000000, reward total was -21.000000. running mean: -20.177276\n",
            "resetting env. episode 61.000000, reward total was -21.000000. running mean: -20.185503\n",
            "resetting env. episode 62.000000, reward total was -21.000000. running mean: -20.193648\n",
            "resetting env. episode 63.000000, reward total was -21.000000. running mean: -20.201711\n",
            "resetting env. episode 64.000000, reward total was -21.000000. running mean: -20.209694\n",
            "resetting env. episode 65.000000, reward total was -21.000000. running mean: -20.217597\n",
            "resetting env. episode 66.000000, reward total was -20.000000. running mean: -20.215421\n",
            "resetting env. episode 67.000000, reward total was -21.000000. running mean: -20.223267\n",
            "resetting env. episode 68.000000, reward total was -21.000000. running mean: -20.231035\n",
            "resetting env. episode 69.000000, reward total was -19.000000. running mean: -20.218724\n",
            "resetting env. episode 70.000000, reward total was -21.000000. running mean: -20.226537\n",
            "resetting env. episode 71.000000, reward total was -21.000000. running mean: -20.234272\n",
            "resetting env. episode 72.000000, reward total was -20.000000. running mean: -20.231929\n",
            "resetting env. episode 73.000000, reward total was -20.000000. running mean: -20.229610\n",
            "resetting env. episode 74.000000, reward total was -21.000000. running mean: -20.237313\n",
            "resetting env. episode 75.000000, reward total was -20.000000. running mean: -20.234940\n",
            "resetting env. episode 76.000000, reward total was -19.000000. running mean: -20.222591\n",
            "resetting env. episode 77.000000, reward total was -21.000000. running mean: -20.230365\n",
            "resetting env. episode 78.000000, reward total was -21.000000. running mean: -20.238061\n",
            "resetting env. episode 79.000000, reward total was -20.000000. running mean: -20.235681\n",
            "resetting env. episode 80.000000, reward total was -19.000000. running mean: -20.223324\n",
            "resetting env. episode 81.000000, reward total was -21.000000. running mean: -20.231091\n",
            "resetting env. episode 82.000000, reward total was -21.000000. running mean: -20.238780\n",
            "resetting env. episode 83.000000, reward total was -21.000000. running mean: -20.246392\n",
            "resetting env. episode 84.000000, reward total was -18.000000. running mean: -20.223928\n",
            "resetting env. episode 85.000000, reward total was -20.000000. running mean: -20.221689\n",
            "resetting env. episode 86.000000, reward total was -21.000000. running mean: -20.229472\n",
            "resetting env. episode 87.000000, reward total was -21.000000. running mean: -20.237177\n",
            "resetting env. episode 88.000000, reward total was -19.000000. running mean: -20.224805\n",
            "resetting env. episode 89.000000, reward total was -21.000000. running mean: -20.232557\n",
            "resetting env. episode 90.000000, reward total was -20.000000. running mean: -20.230232\n",
            "resetting env. episode 91.000000, reward total was -20.000000. running mean: -20.227929\n",
            "resetting env. episode 92.000000, reward total was -19.000000. running mean: -20.215650\n",
            "resetting env. episode 93.000000, reward total was -21.000000. running mean: -20.223494\n",
            "resetting env. episode 94.000000, reward total was -21.000000. running mean: -20.231259\n",
            "resetting env. episode 95.000000, reward total was -21.000000. running mean: -20.238946\n",
            "resetting env. episode 96.000000, reward total was -21.000000. running mean: -20.246557\n",
            "resetting env. episode 97.000000, reward total was -20.000000. running mean: -20.244091\n",
            "resetting env. episode 98.000000, reward total was -21.000000. running mean: -20.251650\n",
            "resetting env. episode 99.000000, reward total was -20.000000. running mean: -20.249134\n",
            "resetting env. episode 100.000000, reward total was -21.000000. running mean: -20.256642\n",
            "resetting env. episode 101.000000, reward total was -20.000000. running mean: -20.254076\n",
            "resetting env. episode 102.000000, reward total was -21.000000. running mean: -20.261535\n",
            "resetting env. episode 103.000000, reward total was -21.000000. running mean: -20.268920\n",
            "resetting env. episode 104.000000, reward total was -20.000000. running mean: -20.266231\n",
            "resetting env. episode 105.000000, reward total was -20.000000. running mean: -20.263568\n",
            "resetting env. episode 106.000000, reward total was -19.000000. running mean: -20.250933\n",
            "resetting env. episode 107.000000, reward total was -21.000000. running mean: -20.258423\n",
            "resetting env. episode 108.000000, reward total was -21.000000. running mean: -20.265839\n",
            "resetting env. episode 109.000000, reward total was -18.000000. running mean: -20.243181\n",
            "resetting env. episode 110.000000, reward total was -20.000000. running mean: -20.240749\n",
            "resetting env. episode 111.000000, reward total was -21.000000. running mean: -20.248341\n",
            "resetting env. episode 112.000000, reward total was -21.000000. running mean: -20.255858\n",
            "resetting env. episode 113.000000, reward total was -21.000000. running mean: -20.263299\n",
            "resetting env. episode 114.000000, reward total was -21.000000. running mean: -20.270666\n",
            "resetting env. episode 115.000000, reward total was -21.000000. running mean: -20.277960\n",
            "resetting env. episode 116.000000, reward total was -19.000000. running mean: -20.265180\n",
            "resetting env. episode 117.000000, reward total was -20.000000. running mean: -20.262528\n",
            "resetting env. episode 118.000000, reward total was -21.000000. running mean: -20.269903\n",
            "resetting env. episode 119.000000, reward total was -20.000000. running mean: -20.267204\n",
            "resetting env. episode 120.000000, reward total was -20.000000. running mean: -20.264532\n",
            "resetting env. episode 121.000000, reward total was -21.000000. running mean: -20.271887\n",
            "resetting env. episode 122.000000, reward total was -19.000000. running mean: -20.259168\n",
            "resetting env. episode 123.000000, reward total was -20.000000. running mean: -20.256576\n",
            "resetting env. episode 124.000000, reward total was -21.000000. running mean: -20.264010\n",
            "resetting env. episode 125.000000, reward total was -21.000000. running mean: -20.271370\n",
            "resetting env. episode 126.000000, reward total was -21.000000. running mean: -20.278657\n",
            "resetting env. episode 127.000000, reward total was -21.000000. running mean: -20.285870\n",
            "resetting env. episode 128.000000, reward total was -21.000000. running mean: -20.293011\n",
            "resetting env. episode 129.000000, reward total was -21.000000. running mean: -20.300081\n",
            "resetting env. episode 130.000000, reward total was -20.000000. running mean: -20.297080\n",
            "resetting env. episode 131.000000, reward total was -19.000000. running mean: -20.284110\n",
            "resetting env. episode 132.000000, reward total was -20.000000. running mean: -20.281268\n",
            "resetting env. episode 133.000000, reward total was -20.000000. running mean: -20.278456\n",
            "resetting env. episode 134.000000, reward total was -21.000000. running mean: -20.285671\n",
            "resetting env. episode 135.000000, reward total was -21.000000. running mean: -20.292815\n",
            "resetting env. episode 136.000000, reward total was -21.000000. running mean: -20.299886\n",
            "resetting env. episode 137.000000, reward total was -21.000000. running mean: -20.306888\n",
            "resetting env. episode 138.000000, reward total was -21.000000. running mean: -20.313819\n",
            "resetting env. episode 139.000000, reward total was -19.000000. running mean: -20.300680\n",
            "resetting env. episode 140.000000, reward total was -20.000000. running mean: -20.297674\n",
            "resetting env. episode 141.000000, reward total was -19.000000. running mean: -20.284697\n",
            "resetting env. episode 142.000000, reward total was -21.000000. running mean: -20.291850\n",
            "resetting env. episode 143.000000, reward total was -19.000000. running mean: -20.278931\n",
            "resetting env. episode 144.000000, reward total was -21.000000. running mean: -20.286142\n",
            "resetting env. episode 145.000000, reward total was -18.000000. running mean: -20.263281\n",
            "resetting env. episode 146.000000, reward total was -19.000000. running mean: -20.250648\n",
            "resetting env. episode 147.000000, reward total was -20.000000. running mean: -20.248141\n",
            "resetting env. episode 148.000000, reward total was -20.000000. running mean: -20.245660\n",
            "resetting env. episode 149.000000, reward total was -19.000000. running mean: -20.233203\n",
            "resetting env. episode 150.000000, reward total was -21.000000. running mean: -20.240871\n",
            "resetting env. episode 151.000000, reward total was -20.000000. running mean: -20.238463\n",
            "resetting env. episode 152.000000, reward total was -21.000000. running mean: -20.246078\n",
            "resetting env. episode 153.000000, reward total was -20.000000. running mean: -20.243617\n",
            "resetting env. episode 154.000000, reward total was -21.000000. running mean: -20.251181\n",
            "resetting env. episode 155.000000, reward total was -20.000000. running mean: -20.248669\n",
            "resetting env. episode 156.000000, reward total was -21.000000. running mean: -20.256183\n",
            "resetting env. episode 157.000000, reward total was -20.000000. running mean: -20.253621\n",
            "resetting env. episode 158.000000, reward total was -20.000000. running mean: -20.251085\n",
            "resetting env. episode 159.000000, reward total was -21.000000. running mean: -20.258574\n",
            "resetting env. episode 160.000000, reward total was -20.000000. running mean: -20.255988\n",
            "resetting env. episode 161.000000, reward total was -21.000000. running mean: -20.263428\n",
            "resetting env. episode 162.000000, reward total was -20.000000. running mean: -20.260794\n",
            "resetting env. episode 163.000000, reward total was -21.000000. running mean: -20.268186\n",
            "resetting env. episode 164.000000, reward total was -20.000000. running mean: -20.265504\n",
            "resetting env. episode 165.000000, reward total was -21.000000. running mean: -20.272849\n",
            "resetting env. episode 166.000000, reward total was -21.000000. running mean: -20.280120\n",
            "resetting env. episode 167.000000, reward total was -20.000000. running mean: -20.277319\n",
            "resetting env. episode 168.000000, reward total was -21.000000. running mean: -20.284546\n",
            "resetting env. episode 169.000000, reward total was -20.000000. running mean: -20.281701\n",
            "resetting env. episode 170.000000, reward total was -21.000000. running mean: -20.288884\n",
            "resetting env. episode 171.000000, reward total was -21.000000. running mean: -20.295995\n",
            "resetting env. episode 172.000000, reward total was -21.000000. running mean: -20.303035\n",
            "resetting env. episode 173.000000, reward total was -21.000000. running mean: -20.310004\n",
            "resetting env. episode 174.000000, reward total was -21.000000. running mean: -20.316904\n",
            "resetting env. episode 175.000000, reward total was -21.000000. running mean: -20.323735\n",
            "resetting env. episode 176.000000, reward total was -21.000000. running mean: -20.330498\n",
            "resetting env. episode 177.000000, reward total was -18.000000. running mean: -20.307193\n",
            "resetting env. episode 178.000000, reward total was -21.000000. running mean: -20.314121\n",
            "resetting env. episode 179.000000, reward total was -20.000000. running mean: -20.310980\n",
            "resetting env. episode 180.000000, reward total was -21.000000. running mean: -20.317870\n",
            "resetting env. episode 181.000000, reward total was -16.000000. running mean: -20.274691\n",
            "resetting env. episode 182.000000, reward total was -21.000000. running mean: -20.281944\n",
            "resetting env. episode 183.000000, reward total was -20.000000. running mean: -20.279125\n",
            "resetting env. episode 184.000000, reward total was -21.000000. running mean: -20.286334\n",
            "resetting env. episode 185.000000, reward total was -21.000000. running mean: -20.293470\n",
            "resetting env. episode 186.000000, reward total was -21.000000. running mean: -20.300536\n",
            "resetting env. episode 187.000000, reward total was -21.000000. running mean: -20.307530\n",
            "resetting env. episode 188.000000, reward total was -18.000000. running mean: -20.284455\n",
            "resetting env. episode 189.000000, reward total was -21.000000. running mean: -20.291611\n",
            "resetting env. episode 190.000000, reward total was -21.000000. running mean: -20.298694\n",
            "resetting env. episode 191.000000, reward total was -21.000000. running mean: -20.305707\n",
            "resetting env. episode 192.000000, reward total was -20.000000. running mean: -20.302650\n",
            "resetting env. episode 193.000000, reward total was -21.000000. running mean: -20.309624\n",
            "resetting env. episode 194.000000, reward total was -21.000000. running mean: -20.316528\n",
            "resetting env. episode 195.000000, reward total was -21.000000. running mean: -20.323362\n",
            "resetting env. episode 196.000000, reward total was -21.000000. running mean: -20.330129\n",
            "resetting env. episode 197.000000, reward total was -21.000000. running mean: -20.336827\n",
            "resetting env. episode 198.000000, reward total was -20.000000. running mean: -20.333459\n",
            "resetting env. episode 199.000000, reward total was -21.000000. running mean: -20.340125\n",
            "resetting env. episode 200.000000, reward total was -18.000000. running mean: -20.316723\n",
            "resetting env. episode 201.000000, reward total was -21.000000. running mean: -20.323556\n",
            "resetting env. episode 202.000000, reward total was -21.000000. running mean: -20.330321\n",
            "resetting env. episode 203.000000, reward total was -19.000000. running mean: -20.317017\n",
            "resetting env. episode 204.000000, reward total was -21.000000. running mean: -20.323847\n",
            "resetting env. episode 205.000000, reward total was -20.000000. running mean: -20.320609\n",
            "resetting env. episode 206.000000, reward total was -19.000000. running mean: -20.307403\n",
            "resetting env. episode 207.000000, reward total was -20.000000. running mean: -20.304329\n",
            "resetting env. episode 208.000000, reward total was -19.000000. running mean: -20.291285\n",
            "resetting env. episode 209.000000, reward total was -19.000000. running mean: -20.278372\n",
            "resetting env. episode 210.000000, reward total was -21.000000. running mean: -20.285589\n",
            "resetting env. episode 211.000000, reward total was -18.000000. running mean: -20.262733\n",
            "resetting env. episode 212.000000, reward total was -20.000000. running mean: -20.260106\n",
            "resetting env. episode 213.000000, reward total was -21.000000. running mean: -20.267504\n",
            "resetting env. episode 214.000000, reward total was -21.000000. running mean: -20.274829\n",
            "resetting env. episode 215.000000, reward total was -21.000000. running mean: -20.282081\n",
            "resetting env. episode 216.000000, reward total was -21.000000. running mean: -20.289260\n",
            "resetting env. episode 217.000000, reward total was -17.000000. running mean: -20.256368\n",
            "resetting env. episode 218.000000, reward total was -17.000000. running mean: -20.223804\n",
            "resetting env. episode 219.000000, reward total was -21.000000. running mean: -20.231566\n",
            "resetting env. episode 220.000000, reward total was -20.000000. running mean: -20.229250\n",
            "resetting env. episode 221.000000, reward total was -19.000000. running mean: -20.216958\n",
            "resetting env. episode 222.000000, reward total was -21.000000. running mean: -20.224788\n",
            "resetting env. episode 223.000000, reward total was -21.000000. running mean: -20.232540\n",
            "resetting env. episode 224.000000, reward total was -21.000000. running mean: -20.240215\n",
            "resetting env. episode 225.000000, reward total was -21.000000. running mean: -20.247813\n",
            "resetting env. episode 226.000000, reward total was -21.000000. running mean: -20.255335\n",
            "resetting env. episode 227.000000, reward total was -19.000000. running mean: -20.242781\n",
            "resetting env. episode 228.000000, reward total was -21.000000. running mean: -20.250354\n",
            "resetting env. episode 229.000000, reward total was -21.000000. running mean: -20.257850\n",
            "resetting env. episode 230.000000, reward total was -20.000000. running mean: -20.255272\n",
            "resetting env. episode 231.000000, reward total was -21.000000. running mean: -20.262719\n",
            "resetting env. episode 232.000000, reward total was -20.000000. running mean: -20.260092\n",
            "resetting env. episode 233.000000, reward total was -21.000000. running mean: -20.267491\n",
            "resetting env. episode 234.000000, reward total was -21.000000. running mean: -20.274816\n",
            "resetting env. episode 235.000000, reward total was -19.000000. running mean: -20.262068\n",
            "resetting env. episode 236.000000, reward total was -21.000000. running mean: -20.269447\n",
            "resetting env. episode 237.000000, reward total was -21.000000. running mean: -20.276752\n",
            "resetting env. episode 238.000000, reward total was -21.000000. running mean: -20.283985\n",
            "resetting env. episode 239.000000, reward total was -21.000000. running mean: -20.291145\n",
            "resetting env. episode 240.000000, reward total was -21.000000. running mean: -20.298234\n",
            "resetting env. episode 241.000000, reward total was -21.000000. running mean: -20.305251\n",
            "resetting env. episode 242.000000, reward total was -19.000000. running mean: -20.292199\n",
            "resetting env. episode 243.000000, reward total was -20.000000. running mean: -20.289277\n",
            "resetting env. episode 244.000000, reward total was -20.000000. running mean: -20.286384\n",
            "resetting env. episode 245.000000, reward total was -21.000000. running mean: -20.293520\n",
            "resetting env. episode 246.000000, reward total was -21.000000. running mean: -20.300585\n",
            "resetting env. episode 247.000000, reward total was -21.000000. running mean: -20.307579\n",
            "resetting env. episode 248.000000, reward total was -21.000000. running mean: -20.314503\n",
            "resetting env. episode 249.000000, reward total was -21.000000. running mean: -20.321358\n",
            "resetting env. episode 250.000000, reward total was -20.000000. running mean: -20.318145\n",
            "resetting env. episode 251.000000, reward total was -20.000000. running mean: -20.314963\n",
            "resetting env. episode 252.000000, reward total was -21.000000. running mean: -20.321814\n",
            "resetting env. episode 253.000000, reward total was -20.000000. running mean: -20.318596\n",
            "resetting env. episode 254.000000, reward total was -21.000000. running mean: -20.325410\n",
            "resetting env. episode 255.000000, reward total was -21.000000. running mean: -20.332155\n",
            "resetting env. episode 256.000000, reward total was -20.000000. running mean: -20.328834\n",
            "resetting env. episode 257.000000, reward total was -21.000000. running mean: -20.335546\n",
            "resetting env. episode 258.000000, reward total was -19.000000. running mean: -20.322190\n",
            "resetting env. episode 259.000000, reward total was -20.000000. running mean: -20.318968\n",
            "resetting env. episode 260.000000, reward total was -21.000000. running mean: -20.325779\n",
            "resetting env. episode 261.000000, reward total was -20.000000. running mean: -20.322521\n",
            "resetting env. episode 262.000000, reward total was -21.000000. running mean: -20.329296\n",
            "resetting env. episode 263.000000, reward total was -19.000000. running mean: -20.316003\n",
            "resetting env. episode 264.000000, reward total was -21.000000. running mean: -20.322843\n",
            "resetting env. episode 265.000000, reward total was -21.000000. running mean: -20.329614\n",
            "resetting env. episode 266.000000, reward total was -20.000000. running mean: -20.326318\n",
            "resetting env. episode 267.000000, reward total was -21.000000. running mean: -20.333055\n",
            "resetting env. episode 268.000000, reward total was -19.000000. running mean: -20.319724\n",
            "resetting env. episode 269.000000, reward total was -18.000000. running mean: -20.296527\n",
            "resetting env. episode 270.000000, reward total was -21.000000. running mean: -20.303562\n",
            "resetting env. episode 271.000000, reward total was -19.000000. running mean: -20.290526\n",
            "resetting env. episode 272.000000, reward total was -21.000000. running mean: -20.297621\n",
            "resetting env. episode 273.000000, reward total was -19.000000. running mean: -20.284645\n",
            "resetting env. episode 274.000000, reward total was -20.000000. running mean: -20.281798\n",
            "resetting env. episode 275.000000, reward total was -21.000000. running mean: -20.288980\n",
            "resetting env. episode 276.000000, reward total was -21.000000. running mean: -20.296090\n",
            "resetting env. episode 277.000000, reward total was -21.000000. running mean: -20.303130\n",
            "resetting env. episode 278.000000, reward total was -20.000000. running mean: -20.300098\n",
            "resetting env. episode 279.000000, reward total was -21.000000. running mean: -20.307097\n",
            "resetting env. episode 280.000000, reward total was -21.000000. running mean: -20.314026\n",
            "resetting env. episode 281.000000, reward total was -20.000000. running mean: -20.310886\n",
            "resetting env. episode 282.000000, reward total was -20.000000. running mean: -20.307777\n",
            "resetting env. episode 283.000000, reward total was -19.000000. running mean: -20.294699\n",
            "resetting env. episode 284.000000, reward total was -20.000000. running mean: -20.291752\n",
            "resetting env. episode 285.000000, reward total was -21.000000. running mean: -20.298835\n",
            "resetting env. episode 286.000000, reward total was -21.000000. running mean: -20.305847\n",
            "resetting env. episode 287.000000, reward total was -20.000000. running mean: -20.302788\n",
            "resetting env. episode 288.000000, reward total was -21.000000. running mean: -20.309760\n",
            "resetting env. episode 289.000000, reward total was -21.000000. running mean: -20.316663\n",
            "resetting env. episode 290.000000, reward total was -20.000000. running mean: -20.313496\n",
            "resetting env. episode 291.000000, reward total was -20.000000. running mean: -20.310361\n",
            "resetting env. episode 292.000000, reward total was -20.000000. running mean: -20.307257\n",
            "resetting env. episode 293.000000, reward total was -21.000000. running mean: -20.314185\n",
            "resetting env. episode 294.000000, reward total was -20.000000. running mean: -20.311043\n",
            "resetting env. episode 295.000000, reward total was -21.000000. running mean: -20.317933\n",
            "resetting env. episode 296.000000, reward total was -21.000000. running mean: -20.324753\n",
            "resetting env. episode 297.000000, reward total was -19.000000. running mean: -20.311506\n",
            "resetting env. episode 298.000000, reward total was -21.000000. running mean: -20.318391\n",
            "resetting env. episode 299.000000, reward total was -20.000000. running mean: -20.315207\n",
            "resetting env. episode 300.000000, reward total was -19.000000. running mean: -20.302055\n",
            "resetting env. episode 301.000000, reward total was -20.000000. running mean: -20.299034\n",
            "resetting env. episode 302.000000, reward total was -21.000000. running mean: -20.306044\n",
            "resetting env. episode 303.000000, reward total was -21.000000. running mean: -20.312983\n",
            "resetting env. episode 304.000000, reward total was -20.000000. running mean: -20.309853\n",
            "resetting env. episode 305.000000, reward total was -21.000000. running mean: -20.316755\n",
            "resetting env. episode 306.000000, reward total was -21.000000. running mean: -20.323587\n",
            "resetting env. episode 307.000000, reward total was -20.000000. running mean: -20.320352\n",
            "resetting env. episode 308.000000, reward total was -21.000000. running mean: -20.327148\n",
            "resetting env. episode 309.000000, reward total was -20.000000. running mean: -20.323877\n",
            "resetting env. episode 310.000000, reward total was -18.000000. running mean: -20.300638\n",
            "resetting env. episode 311.000000, reward total was -20.000000. running mean: -20.297631\n",
            "resetting env. episode 312.000000, reward total was -20.000000. running mean: -20.294655\n",
            "resetting env. episode 313.000000, reward total was -21.000000. running mean: -20.301709\n",
            "resetting env. episode 314.000000, reward total was -21.000000. running mean: -20.308691\n",
            "resetting env. episode 315.000000, reward total was -21.000000. running mean: -20.315605\n",
            "resetting env. episode 316.000000, reward total was -21.000000. running mean: -20.322448\n",
            "resetting env. episode 317.000000, reward total was -20.000000. running mean: -20.319224\n",
            "resetting env. episode 318.000000, reward total was -19.000000. running mean: -20.306032\n",
            "resetting env. episode 319.000000, reward total was -21.000000. running mean: -20.312971\n",
            "resetting env. episode 320.000000, reward total was -21.000000. running mean: -20.319842\n",
            "resetting env. episode 321.000000, reward total was -20.000000. running mean: -20.316643\n",
            "resetting env. episode 322.000000, reward total was -21.000000. running mean: -20.323477\n",
            "resetting env. episode 323.000000, reward total was -21.000000. running mean: -20.330242\n",
            "resetting env. episode 324.000000, reward total was -21.000000. running mean: -20.336940\n",
            "resetting env. episode 325.000000, reward total was -20.000000. running mean: -20.333570\n",
            "resetting env. episode 326.000000, reward total was -21.000000. running mean: -20.340235\n",
            "resetting env. episode 327.000000, reward total was -19.000000. running mean: -20.326832\n",
            "resetting env. episode 328.000000, reward total was -21.000000. running mean: -20.333564\n",
            "resetting env. episode 329.000000, reward total was -20.000000. running mean: -20.330228\n",
            "resetting env. episode 330.000000, reward total was -20.000000. running mean: -20.326926\n",
            "resetting env. episode 331.000000, reward total was -21.000000. running mean: -20.333657\n",
            "resetting env. episode 332.000000, reward total was -21.000000. running mean: -20.340320\n",
            "resetting env. episode 333.000000, reward total was -20.000000. running mean: -20.336917\n",
            "resetting env. episode 334.000000, reward total was -20.000000. running mean: -20.333548\n",
            "resetting env. episode 335.000000, reward total was -20.000000. running mean: -20.330212\n",
            "resetting env. episode 336.000000, reward total was -21.000000. running mean: -20.336910\n",
            "resetting env. episode 337.000000, reward total was -21.000000. running mean: -20.343541\n",
            "resetting env. episode 338.000000, reward total was -20.000000. running mean: -20.340106\n",
            "resetting env. episode 339.000000, reward total was -20.000000. running mean: -20.336705\n",
            "resetting env. episode 340.000000, reward total was -20.000000. running mean: -20.333338\n",
            "resetting env. episode 341.000000, reward total was -21.000000. running mean: -20.340004\n",
            "resetting env. episode 342.000000, reward total was -20.000000. running mean: -20.336604\n",
            "resetting env. episode 343.000000, reward total was -20.000000. running mean: -20.333238\n",
            "resetting env. episode 344.000000, reward total was -21.000000. running mean: -20.339906\n",
            "resetting env. episode 345.000000, reward total was -20.000000. running mean: -20.336507\n",
            "resetting env. episode 346.000000, reward total was -21.000000. running mean: -20.343142\n",
            "resetting env. episode 347.000000, reward total was -18.000000. running mean: -20.319710\n",
            "resetting env. episode 348.000000, reward total was -21.000000. running mean: -20.326513\n",
            "resetting env. episode 349.000000, reward total was -21.000000. running mean: -20.333248\n",
            "resetting env. episode 350.000000, reward total was -21.000000. running mean: -20.339915\n",
            "resetting env. episode 351.000000, reward total was -21.000000. running mean: -20.346516\n",
            "resetting env. episode 352.000000, reward total was -21.000000. running mean: -20.353051\n",
            "resetting env. episode 353.000000, reward total was -19.000000. running mean: -20.339521\n",
            "resetting env. episode 354.000000, reward total was -20.000000. running mean: -20.336125\n",
            "resetting env. episode 355.000000, reward total was -21.000000. running mean: -20.342764\n",
            "resetting env. episode 356.000000, reward total was -21.000000. running mean: -20.349337\n",
            "resetting env. episode 357.000000, reward total was -21.000000. running mean: -20.355843\n",
            "resetting env. episode 358.000000, reward total was -21.000000. running mean: -20.362285\n",
            "resetting env. episode 359.000000, reward total was -20.000000. running mean: -20.358662\n",
            "resetting env. episode 360.000000, reward total was -21.000000. running mean: -20.365075\n",
            "resetting env. episode 361.000000, reward total was -21.000000. running mean: -20.371425\n",
            "resetting env. episode 362.000000, reward total was -20.000000. running mean: -20.367710\n",
            "resetting env. episode 363.000000, reward total was -21.000000. running mean: -20.374033\n",
            "resetting env. episode 364.000000, reward total was -21.000000. running mean: -20.380293\n",
            "resetting env. episode 365.000000, reward total was -21.000000. running mean: -20.386490\n",
            "resetting env. episode 366.000000, reward total was -20.000000. running mean: -20.382625\n",
            "resetting env. episode 367.000000, reward total was -21.000000. running mean: -20.388799\n",
            "resetting env. episode 368.000000, reward total was -21.000000. running mean: -20.394911\n",
            "resetting env. episode 369.000000, reward total was -21.000000. running mean: -20.400962\n",
            "resetting env. episode 370.000000, reward total was -21.000000. running mean: -20.406952\n",
            "resetting env. episode 371.000000, reward total was -20.000000. running mean: -20.402883\n",
            "resetting env. episode 372.000000, reward total was -21.000000. running mean: -20.408854\n",
            "resetting env. episode 373.000000, reward total was -21.000000. running mean: -20.414765\n",
            "resetting env. episode 374.000000, reward total was -21.000000. running mean: -20.420618\n",
            "resetting env. episode 375.000000, reward total was -21.000000. running mean: -20.426411\n",
            "resetting env. episode 376.000000, reward total was -21.000000. running mean: -20.432147\n",
            "resetting env. episode 377.000000, reward total was -19.000000. running mean: -20.417826\n",
            "resetting env. episode 378.000000, reward total was -21.000000. running mean: -20.423648\n",
            "resetting env. episode 379.000000, reward total was -20.000000. running mean: -20.419411\n",
            "resetting env. episode 380.000000, reward total was -20.000000. running mean: -20.415217\n",
            "resetting env. episode 381.000000, reward total was -20.000000. running mean: -20.411065\n",
            "resetting env. episode 382.000000, reward total was -21.000000. running mean: -20.416954\n",
            "resetting env. episode 383.000000, reward total was -20.000000. running mean: -20.412785\n",
            "resetting env. episode 384.000000, reward total was -21.000000. running mean: -20.418657\n",
            "resetting env. episode 385.000000, reward total was -19.000000. running mean: -20.404470\n",
            "resetting env. episode 386.000000, reward total was -19.000000. running mean: -20.390425\n",
            "resetting env. episode 387.000000, reward total was -21.000000. running mean: -20.396521\n",
            "resetting env. episode 388.000000, reward total was -20.000000. running mean: -20.392556\n",
            "resetting env. episode 389.000000, reward total was -21.000000. running mean: -20.398630\n",
            "resetting env. episode 390.000000, reward total was -20.000000. running mean: -20.394644\n",
            "resetting env. episode 391.000000, reward total was -21.000000. running mean: -20.400698\n",
            "resetting env. episode 392.000000, reward total was -21.000000. running mean: -20.406691\n",
            "resetting env. episode 393.000000, reward total was -21.000000. running mean: -20.412624\n",
            "resetting env. episode 394.000000, reward total was -21.000000. running mean: -20.418498\n",
            "resetting env. episode 395.000000, reward total was -21.000000. running mean: -20.424313\n",
            "resetting env. episode 396.000000, reward total was -21.000000. running mean: -20.430069\n",
            "resetting env. episode 397.000000, reward total was -21.000000. running mean: -20.435769\n",
            "resetting env. episode 398.000000, reward total was -20.000000. running mean: -20.431411\n",
            "resetting env. episode 399.000000, reward total was -20.000000. running mean: -20.427097\n",
            "resetting env. episode 400.000000, reward total was -20.000000. running mean: -20.422826\n",
            "resetting env. episode 401.000000, reward total was -19.000000. running mean: -20.408598\n",
            "resetting env. episode 402.000000, reward total was -20.000000. running mean: -20.404512\n",
            "resetting env. episode 403.000000, reward total was -21.000000. running mean: -20.410467\n",
            "resetting env. episode 404.000000, reward total was -20.000000. running mean: -20.406362\n",
            "resetting env. episode 405.000000, reward total was -17.000000. running mean: -20.372298\n",
            "resetting env. episode 406.000000, reward total was -21.000000. running mean: -20.378575\n",
            "resetting env. episode 407.000000, reward total was -20.000000. running mean: -20.374790\n",
            "resetting env. episode 408.000000, reward total was -21.000000. running mean: -20.381042\n",
            "resetting env. episode 409.000000, reward total was -20.000000. running mean: -20.377231\n",
            "resetting env. episode 410.000000, reward total was -21.000000. running mean: -20.383459\n",
            "resetting env. episode 411.000000, reward total was -19.000000. running mean: -20.369624\n",
            "resetting env. episode 412.000000, reward total was -21.000000. running mean: -20.375928\n",
            "resetting env. episode 413.000000, reward total was -21.000000. running mean: -20.382169\n",
            "resetting env. episode 414.000000, reward total was -21.000000. running mean: -20.388347\n",
            "resetting env. episode 415.000000, reward total was -19.000000. running mean: -20.374464\n",
            "resetting env. episode 416.000000, reward total was -21.000000. running mean: -20.380719\n",
            "resetting env. episode 417.000000, reward total was -21.000000. running mean: -20.386912\n",
            "resetting env. episode 418.000000, reward total was -21.000000. running mean: -20.393043\n",
            "resetting env. episode 419.000000, reward total was -21.000000. running mean: -20.399112\n",
            "resetting env. episode 420.000000, reward total was -21.000000. running mean: -20.405121\n",
            "resetting env. episode 421.000000, reward total was -21.000000. running mean: -20.411070\n",
            "resetting env. episode 422.000000, reward total was -19.000000. running mean: -20.396959\n",
            "resetting env. episode 423.000000, reward total was -21.000000. running mean: -20.402990\n",
            "resetting env. episode 424.000000, reward total was -20.000000. running mean: -20.398960\n",
            "resetting env. episode 425.000000, reward total was -21.000000. running mean: -20.404970\n",
            "resetting env. episode 426.000000, reward total was -20.000000. running mean: -20.400921\n",
            "resetting env. episode 427.000000, reward total was -21.000000. running mean: -20.406911\n",
            "resetting env. episode 428.000000, reward total was -21.000000. running mean: -20.412842\n",
            "resetting env. episode 429.000000, reward total was -21.000000. running mean: -20.418714\n",
            "resetting env. episode 430.000000, reward total was -17.000000. running mean: -20.384527\n",
            "resetting env. episode 431.000000, reward total was -21.000000. running mean: -20.390681\n",
            "resetting env. episode 432.000000, reward total was -21.000000. running mean: -20.396775\n",
            "resetting env. episode 433.000000, reward total was -20.000000. running mean: -20.392807\n",
            "resetting env. episode 434.000000, reward total was -21.000000. running mean: -20.398879\n",
            "resetting env. episode 435.000000, reward total was -18.000000. running mean: -20.374890\n",
            "resetting env. episode 436.000000, reward total was -20.000000. running mean: -20.371141\n",
            "resetting env. episode 437.000000, reward total was -19.000000. running mean: -20.357430\n",
            "resetting env. episode 438.000000, reward total was -19.000000. running mean: -20.343855\n",
            "resetting env. episode 439.000000, reward total was -19.000000. running mean: -20.330417\n",
            "resetting env. episode 440.000000, reward total was -20.000000. running mean: -20.327113\n",
            "resetting env. episode 441.000000, reward total was -20.000000. running mean: -20.323841\n",
            "resetting env. episode 442.000000, reward total was -21.000000. running mean: -20.330603\n",
            "resetting env. episode 443.000000, reward total was -20.000000. running mean: -20.327297\n",
            "resetting env. episode 444.000000, reward total was -18.000000. running mean: -20.304024\n",
            "resetting env. episode 445.000000, reward total was -20.000000. running mean: -20.300984\n",
            "resetting env. episode 446.000000, reward total was -20.000000. running mean: -20.297974\n",
            "resetting env. episode 447.000000, reward total was -21.000000. running mean: -20.304994\n",
            "resetting env. episode 448.000000, reward total was -20.000000. running mean: -20.301944\n",
            "resetting env. episode 449.000000, reward total was -21.000000. running mean: -20.308925\n",
            "resetting env. episode 450.000000, reward total was -21.000000. running mean: -20.315836\n",
            "resetting env. episode 451.000000, reward total was -21.000000. running mean: -20.322677\n",
            "resetting env. episode 452.000000, reward total was -20.000000. running mean: -20.319451\n",
            "resetting env. episode 453.000000, reward total was -21.000000. running mean: -20.326256\n",
            "resetting env. episode 454.000000, reward total was -20.000000. running mean: -20.322993\n",
            "resetting env. episode 455.000000, reward total was -20.000000. running mean: -20.319764\n",
            "resetting env. episode 456.000000, reward total was -20.000000. running mean: -20.316566\n",
            "resetting env. episode 457.000000, reward total was -21.000000. running mean: -20.323400\n",
            "resetting env. episode 458.000000, reward total was -21.000000. running mean: -20.330166\n",
            "resetting env. episode 459.000000, reward total was -20.000000. running mean: -20.326865\n",
            "resetting env. episode 460.000000, reward total was -21.000000. running mean: -20.333596\n",
            "resetting env. episode 461.000000, reward total was -21.000000. running mean: -20.340260\n",
            "resetting env. episode 462.000000, reward total was -18.000000. running mean: -20.316857\n",
            "resetting env. episode 463.000000, reward total was -20.000000. running mean: -20.313689\n",
            "resetting env. episode 464.000000, reward total was -19.000000. running mean: -20.300552\n",
            "resetting env. episode 465.000000, reward total was -21.000000. running mean: -20.307546\n",
            "resetting env. episode 466.000000, reward total was -21.000000. running mean: -20.314471\n",
            "resetting env. episode 467.000000, reward total was -21.000000. running mean: -20.321326\n",
            "resetting env. episode 468.000000, reward total was -21.000000. running mean: -20.328113\n",
            "resetting env. episode 469.000000, reward total was -21.000000. running mean: -20.334832\n",
            "resetting env. episode 470.000000, reward total was -20.000000. running mean: -20.331483\n",
            "resetting env. episode 471.000000, reward total was -19.000000. running mean: -20.318169\n",
            "resetting env. episode 472.000000, reward total was -20.000000. running mean: -20.314987\n",
            "resetting env. episode 473.000000, reward total was -21.000000. running mean: -20.321837\n",
            "resetting env. episode 474.000000, reward total was -21.000000. running mean: -20.328619\n",
            "resetting env. episode 475.000000, reward total was -20.000000. running mean: -20.325333\n",
            "resetting env. episode 476.000000, reward total was -19.000000. running mean: -20.312079\n",
            "resetting env. episode 477.000000, reward total was -20.000000. running mean: -20.308958\n",
            "resetting env. episode 478.000000, reward total was -20.000000. running mean: -20.305869\n",
            "resetting env. episode 479.000000, reward total was -20.000000. running mean: -20.302810\n",
            "resetting env. episode 480.000000, reward total was -20.000000. running mean: -20.299782\n",
            "resetting env. episode 481.000000, reward total was -21.000000. running mean: -20.306784\n",
            "resetting env. episode 482.000000, reward total was -20.000000. running mean: -20.303716\n",
            "resetting env. episode 483.000000, reward total was -21.000000. running mean: -20.310679\n",
            "resetting env. episode 484.000000, reward total was -20.000000. running mean: -20.307572\n",
            "resetting env. episode 485.000000, reward total was -21.000000. running mean: -20.314497\n",
            "resetting env. episode 486.000000, reward total was -20.000000. running mean: -20.311352\n",
            "resetting env. episode 487.000000, reward total was -20.000000. running mean: -20.308238\n",
            "resetting env. episode 488.000000, reward total was -21.000000. running mean: -20.315156\n",
            "resetting env. episode 489.000000, reward total was -20.000000. running mean: -20.312004\n",
            "resetting env. episode 490.000000, reward total was -21.000000. running mean: -20.318884\n",
            "resetting env. episode 491.000000, reward total was -20.000000. running mean: -20.315695\n",
            "resetting env. episode 492.000000, reward total was -20.000000. running mean: -20.312538\n",
            "resetting env. episode 493.000000, reward total was -20.000000. running mean: -20.309413\n",
            "resetting env. episode 494.000000, reward total was -21.000000. running mean: -20.316319\n",
            "resetting env. episode 495.000000, reward total was -20.000000. running mean: -20.313156\n",
            "resetting env. episode 496.000000, reward total was -20.000000. running mean: -20.310024\n",
            "resetting env. episode 497.000000, reward total was -21.000000. running mean: -20.316924\n",
            "resetting env. episode 498.000000, reward total was -20.000000. running mean: -20.313755\n",
            "resetting env. episode 499.000000, reward total was -21.000000. running mean: -20.320617\n",
            "resetting env. episode 500.000000, reward total was -21.000000. running mean: -20.327411\n",
            "CPU times: user 23min 12s, sys: 10min 41s, total: 33min 53s\n",
            "Wall time: 17min 35s\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "8fheN9DRlWXQ",
        "outputId": "da98062a-eb67-4b95-96ee-3d683c315e3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        }
      },
      "cell_type": "code",
      "source": [
        "play_game(env, model)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gym/core.py:52: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
            "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
            "  \"The argument mode in render method is deprecated; \"\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode finished without success, accumulated reward = -13.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 320x420 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "9AxOcQhIsKow",
        "outputId": "1f3189e9-c88e-43c6-825d-d280368859e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "%time hist3 = train_model(env, model, total_episodes=3500)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "resetting env. episode 1.000000, reward total was -20.000000. running mean: -20.000000\n",
            "resetting env. episode 2.000000, reward total was -21.000000. running mean: -20.010000\n",
            "resetting env. episode 3.000000, reward total was -21.000000. running mean: -20.019900\n",
            "resetting env. episode 4.000000, reward total was -20.000000. running mean: -20.019701\n",
            "resetting env. episode 5.000000, reward total was -21.000000. running mean: -20.029504\n",
            "resetting env. episode 6.000000, reward total was -21.000000. running mean: -20.039209\n",
            "resetting env. episode 7.000000, reward total was -20.000000. running mean: -20.038817\n",
            "resetting env. episode 8.000000, reward total was -20.000000. running mean: -20.038429\n",
            "resetting env. episode 9.000000, reward total was -21.000000. running mean: -20.048044\n",
            "resetting env. episode 10.000000, reward total was -21.000000. running mean: -20.057564\n",
            "resetting env. episode 11.000000, reward total was -20.000000. running mean: -20.056988\n",
            "resetting env. episode 12.000000, reward total was -20.000000. running mean: -20.056418\n",
            "resetting env. episode 13.000000, reward total was -21.000000. running mean: -20.065854\n",
            "resetting env. episode 14.000000, reward total was -21.000000. running mean: -20.075196\n",
            "resetting env. episode 15.000000, reward total was -20.000000. running mean: -20.074444\n",
            "resetting env. episode 16.000000, reward total was -21.000000. running mean: -20.083699\n",
            "resetting env. episode 17.000000, reward total was -20.000000. running mean: -20.082862\n",
            "resetting env. episode 18.000000, reward total was -21.000000. running mean: -20.092034\n",
            "resetting env. episode 19.000000, reward total was -19.000000. running mean: -20.081113\n",
            "resetting env. episode 20.000000, reward total was -21.000000. running mean: -20.090302\n",
            "resetting env. episode 21.000000, reward total was -19.000000. running mean: -20.079399\n",
            "resetting env. episode 22.000000, reward total was -21.000000. running mean: -20.088605\n",
            "resetting env. episode 23.000000, reward total was -20.000000. running mean: -20.087719\n",
            "resetting env. episode 24.000000, reward total was -20.000000. running mean: -20.086842\n",
            "resetting env. episode 25.000000, reward total was -19.000000. running mean: -20.075974\n",
            "resetting env. episode 26.000000, reward total was -21.000000. running mean: -20.085214\n",
            "resetting env. episode 27.000000, reward total was -20.000000. running mean: -20.084362\n",
            "resetting env. episode 28.000000, reward total was -21.000000. running mean: -20.093518\n",
            "resetting env. episode 29.000000, reward total was -21.000000. running mean: -20.102583\n",
            "resetting env. episode 30.000000, reward total was -21.000000. running mean: -20.111557\n",
            "resetting env. episode 31.000000, reward total was -21.000000. running mean: -20.120441\n",
            "resetting env. episode 32.000000, reward total was -21.000000. running mean: -20.129237\n",
            "resetting env. episode 33.000000, reward total was -19.000000. running mean: -20.117945\n",
            "resetting env. episode 34.000000, reward total was -20.000000. running mean: -20.116765\n",
            "resetting env. episode 35.000000, reward total was -19.000000. running mean: -20.105598\n",
            "resetting env. episode 36.000000, reward total was -18.000000. running mean: -20.084542\n",
            "resetting env. episode 37.000000, reward total was -19.000000. running mean: -20.073696\n",
            "resetting env. episode 38.000000, reward total was -21.000000. running mean: -20.082959\n",
            "resetting env. episode 39.000000, reward total was -21.000000. running mean: -20.092130\n",
            "resetting env. episode 40.000000, reward total was -21.000000. running mean: -20.101208\n",
            "resetting env. episode 41.000000, reward total was -20.000000. running mean: -20.100196\n",
            "resetting env. episode 42.000000, reward total was -21.000000. running mean: -20.109194\n",
            "resetting env. episode 43.000000, reward total was -21.000000. running mean: -20.118102\n",
            "resetting env. episode 44.000000, reward total was -19.000000. running mean: -20.106921\n",
            "resetting env. episode 45.000000, reward total was -21.000000. running mean: -20.115852\n",
            "resetting env. episode 46.000000, reward total was -21.000000. running mean: -20.124694\n",
            "resetting env. episode 47.000000, reward total was -20.000000. running mean: -20.123447\n",
            "resetting env. episode 48.000000, reward total was -19.000000. running mean: -20.112212\n",
            "resetting env. episode 49.000000, reward total was -20.000000. running mean: -20.111090\n",
            "resetting env. episode 50.000000, reward total was -21.000000. running mean: -20.119979\n",
            "resetting env. episode 51.000000, reward total was -21.000000. running mean: -20.128779\n",
            "resetting env. episode 52.000000, reward total was -21.000000. running mean: -20.137492\n",
            "resetting env. episode 53.000000, reward total was -19.000000. running mean: -20.126117\n",
            "resetting env. episode 54.000000, reward total was -21.000000. running mean: -20.134856\n",
            "resetting env. episode 55.000000, reward total was -21.000000. running mean: -20.143507\n",
            "resetting env. episode 56.000000, reward total was -21.000000. running mean: -20.152072\n",
            "resetting env. episode 57.000000, reward total was -21.000000. running mean: -20.160551\n",
            "resetting env. episode 58.000000, reward total was -21.000000. running mean: -20.168946\n",
            "resetting env. episode 59.000000, reward total was -21.000000. running mean: -20.177256\n",
            "resetting env. episode 60.000000, reward total was -21.000000. running mean: -20.185484\n",
            "resetting env. episode 61.000000, reward total was -20.000000. running mean: -20.183629\n",
            "resetting env. episode 62.000000, reward total was -21.000000. running mean: -20.191793\n",
            "resetting env. episode 63.000000, reward total was -21.000000. running mean: -20.199875\n",
            "resetting env. episode 64.000000, reward total was -21.000000. running mean: -20.207876\n",
            "resetting env. episode 65.000000, reward total was -19.000000. running mean: -20.195797\n",
            "resetting env. episode 66.000000, reward total was -21.000000. running mean: -20.203839\n",
            "resetting env. episode 67.000000, reward total was -21.000000. running mean: -20.211801\n",
            "resetting env. episode 68.000000, reward total was -21.000000. running mean: -20.219683\n",
            "resetting env. episode 69.000000, reward total was -20.000000. running mean: -20.217486\n",
            "resetting env. episode 70.000000, reward total was -21.000000. running mean: -20.225311\n",
            "resetting env. episode 71.000000, reward total was -21.000000. running mean: -20.233058\n",
            "resetting env. episode 72.000000, reward total was -18.000000. running mean: -20.210727\n",
            "resetting env. episode 73.000000, reward total was -20.000000. running mean: -20.208620\n",
            "resetting env. episode 74.000000, reward total was -20.000000. running mean: -20.206534\n",
            "resetting env. episode 75.000000, reward total was -19.000000. running mean: -20.194469\n",
            "resetting env. episode 76.000000, reward total was -21.000000. running mean: -20.202524\n",
            "resetting env. episode 77.000000, reward total was -18.000000. running mean: -20.180499\n",
            "resetting env. episode 78.000000, reward total was -19.000000. running mean: -20.168694\n",
            "resetting env. episode 79.000000, reward total was -20.000000. running mean: -20.167007\n",
            "resetting env. episode 80.000000, reward total was -21.000000. running mean: -20.175337\n",
            "resetting env. episode 81.000000, reward total was -21.000000. running mean: -20.183583\n",
            "resetting env. episode 82.000000, reward total was -20.000000. running mean: -20.181747\n",
            "resetting env. episode 83.000000, reward total was -21.000000. running mean: -20.189930\n",
            "resetting env. episode 84.000000, reward total was -20.000000. running mean: -20.188031\n",
            "resetting env. episode 85.000000, reward total was -20.000000. running mean: -20.186150\n",
            "resetting env. episode 86.000000, reward total was -20.000000. running mean: -20.184289\n",
            "resetting env. episode 87.000000, reward total was -19.000000. running mean: -20.172446\n",
            "resetting env. episode 88.000000, reward total was -20.000000. running mean: -20.170721\n",
            "resetting env. episode 89.000000, reward total was -20.000000. running mean: -20.169014\n",
            "resetting env. episode 90.000000, reward total was -21.000000. running mean: -20.177324\n",
            "resetting env. episode 91.000000, reward total was -20.000000. running mean: -20.175551\n",
            "resetting env. episode 92.000000, reward total was -21.000000. running mean: -20.183795\n",
            "resetting env. episode 93.000000, reward total was -21.000000. running mean: -20.191957\n",
            "resetting env. episode 94.000000, reward total was -20.000000. running mean: -20.190038\n",
            "resetting env. episode 95.000000, reward total was -20.000000. running mean: -20.188137\n",
            "resetting env. episode 96.000000, reward total was -19.000000. running mean: -20.176256\n",
            "resetting env. episode 97.000000, reward total was -21.000000. running mean: -20.184494\n",
            "resetting env. episode 98.000000, reward total was -21.000000. running mean: -20.192649\n",
            "resetting env. episode 99.000000, reward total was -21.000000. running mean: -20.200722\n",
            "resetting env. episode 100.000000, reward total was -21.000000. running mean: -20.208715\n",
            "resetting env. episode 101.000000, reward total was -21.000000. running mean: -20.216628\n",
            "resetting env. episode 102.000000, reward total was -21.000000. running mean: -20.224461\n",
            "resetting env. episode 103.000000, reward total was -19.000000. running mean: -20.212217\n",
            "resetting env. episode 104.000000, reward total was -21.000000. running mean: -20.220095\n",
            "resetting env. episode 105.000000, reward total was -21.000000. running mean: -20.227894\n",
            "resetting env. episode 106.000000, reward total was -20.000000. running mean: -20.225615\n",
            "resetting env. episode 107.000000, reward total was -21.000000. running mean: -20.233359\n",
            "resetting env. episode 108.000000, reward total was -21.000000. running mean: -20.241025\n",
            "resetting env. episode 109.000000, reward total was -20.000000. running mean: -20.238615\n",
            "resetting env. episode 110.000000, reward total was -21.000000. running mean: -20.246229\n",
            "resetting env. episode 111.000000, reward total was -19.000000. running mean: -20.233766\n",
            "resetting env. episode 112.000000, reward total was -21.000000. running mean: -20.241429\n",
            "resetting env. episode 113.000000, reward total was -21.000000. running mean: -20.249014\n",
            "resetting env. episode 114.000000, reward total was -21.000000. running mean: -20.256524\n",
            "resetting env. episode 115.000000, reward total was -19.000000. running mean: -20.243959\n",
            "resetting env. episode 116.000000, reward total was -21.000000. running mean: -20.251519\n",
            "resetting env. episode 117.000000, reward total was -21.000000. running mean: -20.259004\n",
            "resetting env. episode 118.000000, reward total was -21.000000. running mean: -20.266414\n",
            "resetting env. episode 119.000000, reward total was -21.000000. running mean: -20.273750\n",
            "resetting env. episode 120.000000, reward total was -19.000000. running mean: -20.261013\n",
            "resetting env. episode 121.000000, reward total was -21.000000. running mean: -20.268402\n",
            "resetting env. episode 122.000000, reward total was -19.000000. running mean: -20.255718\n",
            "resetting env. episode 123.000000, reward total was -19.000000. running mean: -20.243161\n",
            "resetting env. episode 124.000000, reward total was -21.000000. running mean: -20.250730\n",
            "resetting env. episode 125.000000, reward total was -19.000000. running mean: -20.238222\n",
            "resetting env. episode 126.000000, reward total was -20.000000. running mean: -20.235840\n",
            "resetting env. episode 127.000000, reward total was -21.000000. running mean: -20.243482\n",
            "resetting env. episode 128.000000, reward total was -20.000000. running mean: -20.241047\n",
            "resetting env. episode 129.000000, reward total was -19.000000. running mean: -20.228636\n",
            "resetting env. episode 130.000000, reward total was -19.000000. running mean: -20.216350\n",
            "resetting env. episode 131.000000, reward total was -19.000000. running mean: -20.204187\n",
            "resetting env. episode 132.000000, reward total was -21.000000. running mean: -20.212145\n",
            "resetting env. episode 133.000000, reward total was -21.000000. running mean: -20.220023\n",
            "resetting env. episode 134.000000, reward total was -21.000000. running mean: -20.227823\n",
            "resetting env. episode 135.000000, reward total was -20.000000. running mean: -20.225545\n",
            "resetting env. episode 136.000000, reward total was -20.000000. running mean: -20.223289\n",
            "resetting env. episode 137.000000, reward total was -20.000000. running mean: -20.221056\n",
            "resetting env. episode 138.000000, reward total was -19.000000. running mean: -20.208846\n",
            "resetting env. episode 139.000000, reward total was -21.000000. running mean: -20.216757\n",
            "resetting env. episode 140.000000, reward total was -21.000000. running mean: -20.224590\n",
            "resetting env. episode 141.000000, reward total was -21.000000. running mean: -20.232344\n",
            "resetting env. episode 142.000000, reward total was -21.000000. running mean: -20.240021\n",
            "resetting env. episode 143.000000, reward total was -21.000000. running mean: -20.247620\n",
            "resetting env. episode 144.000000, reward total was -19.000000. running mean: -20.235144\n",
            "resetting env. episode 145.000000, reward total was -20.000000. running mean: -20.232793\n",
            "resetting env. episode 146.000000, reward total was -21.000000. running mean: -20.240465\n",
            "resetting env. episode 147.000000, reward total was -21.000000. running mean: -20.248060\n",
            "resetting env. episode 148.000000, reward total was -19.000000. running mean: -20.235579\n",
            "resetting env. episode 149.000000, reward total was -21.000000. running mean: -20.243224\n",
            "resetting env. episode 150.000000, reward total was -20.000000. running mean: -20.240791\n",
            "resetting env. episode 151.000000, reward total was -20.000000. running mean: -20.238384\n",
            "resetting env. episode 152.000000, reward total was -20.000000. running mean: -20.236000\n",
            "resetting env. episode 153.000000, reward total was -19.000000. running mean: -20.223640\n",
            "resetting env. episode 154.000000, reward total was -21.000000. running mean: -20.231403\n",
            "resetting env. episode 155.000000, reward total was -21.000000. running mean: -20.239089\n",
            "resetting env. episode 156.000000, reward total was -20.000000. running mean: -20.236698\n",
            "resetting env. episode 157.000000, reward total was -20.000000. running mean: -20.234331\n",
            "resetting env. episode 158.000000, reward total was -21.000000. running mean: -20.241988\n",
            "resetting env. episode 159.000000, reward total was -21.000000. running mean: -20.249568\n",
            "resetting env. episode 160.000000, reward total was -20.000000. running mean: -20.247073\n",
            "resetting env. episode 161.000000, reward total was -21.000000. running mean: -20.254602\n",
            "resetting env. episode 162.000000, reward total was -21.000000. running mean: -20.262056\n",
            "resetting env. episode 163.000000, reward total was -20.000000. running mean: -20.259435\n",
            "resetting env. episode 164.000000, reward total was -20.000000. running mean: -20.256841\n",
            "resetting env. episode 165.000000, reward total was -20.000000. running mean: -20.254272\n",
            "resetting env. episode 166.000000, reward total was -20.000000. running mean: -20.251730\n",
            "resetting env. episode 167.000000, reward total was -21.000000. running mean: -20.259212\n",
            "resetting env. episode 168.000000, reward total was -19.000000. running mean: -20.246620\n",
            "resetting env. episode 169.000000, reward total was -21.000000. running mean: -20.254154\n",
            "resetting env. episode 170.000000, reward total was -20.000000. running mean: -20.251613\n",
            "resetting env. episode 171.000000, reward total was -19.000000. running mean: -20.239096\n",
            "resetting env. episode 172.000000, reward total was -21.000000. running mean: -20.246705\n",
            "resetting env. episode 173.000000, reward total was -21.000000. running mean: -20.254238\n",
            "resetting env. episode 174.000000, reward total was -21.000000. running mean: -20.261696\n",
            "resetting env. episode 175.000000, reward total was -21.000000. running mean: -20.269079\n",
            "resetting env. episode 176.000000, reward total was -21.000000. running mean: -20.276388\n",
            "resetting env. episode 177.000000, reward total was -21.000000. running mean: -20.283624\n",
            "resetting env. episode 178.000000, reward total was -21.000000. running mean: -20.290788\n",
            "resetting env. episode 179.000000, reward total was -21.000000. running mean: -20.297880\n",
            "resetting env. episode 180.000000, reward total was -21.000000. running mean: -20.304901\n",
            "resetting env. episode 181.000000, reward total was -20.000000. running mean: -20.301852\n",
            "resetting env. episode 182.000000, reward total was -21.000000. running mean: -20.308834\n",
            "resetting env. episode 183.000000, reward total was -21.000000. running mean: -20.315746\n",
            "resetting env. episode 184.000000, reward total was -20.000000. running mean: -20.312588\n",
            "resetting env. episode 185.000000, reward total was -21.000000. running mean: -20.319462\n",
            "resetting env. episode 186.000000, reward total was -20.000000. running mean: -20.316268\n",
            "resetting env. episode 187.000000, reward total was -20.000000. running mean: -20.313105\n",
            "resetting env. episode 188.000000, reward total was -21.000000. running mean: -20.319974\n",
            "resetting env. episode 189.000000, reward total was -21.000000. running mean: -20.326774\n",
            "resetting env. episode 190.000000, reward total was -21.000000. running mean: -20.333506\n",
            "resetting env. episode 191.000000, reward total was -19.000000. running mean: -20.320171\n",
            "resetting env. episode 192.000000, reward total was -21.000000. running mean: -20.326970\n",
            "resetting env. episode 193.000000, reward total was -20.000000. running mean: -20.323700\n",
            "resetting env. episode 194.000000, reward total was -21.000000. running mean: -20.330463\n",
            "resetting env. episode 195.000000, reward total was -20.000000. running mean: -20.327158\n",
            "resetting env. episode 196.000000, reward total was -21.000000. running mean: -20.333887\n",
            "resetting env. episode 197.000000, reward total was -21.000000. running mean: -20.340548\n",
            "resetting env. episode 198.000000, reward total was -21.000000. running mean: -20.347142\n",
            "resetting env. episode 199.000000, reward total was -21.000000. running mean: -20.353671\n",
            "resetting env. episode 200.000000, reward total was -20.000000. running mean: -20.350134\n",
            "resetting env. episode 201.000000, reward total was -21.000000. running mean: -20.356633\n",
            "resetting env. episode 202.000000, reward total was -19.000000. running mean: -20.343067\n",
            "resetting env. episode 203.000000, reward total was -18.000000. running mean: -20.319636\n",
            "resetting env. episode 204.000000, reward total was -21.000000. running mean: -20.326440\n",
            "resetting env. episode 205.000000, reward total was -20.000000. running mean: -20.323175\n",
            "resetting env. episode 206.000000, reward total was -21.000000. running mean: -20.329943\n",
            "resetting env. episode 207.000000, reward total was -20.000000. running mean: -20.326644\n",
            "resetting env. episode 208.000000, reward total was -21.000000. running mean: -20.333378\n",
            "resetting env. episode 209.000000, reward total was -21.000000. running mean: -20.340044\n",
            "resetting env. episode 210.000000, reward total was -19.000000. running mean: -20.326643\n",
            "resetting env. episode 211.000000, reward total was -21.000000. running mean: -20.333377\n",
            "resetting env. episode 212.000000, reward total was -19.000000. running mean: -20.320043\n",
            "resetting env. episode 213.000000, reward total was -21.000000. running mean: -20.326843\n",
            "resetting env. episode 214.000000, reward total was -21.000000. running mean: -20.333574\n",
            "resetting env. episode 215.000000, reward total was -20.000000. running mean: -20.330239\n",
            "resetting env. episode 216.000000, reward total was -21.000000. running mean: -20.336936\n",
            "resetting env. episode 217.000000, reward total was -21.000000. running mean: -20.343567\n",
            "resetting env. episode 218.000000, reward total was -20.000000. running mean: -20.340131\n",
            "resetting env. episode 219.000000, reward total was -20.000000. running mean: -20.336730\n",
            "resetting env. episode 220.000000, reward total was -21.000000. running mean: -20.343363\n",
            "resetting env. episode 221.000000, reward total was -18.000000. running mean: -20.319929\n",
            "resetting env. episode 222.000000, reward total was -20.000000. running mean: -20.316730\n",
            "resetting env. episode 223.000000, reward total was -21.000000. running mean: -20.323562\n",
            "resetting env. episode 224.000000, reward total was -21.000000. running mean: -20.330327\n",
            "resetting env. episode 225.000000, reward total was -21.000000. running mean: -20.337023\n",
            "resetting env. episode 226.000000, reward total was -19.000000. running mean: -20.323653\n",
            "resetting env. episode 227.000000, reward total was -21.000000. running mean: -20.330417\n",
            "resetting env. episode 228.000000, reward total was -20.000000. running mean: -20.327112\n",
            "resetting env. episode 229.000000, reward total was -20.000000. running mean: -20.323841\n",
            "resetting env. episode 230.000000, reward total was -18.000000. running mean: -20.300603\n",
            "resetting env. episode 231.000000, reward total was -20.000000. running mean: -20.297597\n",
            "resetting env. episode 232.000000, reward total was -21.000000. running mean: -20.304621\n",
            "resetting env. episode 233.000000, reward total was -20.000000. running mean: -20.301575\n",
            "resetting env. episode 234.000000, reward total was -19.000000. running mean: -20.288559\n",
            "resetting env. episode 235.000000, reward total was -21.000000. running mean: -20.295673\n",
            "resetting env. episode 236.000000, reward total was -21.000000. running mean: -20.302717\n",
            "resetting env. episode 237.000000, reward total was -20.000000. running mean: -20.299689\n",
            "resetting env. episode 238.000000, reward total was -21.000000. running mean: -20.306693\n",
            "resetting env. episode 239.000000, reward total was -21.000000. running mean: -20.313626\n",
            "resetting env. episode 240.000000, reward total was -18.000000. running mean: -20.290489\n",
            "resetting env. episode 241.000000, reward total was -21.000000. running mean: -20.297585\n",
            "resetting env. episode 242.000000, reward total was -20.000000. running mean: -20.294609\n",
            "resetting env. episode 243.000000, reward total was -21.000000. running mean: -20.301663\n",
            "resetting env. episode 244.000000, reward total was -19.000000. running mean: -20.288646\n",
            "resetting env. episode 245.000000, reward total was -21.000000. running mean: -20.295759\n",
            "resetting env. episode 246.000000, reward total was -21.000000. running mean: -20.302802\n",
            "resetting env. episode 247.000000, reward total was -19.000000. running mean: -20.289774\n",
            "resetting env. episode 248.000000, reward total was -20.000000. running mean: -20.286876\n",
            "resetting env. episode 249.000000, reward total was -21.000000. running mean: -20.294007\n",
            "resetting env. episode 250.000000, reward total was -20.000000. running mean: -20.291067\n",
            "resetting env. episode 251.000000, reward total was -21.000000. running mean: -20.298157\n",
            "resetting env. episode 252.000000, reward total was -20.000000. running mean: -20.295175\n",
            "resetting env. episode 253.000000, reward total was -21.000000. running mean: -20.302223\n",
            "resetting env. episode 254.000000, reward total was -19.000000. running mean: -20.289201\n",
            "resetting env. episode 255.000000, reward total was -21.000000. running mean: -20.296309\n",
            "resetting env. episode 256.000000, reward total was -19.000000. running mean: -20.283346\n",
            "resetting env. episode 257.000000, reward total was -19.000000. running mean: -20.270513\n",
            "resetting env. episode 258.000000, reward total was -20.000000. running mean: -20.267807\n",
            "resetting env. episode 259.000000, reward total was -20.000000. running mean: -20.265129\n",
            "resetting env. episode 260.000000, reward total was -21.000000. running mean: -20.272478\n",
            "resetting env. episode 261.000000, reward total was -21.000000. running mean: -20.279753\n",
            "resetting env. episode 262.000000, reward total was -20.000000. running mean: -20.276956\n",
            "resetting env. episode 263.000000, reward total was -19.000000. running mean: -20.264186\n",
            "resetting env. episode 264.000000, reward total was -21.000000. running mean: -20.271544\n",
            "resetting env. episode 265.000000, reward total was -21.000000. running mean: -20.278829\n",
            "resetting env. episode 266.000000, reward total was -20.000000. running mean: -20.276041\n",
            "resetting env. episode 267.000000, reward total was -20.000000. running mean: -20.273280\n",
            "resetting env. episode 268.000000, reward total was -21.000000. running mean: -20.280547\n",
            "resetting env. episode 269.000000, reward total was -20.000000. running mean: -20.277742\n",
            "resetting env. episode 270.000000, reward total was -21.000000. running mean: -20.284964\n",
            "resetting env. episode 271.000000, reward total was -21.000000. running mean: -20.292115\n",
            "resetting env. episode 272.000000, reward total was -20.000000. running mean: -20.289194\n",
            "resetting env. episode 273.000000, reward total was -20.000000. running mean: -20.286302\n",
            "resetting env. episode 274.000000, reward total was -21.000000. running mean: -20.293439\n",
            "resetting env. episode 275.000000, reward total was -20.000000. running mean: -20.290504\n",
            "resetting env. episode 276.000000, reward total was -21.000000. running mean: -20.297599\n",
            "resetting env. episode 277.000000, reward total was -19.000000. running mean: -20.284623\n",
            "resetting env. episode 278.000000, reward total was -19.000000. running mean: -20.271777\n",
            "resetting env. episode 279.000000, reward total was -20.000000. running mean: -20.269059\n",
            "resetting env. episode 280.000000, reward total was -19.000000. running mean: -20.256369\n",
            "resetting env. episode 281.000000, reward total was -21.000000. running mean: -20.263805\n",
            "resetting env. episode 282.000000, reward total was -21.000000. running mean: -20.271167\n",
            "resetting env. episode 283.000000, reward total was -21.000000. running mean: -20.278455\n",
            "resetting env. episode 284.000000, reward total was -21.000000. running mean: -20.285671\n",
            "resetting env. episode 285.000000, reward total was -19.000000. running mean: -20.272814\n",
            "resetting env. episode 286.000000, reward total was -21.000000. running mean: -20.280086\n",
            "resetting env. episode 287.000000, reward total was -20.000000. running mean: -20.277285\n",
            "resetting env. episode 288.000000, reward total was -21.000000. running mean: -20.284512\n",
            "resetting env. episode 289.000000, reward total was -21.000000. running mean: -20.291667\n",
            "resetting env. episode 290.000000, reward total was -21.000000. running mean: -20.298750\n",
            "resetting env. episode 291.000000, reward total was -20.000000. running mean: -20.295763\n",
            "resetting env. episode 292.000000, reward total was -21.000000. running mean: -20.302805\n",
            "resetting env. episode 293.000000, reward total was -20.000000. running mean: -20.299777\n",
            "resetting env. episode 294.000000, reward total was -20.000000. running mean: -20.296779\n",
            "resetting env. episode 295.000000, reward total was -21.000000. running mean: -20.303812\n",
            "resetting env. episode 296.000000, reward total was -21.000000. running mean: -20.310774\n",
            "resetting env. episode 297.000000, reward total was -21.000000. running mean: -20.317666\n",
            "resetting env. episode 298.000000, reward total was -19.000000. running mean: -20.304489\n",
            "resetting env. episode 299.000000, reward total was -21.000000. running mean: -20.311444\n",
            "resetting env. episode 300.000000, reward total was -20.000000. running mean: -20.308330\n",
            "resetting env. episode 301.000000, reward total was -21.000000. running mean: -20.315247\n",
            "resetting env. episode 302.000000, reward total was -20.000000. running mean: -20.312094\n",
            "resetting env. episode 303.000000, reward total was -21.000000. running mean: -20.318973\n",
            "resetting env. episode 304.000000, reward total was -19.000000. running mean: -20.305783\n",
            "resetting env. episode 305.000000, reward total was -21.000000. running mean: -20.312726\n",
            "resetting env. episode 306.000000, reward total was -19.000000. running mean: -20.299598\n",
            "resetting env. episode 307.000000, reward total was -19.000000. running mean: -20.286602\n",
            "resetting env. episode 308.000000, reward total was -20.000000. running mean: -20.283736\n",
            "resetting env. episode 309.000000, reward total was -21.000000. running mean: -20.290899\n",
            "resetting env. episode 310.000000, reward total was -20.000000. running mean: -20.287990\n",
            "resetting env. episode 311.000000, reward total was -20.000000. running mean: -20.285110\n",
            "resetting env. episode 312.000000, reward total was -21.000000. running mean: -20.292259\n",
            "resetting env. episode 313.000000, reward total was -21.000000. running mean: -20.299336\n",
            "resetting env. episode 314.000000, reward total was -21.000000. running mean: -20.306343\n",
            "resetting env. episode 315.000000, reward total was -20.000000. running mean: -20.303280\n",
            "resetting env. episode 316.000000, reward total was -21.000000. running mean: -20.310247\n",
            "resetting env. episode 317.000000, reward total was -19.000000. running mean: -20.297144\n",
            "resetting env. episode 318.000000, reward total was -21.000000. running mean: -20.304173\n",
            "resetting env. episode 319.000000, reward total was -21.000000. running mean: -20.311131\n",
            "resetting env. episode 320.000000, reward total was -20.000000. running mean: -20.308020\n",
            "resetting env. episode 321.000000, reward total was -21.000000. running mean: -20.314940\n",
            "resetting env. episode 322.000000, reward total was -20.000000. running mean: -20.311790\n",
            "resetting env. episode 323.000000, reward total was -19.000000. running mean: -20.298672\n",
            "resetting env. episode 324.000000, reward total was -21.000000. running mean: -20.305686\n",
            "resetting env. episode 325.000000, reward total was -21.000000. running mean: -20.312629\n",
            "resetting env. episode 326.000000, reward total was -21.000000. running mean: -20.319502\n",
            "resetting env. episode 327.000000, reward total was -21.000000. running mean: -20.326307\n",
            "resetting env. episode 328.000000, reward total was -21.000000. running mean: -20.333044\n",
            "resetting env. episode 329.000000, reward total was -20.000000. running mean: -20.329714\n",
            "resetting env. episode 330.000000, reward total was -20.000000. running mean: -20.326417\n",
            "resetting env. episode 331.000000, reward total was -18.000000. running mean: -20.303153\n",
            "resetting env. episode 332.000000, reward total was -21.000000. running mean: -20.310121\n",
            "resetting env. episode 333.000000, reward total was -19.000000. running mean: -20.297020\n",
            "resetting env. episode 334.000000, reward total was -20.000000. running mean: -20.294050\n",
            "resetting env. episode 335.000000, reward total was -21.000000. running mean: -20.301109\n",
            "resetting env. episode 336.000000, reward total was -21.000000. running mean: -20.308098\n",
            "resetting env. episode 337.000000, reward total was -20.000000. running mean: -20.305017\n",
            "resetting env. episode 338.000000, reward total was -20.000000. running mean: -20.301967\n",
            "resetting env. episode 339.000000, reward total was -21.000000. running mean: -20.308947\n",
            "resetting env. episode 340.000000, reward total was -20.000000. running mean: -20.305858\n",
            "resetting env. episode 341.000000, reward total was -19.000000. running mean: -20.292799\n",
            "resetting env. episode 342.000000, reward total was -20.000000. running mean: -20.289871\n",
            "resetting env. episode 343.000000, reward total was -20.000000. running mean: -20.286972\n",
            "resetting env. episode 344.000000, reward total was -20.000000. running mean: -20.284103\n",
            "resetting env. episode 345.000000, reward total was -19.000000. running mean: -20.271262\n",
            "resetting env. episode 346.000000, reward total was -19.000000. running mean: -20.258549\n",
            "resetting env. episode 347.000000, reward total was -21.000000. running mean: -20.265964\n",
            "resetting env. episode 348.000000, reward total was -19.000000. running mean: -20.253304\n",
            "resetting env. episode 349.000000, reward total was -20.000000. running mean: -20.250771\n",
            "resetting env. episode 350.000000, reward total was -19.000000. running mean: -20.238263\n",
            "resetting env. episode 351.000000, reward total was -21.000000. running mean: -20.245881\n",
            "resetting env. episode 352.000000, reward total was -19.000000. running mean: -20.233422\n",
            "resetting env. episode 353.000000, reward total was -19.000000. running mean: -20.221088\n",
            "resetting env. episode 354.000000, reward total was -21.000000. running mean: -20.228877\n",
            "resetting env. episode 355.000000, reward total was -19.000000. running mean: -20.216588\n",
            "resetting env. episode 356.000000, reward total was -20.000000. running mean: -20.214422\n",
            "resetting env. episode 357.000000, reward total was -19.000000. running mean: -20.202278\n",
            "resetting env. episode 358.000000, reward total was -20.000000. running mean: -20.200255\n",
            "resetting env. episode 359.000000, reward total was -20.000000. running mean: -20.198253\n",
            "resetting env. episode 360.000000, reward total was -20.000000. running mean: -20.196270\n",
            "resetting env. episode 361.000000, reward total was -19.000000. running mean: -20.184307\n",
            "resetting env. episode 362.000000, reward total was -19.000000. running mean: -20.172464\n",
            "resetting env. episode 363.000000, reward total was -21.000000. running mean: -20.180740\n",
            "resetting env. episode 364.000000, reward total was -19.000000. running mean: -20.168932\n",
            "resetting env. episode 365.000000, reward total was -18.000000. running mean: -20.147243\n",
            "resetting env. episode 366.000000, reward total was -21.000000. running mean: -20.155770\n",
            "resetting env. episode 367.000000, reward total was -21.000000. running mean: -20.164213\n",
            "resetting env. episode 368.000000, reward total was -18.000000. running mean: -20.142571\n",
            "resetting env. episode 369.000000, reward total was -21.000000. running mean: -20.151145\n",
            "resetting env. episode 370.000000, reward total was -21.000000. running mean: -20.159633\n",
            "resetting env. episode 371.000000, reward total was -18.000000. running mean: -20.138037\n",
            "resetting env. episode 372.000000, reward total was -18.000000. running mean: -20.116657\n",
            "resetting env. episode 373.000000, reward total was -21.000000. running mean: -20.125490\n",
            "resetting env. episode 374.000000, reward total was -21.000000. running mean: -20.134235\n",
            "resetting env. episode 375.000000, reward total was -21.000000. running mean: -20.142893\n",
            "resetting env. episode 376.000000, reward total was -21.000000. running mean: -20.151464\n",
            "resetting env. episode 377.000000, reward total was -21.000000. running mean: -20.159949\n",
            "resetting env. episode 378.000000, reward total was -21.000000. running mean: -20.168350\n",
            "resetting env. episode 379.000000, reward total was -21.000000. running mean: -20.176666\n",
            "resetting env. episode 380.000000, reward total was -21.000000. running mean: -20.184900\n",
            "resetting env. episode 381.000000, reward total was -19.000000. running mean: -20.173051\n",
            "resetting env. episode 382.000000, reward total was -21.000000. running mean: -20.181320\n",
            "resetting env. episode 383.000000, reward total was -21.000000. running mean: -20.189507\n",
            "resetting env. episode 384.000000, reward total was -18.000000. running mean: -20.167612\n",
            "resetting env. episode 385.000000, reward total was -20.000000. running mean: -20.165936\n",
            "resetting env. episode 386.000000, reward total was -21.000000. running mean: -20.174276\n",
            "resetting env. episode 387.000000, reward total was -21.000000. running mean: -20.182534\n",
            "resetting env. episode 388.000000, reward total was -21.000000. running mean: -20.190708\n",
            "resetting env. episode 389.000000, reward total was -20.000000. running mean: -20.188801\n",
            "resetting env. episode 390.000000, reward total was -19.000000. running mean: -20.176913\n",
            "resetting env. episode 391.000000, reward total was -20.000000. running mean: -20.175144\n",
            "resetting env. episode 392.000000, reward total was -20.000000. running mean: -20.173393\n",
            "resetting env. episode 393.000000, reward total was -21.000000. running mean: -20.181659\n",
            "resetting env. episode 394.000000, reward total was -21.000000. running mean: -20.189842\n",
            "resetting env. episode 395.000000, reward total was -19.000000. running mean: -20.177944\n",
            "resetting env. episode 396.000000, reward total was -20.000000. running mean: -20.176164\n",
            "resetting env. episode 397.000000, reward total was -20.000000. running mean: -20.174403\n",
            "resetting env. episode 398.000000, reward total was -18.000000. running mean: -20.152659\n",
            "resetting env. episode 399.000000, reward total was -20.000000. running mean: -20.151132\n",
            "resetting env. episode 400.000000, reward total was -19.000000. running mean: -20.139621\n",
            "resetting env. episode 401.000000, reward total was -21.000000. running mean: -20.148225\n",
            "resetting env. episode 402.000000, reward total was -21.000000. running mean: -20.156742\n",
            "resetting env. episode 403.000000, reward total was -21.000000. running mean: -20.165175\n",
            "resetting env. episode 404.000000, reward total was -21.000000. running mean: -20.173523\n",
            "resetting env. episode 405.000000, reward total was -21.000000. running mean: -20.181788\n",
            "resetting env. episode 406.000000, reward total was -21.000000. running mean: -20.189970\n",
            "resetting env. episode 407.000000, reward total was -20.000000. running mean: -20.188070\n",
            "resetting env. episode 408.000000, reward total was -21.000000. running mean: -20.196190\n",
            "resetting env. episode 409.000000, reward total was -20.000000. running mean: -20.194228\n",
            "resetting env. episode 410.000000, reward total was -21.000000. running mean: -20.202285\n",
            "resetting env. episode 411.000000, reward total was -21.000000. running mean: -20.210263\n",
            "resetting env. episode 412.000000, reward total was -21.000000. running mean: -20.218160\n",
            "resetting env. episode 413.000000, reward total was -20.000000. running mean: -20.215978\n",
            "resetting env. episode 414.000000, reward total was -21.000000. running mean: -20.223819\n",
            "resetting env. episode 415.000000, reward total was -20.000000. running mean: -20.221580\n",
            "resetting env. episode 416.000000, reward total was -19.000000. running mean: -20.209365\n",
            "resetting env. episode 417.000000, reward total was -20.000000. running mean: -20.207271\n",
            "resetting env. episode 418.000000, reward total was -20.000000. running mean: -20.205198\n",
            "resetting env. episode 419.000000, reward total was -21.000000. running mean: -20.213146\n",
            "resetting env. episode 420.000000, reward total was -21.000000. running mean: -20.221015\n",
            "resetting env. episode 421.000000, reward total was -21.000000. running mean: -20.228805\n",
            "resetting env. episode 422.000000, reward total was -21.000000. running mean: -20.236517\n",
            "resetting env. episode 423.000000, reward total was -21.000000. running mean: -20.244151\n",
            "resetting env. episode 424.000000, reward total was -20.000000. running mean: -20.241710\n",
            "resetting env. episode 425.000000, reward total was -21.000000. running mean: -20.249293\n",
            "resetting env. episode 426.000000, reward total was -20.000000. running mean: -20.246800\n",
            "resetting env. episode 427.000000, reward total was -20.000000. running mean: -20.244332\n",
            "resetting env. episode 428.000000, reward total was -21.000000. running mean: -20.251889\n",
            "resetting env. episode 429.000000, reward total was -21.000000. running mean: -20.259370\n",
            "resetting env. episode 430.000000, reward total was -21.000000. running mean: -20.266776\n",
            "resetting env. episode 431.000000, reward total was -20.000000. running mean: -20.264108\n",
            "resetting env. episode 432.000000, reward total was -21.000000. running mean: -20.271467\n",
            "resetting env. episode 433.000000, reward total was -20.000000. running mean: -20.268752\n",
            "resetting env. episode 434.000000, reward total was -21.000000. running mean: -20.276065\n",
            "resetting env. episode 435.000000, reward total was -18.000000. running mean: -20.253304\n",
            "resetting env. episode 436.000000, reward total was -20.000000. running mean: -20.250771\n",
            "resetting env. episode 437.000000, reward total was -20.000000. running mean: -20.248264\n",
            "resetting env. episode 438.000000, reward total was -19.000000. running mean: -20.235781\n",
            "resetting env. episode 439.000000, reward total was -21.000000. running mean: -20.243423\n",
            "resetting env. episode 440.000000, reward total was -21.000000. running mean: -20.250989\n",
            "resetting env. episode 441.000000, reward total was -20.000000. running mean: -20.248479\n",
            "resetting env. episode 442.000000, reward total was -21.000000. running mean: -20.255994\n",
            "resetting env. episode 443.000000, reward total was -21.000000. running mean: -20.263434\n",
            "resetting env. episode 444.000000, reward total was -21.000000. running mean: -20.270800\n",
            "resetting env. episode 445.000000, reward total was -20.000000. running mean: -20.268092\n",
            "resetting env. episode 446.000000, reward total was -19.000000. running mean: -20.255411\n",
            "resetting env. episode 447.000000, reward total was -19.000000. running mean: -20.242857\n",
            "resetting env. episode 448.000000, reward total was -20.000000. running mean: -20.240428\n",
            "resetting env. episode 449.000000, reward total was -20.000000. running mean: -20.238024\n",
            "resetting env. episode 450.000000, reward total was -21.000000. running mean: -20.245644\n",
            "resetting env. episode 451.000000, reward total was -20.000000. running mean: -20.243187\n",
            "resetting env. episode 452.000000, reward total was -20.000000. running mean: -20.240755\n",
            "resetting env. episode 453.000000, reward total was -20.000000. running mean: -20.238348\n",
            "resetting env. episode 454.000000, reward total was -21.000000. running mean: -20.245964\n",
            "resetting env. episode 455.000000, reward total was -19.000000. running mean: -20.233505\n",
            "resetting env. episode 456.000000, reward total was -21.000000. running mean: -20.241170\n",
            "resetting env. episode 457.000000, reward total was -20.000000. running mean: -20.238758\n",
            "resetting env. episode 458.000000, reward total was -21.000000. running mean: -20.246370\n",
            "resetting env. episode 459.000000, reward total was -19.000000. running mean: -20.233907\n",
            "resetting env. episode 460.000000, reward total was -19.000000. running mean: -20.221568\n",
            "resetting env. episode 461.000000, reward total was -21.000000. running mean: -20.229352\n",
            "resetting env. episode 462.000000, reward total was -20.000000. running mean: -20.227058\n",
            "resetting env. episode 463.000000, reward total was -21.000000. running mean: -20.234788\n",
            "resetting env. episode 464.000000, reward total was -20.000000. running mean: -20.232440\n",
            "resetting env. episode 465.000000, reward total was -19.000000. running mean: -20.220116\n",
            "resetting env. episode 466.000000, reward total was -21.000000. running mean: -20.227914\n",
            "resetting env. episode 467.000000, reward total was -21.000000. running mean: -20.235635\n",
            "resetting env. episode 468.000000, reward total was -21.000000. running mean: -20.243279\n",
            "resetting env. episode 469.000000, reward total was -21.000000. running mean: -20.250846\n",
            "resetting env. episode 470.000000, reward total was -21.000000. running mean: -20.258338\n",
            "resetting env. episode 471.000000, reward total was -20.000000. running mean: -20.255754\n",
            "resetting env. episode 472.000000, reward total was -21.000000. running mean: -20.263197\n",
            "resetting env. episode 473.000000, reward total was -21.000000. running mean: -20.270565\n",
            "resetting env. episode 474.000000, reward total was -21.000000. running mean: -20.277859\n",
            "resetting env. episode 475.000000, reward total was -21.000000. running mean: -20.285081\n",
            "resetting env. episode 476.000000, reward total was -20.000000. running mean: -20.282230\n",
            "resetting env. episode 477.000000, reward total was -21.000000. running mean: -20.289407\n",
            "resetting env. episode 478.000000, reward total was -19.000000. running mean: -20.276513\n",
            "resetting env. episode 479.000000, reward total was -19.000000. running mean: -20.263748\n",
            "resetting env. episode 480.000000, reward total was -20.000000. running mean: -20.261111\n",
            "resetting env. episode 481.000000, reward total was -19.000000. running mean: -20.248500\n",
            "resetting env. episode 482.000000, reward total was -21.000000. running mean: -20.256015\n",
            "resetting env. episode 483.000000, reward total was -21.000000. running mean: -20.263455\n",
            "resetting env. episode 484.000000, reward total was -19.000000. running mean: -20.250820\n",
            "resetting env. episode 485.000000, reward total was -19.000000. running mean: -20.238312\n",
            "resetting env. episode 486.000000, reward total was -21.000000. running mean: -20.245929\n",
            "resetting env. episode 487.000000, reward total was -20.000000. running mean: -20.243469\n",
            "resetting env. episode 488.000000, reward total was -20.000000. running mean: -20.241035\n",
            "resetting env. episode 489.000000, reward total was -20.000000. running mean: -20.238624\n",
            "resetting env. episode 490.000000, reward total was -21.000000. running mean: -20.246238\n",
            "resetting env. episode 491.000000, reward total was -20.000000. running mean: -20.243776\n",
            "resetting env. episode 492.000000, reward total was -19.000000. running mean: -20.231338\n",
            "resetting env. episode 493.000000, reward total was -19.000000. running mean: -20.219025\n",
            "resetting env. episode 494.000000, reward total was -19.000000. running mean: -20.206834\n",
            "resetting env. episode 495.000000, reward total was -20.000000. running mean: -20.204766\n",
            "resetting env. episode 496.000000, reward total was -19.000000. running mean: -20.192718\n",
            "resetting env. episode 497.000000, reward total was -21.000000. running mean: -20.200791\n",
            "resetting env. episode 498.000000, reward total was -18.000000. running mean: -20.178783\n",
            "resetting env. episode 499.000000, reward total was -21.000000. running mean: -20.186995\n",
            "resetting env. episode 500.000000, reward total was -18.000000. running mean: -20.165125\n",
            "resetting env. episode 501.000000, reward total was -21.000000. running mean: -20.173474\n",
            "resetting env. episode 502.000000, reward total was -21.000000. running mean: -20.181739\n",
            "resetting env. episode 503.000000, reward total was -21.000000. running mean: -20.189922\n",
            "resetting env. episode 504.000000, reward total was -21.000000. running mean: -20.198023\n",
            "resetting env. episode 505.000000, reward total was -21.000000. running mean: -20.206043\n",
            "resetting env. episode 506.000000, reward total was -21.000000. running mean: -20.213982\n",
            "resetting env. episode 507.000000, reward total was -19.000000. running mean: -20.201842\n",
            "resetting env. episode 508.000000, reward total was -18.000000. running mean: -20.179824\n",
            "resetting env. episode 509.000000, reward total was -20.000000. running mean: -20.178026\n",
            "resetting env. episode 510.000000, reward total was -21.000000. running mean: -20.186245\n",
            "resetting env. episode 511.000000, reward total was -16.000000. running mean: -20.144383\n",
            "resetting env. episode 512.000000, reward total was -21.000000. running mean: -20.152939\n",
            "resetting env. episode 513.000000, reward total was -19.000000. running mean: -20.141410\n",
            "resetting env. episode 514.000000, reward total was -21.000000. running mean: -20.149996\n",
            "resetting env. episode 515.000000, reward total was -21.000000. running mean: -20.158496\n",
            "resetting env. episode 516.000000, reward total was -21.000000. running mean: -20.166911\n",
            "resetting env. episode 517.000000, reward total was -20.000000. running mean: -20.165242\n",
            "resetting env. episode 518.000000, reward total was -20.000000. running mean: -20.163589\n",
            "resetting env. episode 519.000000, reward total was -21.000000. running mean: -20.171953\n",
            "resetting env. episode 520.000000, reward total was -21.000000. running mean: -20.180234\n",
            "resetting env. episode 521.000000, reward total was -21.000000. running mean: -20.188431\n",
            "resetting env. episode 522.000000, reward total was -21.000000. running mean: -20.196547\n",
            "resetting env. episode 523.000000, reward total was -21.000000. running mean: -20.204582\n",
            "resetting env. episode 524.000000, reward total was -21.000000. running mean: -20.212536\n",
            "resetting env. episode 525.000000, reward total was -21.000000. running mean: -20.220411\n",
            "resetting env. episode 526.000000, reward total was -19.000000. running mean: -20.208206\n",
            "resetting env. episode 527.000000, reward total was -21.000000. running mean: -20.216124\n",
            "resetting env. episode 528.000000, reward total was -21.000000. running mean: -20.223963\n",
            "resetting env. episode 529.000000, reward total was -21.000000. running mean: -20.231723\n",
            "resetting env. episode 530.000000, reward total was -20.000000. running mean: -20.229406\n",
            "resetting env. episode 531.000000, reward total was -20.000000. running mean: -20.227112\n",
            "resetting env. episode 532.000000, reward total was -21.000000. running mean: -20.234841\n",
            "resetting env. episode 533.000000, reward total was -19.000000. running mean: -20.222493\n",
            "resetting env. episode 534.000000, reward total was -20.000000. running mean: -20.220268\n",
            "resetting env. episode 535.000000, reward total was -20.000000. running mean: -20.218065\n",
            "resetting env. episode 536.000000, reward total was -18.000000. running mean: -20.195884\n",
            "resetting env. episode 537.000000, reward total was -21.000000. running mean: -20.203926\n",
            "resetting env. episode 538.000000, reward total was -20.000000. running mean: -20.201886\n",
            "resetting env. episode 539.000000, reward total was -21.000000. running mean: -20.209867\n",
            "resetting env. episode 540.000000, reward total was -21.000000. running mean: -20.217769\n",
            "resetting env. episode 541.000000, reward total was -21.000000. running mean: -20.225591\n",
            "resetting env. episode 542.000000, reward total was -19.000000. running mean: -20.213335\n",
            "resetting env. episode 543.000000, reward total was -19.000000. running mean: -20.201202\n",
            "resetting env. episode 544.000000, reward total was -21.000000. running mean: -20.209190\n",
            "resetting env. episode 545.000000, reward total was -21.000000. running mean: -20.217098\n",
            "resetting env. episode 546.000000, reward total was -21.000000. running mean: -20.224927\n",
            "resetting env. episode 547.000000, reward total was -19.000000. running mean: -20.212678\n",
            "resetting env. episode 548.000000, reward total was -20.000000. running mean: -20.210551\n",
            "resetting env. episode 549.000000, reward total was -21.000000. running mean: -20.218445\n",
            "resetting env. episode 550.000000, reward total was -18.000000. running mean: -20.196261\n",
            "resetting env. episode 551.000000, reward total was -20.000000. running mean: -20.194298\n",
            "resetting env. episode 552.000000, reward total was -19.000000. running mean: -20.182355\n",
            "resetting env. episode 553.000000, reward total was -20.000000. running mean: -20.180532\n",
            "resetting env. episode 554.000000, reward total was -20.000000. running mean: -20.178726\n",
            "resetting env. episode 555.000000, reward total was -21.000000. running mean: -20.186939\n",
            "resetting env. episode 556.000000, reward total was -20.000000. running mean: -20.185070\n",
            "resetting env. episode 557.000000, reward total was -20.000000. running mean: -20.183219\n",
            "resetting env. episode 558.000000, reward total was -21.000000. running mean: -20.191387\n",
            "resetting env. episode 559.000000, reward total was -20.000000. running mean: -20.189473\n",
            "resetting env. episode 560.000000, reward total was -21.000000. running mean: -20.197578\n",
            "resetting env. episode 561.000000, reward total was -21.000000. running mean: -20.205603\n",
            "resetting env. episode 562.000000, reward total was -21.000000. running mean: -20.213546\n",
            "resetting env. episode 563.000000, reward total was -21.000000. running mean: -20.221411\n",
            "resetting env. episode 564.000000, reward total was -18.000000. running mean: -20.199197\n",
            "resetting env. episode 565.000000, reward total was -19.000000. running mean: -20.187205\n",
            "resetting env. episode 566.000000, reward total was -21.000000. running mean: -20.195333\n",
            "resetting env. episode 567.000000, reward total was -21.000000. running mean: -20.203380\n",
            "resetting env. episode 568.000000, reward total was -19.000000. running mean: -20.191346\n",
            "resetting env. episode 569.000000, reward total was -21.000000. running mean: -20.199432\n",
            "resetting env. episode 570.000000, reward total was -20.000000. running mean: -20.197438\n",
            "resetting env. episode 571.000000, reward total was -20.000000. running mean: -20.195464\n",
            "resetting env. episode 572.000000, reward total was -20.000000. running mean: -20.193509\n",
            "resetting env. episode 573.000000, reward total was -21.000000. running mean: -20.201574\n",
            "resetting env. episode 574.000000, reward total was -19.000000. running mean: -20.189558\n",
            "resetting env. episode 575.000000, reward total was -19.000000. running mean: -20.177663\n",
            "resetting env. episode 576.000000, reward total was -21.000000. running mean: -20.185886\n",
            "resetting env. episode 577.000000, reward total was -17.000000. running mean: -20.154027\n",
            "resetting env. episode 578.000000, reward total was -20.000000. running mean: -20.152487\n",
            "resetting env. episode 579.000000, reward total was -20.000000. running mean: -20.150962\n",
            "resetting env. episode 580.000000, reward total was -21.000000. running mean: -20.159452\n",
            "resetting env. episode 581.000000, reward total was -20.000000. running mean: -20.157858\n",
            "resetting env. episode 582.000000, reward total was -21.000000. running mean: -20.166279\n",
            "resetting env. episode 583.000000, reward total was -19.000000. running mean: -20.154616\n",
            "resetting env. episode 584.000000, reward total was -20.000000. running mean: -20.153070\n",
            "resetting env. episode 585.000000, reward total was -19.000000. running mean: -20.141540\n",
            "resetting env. episode 586.000000, reward total was -21.000000. running mean: -20.150124\n",
            "resetting env. episode 587.000000, reward total was -21.000000. running mean: -20.158623\n",
            "resetting env. episode 588.000000, reward total was -20.000000. running mean: -20.157037\n",
            "resetting env. episode 589.000000, reward total was -21.000000. running mean: -20.165466\n",
            "resetting env. episode 590.000000, reward total was -21.000000. running mean: -20.173812\n",
            "resetting env. episode 591.000000, reward total was -21.000000. running mean: -20.182074\n",
            "resetting env. episode 592.000000, reward total was -21.000000. running mean: -20.190253\n",
            "resetting env. episode 593.000000, reward total was -21.000000. running mean: -20.198350\n",
            "resetting env. episode 594.000000, reward total was -20.000000. running mean: -20.196367\n",
            "resetting env. episode 595.000000, reward total was -20.000000. running mean: -20.194403\n",
            "resetting env. episode 596.000000, reward total was -20.000000. running mean: -20.192459\n",
            "resetting env. episode 597.000000, reward total was -21.000000. running mean: -20.200534\n",
            "resetting env. episode 598.000000, reward total was -21.000000. running mean: -20.208529\n",
            "resetting env. episode 599.000000, reward total was -21.000000. running mean: -20.216444\n",
            "resetting env. episode 600.000000, reward total was -21.000000. running mean: -20.224279\n",
            "resetting env. episode 601.000000, reward total was -20.000000. running mean: -20.222037\n",
            "resetting env. episode 602.000000, reward total was -21.000000. running mean: -20.229816\n",
            "resetting env. episode 603.000000, reward total was -19.000000. running mean: -20.217518\n",
            "resetting env. episode 604.000000, reward total was -21.000000. running mean: -20.225343\n",
            "resetting env. episode 605.000000, reward total was -19.000000. running mean: -20.213089\n",
            "resetting env. episode 606.000000, reward total was -19.000000. running mean: -20.200959\n",
            "resetting env. episode 607.000000, reward total was -20.000000. running mean: -20.198949\n",
            "resetting env. episode 608.000000, reward total was -19.000000. running mean: -20.186960\n",
            "resetting env. episode 609.000000, reward total was -18.000000. running mean: -20.165090\n",
            "resetting env. episode 610.000000, reward total was -20.000000. running mean: -20.163439\n",
            "resetting env. episode 611.000000, reward total was -21.000000. running mean: -20.171805\n",
            "resetting env. episode 612.000000, reward total was -21.000000. running mean: -20.180087\n",
            "resetting env. episode 613.000000, reward total was -20.000000. running mean: -20.178286\n",
            "resetting env. episode 614.000000, reward total was -21.000000. running mean: -20.186503\n",
            "resetting env. episode 615.000000, reward total was -18.000000. running mean: -20.164638\n",
            "resetting env. episode 616.000000, reward total was -21.000000. running mean: -20.172991\n",
            "resetting env. episode 617.000000, reward total was -21.000000. running mean: -20.181262\n",
            "resetting env. episode 618.000000, reward total was -20.000000. running mean: -20.179449\n",
            "resetting env. episode 619.000000, reward total was -20.000000. running mean: -20.177654\n",
            "resetting env. episode 620.000000, reward total was -20.000000. running mean: -20.175878\n",
            "resetting env. episode 621.000000, reward total was -20.000000. running mean: -20.174119\n",
            "resetting env. episode 622.000000, reward total was -20.000000. running mean: -20.172378\n",
            "resetting env. episode 623.000000, reward total was -19.000000. running mean: -20.160654\n",
            "resetting env. episode 624.000000, reward total was -21.000000. running mean: -20.169048\n",
            "resetting env. episode 625.000000, reward total was -20.000000. running mean: -20.167357\n",
            "resetting env. episode 626.000000, reward total was -21.000000. running mean: -20.175684\n",
            "resetting env. episode 627.000000, reward total was -20.000000. running mean: -20.173927\n",
            "resetting env. episode 628.000000, reward total was -21.000000. running mean: -20.182187\n",
            "resetting env. episode 629.000000, reward total was -21.000000. running mean: -20.190366\n",
            "resetting env. episode 630.000000, reward total was -20.000000. running mean: -20.188462\n",
            "resetting env. episode 631.000000, reward total was -20.000000. running mean: -20.186577\n",
            "resetting env. episode 632.000000, reward total was -20.000000. running mean: -20.184712\n",
            "resetting env. episode 633.000000, reward total was -20.000000. running mean: -20.182864\n",
            "resetting env. episode 634.000000, reward total was -21.000000. running mean: -20.191036\n",
            "resetting env. episode 635.000000, reward total was -21.000000. running mean: -20.199125\n",
            "resetting env. episode 636.000000, reward total was -21.000000. running mean: -20.207134\n",
            "resetting env. episode 637.000000, reward total was -20.000000. running mean: -20.205063\n",
            "resetting env. episode 638.000000, reward total was -21.000000. running mean: -20.213012\n",
            "resetting env. episode 639.000000, reward total was -19.000000. running mean: -20.200882\n",
            "resetting env. episode 640.000000, reward total was -21.000000. running mean: -20.208873\n",
            "resetting env. episode 641.000000, reward total was -21.000000. running mean: -20.216785\n",
            "resetting env. episode 642.000000, reward total was -20.000000. running mean: -20.214617\n",
            "resetting env. episode 643.000000, reward total was -20.000000. running mean: -20.212470\n",
            "resetting env. episode 644.000000, reward total was -20.000000. running mean: -20.210346\n",
            "resetting env. episode 645.000000, reward total was -21.000000. running mean: -20.218242\n",
            "resetting env. episode 646.000000, reward total was -21.000000. running mean: -20.226060\n",
            "resetting env. episode 647.000000, reward total was -21.000000. running mean: -20.233799\n",
            "resetting env. episode 648.000000, reward total was -20.000000. running mean: -20.231461\n",
            "resetting env. episode 649.000000, reward total was -21.000000. running mean: -20.239147\n",
            "resetting env. episode 650.000000, reward total was -19.000000. running mean: -20.226755\n",
            "resetting env. episode 651.000000, reward total was -20.000000. running mean: -20.224488\n",
            "resetting env. episode 652.000000, reward total was -20.000000. running mean: -20.222243\n",
            "resetting env. episode 653.000000, reward total was -20.000000. running mean: -20.220020\n",
            "resetting env. episode 654.000000, reward total was -21.000000. running mean: -20.227820\n",
            "resetting env. episode 655.000000, reward total was -18.000000. running mean: -20.205542\n",
            "resetting env. episode 656.000000, reward total was -21.000000. running mean: -20.213487\n",
            "resetting env. episode 657.000000, reward total was -19.000000. running mean: -20.201352\n",
            "resetting env. episode 658.000000, reward total was -21.000000. running mean: -20.209338\n",
            "resetting env. episode 659.000000, reward total was -19.000000. running mean: -20.197245\n",
            "resetting env. episode 660.000000, reward total was -20.000000. running mean: -20.195272\n",
            "resetting env. episode 661.000000, reward total was -21.000000. running mean: -20.203320\n",
            "resetting env. episode 662.000000, reward total was -19.000000. running mean: -20.191286\n",
            "resetting env. episode 663.000000, reward total was -21.000000. running mean: -20.199374\n",
            "resetting env. episode 664.000000, reward total was -20.000000. running mean: -20.197380\n",
            "resetting env. episode 665.000000, reward total was -21.000000. running mean: -20.205406\n",
            "resetting env. episode 666.000000, reward total was -21.000000. running mean: -20.213352\n",
            "resetting env. episode 667.000000, reward total was -21.000000. running mean: -20.221218\n",
            "resetting env. episode 668.000000, reward total was -20.000000. running mean: -20.219006\n",
            "resetting env. episode 669.000000, reward total was -21.000000. running mean: -20.226816\n",
            "resetting env. episode 670.000000, reward total was -20.000000. running mean: -20.224548\n",
            "resetting env. episode 671.000000, reward total was -20.000000. running mean: -20.222303\n",
            "resetting env. episode 672.000000, reward total was -21.000000. running mean: -20.230080\n",
            "resetting env. episode 673.000000, reward total was -20.000000. running mean: -20.227779\n",
            "resetting env. episode 674.000000, reward total was -21.000000. running mean: -20.235501\n",
            "resetting env. episode 675.000000, reward total was -21.000000. running mean: -20.243146\n",
            "resetting env. episode 676.000000, reward total was -21.000000. running mean: -20.250714\n",
            "resetting env. episode 677.000000, reward total was -20.000000. running mean: -20.248207\n",
            "resetting env. episode 678.000000, reward total was -18.000000. running mean: -20.225725\n",
            "resetting env. episode 679.000000, reward total was -21.000000. running mean: -20.233468\n",
            "resetting env. episode 680.000000, reward total was -20.000000. running mean: -20.231133\n",
            "resetting env. episode 681.000000, reward total was -20.000000. running mean: -20.228822\n",
            "resetting env. episode 682.000000, reward total was -19.000000. running mean: -20.216534\n",
            "resetting env. episode 683.000000, reward total was -17.000000. running mean: -20.184368\n",
            "resetting env. episode 684.000000, reward total was -19.000000. running mean: -20.172525\n",
            "resetting env. episode 685.000000, reward total was -18.000000. running mean: -20.150800\n",
            "resetting env. episode 686.000000, reward total was -20.000000. running mean: -20.149292\n",
            "resetting env. episode 687.000000, reward total was -21.000000. running mean: -20.157799\n",
            "resetting env. episode 688.000000, reward total was -20.000000. running mean: -20.156221\n",
            "resetting env. episode 689.000000, reward total was -18.000000. running mean: -20.134658\n",
            "resetting env. episode 690.000000, reward total was -20.000000. running mean: -20.133312\n",
            "resetting env. episode 691.000000, reward total was -21.000000. running mean: -20.141979\n",
            "resetting env. episode 692.000000, reward total was -20.000000. running mean: -20.140559\n",
            "resetting env. episode 693.000000, reward total was -20.000000. running mean: -20.139153\n",
            "resetting env. episode 694.000000, reward total was -20.000000. running mean: -20.137762\n",
            "resetting env. episode 695.000000, reward total was -19.000000. running mean: -20.126384\n",
            "resetting env. episode 696.000000, reward total was -20.000000. running mean: -20.125120\n",
            "resetting env. episode 697.000000, reward total was -21.000000. running mean: -20.133869\n",
            "resetting env. episode 698.000000, reward total was -21.000000. running mean: -20.142530\n",
            "resetting env. episode 699.000000, reward total was -21.000000. running mean: -20.151105\n",
            "resetting env. episode 700.000000, reward total was -19.000000. running mean: -20.139594\n",
            "resetting env. episode 701.000000, reward total was -20.000000. running mean: -20.138198\n",
            "resetting env. episode 702.000000, reward total was -21.000000. running mean: -20.146816\n",
            "resetting env. episode 703.000000, reward total was -19.000000. running mean: -20.135348\n",
            "resetting env. episode 704.000000, reward total was -20.000000. running mean: -20.133995\n",
            "resetting env. episode 705.000000, reward total was -19.000000. running mean: -20.122655\n",
            "resetting env. episode 706.000000, reward total was -20.000000. running mean: -20.121428\n",
            "resetting env. episode 707.000000, reward total was -21.000000. running mean: -20.130214\n",
            "resetting env. episode 708.000000, reward total was -21.000000. running mean: -20.138912\n",
            "resetting env. episode 709.000000, reward total was -20.000000. running mean: -20.137522\n",
            "resetting env. episode 710.000000, reward total was -21.000000. running mean: -20.146147\n",
            "resetting env. episode 711.000000, reward total was -21.000000. running mean: -20.154686\n",
            "resetting env. episode 712.000000, reward total was -21.000000. running mean: -20.163139\n",
            "resetting env. episode 713.000000, reward total was -21.000000. running mean: -20.171508\n",
            "resetting env. episode 714.000000, reward total was -21.000000. running mean: -20.179792\n",
            "resetting env. episode 715.000000, reward total was -18.000000. running mean: -20.157995\n",
            "resetting env. episode 716.000000, reward total was -21.000000. running mean: -20.166415\n",
            "resetting env. episode 717.000000, reward total was -21.000000. running mean: -20.174750\n",
            "resetting env. episode 718.000000, reward total was -20.000000. running mean: -20.173003\n",
            "resetting env. episode 719.000000, reward total was -21.000000. running mean: -20.181273\n",
            "resetting env. episode 720.000000, reward total was -20.000000. running mean: -20.179460\n",
            "resetting env. episode 721.000000, reward total was -20.000000. running mean: -20.177666\n",
            "resetting env. episode 722.000000, reward total was -19.000000. running mean: -20.165889\n",
            "resetting env. episode 723.000000, reward total was -20.000000. running mean: -20.164230\n",
            "resetting env. episode 724.000000, reward total was -20.000000. running mean: -20.162588\n",
            "resetting env. episode 725.000000, reward total was -20.000000. running mean: -20.160962\n",
            "resetting env. episode 726.000000, reward total was -20.000000. running mean: -20.159352\n",
            "resetting env. episode 727.000000, reward total was -21.000000. running mean: -20.167759\n",
            "resetting env. episode 728.000000, reward total was -19.000000. running mean: -20.156081\n",
            "resetting env. episode 729.000000, reward total was -21.000000. running mean: -20.164520\n",
            "resetting env. episode 730.000000, reward total was -20.000000. running mean: -20.162875\n",
            "resetting env. episode 731.000000, reward total was -21.000000. running mean: -20.171246\n",
            "resetting env. episode 732.000000, reward total was -20.000000. running mean: -20.169534\n",
            "resetting env. episode 733.000000, reward total was -19.000000. running mean: -20.157839\n",
            "resetting env. episode 734.000000, reward total was -21.000000. running mean: -20.166260\n",
            "resetting env. episode 735.000000, reward total was -20.000000. running mean: -20.164598\n",
            "resetting env. episode 736.000000, reward total was -18.000000. running mean: -20.142952\n",
            "resetting env. episode 737.000000, reward total was -20.000000. running mean: -20.141522\n",
            "resetting env. episode 738.000000, reward total was -21.000000. running mean: -20.150107\n",
            "resetting env. episode 739.000000, reward total was -20.000000. running mean: -20.148606\n",
            "resetting env. episode 740.000000, reward total was -21.000000. running mean: -20.157120\n",
            "resetting env. episode 741.000000, reward total was -21.000000. running mean: -20.165549\n",
            "resetting env. episode 742.000000, reward total was -21.000000. running mean: -20.173893\n",
            "resetting env. episode 743.000000, reward total was -17.000000. running mean: -20.142154\n",
            "resetting env. episode 744.000000, reward total was -21.000000. running mean: -20.150733\n",
            "resetting env. episode 745.000000, reward total was -21.000000. running mean: -20.159225\n",
            "resetting env. episode 746.000000, reward total was -21.000000. running mean: -20.167633\n",
            "resetting env. episode 747.000000, reward total was -21.000000. running mean: -20.175957\n",
            "resetting env. episode 748.000000, reward total was -20.000000. running mean: -20.174197\n",
            "resetting env. episode 749.000000, reward total was -21.000000. running mean: -20.182455\n",
            "resetting env. episode 750.000000, reward total was -21.000000. running mean: -20.190631\n",
            "resetting env. episode 751.000000, reward total was -20.000000. running mean: -20.188724\n",
            "resetting env. episode 752.000000, reward total was -20.000000. running mean: -20.186837\n",
            "resetting env. episode 753.000000, reward total was -21.000000. running mean: -20.194969\n",
            "resetting env. episode 754.000000, reward total was -21.000000. running mean: -20.203019\n",
            "resetting env. episode 755.000000, reward total was -21.000000. running mean: -20.210989\n",
            "resetting env. episode 756.000000, reward total was -20.000000. running mean: -20.208879\n",
            "resetting env. episode 757.000000, reward total was -19.000000. running mean: -20.196790\n",
            "resetting env. episode 758.000000, reward total was -20.000000. running mean: -20.194822\n",
            "resetting env. episode 759.000000, reward total was -19.000000. running mean: -20.182874\n",
            "resetting env. episode 760.000000, reward total was -21.000000. running mean: -20.191045\n",
            "resetting env. episode 761.000000, reward total was -21.000000. running mean: -20.199135\n",
            "resetting env. episode 762.000000, reward total was -21.000000. running mean: -20.207143\n",
            "resetting env. episode 763.000000, reward total was -21.000000. running mean: -20.215072\n",
            "resetting env. episode 764.000000, reward total was -20.000000. running mean: -20.212921\n",
            "resetting env. episode 765.000000, reward total was -20.000000. running mean: -20.210792\n",
            "resetting env. episode 766.000000, reward total was -21.000000. running mean: -20.218684\n",
            "resetting env. episode 767.000000, reward total was -20.000000. running mean: -20.216497\n",
            "resetting env. episode 768.000000, reward total was -20.000000. running mean: -20.214332\n",
            "resetting env. episode 769.000000, reward total was -18.000000. running mean: -20.192189\n",
            "resetting env. episode 770.000000, reward total was -21.000000. running mean: -20.200267\n",
            "resetting env. episode 771.000000, reward total was -20.000000. running mean: -20.198264\n",
            "resetting env. episode 772.000000, reward total was -19.000000. running mean: -20.186282\n",
            "resetting env. episode 773.000000, reward total was -20.000000. running mean: -20.184419\n",
            "resetting env. episode 774.000000, reward total was -18.000000. running mean: -20.162575\n",
            "resetting env. episode 775.000000, reward total was -21.000000. running mean: -20.170949\n",
            "resetting env. episode 776.000000, reward total was -21.000000. running mean: -20.179240\n",
            "resetting env. episode 777.000000, reward total was -19.000000. running mean: -20.167447\n",
            "resetting env. episode 778.000000, reward total was -18.000000. running mean: -20.145773\n",
            "resetting env. episode 779.000000, reward total was -21.000000. running mean: -20.154315\n",
            "resetting env. episode 780.000000, reward total was -21.000000. running mean: -20.162772\n",
            "resetting env. episode 781.000000, reward total was -19.000000. running mean: -20.151144\n",
            "resetting env. episode 782.000000, reward total was -20.000000. running mean: -20.149633\n",
            "resetting env. episode 783.000000, reward total was -21.000000. running mean: -20.158136\n",
            "resetting env. episode 784.000000, reward total was -21.000000. running mean: -20.166555\n",
            "resetting env. episode 785.000000, reward total was -19.000000. running mean: -20.154889\n",
            "resetting env. episode 786.000000, reward total was -19.000000. running mean: -20.143341\n",
            "resetting env. episode 787.000000, reward total was -20.000000. running mean: -20.141907\n",
            "resetting env. episode 788.000000, reward total was -17.000000. running mean: -20.110488\n",
            "resetting env. episode 789.000000, reward total was -21.000000. running mean: -20.119383\n",
            "resetting env. episode 790.000000, reward total was -21.000000. running mean: -20.128189\n",
            "resetting env. episode 791.000000, reward total was -21.000000. running mean: -20.136907\n",
            "resetting env. episode 792.000000, reward total was -21.000000. running mean: -20.145538\n",
            "resetting env. episode 793.000000, reward total was -21.000000. running mean: -20.154083\n",
            "resetting env. episode 794.000000, reward total was -21.000000. running mean: -20.162542\n",
            "resetting env. episode 795.000000, reward total was -20.000000. running mean: -20.160917\n",
            "resetting env. episode 796.000000, reward total was -18.000000. running mean: -20.139308\n",
            "resetting env. episode 797.000000, reward total was -21.000000. running mean: -20.147914\n",
            "resetting env. episode 798.000000, reward total was -21.000000. running mean: -20.156435\n",
            "resetting env. episode 799.000000, reward total was -21.000000. running mean: -20.164871\n",
            "resetting env. episode 800.000000, reward total was -21.000000. running mean: -20.173222\n",
            "resetting env. episode 801.000000, reward total was -21.000000. running mean: -20.181490\n",
            "resetting env. episode 802.000000, reward total was -18.000000. running mean: -20.159675\n",
            "resetting env. episode 803.000000, reward total was -20.000000. running mean: -20.158078\n",
            "resetting env. episode 804.000000, reward total was -20.000000. running mean: -20.156498\n",
            "resetting env. episode 805.000000, reward total was -21.000000. running mean: -20.164933\n",
            "resetting env. episode 806.000000, reward total was -20.000000. running mean: -20.163283\n",
            "resetting env. episode 807.000000, reward total was -21.000000. running mean: -20.171650\n",
            "resetting env. episode 808.000000, reward total was -20.000000. running mean: -20.169934\n",
            "resetting env. episode 809.000000, reward total was -21.000000. running mean: -20.178235\n",
            "resetting env. episode 810.000000, reward total was -18.000000. running mean: -20.156452\n",
            "resetting env. episode 811.000000, reward total was -21.000000. running mean: -20.164888\n",
            "resetting env. episode 812.000000, reward total was -21.000000. running mean: -20.173239\n",
            "resetting env. episode 813.000000, reward total was -20.000000. running mean: -20.171507\n",
            "resetting env. episode 814.000000, reward total was -20.000000. running mean: -20.169791\n",
            "resetting env. episode 815.000000, reward total was -19.000000. running mean: -20.158094\n",
            "resetting env. episode 816.000000, reward total was -18.000000. running mean: -20.136513\n",
            "resetting env. episode 817.000000, reward total was -20.000000. running mean: -20.135147\n",
            "resetting env. episode 818.000000, reward total was -20.000000. running mean: -20.133796\n",
            "resetting env. episode 819.000000, reward total was -17.000000. running mean: -20.102458\n",
            "resetting env. episode 820.000000, reward total was -21.000000. running mean: -20.111433\n",
            "resetting env. episode 821.000000, reward total was -21.000000. running mean: -20.120319\n",
            "resetting env. episode 822.000000, reward total was -19.000000. running mean: -20.109116\n",
            "resetting env. episode 823.000000, reward total was -21.000000. running mean: -20.118025\n",
            "resetting env. episode 824.000000, reward total was -19.000000. running mean: -20.106845\n",
            "resetting env. episode 825.000000, reward total was -20.000000. running mean: -20.105776\n",
            "resetting env. episode 826.000000, reward total was -21.000000. running mean: -20.114718\n",
            "resetting env. episode 827.000000, reward total was -21.000000. running mean: -20.123571\n",
            "resetting env. episode 828.000000, reward total was -21.000000. running mean: -20.132335\n",
            "resetting env. episode 829.000000, reward total was -20.000000. running mean: -20.131012\n",
            "resetting env. episode 830.000000, reward total was -19.000000. running mean: -20.119702\n",
            "resetting env. episode 831.000000, reward total was -21.000000. running mean: -20.128505\n",
            "resetting env. episode 832.000000, reward total was -19.000000. running mean: -20.117220\n",
            "resetting env. episode 833.000000, reward total was -21.000000. running mean: -20.126048\n",
            "resetting env. episode 834.000000, reward total was -21.000000. running mean: -20.134787\n",
            "resetting env. episode 835.000000, reward total was -18.000000. running mean: -20.113439\n",
            "resetting env. episode 836.000000, reward total was -19.000000. running mean: -20.102305\n",
            "resetting env. episode 837.000000, reward total was -21.000000. running mean: -20.111282\n",
            "resetting env. episode 838.000000, reward total was -20.000000. running mean: -20.110169\n",
            "resetting env. episode 839.000000, reward total was -20.000000. running mean: -20.109067\n",
            "resetting env. episode 840.000000, reward total was -21.000000. running mean: -20.117977\n",
            "resetting env. episode 841.000000, reward total was -21.000000. running mean: -20.126797\n",
            "resetting env. episode 842.000000, reward total was -21.000000. running mean: -20.135529\n",
            "resetting env. episode 843.000000, reward total was -20.000000. running mean: -20.134174\n",
            "resetting env. episode 844.000000, reward total was -20.000000. running mean: -20.132832\n",
            "resetting env. episode 845.000000, reward total was -20.000000. running mean: -20.131504\n",
            "resetting env. episode 846.000000, reward total was -21.000000. running mean: -20.140189\n",
            "resetting env. episode 847.000000, reward total was -21.000000. running mean: -20.148787\n",
            "resetting env. episode 848.000000, reward total was -19.000000. running mean: -20.137299\n",
            "resetting env. episode 849.000000, reward total was -21.000000. running mean: -20.145926\n",
            "resetting env. episode 850.000000, reward total was -21.000000. running mean: -20.154467\n",
            "resetting env. episode 851.000000, reward total was -21.000000. running mean: -20.162922\n",
            "resetting env. episode 852.000000, reward total was -21.000000. running mean: -20.171293\n",
            "resetting env. episode 853.000000, reward total was -21.000000. running mean: -20.179580\n",
            "resetting env. episode 854.000000, reward total was -20.000000. running mean: -20.177784\n",
            "resetting env. episode 855.000000, reward total was -21.000000. running mean: -20.186006\n",
            "resetting env. episode 856.000000, reward total was -21.000000. running mean: -20.194146\n",
            "resetting env. episode 857.000000, reward total was -20.000000. running mean: -20.192205\n",
            "resetting env. episode 858.000000, reward total was -20.000000. running mean: -20.190283\n",
            "resetting env. episode 859.000000, reward total was -20.000000. running mean: -20.188380\n",
            "resetting env. episode 860.000000, reward total was -20.000000. running mean: -20.186496\n",
            "resetting env. episode 861.000000, reward total was -21.000000. running mean: -20.194631\n",
            "resetting env. episode 862.000000, reward total was -20.000000. running mean: -20.192685\n",
            "resetting env. episode 863.000000, reward total was -21.000000. running mean: -20.200758\n",
            "resetting env. episode 864.000000, reward total was -17.000000. running mean: -20.168750\n",
            "resetting env. episode 865.000000, reward total was -21.000000. running mean: -20.177063\n",
            "resetting env. episode 866.000000, reward total was -19.000000. running mean: -20.165292\n",
            "resetting env. episode 867.000000, reward total was -21.000000. running mean: -20.173639\n",
            "resetting env. episode 868.000000, reward total was -21.000000. running mean: -20.181903\n",
            "resetting env. episode 869.000000, reward total was -21.000000. running mean: -20.190084\n",
            "resetting env. episode 870.000000, reward total was -20.000000. running mean: -20.188183\n",
            "resetting env. episode 871.000000, reward total was -21.000000. running mean: -20.196301\n",
            "resetting env. episode 872.000000, reward total was -21.000000. running mean: -20.204338\n",
            "resetting env. episode 873.000000, reward total was -21.000000. running mean: -20.212295\n",
            "resetting env. episode 874.000000, reward total was -21.000000. running mean: -20.220172\n",
            "resetting env. episode 875.000000, reward total was -21.000000. running mean: -20.227970\n",
            "resetting env. episode 876.000000, reward total was -20.000000. running mean: -20.225690\n",
            "resetting env. episode 877.000000, reward total was -20.000000. running mean: -20.223433\n",
            "resetting env. episode 878.000000, reward total was -21.000000. running mean: -20.231199\n",
            "resetting env. episode 879.000000, reward total was -21.000000. running mean: -20.238887\n",
            "resetting env. episode 880.000000, reward total was -21.000000. running mean: -20.246498\n",
            "resetting env. episode 881.000000, reward total was -20.000000. running mean: -20.244033\n",
            "resetting env. episode 882.000000, reward total was -21.000000. running mean: -20.251593\n",
            "resetting env. episode 883.000000, reward total was -20.000000. running mean: -20.249077\n",
            "resetting env. episode 884.000000, reward total was -18.000000. running mean: -20.226586\n",
            "resetting env. episode 885.000000, reward total was -21.000000. running mean: -20.234320\n",
            "resetting env. episode 886.000000, reward total was -17.000000. running mean: -20.201977\n",
            "resetting env. episode 887.000000, reward total was -20.000000. running mean: -20.199957\n",
            "resetting env. episode 888.000000, reward total was -20.000000. running mean: -20.197958\n",
            "resetting env. episode 889.000000, reward total was -20.000000. running mean: -20.195978\n",
            "resetting env. episode 890.000000, reward total was -19.000000. running mean: -20.184018\n",
            "resetting env. episode 891.000000, reward total was -20.000000. running mean: -20.182178\n",
            "resetting env. episode 892.000000, reward total was -18.000000. running mean: -20.160357\n",
            "resetting env. episode 893.000000, reward total was -21.000000. running mean: -20.168753\n",
            "resetting env. episode 894.000000, reward total was -21.000000. running mean: -20.177065\n",
            "resetting env. episode 895.000000, reward total was -21.000000. running mean: -20.185295\n",
            "resetting env. episode 896.000000, reward total was -21.000000. running mean: -20.193442\n",
            "resetting env. episode 897.000000, reward total was -20.000000. running mean: -20.191507\n",
            "resetting env. episode 898.000000, reward total was -21.000000. running mean: -20.199592\n",
            "resetting env. episode 899.000000, reward total was -21.000000. running mean: -20.207596\n",
            "resetting env. episode 900.000000, reward total was -19.000000. running mean: -20.195520\n",
            "resetting env. episode 901.000000, reward total was -21.000000. running mean: -20.203565\n",
            "resetting env. episode 902.000000, reward total was -21.000000. running mean: -20.211530\n",
            "resetting env. episode 903.000000, reward total was -20.000000. running mean: -20.209414\n",
            "resetting env. episode 904.000000, reward total was -19.000000. running mean: -20.197320\n",
            "resetting env. episode 905.000000, reward total was -21.000000. running mean: -20.205347\n",
            "resetting env. episode 906.000000, reward total was -21.000000. running mean: -20.213293\n",
            "resetting env. episode 907.000000, reward total was -21.000000. running mean: -20.221161\n",
            "resetting env. episode 908.000000, reward total was -19.000000. running mean: -20.208949\n",
            "resetting env. episode 909.000000, reward total was -21.000000. running mean: -20.216859\n",
            "resetting env. episode 910.000000, reward total was -19.000000. running mean: -20.204691\n",
            "resetting env. episode 911.000000, reward total was -20.000000. running mean: -20.202644\n",
            "resetting env. episode 912.000000, reward total was -18.000000. running mean: -20.180617\n",
            "resetting env. episode 913.000000, reward total was -21.000000. running mean: -20.188811\n",
            "resetting env. episode 914.000000, reward total was -20.000000. running mean: -20.186923\n",
            "resetting env. episode 915.000000, reward total was -21.000000. running mean: -20.195054\n",
            "resetting env. episode 916.000000, reward total was -19.000000. running mean: -20.183103\n",
            "resetting env. episode 917.000000, reward total was -20.000000. running mean: -20.181272\n",
            "resetting env. episode 918.000000, reward total was -20.000000. running mean: -20.179460\n",
            "resetting env. episode 919.000000, reward total was -20.000000. running mean: -20.177665\n",
            "resetting env. episode 920.000000, reward total was -17.000000. running mean: -20.145888\n",
            "resetting env. episode 921.000000, reward total was -21.000000. running mean: -20.154430\n",
            "resetting env. episode 922.000000, reward total was -20.000000. running mean: -20.152885\n",
            "resetting env. episode 923.000000, reward total was -20.000000. running mean: -20.151356\n",
            "resetting env. episode 924.000000, reward total was -21.000000. running mean: -20.159843\n",
            "resetting env. episode 925.000000, reward total was -20.000000. running mean: -20.158244\n",
            "resetting env. episode 926.000000, reward total was -19.000000. running mean: -20.146662\n",
            "resetting env. episode 927.000000, reward total was -18.000000. running mean: -20.125195\n",
            "resetting env. episode 928.000000, reward total was -21.000000. running mean: -20.133943\n",
            "resetting env. episode 929.000000, reward total was -20.000000. running mean: -20.132604\n",
            "resetting env. episode 930.000000, reward total was -21.000000. running mean: -20.141278\n",
            "resetting env. episode 931.000000, reward total was -20.000000. running mean: -20.139865\n",
            "resetting env. episode 932.000000, reward total was -20.000000. running mean: -20.138466\n",
            "resetting env. episode 933.000000, reward total was -20.000000. running mean: -20.137082\n",
            "resetting env. episode 934.000000, reward total was -20.000000. running mean: -20.135711\n",
            "resetting env. episode 935.000000, reward total was -19.000000. running mean: -20.124354\n",
            "resetting env. episode 936.000000, reward total was -21.000000. running mean: -20.133110\n",
            "resetting env. episode 937.000000, reward total was -18.000000. running mean: -20.111779\n",
            "resetting env. episode 938.000000, reward total was -20.000000. running mean: -20.110661\n",
            "resetting env. episode 939.000000, reward total was -19.000000. running mean: -20.099555\n",
            "resetting env. episode 940.000000, reward total was -21.000000. running mean: -20.108559\n",
            "resetting env. episode 941.000000, reward total was -20.000000. running mean: -20.107474\n",
            "resetting env. episode 942.000000, reward total was -19.000000. running mean: -20.096399\n",
            "resetting env. episode 943.000000, reward total was -19.000000. running mean: -20.085435\n",
            "resetting env. episode 944.000000, reward total was -21.000000. running mean: -20.094581\n",
            "resetting env. episode 945.000000, reward total was -19.000000. running mean: -20.083635\n",
            "resetting env. episode 946.000000, reward total was -21.000000. running mean: -20.092798\n",
            "resetting env. episode 947.000000, reward total was -20.000000. running mean: -20.091870\n",
            "resetting env. episode 948.000000, reward total was -20.000000. running mean: -20.090952\n",
            "resetting env. episode 949.000000, reward total was -21.000000. running mean: -20.100042\n",
            "resetting env. episode 950.000000, reward total was -20.000000. running mean: -20.099042\n",
            "resetting env. episode 951.000000, reward total was -20.000000. running mean: -20.098051\n",
            "resetting env. episode 952.000000, reward total was -21.000000. running mean: -20.107071\n",
            "resetting env. episode 953.000000, reward total was -21.000000. running mean: -20.116000\n",
            "resetting env. episode 954.000000, reward total was -19.000000. running mean: -20.104840\n",
            "resetting env. episode 955.000000, reward total was -21.000000. running mean: -20.113792\n",
            "resetting env. episode 956.000000, reward total was -21.000000. running mean: -20.122654\n",
            "resetting env. episode 957.000000, reward total was -18.000000. running mean: -20.101427\n",
            "resetting env. episode 958.000000, reward total was -21.000000. running mean: -20.110413\n",
            "resetting env. episode 959.000000, reward total was -21.000000. running mean: -20.119309\n",
            "resetting env. episode 960.000000, reward total was -20.000000. running mean: -20.118116\n",
            "resetting env. episode 961.000000, reward total was -18.000000. running mean: -20.096935\n",
            "resetting env. episode 962.000000, reward total was -19.000000. running mean: -20.085965\n",
            "resetting env. episode 963.000000, reward total was -21.000000. running mean: -20.095106\n",
            "resetting env. episode 964.000000, reward total was -21.000000. running mean: -20.104155\n",
            "resetting env. episode 965.000000, reward total was -21.000000. running mean: -20.113113\n",
            "resetting env. episode 966.000000, reward total was -21.000000. running mean: -20.121982\n",
            "resetting env. episode 967.000000, reward total was -21.000000. running mean: -20.130762\n",
            "resetting env. episode 968.000000, reward total was -20.000000. running mean: -20.129455\n",
            "resetting env. episode 969.000000, reward total was -20.000000. running mean: -20.128160\n",
            "resetting env. episode 970.000000, reward total was -20.000000. running mean: -20.126878\n",
            "resetting env. episode 971.000000, reward total was -20.000000. running mean: -20.125610\n",
            "resetting env. episode 972.000000, reward total was -19.000000. running mean: -20.114353\n",
            "resetting env. episode 973.000000, reward total was -17.000000. running mean: -20.083210\n",
            "resetting env. episode 974.000000, reward total was -21.000000. running mean: -20.092378\n",
            "resetting env. episode 975.000000, reward total was -21.000000. running mean: -20.101454\n",
            "resetting env. episode 976.000000, reward total was -21.000000. running mean: -20.110440\n",
            "resetting env. episode 977.000000, reward total was -21.000000. running mean: -20.119335\n",
            "resetting env. episode 978.000000, reward total was -18.000000. running mean: -20.098142\n",
            "resetting env. episode 979.000000, reward total was -20.000000. running mean: -20.097160\n",
            "resetting env. episode 980.000000, reward total was -21.000000. running mean: -20.106189\n",
            "resetting env. episode 981.000000, reward total was -21.000000. running mean: -20.115127\n",
            "resetting env. episode 982.000000, reward total was -21.000000. running mean: -20.123976\n",
            "resetting env. episode 983.000000, reward total was -21.000000. running mean: -20.132736\n",
            "resetting env. episode 984.000000, reward total was -18.000000. running mean: -20.111408\n",
            "resetting env. episode 985.000000, reward total was -20.000000. running mean: -20.110294\n",
            "resetting env. episode 986.000000, reward total was -19.000000. running mean: -20.099191\n",
            "resetting env. episode 987.000000, reward total was -20.000000. running mean: -20.098200\n",
            "resetting env. episode 988.000000, reward total was -21.000000. running mean: -20.107218\n",
            "resetting env. episode 989.000000, reward total was -20.000000. running mean: -20.106145\n",
            "resetting env. episode 990.000000, reward total was -19.000000. running mean: -20.095084\n",
            "resetting env. episode 991.000000, reward total was -19.000000. running mean: -20.084133\n",
            "resetting env. episode 992.000000, reward total was -21.000000. running mean: -20.093292\n",
            "resetting env. episode 993.000000, reward total was -21.000000. running mean: -20.102359\n",
            "resetting env. episode 994.000000, reward total was -19.000000. running mean: -20.091335\n",
            "resetting env. episode 995.000000, reward total was -21.000000. running mean: -20.100422\n",
            "resetting env. episode 996.000000, reward total was -20.000000. running mean: -20.099418\n",
            "resetting env. episode 997.000000, reward total was -20.000000. running mean: -20.098423\n",
            "resetting env. episode 998.000000, reward total was -21.000000. running mean: -20.107439\n",
            "resetting env. episode 999.000000, reward total was -20.000000. running mean: -20.106365\n",
            "resetting env. episode 1000.000000, reward total was -20.000000. running mean: -20.105301\n",
            "resetting env. episode 1001.000000, reward total was -19.000000. running mean: -20.094248\n",
            "resetting env. episode 1002.000000, reward total was -21.000000. running mean: -20.103306\n",
            "resetting env. episode 1003.000000, reward total was -18.000000. running mean: -20.082273\n",
            "resetting env. episode 1004.000000, reward total was -21.000000. running mean: -20.091450\n",
            "resetting env. episode 1005.000000, reward total was -20.000000. running mean: -20.090535\n",
            "resetting env. episode 1006.000000, reward total was -19.000000. running mean: -20.079630\n",
            "resetting env. episode 1007.000000, reward total was -21.000000. running mean: -20.088834\n",
            "resetting env. episode 1008.000000, reward total was -19.000000. running mean: -20.077945\n",
            "resetting env. episode 1009.000000, reward total was -20.000000. running mean: -20.077166\n",
            "resetting env. episode 1010.000000, reward total was -21.000000. running mean: -20.086394\n",
            "resetting env. episode 1011.000000, reward total was -21.000000. running mean: -20.095530\n",
            "resetting env. episode 1012.000000, reward total was -20.000000. running mean: -20.094575\n",
            "resetting env. episode 1013.000000, reward total was -20.000000. running mean: -20.093629\n",
            "resetting env. episode 1014.000000, reward total was -21.000000. running mean: -20.102693\n",
            "resetting env. episode 1015.000000, reward total was -19.000000. running mean: -20.091666\n",
            "resetting env. episode 1016.000000, reward total was -19.000000. running mean: -20.080749\n",
            "resetting env. episode 1017.000000, reward total was -20.000000. running mean: -20.079942\n",
            "resetting env. episode 1018.000000, reward total was -21.000000. running mean: -20.089143\n",
            "resetting env. episode 1019.000000, reward total was -19.000000. running mean: -20.078251\n",
            "resetting env. episode 1020.000000, reward total was -19.000000. running mean: -20.067469\n",
            "resetting env. episode 1021.000000, reward total was -21.000000. running mean: -20.076794\n",
            "resetting env. episode 1022.000000, reward total was -21.000000. running mean: -20.086026\n",
            "resetting env. episode 1023.000000, reward total was -20.000000. running mean: -20.085166\n",
            "resetting env. episode 1024.000000, reward total was -20.000000. running mean: -20.084314\n",
            "resetting env. episode 1025.000000, reward total was -18.000000. running mean: -20.063471\n",
            "resetting env. episode 1026.000000, reward total was -20.000000. running mean: -20.062836\n",
            "resetting env. episode 1027.000000, reward total was -19.000000. running mean: -20.052208\n",
            "resetting env. episode 1028.000000, reward total was -21.000000. running mean: -20.061686\n",
            "resetting env. episode 1029.000000, reward total was -18.000000. running mean: -20.041069\n",
            "resetting env. episode 1030.000000, reward total was -21.000000. running mean: -20.050658\n",
            "resetting env. episode 1031.000000, reward total was -20.000000. running mean: -20.050152\n",
            "resetting env. episode 1032.000000, reward total was -20.000000. running mean: -20.049650\n",
            "resetting env. episode 1033.000000, reward total was -21.000000. running mean: -20.059154\n",
            "resetting env. episode 1034.000000, reward total was -20.000000. running mean: -20.058562\n",
            "resetting env. episode 1035.000000, reward total was -19.000000. running mean: -20.047976\n",
            "resetting env. episode 1036.000000, reward total was -19.000000. running mean: -20.037497\n",
            "resetting env. episode 1037.000000, reward total was -18.000000. running mean: -20.017122\n",
            "resetting env. episode 1038.000000, reward total was -21.000000. running mean: -20.026951\n",
            "resetting env. episode 1039.000000, reward total was -21.000000. running mean: -20.036681\n",
            "resetting env. episode 1040.000000, reward total was -20.000000. running mean: -20.036314\n",
            "resetting env. episode 1041.000000, reward total was -19.000000. running mean: -20.025951\n",
            "resetting env. episode 1042.000000, reward total was -20.000000. running mean: -20.025692\n",
            "resetting env. episode 1043.000000, reward total was -21.000000. running mean: -20.035435\n",
            "resetting env. episode 1044.000000, reward total was -20.000000. running mean: -20.035080\n",
            "resetting env. episode 1045.000000, reward total was -20.000000. running mean: -20.034729\n",
            "resetting env. episode 1046.000000, reward total was -19.000000. running mean: -20.024382\n",
            "resetting env. episode 1047.000000, reward total was -18.000000. running mean: -20.004138\n",
            "resetting env. episode 1048.000000, reward total was -18.000000. running mean: -19.984097\n",
            "resetting env. episode 1049.000000, reward total was -20.000000. running mean: -19.984256\n",
            "resetting env. episode 1050.000000, reward total was -20.000000. running mean: -19.984413\n",
            "resetting env. episode 1051.000000, reward total was -19.000000. running mean: -19.974569\n",
            "resetting env. episode 1052.000000, reward total was -20.000000. running mean: -19.974824\n",
            "resetting env. episode 1053.000000, reward total was -20.000000. running mean: -19.975075\n",
            "resetting env. episode 1054.000000, reward total was -19.000000. running mean: -19.965325\n",
            "resetting env. episode 1055.000000, reward total was -20.000000. running mean: -19.965671\n",
            "resetting env. episode 1056.000000, reward total was -21.000000. running mean: -19.976015\n",
            "resetting env. episode 1057.000000, reward total was -18.000000. running mean: -19.956255\n",
            "resetting env. episode 1058.000000, reward total was -20.000000. running mean: -19.956692\n",
            "resetting env. episode 1059.000000, reward total was -17.000000. running mean: -19.927125\n",
            "resetting env. episode 1060.000000, reward total was -21.000000. running mean: -19.937854\n",
            "resetting env. episode 1061.000000, reward total was -21.000000. running mean: -19.948475\n",
            "resetting env. episode 1062.000000, reward total was -20.000000. running mean: -19.948991\n",
            "resetting env. episode 1063.000000, reward total was -20.000000. running mean: -19.949501\n",
            "resetting env. episode 1064.000000, reward total was -21.000000. running mean: -19.960006\n",
            "resetting env. episode 1065.000000, reward total was -20.000000. running mean: -19.960406\n",
            "resetting env. episode 1066.000000, reward total was -21.000000. running mean: -19.970801\n",
            "resetting env. episode 1067.000000, reward total was -18.000000. running mean: -19.951093\n",
            "resetting env. episode 1068.000000, reward total was -21.000000. running mean: -19.961583\n",
            "resetting env. episode 1069.000000, reward total was -20.000000. running mean: -19.961967\n",
            "resetting env. episode 1070.000000, reward total was -20.000000. running mean: -19.962347\n",
            "resetting env. episode 1071.000000, reward total was -20.000000. running mean: -19.962724\n",
            "resetting env. episode 1072.000000, reward total was -19.000000. running mean: -19.953096\n",
            "resetting env. episode 1073.000000, reward total was -21.000000. running mean: -19.963565\n",
            "resetting env. episode 1074.000000, reward total was -20.000000. running mean: -19.963930\n",
            "resetting env. episode 1075.000000, reward total was -21.000000. running mean: -19.974290\n",
            "resetting env. episode 1076.000000, reward total was -20.000000. running mean: -19.974548\n",
            "resetting env. episode 1077.000000, reward total was -21.000000. running mean: -19.984802\n",
            "resetting env. episode 1078.000000, reward total was -21.000000. running mean: -19.994954\n",
            "resetting env. episode 1079.000000, reward total was -21.000000. running mean: -20.005004\n",
            "resetting env. episode 1080.000000, reward total was -21.000000. running mean: -20.014954\n",
            "resetting env. episode 1081.000000, reward total was -19.000000. running mean: -20.004805\n",
            "resetting env. episode 1082.000000, reward total was -20.000000. running mean: -20.004757\n",
            "resetting env. episode 1083.000000, reward total was -21.000000. running mean: -20.014709\n",
            "resetting env. episode 1084.000000, reward total was -21.000000. running mean: -20.024562\n",
            "resetting env. episode 1085.000000, reward total was -20.000000. running mean: -20.024317\n",
            "resetting env. episode 1086.000000, reward total was -21.000000. running mean: -20.034073\n",
            "resetting env. episode 1087.000000, reward total was -21.000000. running mean: -20.043733\n",
            "resetting env. episode 1088.000000, reward total was -21.000000. running mean: -20.053295\n",
            "resetting env. episode 1089.000000, reward total was -18.000000. running mean: -20.032762\n",
            "resetting env. episode 1090.000000, reward total was -19.000000. running mean: -20.022435\n",
            "resetting env. episode 1091.000000, reward total was -21.000000. running mean: -20.032210\n",
            "resetting env. episode 1092.000000, reward total was -21.000000. running mean: -20.041888\n",
            "resetting env. episode 1093.000000, reward total was -21.000000. running mean: -20.051469\n",
            "resetting env. episode 1094.000000, reward total was -19.000000. running mean: -20.040955\n",
            "resetting env. episode 1095.000000, reward total was -20.000000. running mean: -20.040545\n",
            "resetting env. episode 1096.000000, reward total was -20.000000. running mean: -20.040140\n",
            "resetting env. episode 1097.000000, reward total was -20.000000. running mean: -20.039738\n",
            "resetting env. episode 1098.000000, reward total was -19.000000. running mean: -20.029341\n",
            "resetting env. episode 1099.000000, reward total was -20.000000. running mean: -20.029048\n",
            "resetting env. episode 1100.000000, reward total was -21.000000. running mean: -20.038757\n",
            "resetting env. episode 1101.000000, reward total was -20.000000. running mean: -20.038370\n",
            "resetting env. episode 1102.000000, reward total was -21.000000. running mean: -20.047986\n",
            "resetting env. episode 1103.000000, reward total was -20.000000. running mean: -20.047506\n",
            "resetting env. episode 1104.000000, reward total was -19.000000. running mean: -20.037031\n",
            "resetting env. episode 1105.000000, reward total was -21.000000. running mean: -20.046661\n",
            "resetting env. episode 1106.000000, reward total was -21.000000. running mean: -20.056194\n",
            "resetting env. episode 1107.000000, reward total was -20.000000. running mean: -20.055632\n",
            "resetting env. episode 1108.000000, reward total was -21.000000. running mean: -20.065076\n",
            "resetting env. episode 1109.000000, reward total was -20.000000. running mean: -20.064425\n",
            "resetting env. episode 1110.000000, reward total was -21.000000. running mean: -20.073781\n",
            "resetting env. episode 1111.000000, reward total was -20.000000. running mean: -20.073043\n",
            "resetting env. episode 1112.000000, reward total was -21.000000. running mean: -20.082312\n",
            "resetting env. episode 1113.000000, reward total was -21.000000. running mean: -20.091489\n",
            "resetting env. episode 1114.000000, reward total was -19.000000. running mean: -20.080574\n",
            "resetting env. episode 1115.000000, reward total was -19.000000. running mean: -20.069769\n",
            "resetting env. episode 1116.000000, reward total was -21.000000. running mean: -20.079071\n",
            "resetting env. episode 1117.000000, reward total was -20.000000. running mean: -20.078280\n",
            "resetting env. episode 1118.000000, reward total was -21.000000. running mean: -20.087498\n",
            "resetting env. episode 1119.000000, reward total was -19.000000. running mean: -20.076623\n",
            "resetting env. episode 1120.000000, reward total was -19.000000. running mean: -20.065856\n",
            "resetting env. episode 1121.000000, reward total was -20.000000. running mean: -20.065198\n",
            "resetting env. episode 1122.000000, reward total was -19.000000. running mean: -20.054546\n",
            "resetting env. episode 1123.000000, reward total was -21.000000. running mean: -20.064000\n",
            "resetting env. episode 1124.000000, reward total was -18.000000. running mean: -20.043360\n",
            "resetting env. episode 1125.000000, reward total was -19.000000. running mean: -20.032927\n",
            "resetting env. episode 1126.000000, reward total was -21.000000. running mean: -20.042597\n",
            "resetting env. episode 1127.000000, reward total was -19.000000. running mean: -20.032171\n",
            "resetting env. episode 1128.000000, reward total was -21.000000. running mean: -20.041850\n",
            "resetting env. episode 1129.000000, reward total was -21.000000. running mean: -20.051431\n",
            "resetting env. episode 1130.000000, reward total was -21.000000. running mean: -20.060917\n",
            "resetting env. episode 1131.000000, reward total was -21.000000. running mean: -20.070308\n",
            "resetting env. episode 1132.000000, reward total was -21.000000. running mean: -20.079605\n",
            "resetting env. episode 1133.000000, reward total was -21.000000. running mean: -20.088809\n",
            "resetting env. episode 1134.000000, reward total was -20.000000. running mean: -20.087921\n",
            "resetting env. episode 1135.000000, reward total was -20.000000. running mean: -20.087041\n",
            "resetting env. episode 1136.000000, reward total was -20.000000. running mean: -20.086171\n",
            "resetting env. episode 1137.000000, reward total was -20.000000. running mean: -20.085309\n",
            "resetting env. episode 1138.000000, reward total was -21.000000. running mean: -20.094456\n",
            "resetting env. episode 1139.000000, reward total was -21.000000. running mean: -20.103512\n",
            "resetting env. episode 1140.000000, reward total was -20.000000. running mean: -20.102476\n",
            "resetting env. episode 1141.000000, reward total was -20.000000. running mean: -20.101452\n",
            "resetting env. episode 1142.000000, reward total was -20.000000. running mean: -20.100437\n",
            "resetting env. episode 1143.000000, reward total was -19.000000. running mean: -20.089433\n",
            "resetting env. episode 1144.000000, reward total was -21.000000. running mean: -20.098538\n",
            "resetting env. episode 1145.000000, reward total was -20.000000. running mean: -20.097553\n",
            "resetting env. episode 1146.000000, reward total was -20.000000. running mean: -20.096578\n",
            "resetting env. episode 1147.000000, reward total was -21.000000. running mean: -20.105612\n",
            "resetting env. episode 1148.000000, reward total was -19.000000. running mean: -20.094556\n",
            "resetting env. episode 1149.000000, reward total was -19.000000. running mean: -20.083610\n",
            "resetting env. episode 1150.000000, reward total was -21.000000. running mean: -20.092774\n",
            "resetting env. episode 1151.000000, reward total was -20.000000. running mean: -20.091846\n",
            "resetting env. episode 1152.000000, reward total was -21.000000. running mean: -20.100928\n",
            "resetting env. episode 1153.000000, reward total was -21.000000. running mean: -20.109919\n",
            "resetting env. episode 1154.000000, reward total was -21.000000. running mean: -20.118819\n",
            "resetting env. episode 1155.000000, reward total was -19.000000. running mean: -20.107631\n",
            "resetting env. episode 1156.000000, reward total was -19.000000. running mean: -20.096555\n",
            "resetting env. episode 1157.000000, reward total was -20.000000. running mean: -20.095589\n",
            "resetting env. episode 1158.000000, reward total was -20.000000. running mean: -20.094633\n",
            "resetting env. episode 1159.000000, reward total was -19.000000. running mean: -20.083687\n",
            "resetting env. episode 1160.000000, reward total was -21.000000. running mean: -20.092850\n",
            "resetting env. episode 1161.000000, reward total was -19.000000. running mean: -20.081922\n",
            "resetting env. episode 1162.000000, reward total was -19.000000. running mean: -20.071102\n",
            "resetting env. episode 1163.000000, reward total was -21.000000. running mean: -20.080391\n",
            "resetting env. episode 1164.000000, reward total was -20.000000. running mean: -20.079588\n",
            "resetting env. episode 1165.000000, reward total was -19.000000. running mean: -20.068792\n",
            "resetting env. episode 1166.000000, reward total was -21.000000. running mean: -20.078104\n",
            "resetting env. episode 1167.000000, reward total was -19.000000. running mean: -20.067323\n",
            "resetting env. episode 1168.000000, reward total was -20.000000. running mean: -20.066649\n",
            "resetting env. episode 1169.000000, reward total was -21.000000. running mean: -20.075983\n",
            "resetting env. episode 1170.000000, reward total was -20.000000. running mean: -20.075223\n",
            "resetting env. episode 1171.000000, reward total was -19.000000. running mean: -20.064471\n",
            "resetting env. episode 1172.000000, reward total was -19.000000. running mean: -20.053826\n",
            "resetting env. episode 1173.000000, reward total was -21.000000. running mean: -20.063288\n",
            "resetting env. episode 1174.000000, reward total was -21.000000. running mean: -20.072655\n",
            "resetting env. episode 1175.000000, reward total was -21.000000. running mean: -20.081929\n",
            "resetting env. episode 1176.000000, reward total was -17.000000. running mean: -20.051109\n",
            "resetting env. episode 1177.000000, reward total was -21.000000. running mean: -20.060598\n",
            "resetting env. episode 1178.000000, reward total was -20.000000. running mean: -20.059992\n",
            "resetting env. episode 1179.000000, reward total was -20.000000. running mean: -20.059392\n",
            "resetting env. episode 1180.000000, reward total was -20.000000. running mean: -20.058798\n",
            "resetting env. episode 1181.000000, reward total was -20.000000. running mean: -20.058210\n",
            "resetting env. episode 1182.000000, reward total was -20.000000. running mean: -20.057628\n",
            "resetting env. episode 1183.000000, reward total was -21.000000. running mean: -20.067052\n",
            "resetting env. episode 1184.000000, reward total was -19.000000. running mean: -20.056381\n",
            "resetting env. episode 1185.000000, reward total was -21.000000. running mean: -20.065818\n",
            "resetting env. episode 1186.000000, reward total was -20.000000. running mean: -20.065159\n",
            "resetting env. episode 1187.000000, reward total was -21.000000. running mean: -20.074508\n",
            "resetting env. episode 1188.000000, reward total was -21.000000. running mean: -20.083763\n",
            "resetting env. episode 1189.000000, reward total was -21.000000. running mean: -20.092925\n",
            "resetting env. episode 1190.000000, reward total was -21.000000. running mean: -20.101996\n",
            "resetting env. episode 1191.000000, reward total was -19.000000. running mean: -20.090976\n",
            "resetting env. episode 1192.000000, reward total was -20.000000. running mean: -20.090066\n",
            "resetting env. episode 1193.000000, reward total was -20.000000. running mean: -20.089166\n",
            "resetting env. episode 1194.000000, reward total was -19.000000. running mean: -20.078274\n",
            "resetting env. episode 1195.000000, reward total was -20.000000. running mean: -20.077491\n",
            "resetting env. episode 1196.000000, reward total was -21.000000. running mean: -20.086716\n",
            "resetting env. episode 1197.000000, reward total was -20.000000. running mean: -20.085849\n",
            "resetting env. episode 1198.000000, reward total was -21.000000. running mean: -20.094991\n",
            "resetting env. episode 1199.000000, reward total was -19.000000. running mean: -20.084041\n",
            "resetting env. episode 1200.000000, reward total was -20.000000. running mean: -20.083200\n",
            "resetting env. episode 1201.000000, reward total was -18.000000. running mean: -20.062368\n",
            "resetting env. episode 1202.000000, reward total was -21.000000. running mean: -20.071745\n",
            "resetting env. episode 1203.000000, reward total was -19.000000. running mean: -20.061027\n",
            "resetting env. episode 1204.000000, reward total was -21.000000. running mean: -20.070417\n",
            "resetting env. episode 1205.000000, reward total was -21.000000. running mean: -20.079713\n",
            "resetting env. episode 1206.000000, reward total was -21.000000. running mean: -20.088916\n",
            "resetting env. episode 1207.000000, reward total was -21.000000. running mean: -20.098026\n",
            "resetting env. episode 1208.000000, reward total was -21.000000. running mean: -20.107046\n",
            "resetting env. episode 1209.000000, reward total was -21.000000. running mean: -20.115976\n",
            "resetting env. episode 1210.000000, reward total was -20.000000. running mean: -20.114816\n",
            "resetting env. episode 1211.000000, reward total was -21.000000. running mean: -20.123668\n",
            "resetting env. episode 1212.000000, reward total was -20.000000. running mean: -20.122431\n",
            "resetting env. episode 1213.000000, reward total was -21.000000. running mean: -20.131207\n",
            "resetting env. episode 1214.000000, reward total was -17.000000. running mean: -20.099895\n",
            "resetting env. episode 1215.000000, reward total was -21.000000. running mean: -20.108896\n",
            "resetting env. episode 1216.000000, reward total was -19.000000. running mean: -20.097807\n",
            "resetting env. episode 1217.000000, reward total was -20.000000. running mean: -20.096829\n",
            "resetting env. episode 1218.000000, reward total was -20.000000. running mean: -20.095860\n",
            "resetting env. episode 1219.000000, reward total was -20.000000. running mean: -20.094902\n",
            "resetting env. episode 1220.000000, reward total was -20.000000. running mean: -20.093953\n",
            "resetting env. episode 1221.000000, reward total was -21.000000. running mean: -20.103013\n",
            "resetting env. episode 1222.000000, reward total was -18.000000. running mean: -20.081983\n",
            "resetting env. episode 1223.000000, reward total was -21.000000. running mean: -20.091163\n",
            "resetting env. episode 1224.000000, reward total was -20.000000. running mean: -20.090252\n",
            "resetting env. episode 1225.000000, reward total was -20.000000. running mean: -20.089349\n",
            "resetting env. episode 1226.000000, reward total was -21.000000. running mean: -20.098456\n",
            "resetting env. episode 1227.000000, reward total was -19.000000. running mean: -20.087471\n",
            "resetting env. episode 1228.000000, reward total was -21.000000. running mean: -20.096596\n",
            "resetting env. episode 1229.000000, reward total was -20.000000. running mean: -20.095630\n",
            "resetting env. episode 1230.000000, reward total was -20.000000. running mean: -20.094674\n",
            "resetting env. episode 1231.000000, reward total was -20.000000. running mean: -20.093727\n",
            "resetting env. episode 1232.000000, reward total was -20.000000. running mean: -20.092790\n",
            "resetting env. episode 1233.000000, reward total was -20.000000. running mean: -20.091862\n",
            "resetting env. episode 1234.000000, reward total was -20.000000. running mean: -20.090944\n",
            "resetting env. episode 1235.000000, reward total was -20.000000. running mean: -20.090034\n",
            "resetting env. episode 1236.000000, reward total was -19.000000. running mean: -20.079134\n",
            "resetting env. episode 1237.000000, reward total was -20.000000. running mean: -20.078342\n",
            "resetting env. episode 1238.000000, reward total was -18.000000. running mean: -20.057559\n",
            "resetting env. episode 1239.000000, reward total was -20.000000. running mean: -20.056983\n",
            "resetting env. episode 1240.000000, reward total was -19.000000. running mean: -20.046414\n",
            "resetting env. episode 1241.000000, reward total was -20.000000. running mean: -20.045949\n",
            "resetting env. episode 1242.000000, reward total was -20.000000. running mean: -20.045490\n",
            "resetting env. episode 1243.000000, reward total was -20.000000. running mean: -20.045035\n",
            "resetting env. episode 1244.000000, reward total was -21.000000. running mean: -20.054585\n",
            "resetting env. episode 1245.000000, reward total was -19.000000. running mean: -20.044039\n",
            "resetting env. episode 1246.000000, reward total was -21.000000. running mean: -20.053599\n",
            "resetting env. episode 1247.000000, reward total was -21.000000. running mean: -20.063063\n",
            "resetting env. episode 1248.000000, reward total was -20.000000. running mean: -20.062432\n",
            "resetting env. episode 1249.000000, reward total was -21.000000. running mean: -20.071808\n",
            "resetting env. episode 1250.000000, reward total was -21.000000. running mean: -20.081090\n",
            "resetting env. episode 1251.000000, reward total was -19.000000. running mean: -20.070279\n",
            "resetting env. episode 1252.000000, reward total was -21.000000. running mean: -20.079576\n",
            "resetting env. episode 1253.000000, reward total was -20.000000. running mean: -20.078780\n",
            "resetting env. episode 1254.000000, reward total was -21.000000. running mean: -20.087992\n",
            "resetting env. episode 1255.000000, reward total was -21.000000. running mean: -20.097112\n",
            "resetting env. episode 1256.000000, reward total was -20.000000. running mean: -20.096141\n",
            "resetting env. episode 1257.000000, reward total was -20.000000. running mean: -20.095180\n",
            "resetting env. episode 1258.000000, reward total was -20.000000. running mean: -20.094228\n",
            "resetting env. episode 1259.000000, reward total was -19.000000. running mean: -20.083286\n",
            "resetting env. episode 1260.000000, reward total was -19.000000. running mean: -20.072453\n",
            "resetting env. episode 1261.000000, reward total was -18.000000. running mean: -20.051728\n",
            "resetting env. episode 1262.000000, reward total was -21.000000. running mean: -20.061211\n",
            "resetting env. episode 1263.000000, reward total was -20.000000. running mean: -20.060599\n",
            "resetting env. episode 1264.000000, reward total was -18.000000. running mean: -20.039993\n",
            "resetting env. episode 1265.000000, reward total was -21.000000. running mean: -20.049593\n",
            "resetting env. episode 1266.000000, reward total was -21.000000. running mean: -20.059097\n",
            "resetting env. episode 1267.000000, reward total was -20.000000. running mean: -20.058506\n",
            "resetting env. episode 1268.000000, reward total was -19.000000. running mean: -20.047921\n",
            "resetting env. episode 1269.000000, reward total was -20.000000. running mean: -20.047442\n",
            "resetting env. episode 1270.000000, reward total was -17.000000. running mean: -20.016967\n",
            "resetting env. episode 1271.000000, reward total was -19.000000. running mean: -20.006798\n",
            "resetting env. episode 1272.000000, reward total was -21.000000. running mean: -20.016730\n",
            "resetting env. episode 1273.000000, reward total was -21.000000. running mean: -20.026562\n",
            "resetting env. episode 1274.000000, reward total was -20.000000. running mean: -20.026297\n",
            "resetting env. episode 1275.000000, reward total was -20.000000. running mean: -20.026034\n",
            "resetting env. episode 1276.000000, reward total was -21.000000. running mean: -20.035774\n",
            "resetting env. episode 1277.000000, reward total was -20.000000. running mean: -20.035416\n",
            "resetting env. episode 1278.000000, reward total was -21.000000. running mean: -20.045062\n",
            "resetting env. episode 1279.000000, reward total was -19.000000. running mean: -20.034611\n",
            "resetting env. episode 1280.000000, reward total was -19.000000. running mean: -20.024265\n",
            "resetting env. episode 1281.000000, reward total was -21.000000. running mean: -20.034022\n",
            "resetting env. episode 1282.000000, reward total was -20.000000. running mean: -20.033682\n",
            "resetting env. episode 1283.000000, reward total was -21.000000. running mean: -20.043345\n",
            "resetting env. episode 1284.000000, reward total was -20.000000. running mean: -20.042912\n",
            "resetting env. episode 1285.000000, reward total was -21.000000. running mean: -20.052483\n",
            "resetting env. episode 1286.000000, reward total was -18.000000. running mean: -20.031958\n",
            "resetting env. episode 1287.000000, reward total was -20.000000. running mean: -20.031638\n",
            "resetting env. episode 1288.000000, reward total was -20.000000. running mean: -20.031322\n",
            "resetting env. episode 1289.000000, reward total was -21.000000. running mean: -20.041009\n",
            "resetting env. episode 1290.000000, reward total was -20.000000. running mean: -20.040599\n",
            "resetting env. episode 1291.000000, reward total was -21.000000. running mean: -20.050193\n",
            "resetting env. episode 1292.000000, reward total was -17.000000. running mean: -20.019691\n",
            "resetting env. episode 1293.000000, reward total was -21.000000. running mean: -20.029494\n",
            "resetting env. episode 1294.000000, reward total was -18.000000. running mean: -20.009199\n",
            "resetting env. episode 1295.000000, reward total was -21.000000. running mean: -20.019107\n",
            "resetting env. episode 1296.000000, reward total was -20.000000. running mean: -20.018916\n",
            "resetting env. episode 1297.000000, reward total was -19.000000. running mean: -20.008727\n",
            "resetting env. episode 1298.000000, reward total was -21.000000. running mean: -20.018639\n",
            "resetting env. episode 1299.000000, reward total was -20.000000. running mean: -20.018453\n",
            "resetting env. episode 1300.000000, reward total was -21.000000. running mean: -20.028268\n",
            "resetting env. episode 1301.000000, reward total was -21.000000. running mean: -20.037986\n",
            "resetting env. episode 1302.000000, reward total was -20.000000. running mean: -20.037606\n",
            "resetting env. episode 1303.000000, reward total was -21.000000. running mean: -20.047230\n",
            "resetting env. episode 1304.000000, reward total was -21.000000. running mean: -20.056758\n",
            "resetting env. episode 1305.000000, reward total was -21.000000. running mean: -20.066190\n",
            "resetting env. episode 1306.000000, reward total was -21.000000. running mean: -20.075528\n",
            "resetting env. episode 1307.000000, reward total was -20.000000. running mean: -20.074773\n",
            "resetting env. episode 1308.000000, reward total was -21.000000. running mean: -20.084025\n",
            "resetting env. episode 1309.000000, reward total was -21.000000. running mean: -20.093185\n",
            "resetting env. episode 1310.000000, reward total was -20.000000. running mean: -20.092253\n",
            "resetting env. episode 1311.000000, reward total was -20.000000. running mean: -20.091330\n",
            "resetting env. episode 1312.000000, reward total was -21.000000. running mean: -20.100417\n",
            "resetting env. episode 1313.000000, reward total was -21.000000. running mean: -20.109413\n",
            "resetting env. episode 1314.000000, reward total was -20.000000. running mean: -20.108319\n",
            "resetting env. episode 1315.000000, reward total was -19.000000. running mean: -20.097236\n",
            "resetting env. episode 1316.000000, reward total was -20.000000. running mean: -20.096263\n",
            "resetting env. episode 1317.000000, reward total was -21.000000. running mean: -20.105301\n",
            "resetting env. episode 1318.000000, reward total was -21.000000. running mean: -20.114248\n",
            "resetting env. episode 1319.000000, reward total was -19.000000. running mean: -20.103105\n",
            "resetting env. episode 1320.000000, reward total was -20.000000. running mean: -20.102074\n",
            "resetting env. episode 1321.000000, reward total was -20.000000. running mean: -20.101053\n",
            "resetting env. episode 1322.000000, reward total was -20.000000. running mean: -20.100043\n",
            "resetting env. episode 1323.000000, reward total was -21.000000. running mean: -20.109042\n",
            "resetting env. episode 1324.000000, reward total was -20.000000. running mean: -20.107952\n",
            "resetting env. episode 1325.000000, reward total was -19.000000. running mean: -20.096872\n",
            "resetting env. episode 1326.000000, reward total was -21.000000. running mean: -20.105904\n",
            "resetting env. episode 1327.000000, reward total was -21.000000. running mean: -20.114845\n",
            "resetting env. episode 1328.000000, reward total was -21.000000. running mean: -20.123696\n",
            "resetting env. episode 1329.000000, reward total was -20.000000. running mean: -20.122459\n",
            "resetting env. episode 1330.000000, reward total was -21.000000. running mean: -20.131235\n",
            "resetting env. episode 1331.000000, reward total was -21.000000. running mean: -20.139922\n",
            "resetting env. episode 1332.000000, reward total was -20.000000. running mean: -20.138523\n",
            "resetting env. episode 1333.000000, reward total was -18.000000. running mean: -20.117138\n",
            "resetting env. episode 1334.000000, reward total was -19.000000. running mean: -20.105967\n",
            "resetting env. episode 1335.000000, reward total was -17.000000. running mean: -20.074907\n",
            "resetting env. episode 1336.000000, reward total was -21.000000. running mean: -20.084158\n",
            "resetting env. episode 1337.000000, reward total was -21.000000. running mean: -20.093316\n",
            "resetting env. episode 1338.000000, reward total was -21.000000. running mean: -20.102383\n",
            "resetting env. episode 1339.000000, reward total was -20.000000. running mean: -20.101359\n",
            "resetting env. episode 1340.000000, reward total was -21.000000. running mean: -20.110346\n",
            "resetting env. episode 1341.000000, reward total was -21.000000. running mean: -20.119242\n",
            "resetting env. episode 1342.000000, reward total was -20.000000. running mean: -20.118050\n",
            "resetting env. episode 1343.000000, reward total was -20.000000. running mean: -20.116869\n",
            "resetting env. episode 1344.000000, reward total was -20.000000. running mean: -20.115701\n",
            "resetting env. episode 1345.000000, reward total was -20.000000. running mean: -20.114544\n",
            "resetting env. episode 1346.000000, reward total was -21.000000. running mean: -20.123398\n",
            "resetting env. episode 1347.000000, reward total was -20.000000. running mean: -20.122164\n",
            "resetting env. episode 1348.000000, reward total was -21.000000. running mean: -20.130942\n",
            "resetting env. episode 1349.000000, reward total was -19.000000. running mean: -20.119633\n",
            "resetting env. episode 1350.000000, reward total was -19.000000. running mean: -20.108437\n",
            "resetting env. episode 1351.000000, reward total was -21.000000. running mean: -20.117352\n",
            "resetting env. episode 1352.000000, reward total was -21.000000. running mean: -20.126179\n",
            "resetting env. episode 1353.000000, reward total was -21.000000. running mean: -20.134917\n",
            "resetting env. episode 1354.000000, reward total was -20.000000. running mean: -20.133568\n",
            "resetting env. episode 1355.000000, reward total was -18.000000. running mean: -20.112232\n",
            "resetting env. episode 1356.000000, reward total was -20.000000. running mean: -20.111110\n",
            "resetting env. episode 1357.000000, reward total was -21.000000. running mean: -20.119999\n",
            "resetting env. episode 1358.000000, reward total was -20.000000. running mean: -20.118799\n",
            "resetting env. episode 1359.000000, reward total was -17.000000. running mean: -20.087611\n",
            "resetting env. episode 1360.000000, reward total was -19.000000. running mean: -20.076735\n",
            "resetting env. episode 1361.000000, reward total was -21.000000. running mean: -20.085967\n",
            "resetting env. episode 1362.000000, reward total was -21.000000. running mean: -20.095108\n",
            "resetting env. episode 1363.000000, reward total was -20.000000. running mean: -20.094157\n",
            "resetting env. episode 1364.000000, reward total was -20.000000. running mean: -20.093215\n",
            "resetting env. episode 1365.000000, reward total was -21.000000. running mean: -20.102283\n",
            "resetting env. episode 1366.000000, reward total was -21.000000. running mean: -20.111260\n",
            "resetting env. episode 1367.000000, reward total was -20.000000. running mean: -20.110147\n",
            "resetting env. episode 1368.000000, reward total was -19.000000. running mean: -20.099046\n",
            "resetting env. episode 1369.000000, reward total was -18.000000. running mean: -20.078056\n",
            "resetting env. episode 1370.000000, reward total was -20.000000. running mean: -20.077275\n",
            "resetting env. episode 1371.000000, reward total was -21.000000. running mean: -20.086502\n",
            "resetting env. episode 1372.000000, reward total was -19.000000. running mean: -20.075637\n",
            "resetting env. episode 1373.000000, reward total was -19.000000. running mean: -20.064881\n",
            "resetting env. episode 1374.000000, reward total was -18.000000. running mean: -20.044232\n",
            "resetting env. episode 1375.000000, reward total was -19.000000. running mean: -20.033790\n",
            "resetting env. episode 1376.000000, reward total was -19.000000. running mean: -20.023452\n",
            "resetting env. episode 1377.000000, reward total was -19.000000. running mean: -20.013217\n",
            "resetting env. episode 1378.000000, reward total was -21.000000. running mean: -20.023085\n",
            "resetting env. episode 1379.000000, reward total was -20.000000. running mean: -20.022854\n",
            "resetting env. episode 1380.000000, reward total was -19.000000. running mean: -20.012626\n",
            "resetting env. episode 1381.000000, reward total was -21.000000. running mean: -20.022499\n",
            "resetting env. episode 1382.000000, reward total was -21.000000. running mean: -20.032274\n",
            "resetting env. episode 1383.000000, reward total was -20.000000. running mean: -20.031952\n",
            "resetting env. episode 1384.000000, reward total was -19.000000. running mean: -20.021632\n",
            "resetting env. episode 1385.000000, reward total was -21.000000. running mean: -20.031416\n",
            "resetting env. episode 1386.000000, reward total was -20.000000. running mean: -20.031102\n",
            "resetting env. episode 1387.000000, reward total was -19.000000. running mean: -20.020791\n",
            "resetting env. episode 1388.000000, reward total was -21.000000. running mean: -20.030583\n",
            "resetting env. episode 1389.000000, reward total was -19.000000. running mean: -20.020277\n",
            "resetting env. episode 1390.000000, reward total was -21.000000. running mean: -20.030074\n",
            "resetting env. episode 1391.000000, reward total was -19.000000. running mean: -20.019773\n",
            "resetting env. episode 1392.000000, reward total was -21.000000. running mean: -20.029576\n",
            "resetting env. episode 1393.000000, reward total was -20.000000. running mean: -20.029280\n",
            "resetting env. episode 1394.000000, reward total was -17.000000. running mean: -19.998987\n",
            "resetting env. episode 1395.000000, reward total was -21.000000. running mean: -20.008997\n",
            "resetting env. episode 1396.000000, reward total was -20.000000. running mean: -20.008907\n",
            "resetting env. episode 1397.000000, reward total was -20.000000. running mean: -20.008818\n",
            "resetting env. episode 1398.000000, reward total was -19.000000. running mean: -19.998730\n",
            "resetting env. episode 1399.000000, reward total was -21.000000. running mean: -20.008743\n",
            "resetting env. episode 1400.000000, reward total was -18.000000. running mean: -19.988655\n",
            "resetting env. episode 1401.000000, reward total was -21.000000. running mean: -19.998769\n",
            "resetting env. episode 1402.000000, reward total was -20.000000. running mean: -19.998781\n",
            "resetting env. episode 1403.000000, reward total was -20.000000. running mean: -19.998793\n",
            "resetting env. episode 1404.000000, reward total was -20.000000. running mean: -19.998805\n",
            "resetting env. episode 1405.000000, reward total was -19.000000. running mean: -19.988817\n",
            "resetting env. episode 1406.000000, reward total was -20.000000. running mean: -19.988929\n",
            "resetting env. episode 1407.000000, reward total was -19.000000. running mean: -19.979040\n",
            "resetting env. episode 1408.000000, reward total was -19.000000. running mean: -19.969249\n",
            "resetting env. episode 1409.000000, reward total was -20.000000. running mean: -19.969557\n",
            "resetting env. episode 1410.000000, reward total was -20.000000. running mean: -19.969861\n",
            "resetting env. episode 1411.000000, reward total was -21.000000. running mean: -19.980163\n",
            "resetting env. episode 1412.000000, reward total was -19.000000. running mean: -19.970361\n",
            "resetting env. episode 1413.000000, reward total was -20.000000. running mean: -19.970658\n",
            "resetting env. episode 1414.000000, reward total was -21.000000. running mean: -19.980951\n",
            "resetting env. episode 1415.000000, reward total was -20.000000. running mean: -19.981141\n",
            "resetting env. episode 1416.000000, reward total was -21.000000. running mean: -19.991330\n",
            "resetting env. episode 1417.000000, reward total was -21.000000. running mean: -20.001417\n",
            "resetting env. episode 1418.000000, reward total was -21.000000. running mean: -20.011403\n",
            "resetting env. episode 1419.000000, reward total was -21.000000. running mean: -20.021289\n",
            "resetting env. episode 1420.000000, reward total was -21.000000. running mean: -20.031076\n",
            "resetting env. episode 1421.000000, reward total was -21.000000. running mean: -20.040765\n",
            "resetting env. episode 1422.000000, reward total was -21.000000. running mean: -20.050357\n",
            "resetting env. episode 1423.000000, reward total was -20.000000. running mean: -20.049854\n",
            "resetting env. episode 1424.000000, reward total was -21.000000. running mean: -20.059355\n",
            "resetting env. episode 1425.000000, reward total was -21.000000. running mean: -20.068762\n",
            "resetting env. episode 1426.000000, reward total was -19.000000. running mean: -20.058074\n",
            "resetting env. episode 1427.000000, reward total was -21.000000. running mean: -20.067493\n",
            "resetting env. episode 1428.000000, reward total was -21.000000. running mean: -20.076818\n",
            "resetting env. episode 1429.000000, reward total was -19.000000. running mean: -20.066050\n",
            "resetting env. episode 1430.000000, reward total was -21.000000. running mean: -20.075390\n",
            "resetting env. episode 1431.000000, reward total was -20.000000. running mean: -20.074636\n",
            "resetting env. episode 1432.000000, reward total was -17.000000. running mean: -20.043889\n",
            "resetting env. episode 1433.000000, reward total was -21.000000. running mean: -20.053450\n",
            "resetting env. episode 1434.000000, reward total was -19.000000. running mean: -20.042916\n",
            "resetting env. episode 1435.000000, reward total was -21.000000. running mean: -20.052487\n",
            "resetting env. episode 1436.000000, reward total was -20.000000. running mean: -20.051962\n",
            "resetting env. episode 1437.000000, reward total was -18.000000. running mean: -20.031442\n",
            "resetting env. episode 1438.000000, reward total was -20.000000. running mean: -20.031128\n",
            "resetting env. episode 1439.000000, reward total was -20.000000. running mean: -20.030817\n",
            "resetting env. episode 1440.000000, reward total was -16.000000. running mean: -19.990508\n",
            "resetting env. episode 1441.000000, reward total was -20.000000. running mean: -19.990603\n",
            "resetting env. episode 1442.000000, reward total was -20.000000. running mean: -19.990697\n",
            "resetting env. episode 1443.000000, reward total was -21.000000. running mean: -20.000790\n",
            "resetting env. episode 1444.000000, reward total was -21.000000. running mean: -20.010782\n",
            "resetting env. episode 1445.000000, reward total was -18.000000. running mean: -19.990675\n",
            "resetting env. episode 1446.000000, reward total was -21.000000. running mean: -20.000768\n",
            "resetting env. episode 1447.000000, reward total was -21.000000. running mean: -20.010760\n",
            "resetting env. episode 1448.000000, reward total was -20.000000. running mean: -20.010653\n",
            "resetting env. episode 1449.000000, reward total was -21.000000. running mean: -20.020546\n",
            "resetting env. episode 1450.000000, reward total was -20.000000. running mean: -20.020341\n",
            "resetting env. episode 1451.000000, reward total was -18.000000. running mean: -20.000137\n",
            "resetting env. episode 1452.000000, reward total was -21.000000. running mean: -20.010136\n",
            "resetting env. episode 1453.000000, reward total was -21.000000. running mean: -20.020034\n",
            "resetting env. episode 1454.000000, reward total was -21.000000. running mean: -20.029834\n",
            "resetting env. episode 1455.000000, reward total was -20.000000. running mean: -20.029536\n",
            "resetting env. episode 1456.000000, reward total was -20.000000. running mean: -20.029240\n",
            "resetting env. episode 1457.000000, reward total was -20.000000. running mean: -20.028948\n",
            "resetting env. episode 1458.000000, reward total was -20.000000. running mean: -20.028659\n",
            "resetting env. episode 1459.000000, reward total was -19.000000. running mean: -20.018372\n",
            "resetting env. episode 1460.000000, reward total was -18.000000. running mean: -19.998188\n",
            "resetting env. episode 1461.000000, reward total was -21.000000. running mean: -20.008206\n",
            "resetting env. episode 1462.000000, reward total was -20.000000. running mean: -20.008124\n",
            "resetting env. episode 1463.000000, reward total was -21.000000. running mean: -20.018043\n",
            "resetting env. episode 1464.000000, reward total was -20.000000. running mean: -20.017863\n",
            "resetting env. episode 1465.000000, reward total was -20.000000. running mean: -20.017684\n",
            "resetting env. episode 1466.000000, reward total was -18.000000. running mean: -19.997507\n",
            "resetting env. episode 1467.000000, reward total was -21.000000. running mean: -20.007532\n",
            "resetting env. episode 1468.000000, reward total was -20.000000. running mean: -20.007457\n",
            "resetting env. episode 1469.000000, reward total was -21.000000. running mean: -20.017382\n",
            "resetting env. episode 1470.000000, reward total was -20.000000. running mean: -20.017208\n",
            "resetting env. episode 1471.000000, reward total was -20.000000. running mean: -20.017036\n",
            "resetting env. episode 1472.000000, reward total was -18.000000. running mean: -19.996866\n",
            "resetting env. episode 1473.000000, reward total was -20.000000. running mean: -19.996897\n",
            "resetting env. episode 1474.000000, reward total was -21.000000. running mean: -20.006928\n",
            "resetting env. episode 1475.000000, reward total was -21.000000. running mean: -20.016859\n",
            "resetting env. episode 1476.000000, reward total was -19.000000. running mean: -20.006690\n",
            "resetting env. episode 1477.000000, reward total was -21.000000. running mean: -20.016624\n",
            "resetting env. episode 1478.000000, reward total was -20.000000. running mean: -20.016457\n",
            "resetting env. episode 1479.000000, reward total was -20.000000. running mean: -20.016293\n",
            "resetting env. episode 1480.000000, reward total was -20.000000. running mean: -20.016130\n",
            "resetting env. episode 1481.000000, reward total was -21.000000. running mean: -20.025968\n",
            "resetting env. episode 1482.000000, reward total was -20.000000. running mean: -20.025709\n",
            "resetting env. episode 1483.000000, reward total was -18.000000. running mean: -20.005452\n",
            "resetting env. episode 1484.000000, reward total was -20.000000. running mean: -20.005397\n",
            "resetting env. episode 1485.000000, reward total was -21.000000. running mean: -20.015343\n",
            "resetting env. episode 1486.000000, reward total was -20.000000. running mean: -20.015190\n",
            "resetting env. episode 1487.000000, reward total was -20.000000. running mean: -20.015038\n",
            "resetting env. episode 1488.000000, reward total was -21.000000. running mean: -20.024888\n",
            "resetting env. episode 1489.000000, reward total was -21.000000. running mean: -20.034639\n",
            "resetting env. episode 1490.000000, reward total was -19.000000. running mean: -20.024292\n",
            "resetting env. episode 1491.000000, reward total was -21.000000. running mean: -20.034049\n",
            "resetting env. episode 1492.000000, reward total was -21.000000. running mean: -20.043709\n",
            "resetting env. episode 1493.000000, reward total was -20.000000. running mean: -20.043272\n",
            "resetting env. episode 1494.000000, reward total was -20.000000. running mean: -20.042839\n",
            "resetting env. episode 1495.000000, reward total was -20.000000. running mean: -20.042411\n",
            "resetting env. episode 1496.000000, reward total was -21.000000. running mean: -20.051987\n",
            "resetting env. episode 1497.000000, reward total was -21.000000. running mean: -20.061467\n",
            "resetting env. episode 1498.000000, reward total was -20.000000. running mean: -20.060852\n",
            "resetting env. episode 1499.000000, reward total was -21.000000. running mean: -20.070243\n",
            "resetting env. episode 1500.000000, reward total was -21.000000. running mean: -20.079541\n",
            "resetting env. episode 1501.000000, reward total was -19.000000. running mean: -20.068746\n",
            "resetting env. episode 1502.000000, reward total was -20.000000. running mean: -20.068058\n",
            "resetting env. episode 1503.000000, reward total was -18.000000. running mean: -20.047378\n",
            "resetting env. episode 1504.000000, reward total was -21.000000. running mean: -20.056904\n",
            "resetting env. episode 1505.000000, reward total was -21.000000. running mean: -20.066335\n",
            "resetting env. episode 1506.000000, reward total was -20.000000. running mean: -20.065671\n",
            "resetting env. episode 1507.000000, reward total was -18.000000. running mean: -20.045015\n",
            "resetting env. episode 1508.000000, reward total was -21.000000. running mean: -20.054565\n",
            "resetting env. episode 1509.000000, reward total was -20.000000. running mean: -20.054019\n",
            "resetting env. episode 1510.000000, reward total was -20.000000. running mean: -20.053479\n",
            "resetting env. episode 1511.000000, reward total was -21.000000. running mean: -20.062944\n",
            "resetting env. episode 1512.000000, reward total was -21.000000. running mean: -20.072315\n",
            "resetting env. episode 1513.000000, reward total was -21.000000. running mean: -20.081591\n",
            "resetting env. episode 1514.000000, reward total was -19.000000. running mean: -20.070775\n",
            "resetting env. episode 1515.000000, reward total was -20.000000. running mean: -20.070068\n",
            "resetting env. episode 1516.000000, reward total was -18.000000. running mean: -20.049367\n",
            "resetting env. episode 1517.000000, reward total was -21.000000. running mean: -20.058873\n",
            "resetting env. episode 1518.000000, reward total was -21.000000. running mean: -20.068285\n",
            "resetting env. episode 1519.000000, reward total was -19.000000. running mean: -20.057602\n",
            "resetting env. episode 1520.000000, reward total was -20.000000. running mean: -20.057026\n",
            "resetting env. episode 1521.000000, reward total was -20.000000. running mean: -20.056455\n",
            "resetting env. episode 1522.000000, reward total was -18.000000. running mean: -20.035891\n",
            "resetting env. episode 1523.000000, reward total was -19.000000. running mean: -20.025532\n",
            "resetting env. episode 1524.000000, reward total was -19.000000. running mean: -20.015277\n",
            "resetting env. episode 1525.000000, reward total was -20.000000. running mean: -20.015124\n",
            "resetting env. episode 1526.000000, reward total was -21.000000. running mean: -20.024973\n",
            "resetting env. episode 1527.000000, reward total was -20.000000. running mean: -20.024723\n",
            "resetting env. episode 1528.000000, reward total was -20.000000. running mean: -20.024476\n",
            "resetting env. episode 1529.000000, reward total was -21.000000. running mean: -20.034231\n",
            "resetting env. episode 1530.000000, reward total was -18.000000. running mean: -20.013889\n",
            "resetting env. episode 1531.000000, reward total was -20.000000. running mean: -20.013750\n",
            "resetting env. episode 1532.000000, reward total was -20.000000. running mean: -20.013612\n",
            "resetting env. episode 1533.000000, reward total was -20.000000. running mean: -20.013476\n",
            "resetting env. episode 1534.000000, reward total was -20.000000. running mean: -20.013341\n",
            "resetting env. episode 1535.000000, reward total was -21.000000. running mean: -20.023208\n",
            "resetting env. episode 1536.000000, reward total was -21.000000. running mean: -20.032976\n",
            "resetting env. episode 1537.000000, reward total was -20.000000. running mean: -20.032646\n",
            "resetting env. episode 1538.000000, reward total was -21.000000. running mean: -20.042320\n",
            "resetting env. episode 1539.000000, reward total was -20.000000. running mean: -20.041896\n",
            "resetting env. episode 1540.000000, reward total was -20.000000. running mean: -20.041478\n",
            "resetting env. episode 1541.000000, reward total was -17.000000. running mean: -20.011063\n",
            "resetting env. episode 1542.000000, reward total was -21.000000. running mean: -20.020952\n",
            "resetting env. episode 1543.000000, reward total was -20.000000. running mean: -20.020743\n",
            "resetting env. episode 1544.000000, reward total was -21.000000. running mean: -20.030535\n",
            "resetting env. episode 1545.000000, reward total was -20.000000. running mean: -20.030230\n",
            "resetting env. episode 1546.000000, reward total was -21.000000. running mean: -20.039928\n",
            "resetting env. episode 1547.000000, reward total was -18.000000. running mean: -20.019528\n",
            "resetting env. episode 1548.000000, reward total was -21.000000. running mean: -20.029333\n",
            "resetting env. episode 1549.000000, reward total was -21.000000. running mean: -20.039040\n",
            "resetting env. episode 1550.000000, reward total was -21.000000. running mean: -20.048649\n",
            "resetting env. episode 1551.000000, reward total was -20.000000. running mean: -20.048163\n",
            "resetting env. episode 1552.000000, reward total was -19.000000. running mean: -20.037681\n",
            "resetting env. episode 1553.000000, reward total was -20.000000. running mean: -20.037304\n",
            "resetting env. episode 1554.000000, reward total was -20.000000. running mean: -20.036931\n",
            "resetting env. episode 1555.000000, reward total was -20.000000. running mean: -20.036562\n",
            "resetting env. episode 1556.000000, reward total was -21.000000. running mean: -20.046196\n",
            "resetting env. episode 1557.000000, reward total was -20.000000. running mean: -20.045734\n",
            "resetting env. episode 1558.000000, reward total was -19.000000. running mean: -20.035277\n",
            "resetting env. episode 1559.000000, reward total was -20.000000. running mean: -20.034924\n",
            "resetting env. episode 1560.000000, reward total was -19.000000. running mean: -20.024575\n",
            "resetting env. episode 1561.000000, reward total was -19.000000. running mean: -20.014329\n",
            "resetting env. episode 1562.000000, reward total was -21.000000. running mean: -20.024186\n",
            "resetting env. episode 1563.000000, reward total was -20.000000. running mean: -20.023944\n",
            "resetting env. episode 1564.000000, reward total was -21.000000. running mean: -20.033705\n",
            "resetting env. episode 1565.000000, reward total was -20.000000. running mean: -20.033368\n",
            "resetting env. episode 1566.000000, reward total was -20.000000. running mean: -20.033034\n",
            "resetting env. episode 1567.000000, reward total was -19.000000. running mean: -20.022704\n",
            "resetting env. episode 1568.000000, reward total was -21.000000. running mean: -20.032477\n",
            "resetting env. episode 1569.000000, reward total was -20.000000. running mean: -20.032152\n",
            "resetting env. episode 1570.000000, reward total was -21.000000. running mean: -20.041830\n",
            "resetting env. episode 1571.000000, reward total was -21.000000. running mean: -20.051412\n",
            "resetting env. episode 1572.000000, reward total was -19.000000. running mean: -20.040898\n",
            "resetting env. episode 1573.000000, reward total was -19.000000. running mean: -20.030489\n",
            "resetting env. episode 1574.000000, reward total was -20.000000. running mean: -20.030184\n",
            "resetting env. episode 1575.000000, reward total was -21.000000. running mean: -20.039882\n",
            "resetting env. episode 1576.000000, reward total was -19.000000. running mean: -20.029483\n",
            "resetting env. episode 1577.000000, reward total was -20.000000. running mean: -20.029189\n",
            "resetting env. episode 1578.000000, reward total was -20.000000. running mean: -20.028897\n",
            "resetting env. episode 1579.000000, reward total was -21.000000. running mean: -20.038608\n",
            "resetting env. episode 1580.000000, reward total was -20.000000. running mean: -20.038222\n",
            "resetting env. episode 1581.000000, reward total was -20.000000. running mean: -20.037839\n",
            "resetting env. episode 1582.000000, reward total was -20.000000. running mean: -20.037461\n",
            "resetting env. episode 1583.000000, reward total was -20.000000. running mean: -20.037086\n",
            "resetting env. episode 1584.000000, reward total was -16.000000. running mean: -19.996715\n",
            "resetting env. episode 1585.000000, reward total was -18.000000. running mean: -19.976748\n",
            "resetting env. episode 1586.000000, reward total was -21.000000. running mean: -19.986981\n",
            "resetting env. episode 1587.000000, reward total was -21.000000. running mean: -19.997111\n",
            "resetting env. episode 1588.000000, reward total was -18.000000. running mean: -19.977140\n",
            "resetting env. episode 1589.000000, reward total was -21.000000. running mean: -19.987369\n",
            "resetting env. episode 1590.000000, reward total was -20.000000. running mean: -19.987495\n",
            "resetting env. episode 1591.000000, reward total was -21.000000. running mean: -19.997620\n",
            "resetting env. episode 1592.000000, reward total was -18.000000. running mean: -19.977644\n",
            "resetting env. episode 1593.000000, reward total was -21.000000. running mean: -19.987867\n",
            "resetting env. episode 1594.000000, reward total was -20.000000. running mean: -19.987989\n",
            "resetting env. episode 1595.000000, reward total was -19.000000. running mean: -19.978109\n",
            "resetting env. episode 1596.000000, reward total was -19.000000. running mean: -19.968328\n",
            "resetting env. episode 1597.000000, reward total was -20.000000. running mean: -19.968644\n",
            "resetting env. episode 1598.000000, reward total was -21.000000. running mean: -19.978958\n",
            "resetting env. episode 1599.000000, reward total was -21.000000. running mean: -19.989168\n",
            "resetting env. episode 1600.000000, reward total was -21.000000. running mean: -19.999277\n",
            "resetting env. episode 1601.000000, reward total was -21.000000. running mean: -20.009284\n",
            "resetting env. episode 1602.000000, reward total was -20.000000. running mean: -20.009191\n",
            "resetting env. episode 1603.000000, reward total was -19.000000. running mean: -19.999099\n",
            "resetting env. episode 1604.000000, reward total was -21.000000. running mean: -20.009108\n",
            "resetting env. episode 1605.000000, reward total was -20.000000. running mean: -20.009017\n",
            "resetting env. episode 1606.000000, reward total was -21.000000. running mean: -20.018927\n",
            "resetting env. episode 1607.000000, reward total was -21.000000. running mean: -20.028738\n",
            "resetting env. episode 1608.000000, reward total was -21.000000. running mean: -20.038450\n",
            "resetting env. episode 1609.000000, reward total was -17.000000. running mean: -20.008066\n",
            "resetting env. episode 1610.000000, reward total was -21.000000. running mean: -20.017985\n",
            "resetting env. episode 1611.000000, reward total was -21.000000. running mean: -20.027805\n",
            "resetting env. episode 1612.000000, reward total was -19.000000. running mean: -20.017527\n",
            "resetting env. episode 1613.000000, reward total was -21.000000. running mean: -20.027352\n",
            "resetting env. episode 1614.000000, reward total was -20.000000. running mean: -20.027078\n",
            "resetting env. episode 1615.000000, reward total was -20.000000. running mean: -20.026808\n",
            "resetting env. episode 1616.000000, reward total was -20.000000. running mean: -20.026540\n",
            "resetting env. episode 1617.000000, reward total was -19.000000. running mean: -20.016274\n",
            "resetting env. episode 1618.000000, reward total was -16.000000. running mean: -19.976111\n",
            "resetting env. episode 1619.000000, reward total was -21.000000. running mean: -19.986350\n",
            "resetting env. episode 1620.000000, reward total was -21.000000. running mean: -19.996487\n",
            "resetting env. episode 1621.000000, reward total was -21.000000. running mean: -20.006522\n",
            "resetting env. episode 1622.000000, reward total was -20.000000. running mean: -20.006457\n",
            "resetting env. episode 1623.000000, reward total was -21.000000. running mean: -20.016392\n",
            "resetting env. episode 1624.000000, reward total was -20.000000. running mean: -20.016228\n",
            "resetting env. episode 1625.000000, reward total was -21.000000. running mean: -20.026066\n",
            "resetting env. episode 1626.000000, reward total was -19.000000. running mean: -20.015805\n",
            "resetting env. episode 1627.000000, reward total was -21.000000. running mean: -20.025647\n",
            "resetting env. episode 1628.000000, reward total was -21.000000. running mean: -20.035391\n",
            "resetting env. episode 1629.000000, reward total was -21.000000. running mean: -20.045037\n",
            "resetting env. episode 1630.000000, reward total was -19.000000. running mean: -20.034586\n",
            "resetting env. episode 1631.000000, reward total was -20.000000. running mean: -20.034241\n",
            "resetting env. episode 1632.000000, reward total was -20.000000. running mean: -20.033898\n",
            "resetting env. episode 1633.000000, reward total was -21.000000. running mean: -20.043559\n",
            "resetting env. episode 1634.000000, reward total was -20.000000. running mean: -20.043124\n",
            "resetting env. episode 1635.000000, reward total was -20.000000. running mean: -20.042692\n",
            "resetting env. episode 1636.000000, reward total was -20.000000. running mean: -20.042265\n",
            "resetting env. episode 1637.000000, reward total was -19.000000. running mean: -20.031843\n",
            "resetting env. episode 1638.000000, reward total was -20.000000. running mean: -20.031524\n",
            "resetting env. episode 1639.000000, reward total was -19.000000. running mean: -20.021209\n",
            "resetting env. episode 1640.000000, reward total was -20.000000. running mean: -20.020997\n",
            "resetting env. episode 1641.000000, reward total was -21.000000. running mean: -20.030787\n",
            "resetting env. episode 1642.000000, reward total was -17.000000. running mean: -20.000479\n",
            "resetting env. episode 1643.000000, reward total was -18.000000. running mean: -19.980474\n",
            "resetting env. episode 1644.000000, reward total was -21.000000. running mean: -19.990670\n",
            "resetting env. episode 1645.000000, reward total was -19.000000. running mean: -19.980763\n",
            "resetting env. episode 1646.000000, reward total was -18.000000. running mean: -19.960955\n",
            "resetting env. episode 1647.000000, reward total was -19.000000. running mean: -19.951346\n",
            "resetting env. episode 1648.000000, reward total was -21.000000. running mean: -19.961832\n",
            "resetting env. episode 1649.000000, reward total was -21.000000. running mean: -19.972214\n",
            "resetting env. episode 1650.000000, reward total was -19.000000. running mean: -19.962492\n",
            "resetting env. episode 1651.000000, reward total was -21.000000. running mean: -19.972867\n",
            "resetting env. episode 1652.000000, reward total was -18.000000. running mean: -19.953138\n",
            "resetting env. episode 1653.000000, reward total was -19.000000. running mean: -19.943607\n",
            "resetting env. episode 1654.000000, reward total was -21.000000. running mean: -19.954171\n",
            "resetting env. episode 1655.000000, reward total was -21.000000. running mean: -19.964629\n",
            "resetting env. episode 1656.000000, reward total was -20.000000. running mean: -19.964983\n",
            "resetting env. episode 1657.000000, reward total was -20.000000. running mean: -19.965333\n",
            "resetting env. episode 1658.000000, reward total was -20.000000. running mean: -19.965680\n",
            "resetting env. episode 1659.000000, reward total was -19.000000. running mean: -19.956023\n",
            "resetting env. episode 1660.000000, reward total was -18.000000. running mean: -19.936463\n",
            "resetting env. episode 1661.000000, reward total was -20.000000. running mean: -19.937098\n",
            "resetting env. episode 1662.000000, reward total was -20.000000. running mean: -19.937727\n",
            "resetting env. episode 1663.000000, reward total was -20.000000. running mean: -19.938350\n",
            "resetting env. episode 1664.000000, reward total was -20.000000. running mean: -19.938966\n",
            "resetting env. episode 1665.000000, reward total was -21.000000. running mean: -19.949577\n",
            "resetting env. episode 1666.000000, reward total was -19.000000. running mean: -19.940081\n",
            "resetting env. episode 1667.000000, reward total was -21.000000. running mean: -19.950680\n",
            "resetting env. episode 1668.000000, reward total was -20.000000. running mean: -19.951173\n",
            "resetting env. episode 1669.000000, reward total was -21.000000. running mean: -19.961661\n",
            "resetting env. episode 1670.000000, reward total was -21.000000. running mean: -19.972045\n",
            "resetting env. episode 1671.000000, reward total was -21.000000. running mean: -19.982324\n",
            "resetting env. episode 1672.000000, reward total was -20.000000. running mean: -19.982501\n",
            "resetting env. episode 1673.000000, reward total was -20.000000. running mean: -19.982676\n",
            "resetting env. episode 1674.000000, reward total was -21.000000. running mean: -19.992849\n",
            "resetting env. episode 1675.000000, reward total was -20.000000. running mean: -19.992921\n",
            "resetting env. episode 1676.000000, reward total was -20.000000. running mean: -19.992992\n",
            "resetting env. episode 1677.000000, reward total was -21.000000. running mean: -20.003062\n",
            "resetting env. episode 1678.000000, reward total was -21.000000. running mean: -20.013031\n",
            "resetting env. episode 1679.000000, reward total was -20.000000. running mean: -20.012901\n",
            "resetting env. episode 1680.000000, reward total was -21.000000. running mean: -20.022772\n",
            "resetting env. episode 1681.000000, reward total was -19.000000. running mean: -20.012544\n",
            "resetting env. episode 1682.000000, reward total was -21.000000. running mean: -20.022419\n",
            "resetting env. episode 1683.000000, reward total was -19.000000. running mean: -20.012195\n",
            "resetting env. episode 1684.000000, reward total was -19.000000. running mean: -20.002073\n",
            "resetting env. episode 1685.000000, reward total was -20.000000. running mean: -20.002052\n",
            "resetting env. episode 1686.000000, reward total was -21.000000. running mean: -20.012031\n",
            "resetting env. episode 1687.000000, reward total was -18.000000. running mean: -19.991911\n",
            "resetting env. episode 1688.000000, reward total was -20.000000. running mean: -19.991992\n",
            "resetting env. episode 1689.000000, reward total was -18.000000. running mean: -19.972072\n",
            "resetting env. episode 1690.000000, reward total was -21.000000. running mean: -19.982351\n",
            "resetting env. episode 1691.000000, reward total was -18.000000. running mean: -19.962528\n",
            "resetting env. episode 1692.000000, reward total was -20.000000. running mean: -19.962902\n",
            "resetting env. episode 1693.000000, reward total was -19.000000. running mean: -19.953273\n",
            "resetting env. episode 1694.000000, reward total was -21.000000. running mean: -19.963741\n",
            "resetting env. episode 1695.000000, reward total was -21.000000. running mean: -19.974103\n",
            "resetting env. episode 1696.000000, reward total was -21.000000. running mean: -19.984362\n",
            "resetting env. episode 1697.000000, reward total was -20.000000. running mean: -19.984519\n",
            "resetting env. episode 1698.000000, reward total was -21.000000. running mean: -19.994673\n",
            "resetting env. episode 1699.000000, reward total was -21.000000. running mean: -20.004727\n",
            "resetting env. episode 1700.000000, reward total was -20.000000. running mean: -20.004679\n",
            "resetting env. episode 1701.000000, reward total was -21.000000. running mean: -20.014633\n",
            "resetting env. episode 1702.000000, reward total was -20.000000. running mean: -20.014486\n",
            "resetting env. episode 1703.000000, reward total was -20.000000. running mean: -20.014341\n",
            "resetting env. episode 1704.000000, reward total was -19.000000. running mean: -20.004198\n",
            "resetting env. episode 1705.000000, reward total was -21.000000. running mean: -20.014156\n",
            "resetting env. episode 1706.000000, reward total was -20.000000. running mean: -20.014015\n",
            "resetting env. episode 1707.000000, reward total was -21.000000. running mean: -20.023874\n",
            "resetting env. episode 1708.000000, reward total was -21.000000. running mean: -20.033636\n",
            "resetting env. episode 1709.000000, reward total was -21.000000. running mean: -20.043299\n",
            "resetting env. episode 1710.000000, reward total was -21.000000. running mean: -20.052866\n",
            "resetting env. episode 1711.000000, reward total was -21.000000. running mean: -20.062338\n",
            "resetting env. episode 1712.000000, reward total was -20.000000. running mean: -20.061714\n",
            "resetting env. episode 1713.000000, reward total was -21.000000. running mean: -20.071097\n",
            "resetting env. episode 1714.000000, reward total was -20.000000. running mean: -20.070386\n",
            "resetting env. episode 1715.000000, reward total was -18.000000. running mean: -20.049682\n",
            "resetting env. episode 1716.000000, reward total was -21.000000. running mean: -20.059185\n",
            "resetting env. episode 1717.000000, reward total was -21.000000. running mean: -20.068594\n",
            "resetting env. episode 1718.000000, reward total was -20.000000. running mean: -20.067908\n",
            "resetting env. episode 1719.000000, reward total was -20.000000. running mean: -20.067229\n",
            "resetting env. episode 1720.000000, reward total was -19.000000. running mean: -20.056556\n",
            "resetting env. episode 1721.000000, reward total was -21.000000. running mean: -20.065991\n",
            "resetting env. episode 1722.000000, reward total was -20.000000. running mean: -20.065331\n",
            "resetting env. episode 1723.000000, reward total was -21.000000. running mean: -20.074678\n",
            "resetting env. episode 1724.000000, reward total was -20.000000. running mean: -20.073931\n",
            "resetting env. episode 1725.000000, reward total was -21.000000. running mean: -20.083191\n",
            "resetting env. episode 1726.000000, reward total was -20.000000. running mean: -20.082360\n",
            "resetting env. episode 1727.000000, reward total was -20.000000. running mean: -20.081536\n",
            "resetting env. episode 1728.000000, reward total was -20.000000. running mean: -20.080721\n",
            "resetting env. episode 1729.000000, reward total was -21.000000. running mean: -20.089913\n",
            "resetting env. episode 1730.000000, reward total was -19.000000. running mean: -20.079014\n",
            "resetting env. episode 1731.000000, reward total was -21.000000. running mean: -20.088224\n",
            "resetting env. episode 1732.000000, reward total was -19.000000. running mean: -20.077342\n",
            "resetting env. episode 1733.000000, reward total was -19.000000. running mean: -20.066568\n",
            "resetting env. episode 1734.000000, reward total was -21.000000. running mean: -20.075903\n",
            "resetting env. episode 1735.000000, reward total was -21.000000. running mean: -20.085144\n",
            "resetting env. episode 1736.000000, reward total was -20.000000. running mean: -20.084292\n",
            "resetting env. episode 1737.000000, reward total was -21.000000. running mean: -20.093449\n",
            "resetting env. episode 1738.000000, reward total was -21.000000. running mean: -20.102515\n",
            "resetting env. episode 1739.000000, reward total was -20.000000. running mean: -20.101490\n",
            "resetting env. episode 1740.000000, reward total was -20.000000. running mean: -20.100475\n",
            "resetting env. episode 1741.000000, reward total was -21.000000. running mean: -20.109470\n",
            "resetting env. episode 1742.000000, reward total was -20.000000. running mean: -20.108375\n",
            "resetting env. episode 1743.000000, reward total was -19.000000. running mean: -20.097292\n",
            "resetting env. episode 1744.000000, reward total was -20.000000. running mean: -20.096319\n",
            "resetting env. episode 1745.000000, reward total was -19.000000. running mean: -20.085356\n",
            "resetting env. episode 1746.000000, reward total was -21.000000. running mean: -20.094502\n",
            "resetting env. episode 1747.000000, reward total was -21.000000. running mean: -20.103557\n",
            "resetting env. episode 1748.000000, reward total was -19.000000. running mean: -20.092521\n",
            "resetting env. episode 1749.000000, reward total was -20.000000. running mean: -20.091596\n",
            "resetting env. episode 1750.000000, reward total was -20.000000. running mean: -20.090680\n",
            "resetting env. episode 1751.000000, reward total was -20.000000. running mean: -20.089773\n",
            "resetting env. episode 1752.000000, reward total was -20.000000. running mean: -20.088876\n",
            "resetting env. episode 1753.000000, reward total was -20.000000. running mean: -20.087987\n",
            "resetting env. episode 1754.000000, reward total was -20.000000. running mean: -20.087107\n",
            "resetting env. episode 1755.000000, reward total was -21.000000. running mean: -20.096236\n",
            "resetting env. episode 1756.000000, reward total was -20.000000. running mean: -20.095274\n",
            "resetting env. episode 1757.000000, reward total was -20.000000. running mean: -20.094321\n",
            "resetting env. episode 1758.000000, reward total was -20.000000. running mean: -20.093378\n",
            "resetting env. episode 1759.000000, reward total was -20.000000. running mean: -20.092444\n",
            "resetting env. episode 1760.000000, reward total was -19.000000. running mean: -20.081519\n",
            "resetting env. episode 1761.000000, reward total was -21.000000. running mean: -20.090704\n",
            "resetting env. episode 1762.000000, reward total was -21.000000. running mean: -20.099797\n",
            "resetting env. episode 1763.000000, reward total was -21.000000. running mean: -20.108799\n",
            "resetting env. episode 1764.000000, reward total was -19.000000. running mean: -20.097711\n",
            "resetting env. episode 1765.000000, reward total was -21.000000. running mean: -20.106734\n",
            "resetting env. episode 1766.000000, reward total was -21.000000. running mean: -20.115667\n",
            "resetting env. episode 1767.000000, reward total was -21.000000. running mean: -20.124510\n",
            "resetting env. episode 1768.000000, reward total was -21.000000. running mean: -20.133265\n",
            "resetting env. episode 1769.000000, reward total was -20.000000. running mean: -20.131932\n",
            "resetting env. episode 1770.000000, reward total was -21.000000. running mean: -20.140613\n",
            "resetting env. episode 1771.000000, reward total was -21.000000. running mean: -20.149207\n",
            "resetting env. episode 1772.000000, reward total was -18.000000. running mean: -20.127715\n",
            "resetting env. episode 1773.000000, reward total was -21.000000. running mean: -20.136438\n",
            "resetting env. episode 1774.000000, reward total was -20.000000. running mean: -20.135073\n",
            "resetting env. episode 1775.000000, reward total was -20.000000. running mean: -20.133723\n",
            "resetting env. episode 1776.000000, reward total was -21.000000. running mean: -20.142385\n",
            "resetting env. episode 1777.000000, reward total was -20.000000. running mean: -20.140961\n",
            "resetting env. episode 1778.000000, reward total was -21.000000. running mean: -20.149552\n",
            "resetting env. episode 1779.000000, reward total was -20.000000. running mean: -20.148056\n",
            "resetting env. episode 1780.000000, reward total was -19.000000. running mean: -20.136576\n",
            "resetting env. episode 1781.000000, reward total was -19.000000. running mean: -20.125210\n",
            "resetting env. episode 1782.000000, reward total was -20.000000. running mean: -20.123958\n",
            "resetting env. episode 1783.000000, reward total was -20.000000. running mean: -20.122718\n",
            "resetting env. episode 1784.000000, reward total was -19.000000. running mean: -20.111491\n",
            "resetting env. episode 1785.000000, reward total was -21.000000. running mean: -20.120376\n",
            "resetting env. episode 1786.000000, reward total was -19.000000. running mean: -20.109173\n",
            "resetting env. episode 1787.000000, reward total was -21.000000. running mean: -20.118081\n",
            "resetting env. episode 1788.000000, reward total was -20.000000. running mean: -20.116900\n",
            "resetting env. episode 1789.000000, reward total was -20.000000. running mean: -20.115731\n",
            "resetting env. episode 1790.000000, reward total was -20.000000. running mean: -20.114574\n",
            "resetting env. episode 1791.000000, reward total was -20.000000. running mean: -20.113428\n",
            "resetting env. episode 1792.000000, reward total was -21.000000. running mean: -20.122294\n",
            "resetting env. episode 1793.000000, reward total was -21.000000. running mean: -20.131071\n",
            "resetting env. episode 1794.000000, reward total was -20.000000. running mean: -20.129760\n",
            "resetting env. episode 1795.000000, reward total was -21.000000. running mean: -20.138462\n",
            "resetting env. episode 1796.000000, reward total was -21.000000. running mean: -20.147078\n",
            "resetting env. episode 1797.000000, reward total was -20.000000. running mean: -20.145607\n",
            "resetting env. episode 1798.000000, reward total was -21.000000. running mean: -20.154151\n",
            "resetting env. episode 1799.000000, reward total was -19.000000. running mean: -20.142609\n",
            "resetting env. episode 1800.000000, reward total was -19.000000. running mean: -20.131183\n",
            "resetting env. episode 1801.000000, reward total was -21.000000. running mean: -20.139871\n",
            "resetting env. episode 1802.000000, reward total was -18.000000. running mean: -20.118473\n",
            "resetting env. episode 1803.000000, reward total was -20.000000. running mean: -20.117288\n",
            "resetting env. episode 1804.000000, reward total was -19.000000. running mean: -20.106115\n",
            "resetting env. episode 1805.000000, reward total was -21.000000. running mean: -20.115054\n",
            "resetting env. episode 1806.000000, reward total was -20.000000. running mean: -20.113903\n",
            "resetting env. episode 1807.000000, reward total was -21.000000. running mean: -20.122764\n",
            "resetting env. episode 1808.000000, reward total was -21.000000. running mean: -20.131537\n",
            "resetting env. episode 1809.000000, reward total was -20.000000. running mean: -20.130221\n",
            "resetting env. episode 1810.000000, reward total was -18.000000. running mean: -20.108919\n",
            "resetting env. episode 1811.000000, reward total was -20.000000. running mean: -20.107830\n",
            "resetting env. episode 1812.000000, reward total was -20.000000. running mean: -20.106752\n",
            "resetting env. episode 1813.000000, reward total was -20.000000. running mean: -20.105684\n",
            "resetting env. episode 1814.000000, reward total was -20.000000. running mean: -20.104627\n",
            "resetting env. episode 1815.000000, reward total was -20.000000. running mean: -20.103581\n",
            "resetting env. episode 1816.000000, reward total was -19.000000. running mean: -20.092545\n",
            "resetting env. episode 1817.000000, reward total was -19.000000. running mean: -20.081620\n",
            "resetting env. episode 1818.000000, reward total was -20.000000. running mean: -20.080804\n",
            "resetting env. episode 1819.000000, reward total was -20.000000. running mean: -20.079996\n",
            "resetting env. episode 1820.000000, reward total was -19.000000. running mean: -20.069196\n",
            "resetting env. episode 1821.000000, reward total was -21.000000. running mean: -20.078504\n",
            "resetting env. episode 1822.000000, reward total was -20.000000. running mean: -20.077719\n",
            "resetting env. episode 1823.000000, reward total was -20.000000. running mean: -20.076941\n",
            "resetting env. episode 1824.000000, reward total was -21.000000. running mean: -20.086172\n",
            "resetting env. episode 1825.000000, reward total was -18.000000. running mean: -20.065310\n",
            "resetting env. episode 1826.000000, reward total was -21.000000. running mean: -20.074657\n",
            "resetting env. episode 1827.000000, reward total was -18.000000. running mean: -20.053911\n",
            "resetting env. episode 1828.000000, reward total was -21.000000. running mean: -20.063372\n",
            "resetting env. episode 1829.000000, reward total was -19.000000. running mean: -20.052738\n",
            "resetting env. episode 1830.000000, reward total was -21.000000. running mean: -20.062210\n",
            "resetting env. episode 1831.000000, reward total was -20.000000. running mean: -20.061588\n",
            "resetting env. episode 1832.000000, reward total was -19.000000. running mean: -20.050972\n",
            "resetting env. episode 1833.000000, reward total was -19.000000. running mean: -20.040463\n",
            "resetting env. episode 1834.000000, reward total was -21.000000. running mean: -20.050058\n",
            "resetting env. episode 1835.000000, reward total was -19.000000. running mean: -20.039558\n",
            "resetting env. episode 1836.000000, reward total was -20.000000. running mean: -20.039162\n",
            "resetting env. episode 1837.000000, reward total was -20.000000. running mean: -20.038770\n",
            "resetting env. episode 1838.000000, reward total was -21.000000. running mean: -20.048383\n",
            "resetting env. episode 1839.000000, reward total was -17.000000. running mean: -20.017899\n",
            "resetting env. episode 1840.000000, reward total was -21.000000. running mean: -20.027720\n",
            "resetting env. episode 1841.000000, reward total was -20.000000. running mean: -20.027443\n",
            "resetting env. episode 1842.000000, reward total was -21.000000. running mean: -20.037168\n",
            "resetting env. episode 1843.000000, reward total was -20.000000. running mean: -20.036797\n",
            "resetting env. episode 1844.000000, reward total was -19.000000. running mean: -20.026429\n",
            "resetting env. episode 1845.000000, reward total was -19.000000. running mean: -20.016164\n",
            "resetting env. episode 1846.000000, reward total was -20.000000. running mean: -20.016003\n",
            "resetting env. episode 1847.000000, reward total was -20.000000. running mean: -20.015843\n",
            "resetting env. episode 1848.000000, reward total was -20.000000. running mean: -20.015684\n",
            "resetting env. episode 1849.000000, reward total was -21.000000. running mean: -20.025527\n",
            "resetting env. episode 1850.000000, reward total was -21.000000. running mean: -20.035272\n",
            "resetting env. episode 1851.000000, reward total was -19.000000. running mean: -20.024919\n",
            "resetting env. episode 1852.000000, reward total was -20.000000. running mean: -20.024670\n",
            "resetting env. episode 1853.000000, reward total was -21.000000. running mean: -20.034423\n",
            "resetting env. episode 1854.000000, reward total was -21.000000. running mean: -20.044079\n",
            "resetting env. episode 1855.000000, reward total was -19.000000. running mean: -20.033638\n",
            "resetting env. episode 1856.000000, reward total was -21.000000. running mean: -20.043302\n",
            "resetting env. episode 1857.000000, reward total was -21.000000. running mean: -20.052869\n",
            "resetting env. episode 1858.000000, reward total was -20.000000. running mean: -20.052340\n",
            "resetting env. episode 1859.000000, reward total was -21.000000. running mean: -20.061817\n",
            "resetting env. episode 1860.000000, reward total was -17.000000. running mean: -20.031199\n",
            "resetting env. episode 1861.000000, reward total was -15.000000. running mean: -19.980887\n",
            "resetting env. episode 1862.000000, reward total was -21.000000. running mean: -19.991078\n",
            "resetting env. episode 1863.000000, reward total was -21.000000. running mean: -20.001167\n",
            "resetting env. episode 1864.000000, reward total was -21.000000. running mean: -20.011155\n",
            "resetting env. episode 1865.000000, reward total was -21.000000. running mean: -20.021044\n",
            "resetting env. episode 1866.000000, reward total was -21.000000. running mean: -20.030833\n",
            "resetting env. episode 1867.000000, reward total was -20.000000. running mean: -20.030525\n",
            "resetting env. episode 1868.000000, reward total was -20.000000. running mean: -20.030220\n",
            "resetting env. episode 1869.000000, reward total was -21.000000. running mean: -20.039918\n",
            "resetting env. episode 1870.000000, reward total was -21.000000. running mean: -20.049518\n",
            "resetting env. episode 1871.000000, reward total was -17.000000. running mean: -20.019023\n",
            "resetting env. episode 1872.000000, reward total was -19.000000. running mean: -20.008833\n",
            "resetting env. episode 1873.000000, reward total was -21.000000. running mean: -20.018745\n",
            "resetting env. episode 1874.000000, reward total was -20.000000. running mean: -20.018557\n",
            "resetting env. episode 1875.000000, reward total was -21.000000. running mean: -20.028372\n",
            "resetting env. episode 1876.000000, reward total was -20.000000. running mean: -20.028088\n",
            "resetting env. episode 1877.000000, reward total was -19.000000. running mean: -20.017807\n",
            "resetting env. episode 1878.000000, reward total was -21.000000. running mean: -20.027629\n",
            "resetting env. episode 1879.000000, reward total was -20.000000. running mean: -20.027353\n",
            "resetting env. episode 1880.000000, reward total was -19.000000. running mean: -20.017079\n",
            "resetting env. episode 1881.000000, reward total was -21.000000. running mean: -20.026908\n",
            "resetting env. episode 1882.000000, reward total was -21.000000. running mean: -20.036639\n",
            "resetting env. episode 1883.000000, reward total was -21.000000. running mean: -20.046273\n",
            "resetting env. episode 1884.000000, reward total was -20.000000. running mean: -20.045810\n",
            "resetting env. episode 1885.000000, reward total was -21.000000. running mean: -20.055352\n",
            "resetting env. episode 1886.000000, reward total was -21.000000. running mean: -20.064799\n",
            "resetting env. episode 1887.000000, reward total was -20.000000. running mean: -20.064151\n",
            "resetting env. episode 1888.000000, reward total was -21.000000. running mean: -20.073509\n",
            "resetting env. episode 1889.000000, reward total was -21.000000. running mean: -20.082774\n",
            "resetting env. episode 1890.000000, reward total was -20.000000. running mean: -20.081946\n",
            "resetting env. episode 1891.000000, reward total was -20.000000. running mean: -20.081127\n",
            "resetting env. episode 1892.000000, reward total was -21.000000. running mean: -20.090316\n",
            "resetting env. episode 1893.000000, reward total was -21.000000. running mean: -20.099412\n",
            "resetting env. episode 1894.000000, reward total was -20.000000. running mean: -20.098418\n",
            "resetting env. episode 1895.000000, reward total was -21.000000. running mean: -20.107434\n",
            "resetting env. episode 1896.000000, reward total was -20.000000. running mean: -20.106360\n",
            "resetting env. episode 1897.000000, reward total was -19.000000. running mean: -20.095296\n",
            "resetting env. episode 1898.000000, reward total was -21.000000. running mean: -20.104343\n",
            "resetting env. episode 1899.000000, reward total was -20.000000. running mean: -20.103300\n",
            "resetting env. episode 1900.000000, reward total was -20.000000. running mean: -20.102267\n",
            "resetting env. episode 1901.000000, reward total was -20.000000. running mean: -20.101244\n",
            "resetting env. episode 1902.000000, reward total was -19.000000. running mean: -20.090232\n",
            "resetting env. episode 1903.000000, reward total was -18.000000. running mean: -20.069329\n",
            "resetting env. episode 1904.000000, reward total was -21.000000. running mean: -20.078636\n",
            "resetting env. episode 1905.000000, reward total was -21.000000. running mean: -20.087850\n",
            "resetting env. episode 1906.000000, reward total was -21.000000. running mean: -20.096971\n",
            "resetting env. episode 1907.000000, reward total was -21.000000. running mean: -20.106001\n",
            "resetting env. episode 1908.000000, reward total was -19.000000. running mean: -20.094941\n",
            "resetting env. episode 1909.000000, reward total was -21.000000. running mean: -20.103992\n",
            "resetting env. episode 1910.000000, reward total was -21.000000. running mean: -20.112952\n",
            "resetting env. episode 1911.000000, reward total was -18.000000. running mean: -20.091823\n",
            "resetting env. episode 1912.000000, reward total was -18.000000. running mean: -20.070904\n",
            "resetting env. episode 1913.000000, reward total was -19.000000. running mean: -20.060195\n",
            "resetting env. episode 1914.000000, reward total was -19.000000. running mean: -20.049593\n",
            "resetting env. episode 1915.000000, reward total was -21.000000. running mean: -20.059097\n",
            "resetting env. episode 1916.000000, reward total was -20.000000. running mean: -20.058506\n",
            "resetting env. episode 1917.000000, reward total was -19.000000. running mean: -20.047921\n",
            "resetting env. episode 1918.000000, reward total was -21.000000. running mean: -20.057442\n",
            "resetting env. episode 1919.000000, reward total was -21.000000. running mean: -20.066868\n",
            "resetting env. episode 1920.000000, reward total was -20.000000. running mean: -20.066199\n",
            "resetting env. episode 1921.000000, reward total was -20.000000. running mean: -20.065537\n",
            "resetting env. episode 1922.000000, reward total was -20.000000. running mean: -20.064882\n",
            "resetting env. episode 1923.000000, reward total was -21.000000. running mean: -20.074233\n",
            "resetting env. episode 1924.000000, reward total was -18.000000. running mean: -20.053491\n",
            "resetting env. episode 1925.000000, reward total was -21.000000. running mean: -20.062956\n",
            "resetting env. episode 1926.000000, reward total was -21.000000. running mean: -20.072326\n",
            "resetting env. episode 1927.000000, reward total was -18.000000. running mean: -20.051603\n",
            "resetting env. episode 1928.000000, reward total was -19.000000. running mean: -20.041087\n",
            "resetting env. episode 1929.000000, reward total was -21.000000. running mean: -20.050676\n",
            "resetting env. episode 1930.000000, reward total was -20.000000. running mean: -20.050169\n",
            "resetting env. episode 1931.000000, reward total was -21.000000. running mean: -20.059668\n",
            "resetting env. episode 1932.000000, reward total was -20.000000. running mean: -20.059071\n",
            "resetting env. episode 1933.000000, reward total was -19.000000. running mean: -20.048480\n",
            "resetting env. episode 1934.000000, reward total was -21.000000. running mean: -20.057995\n",
            "resetting env. episode 1935.000000, reward total was -21.000000. running mean: -20.067415\n",
            "resetting env. episode 1936.000000, reward total was -21.000000. running mean: -20.076741\n",
            "resetting env. episode 1937.000000, reward total was -21.000000. running mean: -20.085974\n",
            "resetting env. episode 1938.000000, reward total was -18.000000. running mean: -20.065114\n",
            "resetting env. episode 1939.000000, reward total was -21.000000. running mean: -20.074463\n",
            "resetting env. episode 1940.000000, reward total was -21.000000. running mean: -20.083718\n",
            "resetting env. episode 1941.000000, reward total was -19.000000. running mean: -20.072881\n",
            "resetting env. episode 1942.000000, reward total was -21.000000. running mean: -20.082152\n",
            "resetting env. episode 1943.000000, reward total was -21.000000. running mean: -20.091331\n",
            "resetting env. episode 1944.000000, reward total was -21.000000. running mean: -20.100417\n",
            "resetting env. episode 1945.000000, reward total was -21.000000. running mean: -20.109413\n",
            "resetting env. episode 1946.000000, reward total was -21.000000. running mean: -20.118319\n",
            "resetting env. episode 1947.000000, reward total was -19.000000. running mean: -20.107136\n",
            "resetting env. episode 1948.000000, reward total was -19.000000. running mean: -20.096065\n",
            "resetting env. episode 1949.000000, reward total was -19.000000. running mean: -20.085104\n",
            "resetting env. episode 1950.000000, reward total was -21.000000. running mean: -20.094253\n",
            "resetting env. episode 1951.000000, reward total was -20.000000. running mean: -20.093310\n",
            "resetting env. episode 1952.000000, reward total was -19.000000. running mean: -20.082377\n",
            "resetting env. episode 1953.000000, reward total was -21.000000. running mean: -20.091554\n",
            "resetting env. episode 1954.000000, reward total was -20.000000. running mean: -20.090638\n",
            "resetting env. episode 1955.000000, reward total was -21.000000. running mean: -20.099732\n",
            "resetting env. episode 1956.000000, reward total was -21.000000. running mean: -20.108734\n",
            "resetting env. episode 1957.000000, reward total was -20.000000. running mean: -20.107647\n",
            "resetting env. episode 1958.000000, reward total was -21.000000. running mean: -20.116570\n",
            "resetting env. episode 1959.000000, reward total was -19.000000. running mean: -20.105405\n",
            "resetting env. episode 1960.000000, reward total was -20.000000. running mean: -20.104351\n",
            "resetting env. episode 1961.000000, reward total was -20.000000. running mean: -20.103307\n",
            "resetting env. episode 1962.000000, reward total was -20.000000. running mean: -20.102274\n",
            "resetting env. episode 1963.000000, reward total was -20.000000. running mean: -20.101251\n",
            "resetting env. episode 1964.000000, reward total was -19.000000. running mean: -20.090239\n",
            "resetting env. episode 1965.000000, reward total was -21.000000. running mean: -20.099337\n",
            "resetting env. episode 1966.000000, reward total was -21.000000. running mean: -20.108343\n",
            "resetting env. episode 1967.000000, reward total was -21.000000. running mean: -20.117260\n",
            "resetting env. episode 1968.000000, reward total was -21.000000. running mean: -20.126087\n",
            "resetting env. episode 1969.000000, reward total was -21.000000. running mean: -20.134826\n",
            "resetting env. episode 1970.000000, reward total was -20.000000. running mean: -20.133478\n",
            "resetting env. episode 1971.000000, reward total was -21.000000. running mean: -20.142143\n",
            "resetting env. episode 1972.000000, reward total was -20.000000. running mean: -20.140722\n",
            "resetting env. episode 1973.000000, reward total was -21.000000. running mean: -20.149315\n",
            "resetting env. episode 1974.000000, reward total was -21.000000. running mean: -20.157821\n",
            "resetting env. episode 1975.000000, reward total was -21.000000. running mean: -20.166243\n",
            "resetting env. episode 1976.000000, reward total was -21.000000. running mean: -20.174581\n",
            "resetting env. episode 1977.000000, reward total was -20.000000. running mean: -20.172835\n",
            "resetting env. episode 1978.000000, reward total was -20.000000. running mean: -20.171107\n",
            "resetting env. episode 1979.000000, reward total was -16.000000. running mean: -20.129396\n",
            "resetting env. episode 1980.000000, reward total was -21.000000. running mean: -20.138102\n",
            "resetting env. episode 1981.000000, reward total was -21.000000. running mean: -20.146721\n",
            "resetting env. episode 1982.000000, reward total was -20.000000. running mean: -20.145253\n",
            "resetting env. episode 1983.000000, reward total was -21.000000. running mean: -20.153801\n",
            "resetting env. episode 1984.000000, reward total was -19.000000. running mean: -20.142263\n",
            "resetting env. episode 1985.000000, reward total was -19.000000. running mean: -20.130840\n",
            "resetting env. episode 1986.000000, reward total was -20.000000. running mean: -20.129532\n",
            "resetting env. episode 1987.000000, reward total was -20.000000. running mean: -20.128236\n",
            "resetting env. episode 1988.000000, reward total was -20.000000. running mean: -20.126954\n",
            "resetting env. episode 1989.000000, reward total was -21.000000. running mean: -20.135685\n",
            "resetting env. episode 1990.000000, reward total was -20.000000. running mean: -20.134328\n",
            "resetting env. episode 1991.000000, reward total was -21.000000. running mean: -20.142984\n",
            "resetting env. episode 1992.000000, reward total was -21.000000. running mean: -20.151555\n",
            "resetting env. episode 1993.000000, reward total was -21.000000. running mean: -20.160039\n",
            "resetting env. episode 1994.000000, reward total was -19.000000. running mean: -20.148439\n",
            "resetting env. episode 1995.000000, reward total was -19.000000. running mean: -20.136954\n",
            "resetting env. episode 1996.000000, reward total was -19.000000. running mean: -20.125585\n",
            "resetting env. episode 1997.000000, reward total was -19.000000. running mean: -20.114329\n",
            "resetting env. episode 1998.000000, reward total was -20.000000. running mean: -20.113186\n",
            "resetting env. episode 1999.000000, reward total was -18.000000. running mean: -20.092054\n",
            "resetting env. episode 2000.000000, reward total was -21.000000. running mean: -20.101133\n",
            "resetting env. episode 2001.000000, reward total was -19.000000. running mean: -20.090122\n",
            "resetting env. episode 2002.000000, reward total was -20.000000. running mean: -20.089221\n",
            "resetting env. episode 2003.000000, reward total was -18.000000. running mean: -20.068328\n",
            "resetting env. episode 2004.000000, reward total was -20.000000. running mean: -20.067645\n",
            "resetting env. episode 2005.000000, reward total was -20.000000. running mean: -20.066969\n",
            "resetting env. episode 2006.000000, reward total was -21.000000. running mean: -20.076299\n",
            "resetting env. episode 2007.000000, reward total was -19.000000. running mean: -20.065536\n",
            "resetting env. episode 2008.000000, reward total was -19.000000. running mean: -20.054881\n",
            "resetting env. episode 2009.000000, reward total was -21.000000. running mean: -20.064332\n",
            "resetting env. episode 2010.000000, reward total was -21.000000. running mean: -20.073689\n",
            "resetting env. episode 2011.000000, reward total was -20.000000. running mean: -20.072952\n",
            "resetting env. episode 2012.000000, reward total was -20.000000. running mean: -20.072222\n",
            "resetting env. episode 2013.000000, reward total was -21.000000. running mean: -20.081500\n",
            "resetting env. episode 2014.000000, reward total was -21.000000. running mean: -20.090685\n",
            "resetting env. episode 2015.000000, reward total was -20.000000. running mean: -20.089778\n",
            "resetting env. episode 2016.000000, reward total was -20.000000. running mean: -20.088880\n",
            "resetting env. episode 2017.000000, reward total was -19.000000. running mean: -20.077991\n",
            "resetting env. episode 2018.000000, reward total was -20.000000. running mean: -20.077212\n",
            "resetting env. episode 2019.000000, reward total was -19.000000. running mean: -20.066439\n",
            "resetting env. episode 2020.000000, reward total was -20.000000. running mean: -20.065775\n",
            "resetting env. episode 2021.000000, reward total was -16.000000. running mean: -20.025117\n",
            "resetting env. episode 2022.000000, reward total was -20.000000. running mean: -20.024866\n",
            "resetting env. episode 2023.000000, reward total was -21.000000. running mean: -20.034617\n",
            "resetting env. episode 2024.000000, reward total was -20.000000. running mean: -20.034271\n",
            "resetting env. episode 2025.000000, reward total was -20.000000. running mean: -20.033929\n",
            "resetting env. episode 2026.000000, reward total was -20.000000. running mean: -20.033589\n",
            "resetting env. episode 2027.000000, reward total was -20.000000. running mean: -20.033253\n",
            "resetting env. episode 2028.000000, reward total was -20.000000. running mean: -20.032921\n",
            "resetting env. episode 2029.000000, reward total was -20.000000. running mean: -20.032592\n",
            "resetting env. episode 2030.000000, reward total was -17.000000. running mean: -20.002266\n",
            "resetting env. episode 2031.000000, reward total was -21.000000. running mean: -20.012243\n",
            "resetting env. episode 2032.000000, reward total was -19.000000. running mean: -20.002121\n",
            "resetting env. episode 2033.000000, reward total was -21.000000. running mean: -20.012099\n",
            "resetting env. episode 2034.000000, reward total was -21.000000. running mean: -20.021978\n",
            "resetting env. episode 2035.000000, reward total was -20.000000. running mean: -20.021759\n",
            "resetting env. episode 2036.000000, reward total was -21.000000. running mean: -20.031541\n",
            "resetting env. episode 2037.000000, reward total was -20.000000. running mean: -20.031226\n",
            "resetting env. episode 2038.000000, reward total was -20.000000. running mean: -20.030913\n",
            "resetting env. episode 2039.000000, reward total was -19.000000. running mean: -20.020604\n",
            "resetting env. episode 2040.000000, reward total was -21.000000. running mean: -20.030398\n",
            "resetting env. episode 2041.000000, reward total was -20.000000. running mean: -20.030094\n",
            "resetting env. episode 2042.000000, reward total was -20.000000. running mean: -20.029793\n",
            "resetting env. episode 2043.000000, reward total was -19.000000. running mean: -20.019495\n",
            "resetting env. episode 2044.000000, reward total was -20.000000. running mean: -20.019300\n",
            "resetting env. episode 2045.000000, reward total was -19.000000. running mean: -20.009107\n",
            "resetting env. episode 2046.000000, reward total was -19.000000. running mean: -19.999016\n",
            "resetting env. episode 2047.000000, reward total was -21.000000. running mean: -20.009026\n",
            "resetting env. episode 2048.000000, reward total was -21.000000. running mean: -20.018936\n",
            "resetting env. episode 2049.000000, reward total was -20.000000. running mean: -20.018747\n",
            "resetting env. episode 2050.000000, reward total was -21.000000. running mean: -20.028559\n",
            "resetting env. episode 2051.000000, reward total was -20.000000. running mean: -20.028274\n",
            "resetting env. episode 2052.000000, reward total was -21.000000. running mean: -20.037991\n",
            "resetting env. episode 2053.000000, reward total was -21.000000. running mean: -20.047611\n",
            "resetting env. episode 2054.000000, reward total was -21.000000. running mean: -20.057135\n",
            "resetting env. episode 2055.000000, reward total was -21.000000. running mean: -20.066563\n",
            "resetting env. episode 2056.000000, reward total was -21.000000. running mean: -20.075898\n",
            "resetting env. episode 2057.000000, reward total was -19.000000. running mean: -20.065139\n",
            "resetting env. episode 2058.000000, reward total was -18.000000. running mean: -20.044487\n",
            "resetting env. episode 2059.000000, reward total was -21.000000. running mean: -20.054043\n",
            "resetting env. episode 2060.000000, reward total was -21.000000. running mean: -20.063502\n",
            "resetting env. episode 2061.000000, reward total was -21.000000. running mean: -20.072867\n",
            "resetting env. episode 2062.000000, reward total was -19.000000. running mean: -20.062138\n",
            "resetting env. episode 2063.000000, reward total was -21.000000. running mean: -20.071517\n",
            "resetting env. episode 2064.000000, reward total was -21.000000. running mean: -20.080802\n",
            "resetting env. episode 2065.000000, reward total was -21.000000. running mean: -20.089994\n",
            "resetting env. episode 2066.000000, reward total was -19.000000. running mean: -20.079094\n",
            "resetting env. episode 2067.000000, reward total was -21.000000. running mean: -20.088303\n",
            "resetting env. episode 2068.000000, reward total was -19.000000. running mean: -20.077420\n",
            "resetting env. episode 2069.000000, reward total was -20.000000. running mean: -20.076646\n",
            "resetting env. episode 2070.000000, reward total was -21.000000. running mean: -20.085879\n",
            "resetting env. episode 2071.000000, reward total was -21.000000. running mean: -20.095020\n",
            "resetting env. episode 2072.000000, reward total was -19.000000. running mean: -20.084070\n",
            "resetting env. episode 2073.000000, reward total was -19.000000. running mean: -20.073230\n",
            "resetting env. episode 2074.000000, reward total was -20.000000. running mean: -20.072497\n",
            "resetting env. episode 2075.000000, reward total was -18.000000. running mean: -20.051772\n",
            "resetting env. episode 2076.000000, reward total was -20.000000. running mean: -20.051255\n",
            "resetting env. episode 2077.000000, reward total was -20.000000. running mean: -20.050742\n",
            "resetting env. episode 2078.000000, reward total was -19.000000. running mean: -20.040235\n",
            "resetting env. episode 2079.000000, reward total was -21.000000. running mean: -20.049832\n",
            "resetting env. episode 2080.000000, reward total was -21.000000. running mean: -20.059334\n",
            "resetting env. episode 2081.000000, reward total was -21.000000. running mean: -20.068741\n",
            "resetting env. episode 2082.000000, reward total was -19.000000. running mean: -20.058053\n",
            "resetting env. episode 2083.000000, reward total was -21.000000. running mean: -20.067473\n",
            "resetting env. episode 2084.000000, reward total was -19.000000. running mean: -20.056798\n",
            "resetting env. episode 2085.000000, reward total was -19.000000. running mean: -20.046230\n",
            "resetting env. episode 2086.000000, reward total was -19.000000. running mean: -20.035768\n",
            "resetting env. episode 2087.000000, reward total was -18.000000. running mean: -20.015410\n",
            "resetting env. episode 2088.000000, reward total was -20.000000. running mean: -20.015256\n",
            "resetting env. episode 2089.000000, reward total was -21.000000. running mean: -20.025103\n",
            "resetting env. episode 2090.000000, reward total was -20.000000. running mean: -20.024852\n",
            "resetting env. episode 2091.000000, reward total was -21.000000. running mean: -20.034604\n",
            "resetting env. episode 2092.000000, reward total was -21.000000. running mean: -20.044258\n",
            "resetting env. episode 2093.000000, reward total was -18.000000. running mean: -20.023815\n",
            "resetting env. episode 2094.000000, reward total was -19.000000. running mean: -20.013577\n",
            "resetting env. episode 2095.000000, reward total was -20.000000. running mean: -20.013441\n",
            "resetting env. episode 2096.000000, reward total was -21.000000. running mean: -20.023307\n",
            "resetting env. episode 2097.000000, reward total was -20.000000. running mean: -20.023074\n",
            "resetting env. episode 2098.000000, reward total was -20.000000. running mean: -20.022843\n",
            "resetting env. episode 2099.000000, reward total was -20.000000. running mean: -20.022615\n",
            "resetting env. episode 2100.000000, reward total was -21.000000. running mean: -20.032388\n",
            "resetting env. episode 2101.000000, reward total was -20.000000. running mean: -20.032065\n",
            "resetting env. episode 2102.000000, reward total was -21.000000. running mean: -20.041744\n",
            "resetting env. episode 2103.000000, reward total was -19.000000. running mean: -20.031326\n",
            "resetting env. episode 2104.000000, reward total was -21.000000. running mean: -20.041013\n",
            "resetting env. episode 2105.000000, reward total was -19.000000. running mean: -20.030603\n",
            "resetting env. episode 2106.000000, reward total was -20.000000. running mean: -20.030297\n",
            "resetting env. episode 2107.000000, reward total was -19.000000. running mean: -20.019994\n",
            "resetting env. episode 2108.000000, reward total was -19.000000. running mean: -20.009794\n",
            "resetting env. episode 2109.000000, reward total was -17.000000. running mean: -19.979696\n",
            "resetting env. episode 2110.000000, reward total was -21.000000. running mean: -19.989899\n",
            "resetting env. episode 2111.000000, reward total was -20.000000. running mean: -19.990000\n",
            "resetting env. episode 2112.000000, reward total was -20.000000. running mean: -19.990100\n",
            "resetting env. episode 2113.000000, reward total was -18.000000. running mean: -19.970199\n",
            "resetting env. episode 2114.000000, reward total was -20.000000. running mean: -19.970497\n",
            "resetting env. episode 2115.000000, reward total was -21.000000. running mean: -19.980792\n",
            "resetting env. episode 2116.000000, reward total was -21.000000. running mean: -19.990984\n",
            "resetting env. episode 2117.000000, reward total was -20.000000. running mean: -19.991075\n",
            "resetting env. episode 2118.000000, reward total was -21.000000. running mean: -20.001164\n",
            "resetting env. episode 2119.000000, reward total was -19.000000. running mean: -19.991152\n",
            "resetting env. episode 2120.000000, reward total was -20.000000. running mean: -19.991241\n",
            "resetting env. episode 2121.000000, reward total was -21.000000. running mean: -20.001328\n",
            "resetting env. episode 2122.000000, reward total was -21.000000. running mean: -20.011315\n",
            "resetting env. episode 2123.000000, reward total was -21.000000. running mean: -20.021202\n",
            "resetting env. episode 2124.000000, reward total was -17.000000. running mean: -19.990990\n",
            "resetting env. episode 2125.000000, reward total was -21.000000. running mean: -20.001080\n",
            "resetting env. episode 2126.000000, reward total was -20.000000. running mean: -20.001069\n",
            "resetting env. episode 2127.000000, reward total was -20.000000. running mean: -20.001058\n",
            "resetting env. episode 2128.000000, reward total was -21.000000. running mean: -20.011048\n",
            "resetting env. episode 2129.000000, reward total was -21.000000. running mean: -20.020937\n",
            "resetting env. episode 2130.000000, reward total was -21.000000. running mean: -20.030728\n",
            "resetting env. episode 2131.000000, reward total was -19.000000. running mean: -20.020421\n",
            "resetting env. episode 2132.000000, reward total was -21.000000. running mean: -20.030216\n",
            "resetting env. episode 2133.000000, reward total was -20.000000. running mean: -20.029914\n",
            "resetting env. episode 2134.000000, reward total was -18.000000. running mean: -20.009615\n",
            "resetting env. episode 2135.000000, reward total was -20.000000. running mean: -20.009519\n",
            "resetting env. episode 2136.000000, reward total was -21.000000. running mean: -20.019424\n",
            "resetting env. episode 2137.000000, reward total was -21.000000. running mean: -20.029230\n",
            "resetting env. episode 2138.000000, reward total was -20.000000. running mean: -20.028937\n",
            "resetting env. episode 2139.000000, reward total was -20.000000. running mean: -20.028648\n",
            "resetting env. episode 2140.000000, reward total was -20.000000. running mean: -20.028361\n",
            "resetting env. episode 2141.000000, reward total was -21.000000. running mean: -20.038078\n",
            "resetting env. episode 2142.000000, reward total was -19.000000. running mean: -20.027697\n",
            "resetting env. episode 2143.000000, reward total was -20.000000. running mean: -20.027420\n",
            "resetting env. episode 2144.000000, reward total was -21.000000. running mean: -20.037146\n",
            "resetting env. episode 2145.000000, reward total was -19.000000. running mean: -20.026774\n",
            "resetting env. episode 2146.000000, reward total was -21.000000. running mean: -20.036507\n",
            "resetting env. episode 2147.000000, reward total was -18.000000. running mean: -20.016142\n",
            "resetting env. episode 2148.000000, reward total was -21.000000. running mean: -20.025980\n",
            "resetting env. episode 2149.000000, reward total was -21.000000. running mean: -20.035720\n",
            "resetting env. episode 2150.000000, reward total was -19.000000. running mean: -20.025363\n",
            "resetting env. episode 2151.000000, reward total was -19.000000. running mean: -20.015110\n",
            "resetting env. episode 2152.000000, reward total was -19.000000. running mean: -20.004958\n",
            "resetting env. episode 2153.000000, reward total was -18.000000. running mean: -19.984909\n",
            "resetting env. episode 2154.000000, reward total was -20.000000. running mean: -19.985060\n",
            "resetting env. episode 2155.000000, reward total was -19.000000. running mean: -19.975209\n",
            "resetting env. episode 2156.000000, reward total was -20.000000. running mean: -19.975457\n",
            "resetting env. episode 2157.000000, reward total was -21.000000. running mean: -19.985702\n",
            "resetting env. episode 2158.000000, reward total was -20.000000. running mean: -19.985845\n",
            "resetting env. episode 2159.000000, reward total was -19.000000. running mean: -19.975987\n",
            "resetting env. episode 2160.000000, reward total was -18.000000. running mean: -19.956227\n",
            "resetting env. episode 2161.000000, reward total was -20.000000. running mean: -19.956665\n",
            "resetting env. episode 2162.000000, reward total was -21.000000. running mean: -19.967098\n",
            "resetting env. episode 2163.000000, reward total was -21.000000. running mean: -19.977427\n",
            "resetting env. episode 2164.000000, reward total was -20.000000. running mean: -19.977653\n",
            "resetting env. episode 2165.000000, reward total was -19.000000. running mean: -19.967876\n",
            "resetting env. episode 2166.000000, reward total was -19.000000. running mean: -19.958198\n",
            "resetting env. episode 2167.000000, reward total was -21.000000. running mean: -19.968616\n",
            "resetting env. episode 2168.000000, reward total was -21.000000. running mean: -19.978930\n",
            "resetting env. episode 2169.000000, reward total was -19.000000. running mean: -19.969140\n",
            "resetting env. episode 2170.000000, reward total was -21.000000. running mean: -19.979449\n",
            "resetting env. episode 2171.000000, reward total was -19.000000. running mean: -19.969654\n",
            "resetting env. episode 2172.000000, reward total was -21.000000. running mean: -19.979958\n",
            "resetting env. episode 2173.000000, reward total was -21.000000. running mean: -19.990158\n",
            "resetting env. episode 2174.000000, reward total was -19.000000. running mean: -19.980257\n",
            "resetting env. episode 2175.000000, reward total was -20.000000. running mean: -19.980454\n",
            "resetting env. episode 2176.000000, reward total was -18.000000. running mean: -19.960650\n",
            "resetting env. episode 2177.000000, reward total was -20.000000. running mean: -19.961043\n",
            "resetting env. episode 2178.000000, reward total was -19.000000. running mean: -19.951433\n",
            "resetting env. episode 2179.000000, reward total was -19.000000. running mean: -19.941918\n",
            "resetting env. episode 2180.000000, reward total was -20.000000. running mean: -19.942499\n",
            "resetting env. episode 2181.000000, reward total was -20.000000. running mean: -19.943074\n",
            "resetting env. episode 2182.000000, reward total was -20.000000. running mean: -19.943643\n",
            "resetting env. episode 2183.000000, reward total was -20.000000. running mean: -19.944207\n",
            "resetting env. episode 2184.000000, reward total was -21.000000. running mean: -19.954765\n",
            "resetting env. episode 2185.000000, reward total was -20.000000. running mean: -19.955217\n",
            "resetting env. episode 2186.000000, reward total was -21.000000. running mean: -19.965665\n",
            "resetting env. episode 2187.000000, reward total was -21.000000. running mean: -19.976008\n",
            "resetting env. episode 2188.000000, reward total was -20.000000. running mean: -19.976248\n",
            "resetting env. episode 2189.000000, reward total was -20.000000. running mean: -19.976486\n",
            "resetting env. episode 2190.000000, reward total was -21.000000. running mean: -19.986721\n",
            "resetting env. episode 2191.000000, reward total was -19.000000. running mean: -19.976854\n",
            "resetting env. episode 2192.000000, reward total was -20.000000. running mean: -19.977085\n",
            "resetting env. episode 2193.000000, reward total was -19.000000. running mean: -19.967314\n",
            "resetting env. episode 2194.000000, reward total was -21.000000. running mean: -19.977641\n",
            "resetting env. episode 2195.000000, reward total was -17.000000. running mean: -19.947865\n",
            "resetting env. episode 2196.000000, reward total was -18.000000. running mean: -19.928386\n",
            "resetting env. episode 2197.000000, reward total was -21.000000. running mean: -19.939102\n",
            "resetting env. episode 2198.000000, reward total was -19.000000. running mean: -19.929711\n",
            "resetting env. episode 2199.000000, reward total was -20.000000. running mean: -19.930414\n",
            "resetting env. episode 2200.000000, reward total was -21.000000. running mean: -19.941110\n",
            "resetting env. episode 2201.000000, reward total was -20.000000. running mean: -19.941699\n",
            "resetting env. episode 2202.000000, reward total was -20.000000. running mean: -19.942282\n",
            "resetting env. episode 2203.000000, reward total was -20.000000. running mean: -19.942859\n",
            "resetting env. episode 2204.000000, reward total was -20.000000. running mean: -19.943431\n",
            "resetting env. episode 2205.000000, reward total was -21.000000. running mean: -19.953996\n",
            "resetting env. episode 2206.000000, reward total was -20.000000. running mean: -19.954456\n",
            "resetting env. episode 2207.000000, reward total was -19.000000. running mean: -19.944912\n",
            "resetting env. episode 2208.000000, reward total was -21.000000. running mean: -19.955463\n",
            "resetting env. episode 2209.000000, reward total was -19.000000. running mean: -19.945908\n",
            "resetting env. episode 2210.000000, reward total was -21.000000. running mean: -19.956449\n",
            "resetting env. episode 2211.000000, reward total was -18.000000. running mean: -19.936884\n",
            "resetting env. episode 2212.000000, reward total was -21.000000. running mean: -19.947516\n",
            "resetting env. episode 2213.000000, reward total was -21.000000. running mean: -19.958040\n",
            "resetting env. episode 2214.000000, reward total was -20.000000. running mean: -19.958460\n",
            "resetting env. episode 2215.000000, reward total was -17.000000. running mean: -19.928875\n",
            "resetting env. episode 2216.000000, reward total was -21.000000. running mean: -19.939587\n",
            "resetting env. episode 2217.000000, reward total was -21.000000. running mean: -19.950191\n",
            "resetting env. episode 2218.000000, reward total was -19.000000. running mean: -19.940689\n",
            "resetting env. episode 2219.000000, reward total was -21.000000. running mean: -19.951282\n",
            "resetting env. episode 2220.000000, reward total was -21.000000. running mean: -19.961769\n",
            "resetting env. episode 2221.000000, reward total was -19.000000. running mean: -19.952151\n",
            "resetting env. episode 2222.000000, reward total was -19.000000. running mean: -19.942630\n",
            "resetting env. episode 2223.000000, reward total was -21.000000. running mean: -19.953204\n",
            "resetting env. episode 2224.000000, reward total was -20.000000. running mean: -19.953672\n",
            "resetting env. episode 2225.000000, reward total was -21.000000. running mean: -19.964135\n",
            "resetting env. episode 2226.000000, reward total was -21.000000. running mean: -19.974494\n",
            "resetting env. episode 2227.000000, reward total was -19.000000. running mean: -19.964749\n",
            "resetting env. episode 2228.000000, reward total was -21.000000. running mean: -19.975101\n",
            "resetting env. episode 2229.000000, reward total was -21.000000. running mean: -19.985350\n",
            "resetting env. episode 2230.000000, reward total was -20.000000. running mean: -19.985497\n",
            "resetting env. episode 2231.000000, reward total was -19.000000. running mean: -19.975642\n",
            "resetting env. episode 2232.000000, reward total was -20.000000. running mean: -19.975885\n",
            "resetting env. episode 2233.000000, reward total was -20.000000. running mean: -19.976126\n",
            "resetting env. episode 2234.000000, reward total was -17.000000. running mean: -19.946365\n",
            "resetting env. episode 2235.000000, reward total was -21.000000. running mean: -19.956901\n",
            "resetting env. episode 2236.000000, reward total was -20.000000. running mean: -19.957332\n",
            "resetting env. episode 2237.000000, reward total was -20.000000. running mean: -19.957759\n",
            "resetting env. episode 2238.000000, reward total was -21.000000. running mean: -19.968182\n",
            "resetting env. episode 2239.000000, reward total was -18.000000. running mean: -19.948500\n",
            "resetting env. episode 2240.000000, reward total was -19.000000. running mean: -19.939015\n",
            "resetting env. episode 2241.000000, reward total was -21.000000. running mean: -19.949625\n",
            "resetting env. episode 2242.000000, reward total was -20.000000. running mean: -19.950128\n",
            "resetting env. episode 2243.000000, reward total was -21.000000. running mean: -19.960627\n",
            "resetting env. episode 2244.000000, reward total was -19.000000. running mean: -19.951021\n",
            "resetting env. episode 2245.000000, reward total was -21.000000. running mean: -19.961511\n",
            "resetting env. episode 2246.000000, reward total was -20.000000. running mean: -19.961895\n",
            "resetting env. episode 2247.000000, reward total was -21.000000. running mean: -19.972277\n",
            "resetting env. episode 2248.000000, reward total was -20.000000. running mean: -19.972554\n",
            "resetting env. episode 2249.000000, reward total was -20.000000. running mean: -19.972828\n",
            "resetting env. episode 2250.000000, reward total was -20.000000. running mean: -19.973100\n",
            "resetting env. episode 2251.000000, reward total was -20.000000. running mean: -19.973369\n",
            "resetting env. episode 2252.000000, reward total was -20.000000. running mean: -19.973635\n",
            "resetting env. episode 2253.000000, reward total was -20.000000. running mean: -19.973899\n",
            "resetting env. episode 2254.000000, reward total was -19.000000. running mean: -19.964160\n",
            "resetting env. episode 2255.000000, reward total was -19.000000. running mean: -19.954518\n",
            "resetting env. episode 2256.000000, reward total was -18.000000. running mean: -19.934973\n",
            "resetting env. episode 2257.000000, reward total was -21.000000. running mean: -19.945623\n",
            "resetting env. episode 2258.000000, reward total was -21.000000. running mean: -19.956167\n",
            "resetting env. episode 2259.000000, reward total was -20.000000. running mean: -19.956605\n",
            "resetting env. episode 2260.000000, reward total was -20.000000. running mean: -19.957039\n",
            "resetting env. episode 2261.000000, reward total was -20.000000. running mean: -19.957469\n",
            "resetting env. episode 2262.000000, reward total was -19.000000. running mean: -19.947894\n",
            "resetting env. episode 2263.000000, reward total was -21.000000. running mean: -19.958415\n",
            "resetting env. episode 2264.000000, reward total was -21.000000. running mean: -19.968831\n",
            "resetting env. episode 2265.000000, reward total was -20.000000. running mean: -19.969143\n",
            "resetting env. episode 2266.000000, reward total was -21.000000. running mean: -19.979451\n",
            "resetting env. episode 2267.000000, reward total was -19.000000. running mean: -19.969657\n",
            "resetting env. episode 2268.000000, reward total was -20.000000. running mean: -19.969960\n",
            "resetting env. episode 2269.000000, reward total was -19.000000. running mean: -19.960261\n",
            "resetting env. episode 2270.000000, reward total was -21.000000. running mean: -19.970658\n",
            "resetting env. episode 2271.000000, reward total was -17.000000. running mean: -19.940952\n",
            "resetting env. episode 2272.000000, reward total was -21.000000. running mean: -19.951542\n",
            "resetting env. episode 2273.000000, reward total was -20.000000. running mean: -19.952027\n",
            "resetting env. episode 2274.000000, reward total was -21.000000. running mean: -19.962506\n",
            "resetting env. episode 2275.000000, reward total was -21.000000. running mean: -19.972881\n",
            "resetting env. episode 2276.000000, reward total was -17.000000. running mean: -19.943153\n",
            "resetting env. episode 2277.000000, reward total was -21.000000. running mean: -19.953721\n",
            "resetting env. episode 2278.000000, reward total was -20.000000. running mean: -19.954184\n",
            "resetting env. episode 2279.000000, reward total was -21.000000. running mean: -19.964642\n",
            "resetting env. episode 2280.000000, reward total was -21.000000. running mean: -19.974996\n",
            "resetting env. episode 2281.000000, reward total was -21.000000. running mean: -19.985246\n",
            "resetting env. episode 2282.000000, reward total was -20.000000. running mean: -19.985393\n",
            "resetting env. episode 2283.000000, reward total was -21.000000. running mean: -19.995539\n",
            "resetting env. episode 2284.000000, reward total was -20.000000. running mean: -19.995584\n",
            "resetting env. episode 2285.000000, reward total was -20.000000. running mean: -19.995628\n",
            "resetting env. episode 2286.000000, reward total was -19.000000. running mean: -19.985672\n",
            "resetting env. episode 2287.000000, reward total was -21.000000. running mean: -19.995815\n",
            "resetting env. episode 2288.000000, reward total was -21.000000. running mean: -20.005857\n",
            "resetting env. episode 2289.000000, reward total was -19.000000. running mean: -19.995798\n",
            "resetting env. episode 2290.000000, reward total was -20.000000. running mean: -19.995840\n",
            "resetting env. episode 2291.000000, reward total was -20.000000. running mean: -19.995882\n",
            "resetting env. episode 2292.000000, reward total was -20.000000. running mean: -19.995923\n",
            "resetting env. episode 2293.000000, reward total was -18.000000. running mean: -19.975964\n",
            "resetting env. episode 2294.000000, reward total was -20.000000. running mean: -19.976204\n",
            "resetting env. episode 2295.000000, reward total was -20.000000. running mean: -19.976442\n",
            "resetting env. episode 2296.000000, reward total was -21.000000. running mean: -19.986678\n",
            "resetting env. episode 2297.000000, reward total was -21.000000. running mean: -19.996811\n",
            "resetting env. episode 2298.000000, reward total was -21.000000. running mean: -20.006843\n",
            "resetting env. episode 2299.000000, reward total was -19.000000. running mean: -19.996774\n",
            "resetting env. episode 2300.000000, reward total was -20.000000. running mean: -19.996807\n",
            "resetting env. episode 2301.000000, reward total was -20.000000. running mean: -19.996839\n",
            "resetting env. episode 2302.000000, reward total was -21.000000. running mean: -20.006870\n",
            "resetting env. episode 2303.000000, reward total was -20.000000. running mean: -20.006802\n",
            "resetting env. episode 2304.000000, reward total was -20.000000. running mean: -20.006733\n",
            "resetting env. episode 2305.000000, reward total was -18.000000. running mean: -19.986666\n",
            "resetting env. episode 2306.000000, reward total was -20.000000. running mean: -19.986799\n",
            "resetting env. episode 2307.000000, reward total was -21.000000. running mean: -19.996931\n",
            "resetting env. episode 2308.000000, reward total was -19.000000. running mean: -19.986962\n",
            "resetting env. episode 2309.000000, reward total was -19.000000. running mean: -19.977093\n",
            "resetting env. episode 2310.000000, reward total was -19.000000. running mean: -19.967322\n",
            "resetting env. episode 2311.000000, reward total was -18.000000. running mean: -19.947648\n",
            "resetting env. episode 2312.000000, reward total was -20.000000. running mean: -19.948172\n",
            "resetting env. episode 2313.000000, reward total was -21.000000. running mean: -19.958690\n",
            "resetting env. episode 2314.000000, reward total was -19.000000. running mean: -19.949103\n",
            "resetting env. episode 2315.000000, reward total was -18.000000. running mean: -19.929612\n",
            "resetting env. episode 2316.000000, reward total was -19.000000. running mean: -19.920316\n",
            "resetting env. episode 2317.000000, reward total was -21.000000. running mean: -19.931113\n",
            "resetting env. episode 2318.000000, reward total was -19.000000. running mean: -19.921802\n",
            "resetting env. episode 2319.000000, reward total was -21.000000. running mean: -19.932584\n",
            "resetting env. episode 2320.000000, reward total was -15.000000. running mean: -19.883258\n",
            "resetting env. episode 2321.000000, reward total was -21.000000. running mean: -19.894425\n",
            "resetting env. episode 2322.000000, reward total was -19.000000. running mean: -19.885481\n",
            "resetting env. episode 2323.000000, reward total was -21.000000. running mean: -19.896626\n",
            "resetting env. episode 2324.000000, reward total was -20.000000. running mean: -19.897660\n",
            "resetting env. episode 2325.000000, reward total was -20.000000. running mean: -19.898683\n",
            "resetting env. episode 2326.000000, reward total was -21.000000. running mean: -19.909697\n",
            "resetting env. episode 2327.000000, reward total was -21.000000. running mean: -19.920600\n",
            "resetting env. episode 2328.000000, reward total was -21.000000. running mean: -19.931394\n",
            "resetting env. episode 2329.000000, reward total was -21.000000. running mean: -19.942080\n",
            "resetting env. episode 2330.000000, reward total was -20.000000. running mean: -19.942659\n",
            "resetting env. episode 2331.000000, reward total was -21.000000. running mean: -19.953232\n",
            "resetting env. episode 2332.000000, reward total was -20.000000. running mean: -19.953700\n",
            "resetting env. episode 2333.000000, reward total was -19.000000. running mean: -19.944163\n",
            "resetting env. episode 2334.000000, reward total was -19.000000. running mean: -19.934721\n",
            "resetting env. episode 2335.000000, reward total was -19.000000. running mean: -19.925374\n",
            "resetting env. episode 2336.000000, reward total was -21.000000. running mean: -19.936120\n",
            "resetting env. episode 2337.000000, reward total was -20.000000. running mean: -19.936759\n",
            "resetting env. episode 2338.000000, reward total was -21.000000. running mean: -19.947392\n",
            "resetting env. episode 2339.000000, reward total was -18.000000. running mean: -19.927918\n",
            "resetting env. episode 2340.000000, reward total was -19.000000. running mean: -19.918639\n",
            "resetting env. episode 2341.000000, reward total was -20.000000. running mean: -19.919452\n",
            "resetting env. episode 2342.000000, reward total was -21.000000. running mean: -19.930258\n",
            "resetting env. episode 2343.000000, reward total was -17.000000. running mean: -19.900955\n",
            "resetting env. episode 2344.000000, reward total was -21.000000. running mean: -19.911946\n",
            "resetting env. episode 2345.000000, reward total was -21.000000. running mean: -19.922826\n",
            "resetting env. episode 2346.000000, reward total was -20.000000. running mean: -19.923598\n",
            "resetting env. episode 2347.000000, reward total was -21.000000. running mean: -19.934362\n",
            "resetting env. episode 2348.000000, reward total was -21.000000. running mean: -19.945018\n",
            "resetting env. episode 2349.000000, reward total was -21.000000. running mean: -19.955568\n",
            "resetting env. episode 2350.000000, reward total was -19.000000. running mean: -19.946012\n",
            "resetting env. episode 2351.000000, reward total was -20.000000. running mean: -19.946552\n",
            "resetting env. episode 2352.000000, reward total was -20.000000. running mean: -19.947087\n",
            "resetting env. episode 2353.000000, reward total was -20.000000. running mean: -19.947616\n",
            "resetting env. episode 2354.000000, reward total was -21.000000. running mean: -19.958140\n",
            "resetting env. episode 2355.000000, reward total was -21.000000. running mean: -19.968558\n",
            "resetting env. episode 2356.000000, reward total was -19.000000. running mean: -19.958873\n",
            "resetting env. episode 2357.000000, reward total was -20.000000. running mean: -19.959284\n",
            "resetting env. episode 2358.000000, reward total was -20.000000. running mean: -19.959691\n",
            "resetting env. episode 2359.000000, reward total was -21.000000. running mean: -19.970094\n",
            "resetting env. episode 2360.000000, reward total was -20.000000. running mean: -19.970393\n",
            "resetting env. episode 2361.000000, reward total was -21.000000. running mean: -19.980689\n",
            "resetting env. episode 2362.000000, reward total was -21.000000. running mean: -19.990882\n",
            "resetting env. episode 2363.000000, reward total was -21.000000. running mean: -20.000974\n",
            "resetting env. episode 2364.000000, reward total was -21.000000. running mean: -20.010964\n",
            "resetting env. episode 2365.000000, reward total was -16.000000. running mean: -19.970854\n",
            "resetting env. episode 2366.000000, reward total was -19.000000. running mean: -19.961146\n",
            "resetting env. episode 2367.000000, reward total was -21.000000. running mean: -19.971534\n",
            "resetting env. episode 2368.000000, reward total was -20.000000. running mean: -19.971819\n",
            "resetting env. episode 2369.000000, reward total was -20.000000. running mean: -19.972101\n",
            "resetting env. episode 2370.000000, reward total was -21.000000. running mean: -19.982380\n",
            "resetting env. episode 2371.000000, reward total was -20.000000. running mean: -19.982556\n",
            "resetting env. episode 2372.000000, reward total was -20.000000. running mean: -19.982730\n",
            "resetting env. episode 2373.000000, reward total was -20.000000. running mean: -19.982903\n",
            "resetting env. episode 2374.000000, reward total was -19.000000. running mean: -19.973074\n",
            "resetting env. episode 2375.000000, reward total was -20.000000. running mean: -19.973343\n",
            "resetting env. episode 2376.000000, reward total was -20.000000. running mean: -19.973610\n",
            "resetting env. episode 2377.000000, reward total was -21.000000. running mean: -19.983874\n",
            "resetting env. episode 2378.000000, reward total was -21.000000. running mean: -19.994035\n",
            "resetting env. episode 2379.000000, reward total was -21.000000. running mean: -20.004095\n",
            "resetting env. episode 2380.000000, reward total was -21.000000. running mean: -20.014054\n",
            "resetting env. episode 2381.000000, reward total was -21.000000. running mean: -20.023913\n",
            "resetting env. episode 2382.000000, reward total was -19.000000. running mean: -20.013674\n",
            "resetting env. episode 2383.000000, reward total was -19.000000. running mean: -20.003537\n",
            "resetting env. episode 2384.000000, reward total was -18.000000. running mean: -19.983502\n",
            "resetting env. episode 2385.000000, reward total was -21.000000. running mean: -19.993667\n",
            "resetting env. episode 2386.000000, reward total was -21.000000. running mean: -20.003730\n",
            "resetting env. episode 2387.000000, reward total was -21.000000. running mean: -20.013693\n",
            "resetting env. episode 2388.000000, reward total was -20.000000. running mean: -20.013556\n",
            "resetting env. episode 2389.000000, reward total was -19.000000. running mean: -20.003420\n",
            "resetting env. episode 2390.000000, reward total was -19.000000. running mean: -19.993386\n",
            "resetting env. episode 2391.000000, reward total was -19.000000. running mean: -19.983452\n",
            "resetting env. episode 2392.000000, reward total was -20.000000. running mean: -19.983618\n",
            "resetting env. episode 2393.000000, reward total was -21.000000. running mean: -19.993782\n",
            "resetting env. episode 2394.000000, reward total was -21.000000. running mean: -20.003844\n",
            "resetting env. episode 2395.000000, reward total was -20.000000. running mean: -20.003805\n",
            "resetting env. episode 2396.000000, reward total was -20.000000. running mean: -20.003767\n",
            "resetting env. episode 2397.000000, reward total was -19.000000. running mean: -19.993730\n",
            "resetting env. episode 2398.000000, reward total was -18.000000. running mean: -19.973792\n",
            "resetting env. episode 2399.000000, reward total was -21.000000. running mean: -19.984054\n",
            "resetting env. episode 2400.000000, reward total was -21.000000. running mean: -19.994214\n",
            "resetting env. episode 2401.000000, reward total was -21.000000. running mean: -20.004272\n",
            "resetting env. episode 2402.000000, reward total was -19.000000. running mean: -19.994229\n",
            "resetting env. episode 2403.000000, reward total was -19.000000. running mean: -19.984287\n",
            "resetting env. episode 2404.000000, reward total was -21.000000. running mean: -19.994444\n",
            "resetting env. episode 2405.000000, reward total was -17.000000. running mean: -19.964499\n",
            "resetting env. episode 2406.000000, reward total was -19.000000. running mean: -19.954854\n",
            "resetting env. episode 2407.000000, reward total was -21.000000. running mean: -19.965306\n",
            "resetting env. episode 2408.000000, reward total was -20.000000. running mean: -19.965653\n",
            "resetting env. episode 2409.000000, reward total was -21.000000. running mean: -19.975996\n",
            "resetting env. episode 2410.000000, reward total was -19.000000. running mean: -19.966236\n",
            "resetting env. episode 2411.000000, reward total was -21.000000. running mean: -19.976574\n",
            "resetting env. episode 2412.000000, reward total was -19.000000. running mean: -19.966808\n",
            "resetting env. episode 2413.000000, reward total was -20.000000. running mean: -19.967140\n",
            "resetting env. episode 2414.000000, reward total was -21.000000. running mean: -19.977469\n",
            "resetting env. episode 2415.000000, reward total was -18.000000. running mean: -19.957694\n",
            "resetting env. episode 2416.000000, reward total was -20.000000. running mean: -19.958117\n",
            "resetting env. episode 2417.000000, reward total was -21.000000. running mean: -19.968536\n",
            "resetting env. episode 2418.000000, reward total was -19.000000. running mean: -19.958851\n",
            "resetting env. episode 2419.000000, reward total was -20.000000. running mean: -19.959262\n",
            "resetting env. episode 2420.000000, reward total was -19.000000. running mean: -19.949670\n",
            "resetting env. episode 2421.000000, reward total was -21.000000. running mean: -19.960173\n",
            "resetting env. episode 2422.000000, reward total was -21.000000. running mean: -19.970571\n",
            "resetting env. episode 2423.000000, reward total was -21.000000. running mean: -19.980865\n",
            "resetting env. episode 2424.000000, reward total was -19.000000. running mean: -19.971057\n",
            "resetting env. episode 2425.000000, reward total was -19.000000. running mean: -19.961346\n",
            "resetting env. episode 2426.000000, reward total was -20.000000. running mean: -19.961733\n",
            "resetting env. episode 2427.000000, reward total was -20.000000. running mean: -19.962115\n",
            "resetting env. episode 2428.000000, reward total was -20.000000. running mean: -19.962494\n",
            "resetting env. episode 2429.000000, reward total was -21.000000. running mean: -19.972869\n",
            "resetting env. episode 2430.000000, reward total was -20.000000. running mean: -19.973141\n",
            "resetting env. episode 2431.000000, reward total was -19.000000. running mean: -19.963409\n",
            "resetting env. episode 2432.000000, reward total was -20.000000. running mean: -19.963775\n",
            "resetting env. episode 2433.000000, reward total was -21.000000. running mean: -19.974137\n",
            "resetting env. episode 2434.000000, reward total was -19.000000. running mean: -19.964396\n",
            "resetting env. episode 2435.000000, reward total was -20.000000. running mean: -19.964752\n",
            "resetting env. episode 2436.000000, reward total was -20.000000. running mean: -19.965104\n",
            "resetting env. episode 2437.000000, reward total was -21.000000. running mean: -19.975453\n",
            "resetting env. episode 2438.000000, reward total was -19.000000. running mean: -19.965699\n",
            "resetting env. episode 2439.000000, reward total was -21.000000. running mean: -19.976042\n",
            "resetting env. episode 2440.000000, reward total was -18.000000. running mean: -19.956281\n",
            "resetting env. episode 2441.000000, reward total was -21.000000. running mean: -19.966719\n",
            "resetting env. episode 2442.000000, reward total was -18.000000. running mean: -19.947051\n",
            "resetting env. episode 2443.000000, reward total was -19.000000. running mean: -19.937581\n",
            "resetting env. episode 2444.000000, reward total was -21.000000. running mean: -19.948205\n",
            "resetting env. episode 2445.000000, reward total was -18.000000. running mean: -19.928723\n",
            "resetting env. episode 2446.000000, reward total was -19.000000. running mean: -19.919436\n",
            "resetting env. episode 2447.000000, reward total was -21.000000. running mean: -19.930242\n",
            "resetting env. episode 2448.000000, reward total was -18.000000. running mean: -19.910939\n",
            "resetting env. episode 2449.000000, reward total was -20.000000. running mean: -19.911830\n",
            "resetting env. episode 2450.000000, reward total was -20.000000. running mean: -19.912711\n",
            "resetting env. episode 2451.000000, reward total was -19.000000. running mean: -19.903584\n",
            "resetting env. episode 2452.000000, reward total was -21.000000. running mean: -19.914548\n",
            "resetting env. episode 2453.000000, reward total was -21.000000. running mean: -19.925403\n",
            "resetting env. episode 2454.000000, reward total was -20.000000. running mean: -19.926149\n",
            "resetting env. episode 2455.000000, reward total was -20.000000. running mean: -19.926887\n",
            "resetting env. episode 2456.000000, reward total was -21.000000. running mean: -19.937619\n",
            "resetting env. episode 2457.000000, reward total was -20.000000. running mean: -19.938242\n",
            "resetting env. episode 2458.000000, reward total was -19.000000. running mean: -19.928860\n",
            "resetting env. episode 2459.000000, reward total was -19.000000. running mean: -19.919571\n",
            "resetting env. episode 2460.000000, reward total was -20.000000. running mean: -19.920376\n",
            "resetting env. episode 2461.000000, reward total was -19.000000. running mean: -19.911172\n",
            "resetting env. episode 2462.000000, reward total was -20.000000. running mean: -19.912060\n",
            "resetting env. episode 2463.000000, reward total was -20.000000. running mean: -19.912940\n",
            "resetting env. episode 2464.000000, reward total was -21.000000. running mean: -19.923810\n",
            "resetting env. episode 2465.000000, reward total was -21.000000. running mean: -19.934572\n",
            "resetting env. episode 2466.000000, reward total was -20.000000. running mean: -19.935226\n",
            "resetting env. episode 2467.000000, reward total was -21.000000. running mean: -19.945874\n",
            "resetting env. episode 2468.000000, reward total was -19.000000. running mean: -19.936415\n",
            "resetting env. episode 2469.000000, reward total was -19.000000. running mean: -19.927051\n",
            "resetting env. episode 2470.000000, reward total was -20.000000. running mean: -19.927781\n",
            "resetting env. episode 2471.000000, reward total was -19.000000. running mean: -19.918503\n",
            "resetting env. episode 2472.000000, reward total was -21.000000. running mean: -19.929318\n",
            "resetting env. episode 2473.000000, reward total was -19.000000. running mean: -19.920025\n",
            "resetting env. episode 2474.000000, reward total was -20.000000. running mean: -19.920824\n",
            "resetting env. episode 2475.000000, reward total was -21.000000. running mean: -19.931616\n",
            "resetting env. episode 2476.000000, reward total was -20.000000. running mean: -19.932300\n",
            "resetting env. episode 2477.000000, reward total was -21.000000. running mean: -19.942977\n",
            "resetting env. episode 2478.000000, reward total was -19.000000. running mean: -19.933547\n",
            "resetting env. episode 2479.000000, reward total was -20.000000. running mean: -19.934212\n",
            "resetting env. episode 2480.000000, reward total was -17.000000. running mean: -19.904870\n",
            "resetting env. episode 2481.000000, reward total was -21.000000. running mean: -19.915821\n",
            "resetting env. episode 2482.000000, reward total was -20.000000. running mean: -19.916663\n",
            "resetting env. episode 2483.000000, reward total was -20.000000. running mean: -19.917496\n",
            "resetting env. episode 2484.000000, reward total was -20.000000. running mean: -19.918321\n",
            "resetting env. episode 2485.000000, reward total was -18.000000. running mean: -19.899138\n",
            "resetting env. episode 2486.000000, reward total was -19.000000. running mean: -19.890147\n",
            "resetting env. episode 2487.000000, reward total was -20.000000. running mean: -19.891245\n",
            "resetting env. episode 2488.000000, reward total was -21.000000. running mean: -19.902333\n",
            "resetting env. episode 2489.000000, reward total was -21.000000. running mean: -19.913309\n",
            "resetting env. episode 2490.000000, reward total was -21.000000. running mean: -19.924176\n",
            "resetting env. episode 2491.000000, reward total was -21.000000. running mean: -19.934934\n",
            "resetting env. episode 2492.000000, reward total was -19.000000. running mean: -19.925585\n",
            "resetting env. episode 2493.000000, reward total was -20.000000. running mean: -19.926329\n",
            "resetting env. episode 2494.000000, reward total was -19.000000. running mean: -19.917066\n",
            "resetting env. episode 2495.000000, reward total was -20.000000. running mean: -19.917895\n",
            "resetting env. episode 2496.000000, reward total was -20.000000. running mean: -19.918716\n",
            "resetting env. episode 2497.000000, reward total was -20.000000. running mean: -19.919529\n",
            "resetting env. episode 2498.000000, reward total was -21.000000. running mean: -19.930334\n",
            "resetting env. episode 2499.000000, reward total was -21.000000. running mean: -19.941031\n",
            "resetting env. episode 2500.000000, reward total was -19.000000. running mean: -19.931620\n",
            "resetting env. episode 2501.000000, reward total was -21.000000. running mean: -19.942304\n",
            "resetting env. episode 2502.000000, reward total was -21.000000. running mean: -19.952881\n",
            "resetting env. episode 2503.000000, reward total was -20.000000. running mean: -19.953352\n",
            "resetting env. episode 2504.000000, reward total was -19.000000. running mean: -19.943819\n",
            "resetting env. episode 2505.000000, reward total was -21.000000. running mean: -19.954381\n",
            "resetting env. episode 2506.000000, reward total was -18.000000. running mean: -19.934837\n",
            "resetting env. episode 2507.000000, reward total was -18.000000. running mean: -19.915488\n",
            "resetting env. episode 2508.000000, reward total was -18.000000. running mean: -19.896333\n",
            "resetting env. episode 2509.000000, reward total was -20.000000. running mean: -19.897370\n",
            "resetting env. episode 2510.000000, reward total was -19.000000. running mean: -19.888396\n",
            "resetting env. episode 2511.000000, reward total was -20.000000. running mean: -19.889512\n",
            "resetting env. episode 2512.000000, reward total was -20.000000. running mean: -19.890617\n",
            "resetting env. episode 2513.000000, reward total was -21.000000. running mean: -19.901711\n",
            "resetting env. episode 2514.000000, reward total was -17.000000. running mean: -19.872694\n",
            "resetting env. episode 2515.000000, reward total was -20.000000. running mean: -19.873967\n",
            "resetting env. episode 2516.000000, reward total was -21.000000. running mean: -19.885227\n",
            "resetting env. episode 2517.000000, reward total was -17.000000. running mean: -19.856375\n",
            "resetting env. episode 2518.000000, reward total was -21.000000. running mean: -19.867811\n",
            "resetting env. episode 2519.000000, reward total was -19.000000. running mean: -19.859133\n",
            "resetting env. episode 2520.000000, reward total was -20.000000. running mean: -19.860542\n",
            "resetting env. episode 2521.000000, reward total was -21.000000. running mean: -19.871937\n",
            "resetting env. episode 2522.000000, reward total was -20.000000. running mean: -19.873217\n",
            "resetting env. episode 2523.000000, reward total was -20.000000. running mean: -19.874485\n",
            "resetting env. episode 2524.000000, reward total was -19.000000. running mean: -19.865740\n",
            "resetting env. episode 2525.000000, reward total was -19.000000. running mean: -19.857083\n",
            "resetting env. episode 2526.000000, reward total was -19.000000. running mean: -19.848512\n",
            "resetting env. episode 2527.000000, reward total was -19.000000. running mean: -19.840027\n",
            "resetting env. episode 2528.000000, reward total was -19.000000. running mean: -19.831627\n",
            "resetting env. episode 2529.000000, reward total was -20.000000. running mean: -19.833310\n",
            "resetting env. episode 2530.000000, reward total was -19.000000. running mean: -19.824977\n",
            "resetting env. episode 2531.000000, reward total was -21.000000. running mean: -19.836727\n",
            "resetting env. episode 2532.000000, reward total was -19.000000. running mean: -19.828360\n",
            "resetting env. episode 2533.000000, reward total was -21.000000. running mean: -19.840077\n",
            "resetting env. episode 2534.000000, reward total was -20.000000. running mean: -19.841676\n",
            "resetting env. episode 2535.000000, reward total was -19.000000. running mean: -19.833259\n",
            "resetting env. episode 2536.000000, reward total was -20.000000. running mean: -19.834926\n",
            "resetting env. episode 2537.000000, reward total was -19.000000. running mean: -19.826577\n",
            "resetting env. episode 2538.000000, reward total was -21.000000. running mean: -19.838311\n",
            "resetting env. episode 2539.000000, reward total was -20.000000. running mean: -19.839928\n",
            "resetting env. episode 2540.000000, reward total was -20.000000. running mean: -19.841529\n",
            "resetting env. episode 2541.000000, reward total was -21.000000. running mean: -19.853114\n",
            "resetting env. episode 2542.000000, reward total was -19.000000. running mean: -19.844583\n",
            "resetting env. episode 2543.000000, reward total was -19.000000. running mean: -19.836137\n",
            "resetting env. episode 2544.000000, reward total was -21.000000. running mean: -19.847775\n",
            "resetting env. episode 2545.000000, reward total was -21.000000. running mean: -19.859298\n",
            "resetting env. episode 2546.000000, reward total was -18.000000. running mean: -19.840705\n",
            "resetting env. episode 2547.000000, reward total was -21.000000. running mean: -19.852298\n",
            "resetting env. episode 2548.000000, reward total was -21.000000. running mean: -19.863775\n",
            "resetting env. episode 2549.000000, reward total was -20.000000. running mean: -19.865137\n",
            "resetting env. episode 2550.000000, reward total was -20.000000. running mean: -19.866485\n",
            "resetting env. episode 2551.000000, reward total was -20.000000. running mean: -19.867821\n",
            "resetting env. episode 2552.000000, reward total was -21.000000. running mean: -19.879142\n",
            "resetting env. episode 2553.000000, reward total was -20.000000. running mean: -19.880351\n",
            "resetting env. episode 2554.000000, reward total was -20.000000. running mean: -19.881548\n",
            "resetting env. episode 2555.000000, reward total was -18.000000. running mean: -19.862732\n",
            "resetting env. episode 2556.000000, reward total was -21.000000. running mean: -19.874105\n",
            "resetting env. episode 2557.000000, reward total was -19.000000. running mean: -19.865364\n",
            "resetting env. episode 2558.000000, reward total was -21.000000. running mean: -19.876710\n",
            "resetting env. episode 2559.000000, reward total was -19.000000. running mean: -19.867943\n",
            "resetting env. episode 2560.000000, reward total was -19.000000. running mean: -19.859263\n",
            "resetting env. episode 2561.000000, reward total was -19.000000. running mean: -19.850671\n",
            "resetting env. episode 2562.000000, reward total was -21.000000. running mean: -19.862164\n",
            "resetting env. episode 2563.000000, reward total was -21.000000. running mean: -19.873543\n",
            "resetting env. episode 2564.000000, reward total was -20.000000. running mean: -19.874807\n",
            "resetting env. episode 2565.000000, reward total was -19.000000. running mean: -19.866059\n",
            "resetting env. episode 2566.000000, reward total was -20.000000. running mean: -19.867398\n",
            "resetting env. episode 2567.000000, reward total was -17.000000. running mean: -19.838724\n",
            "resetting env. episode 2568.000000, reward total was -16.000000. running mean: -19.800337\n",
            "resetting env. episode 2569.000000, reward total was -21.000000. running mean: -19.812334\n",
            "resetting env. episode 2570.000000, reward total was -20.000000. running mean: -19.814210\n",
            "resetting env. episode 2571.000000, reward total was -21.000000. running mean: -19.826068\n",
            "resetting env. episode 2572.000000, reward total was -18.000000. running mean: -19.807808\n",
            "resetting env. episode 2573.000000, reward total was -21.000000. running mean: -19.819730\n",
            "resetting env. episode 2574.000000, reward total was -21.000000. running mean: -19.831532\n",
            "resetting env. episode 2575.000000, reward total was -20.000000. running mean: -19.833217\n",
            "resetting env. episode 2576.000000, reward total was -20.000000. running mean: -19.834885\n",
            "resetting env. episode 2577.000000, reward total was -19.000000. running mean: -19.826536\n",
            "resetting env. episode 2578.000000, reward total was -19.000000. running mean: -19.818271\n",
            "resetting env. episode 2579.000000, reward total was -21.000000. running mean: -19.830088\n",
            "resetting env. episode 2580.000000, reward total was -20.000000. running mean: -19.831787\n",
            "resetting env. episode 2581.000000, reward total was -17.000000. running mean: -19.803469\n",
            "resetting env. episode 2582.000000, reward total was -20.000000. running mean: -19.805434\n",
            "resetting env. episode 2583.000000, reward total was -20.000000. running mean: -19.807380\n",
            "resetting env. episode 2584.000000, reward total was -21.000000. running mean: -19.819306\n",
            "resetting env. episode 2585.000000, reward total was -19.000000. running mean: -19.811113\n",
            "resetting env. episode 2586.000000, reward total was -19.000000. running mean: -19.803002\n",
            "resetting env. episode 2587.000000, reward total was -17.000000. running mean: -19.774972\n",
            "resetting env. episode 2588.000000, reward total was -20.000000. running mean: -19.777222\n",
            "resetting env. episode 2589.000000, reward total was -21.000000. running mean: -19.789450\n",
            "resetting env. episode 2590.000000, reward total was -21.000000. running mean: -19.801556\n",
            "resetting env. episode 2591.000000, reward total was -21.000000. running mean: -19.813540\n",
            "resetting env. episode 2592.000000, reward total was -20.000000. running mean: -19.815405\n",
            "resetting env. episode 2593.000000, reward total was -21.000000. running mean: -19.827251\n",
            "resetting env. episode 2594.000000, reward total was -20.000000. running mean: -19.828978\n",
            "resetting env. episode 2595.000000, reward total was -19.000000. running mean: -19.820688\n",
            "resetting env. episode 2596.000000, reward total was -18.000000. running mean: -19.802481\n",
            "resetting env. episode 2597.000000, reward total was -18.000000. running mean: -19.784457\n",
            "resetting env. episode 2598.000000, reward total was -20.000000. running mean: -19.786612\n",
            "resetting env. episode 2599.000000, reward total was -18.000000. running mean: -19.768746\n",
            "resetting env. episode 2600.000000, reward total was -20.000000. running mean: -19.771059\n",
            "resetting env. episode 2601.000000, reward total was -19.000000. running mean: -19.763348\n",
            "resetting env. episode 2602.000000, reward total was -21.000000. running mean: -19.775714\n",
            "resetting env. episode 2603.000000, reward total was -21.000000. running mean: -19.787957\n",
            "resetting env. episode 2604.000000, reward total was -21.000000. running mean: -19.800078\n",
            "resetting env. episode 2605.000000, reward total was -19.000000. running mean: -19.792077\n",
            "resetting env. episode 2606.000000, reward total was -19.000000. running mean: -19.784156\n",
            "resetting env. episode 2607.000000, reward total was -17.000000. running mean: -19.756315\n",
            "resetting env. episode 2608.000000, reward total was -20.000000. running mean: -19.758751\n",
            "resetting env. episode 2609.000000, reward total was -19.000000. running mean: -19.751164\n",
            "resetting env. episode 2610.000000, reward total was -20.000000. running mean: -19.753652\n",
            "resetting env. episode 2611.000000, reward total was -20.000000. running mean: -19.756116\n",
            "resetting env. episode 2612.000000, reward total was -19.000000. running mean: -19.748555\n",
            "resetting env. episode 2613.000000, reward total was -20.000000. running mean: -19.751069\n",
            "resetting env. episode 2614.000000, reward total was -20.000000. running mean: -19.753558\n",
            "resetting env. episode 2615.000000, reward total was -21.000000. running mean: -19.766023\n",
            "resetting env. episode 2616.000000, reward total was -18.000000. running mean: -19.748363\n",
            "resetting env. episode 2617.000000, reward total was -21.000000. running mean: -19.760879\n",
            "resetting env. episode 2618.000000, reward total was -20.000000. running mean: -19.763270\n",
            "resetting env. episode 2619.000000, reward total was -21.000000. running mean: -19.775637\n",
            "resetting env. episode 2620.000000, reward total was -20.000000. running mean: -19.777881\n",
            "resetting env. episode 2621.000000, reward total was -21.000000. running mean: -19.790102\n",
            "resetting env. episode 2622.000000, reward total was -19.000000. running mean: -19.782201\n",
            "resetting env. episode 2623.000000, reward total was -17.000000. running mean: -19.754379\n",
            "resetting env. episode 2624.000000, reward total was -19.000000. running mean: -19.746835\n",
            "resetting env. episode 2625.000000, reward total was -20.000000. running mean: -19.749367\n",
            "resetting env. episode 2626.000000, reward total was -21.000000. running mean: -19.761873\n",
            "resetting env. episode 2627.000000, reward total was -20.000000. running mean: -19.764255\n",
            "resetting env. episode 2628.000000, reward total was -19.000000. running mean: -19.756612\n",
            "resetting env. episode 2629.000000, reward total was -21.000000. running mean: -19.769046\n",
            "resetting env. episode 2630.000000, reward total was -19.000000. running mean: -19.761356\n",
            "resetting env. episode 2631.000000, reward total was -20.000000. running mean: -19.763742\n",
            "resetting env. episode 2632.000000, reward total was -20.000000. running mean: -19.766105\n",
            "resetting env. episode 2633.000000, reward total was -19.000000. running mean: -19.758444\n",
            "resetting env. episode 2634.000000, reward total was -16.000000. running mean: -19.720859\n",
            "resetting env. episode 2635.000000, reward total was -20.000000. running mean: -19.723651\n",
            "resetting env. episode 2636.000000, reward total was -21.000000. running mean: -19.736414\n",
            "resetting env. episode 2637.000000, reward total was -20.000000. running mean: -19.739050\n",
            "resetting env. episode 2638.000000, reward total was -18.000000. running mean: -19.721659\n",
            "resetting env. episode 2639.000000, reward total was -21.000000. running mean: -19.734443\n",
            "resetting env. episode 2640.000000, reward total was -21.000000. running mean: -19.747098\n",
            "resetting env. episode 2641.000000, reward total was -21.000000. running mean: -19.759627\n",
            "resetting env. episode 2642.000000, reward total was -21.000000. running mean: -19.772031\n",
            "resetting env. episode 2643.000000, reward total was -20.000000. running mean: -19.774311\n",
            "resetting env. episode 2644.000000, reward total was -19.000000. running mean: -19.766568\n",
            "resetting env. episode 2645.000000, reward total was -21.000000. running mean: -19.778902\n",
            "resetting env. episode 2646.000000, reward total was -20.000000. running mean: -19.781113\n",
            "resetting env. episode 2647.000000, reward total was -19.000000. running mean: -19.773302\n",
            "resetting env. episode 2648.000000, reward total was -20.000000. running mean: -19.775569\n",
            "resetting env. episode 2649.000000, reward total was -20.000000. running mean: -19.777813\n",
            "resetting env. episode 2650.000000, reward total was -20.000000. running mean: -19.780035\n",
            "resetting env. episode 2651.000000, reward total was -21.000000. running mean: -19.792235\n",
            "resetting env. episode 2652.000000, reward total was -21.000000. running mean: -19.804312\n",
            "resetting env. episode 2653.000000, reward total was -20.000000. running mean: -19.806269\n",
            "resetting env. episode 2654.000000, reward total was -19.000000. running mean: -19.798207\n",
            "resetting env. episode 2655.000000, reward total was -20.000000. running mean: -19.800224\n",
            "resetting env. episode 2656.000000, reward total was -20.000000. running mean: -19.802222\n",
            "resetting env. episode 2657.000000, reward total was -18.000000. running mean: -19.784200\n",
            "resetting env. episode 2658.000000, reward total was -21.000000. running mean: -19.796358\n",
            "resetting env. episode 2659.000000, reward total was -19.000000. running mean: -19.788394\n",
            "resetting env. episode 2660.000000, reward total was -21.000000. running mean: -19.800510\n",
            "resetting env. episode 2661.000000, reward total was -19.000000. running mean: -19.792505\n",
            "resetting env. episode 2662.000000, reward total was -20.000000. running mean: -19.794580\n",
            "resetting env. episode 2663.000000, reward total was -21.000000. running mean: -19.806634\n",
            "resetting env. episode 2664.000000, reward total was -18.000000. running mean: -19.788568\n",
            "resetting env. episode 2665.000000, reward total was -21.000000. running mean: -19.800682\n",
            "resetting env. episode 2666.000000, reward total was -19.000000. running mean: -19.792676\n",
            "resetting env. episode 2667.000000, reward total was -21.000000. running mean: -19.804749\n",
            "resetting env. episode 2668.000000, reward total was -21.000000. running mean: -19.816701\n",
            "resetting env. episode 2669.000000, reward total was -20.000000. running mean: -19.818534\n",
            "resetting env. episode 2670.000000, reward total was -19.000000. running mean: -19.810349\n",
            "resetting env. episode 2671.000000, reward total was -21.000000. running mean: -19.822246\n",
            "resetting env. episode 2672.000000, reward total was -19.000000. running mean: -19.814023\n",
            "resetting env. episode 2673.000000, reward total was -19.000000. running mean: -19.805883\n",
            "resetting env. episode 2674.000000, reward total was -19.000000. running mean: -19.797824\n",
            "resetting env. episode 2675.000000, reward total was -21.000000. running mean: -19.809846\n",
            "resetting env. episode 2676.000000, reward total was -21.000000. running mean: -19.821747\n",
            "resetting env. episode 2677.000000, reward total was -20.000000. running mean: -19.823530\n",
            "resetting env. episode 2678.000000, reward total was -19.000000. running mean: -19.815295\n",
            "resetting env. episode 2679.000000, reward total was -20.000000. running mean: -19.817142\n",
            "resetting env. episode 2680.000000, reward total was -20.000000. running mean: -19.818970\n",
            "resetting env. episode 2681.000000, reward total was -21.000000. running mean: -19.830780\n",
            "resetting env. episode 2682.000000, reward total was -20.000000. running mean: -19.832473\n",
            "resetting env. episode 2683.000000, reward total was -20.000000. running mean: -19.834148\n",
            "resetting env. episode 2684.000000, reward total was -21.000000. running mean: -19.845806\n",
            "resetting env. episode 2685.000000, reward total was -20.000000. running mean: -19.847348\n",
            "resetting env. episode 2686.000000, reward total was -19.000000. running mean: -19.838875\n",
            "resetting env. episode 2687.000000, reward total was -20.000000. running mean: -19.840486\n",
            "resetting env. episode 2688.000000, reward total was -20.000000. running mean: -19.842081\n",
            "resetting env. episode 2689.000000, reward total was -20.000000. running mean: -19.843661\n",
            "resetting env. episode 2690.000000, reward total was -21.000000. running mean: -19.855224\n",
            "resetting env. episode 2691.000000, reward total was -21.000000. running mean: -19.866672\n",
            "resetting env. episode 2692.000000, reward total was -21.000000. running mean: -19.878005\n",
            "resetting env. episode 2693.000000, reward total was -20.000000. running mean: -19.879225\n",
            "resetting env. episode 2694.000000, reward total was -20.000000. running mean: -19.880433\n",
            "resetting env. episode 2695.000000, reward total was -21.000000. running mean: -19.891628\n",
            "resetting env. episode 2696.000000, reward total was -20.000000. running mean: -19.892712\n",
            "resetting env. episode 2697.000000, reward total was -20.000000. running mean: -19.893785\n",
            "resetting env. episode 2698.000000, reward total was -21.000000. running mean: -19.904847\n",
            "resetting env. episode 2699.000000, reward total was -20.000000. running mean: -19.905799\n",
            "resetting env. episode 2700.000000, reward total was -19.000000. running mean: -19.896741\n",
            "resetting env. episode 2701.000000, reward total was -20.000000. running mean: -19.897773\n",
            "resetting env. episode 2702.000000, reward total was -21.000000. running mean: -19.908795\n",
            "resetting env. episode 2703.000000, reward total was -21.000000. running mean: -19.919708\n",
            "resetting env. episode 2704.000000, reward total was -21.000000. running mean: -19.930510\n",
            "resetting env. episode 2705.000000, reward total was -21.000000. running mean: -19.941205\n",
            "resetting env. episode 2706.000000, reward total was -21.000000. running mean: -19.951793\n",
            "resetting env. episode 2707.000000, reward total was -19.000000. running mean: -19.942275\n",
            "resetting env. episode 2708.000000, reward total was -16.000000. running mean: -19.902853\n",
            "resetting env. episode 2709.000000, reward total was -21.000000. running mean: -19.913824\n",
            "resetting env. episode 2710.000000, reward total was -21.000000. running mean: -19.924686\n",
            "resetting env. episode 2711.000000, reward total was -19.000000. running mean: -19.915439\n",
            "resetting env. episode 2712.000000, reward total was -19.000000. running mean: -19.906285\n",
            "resetting env. episode 2713.000000, reward total was -21.000000. running mean: -19.917222\n",
            "resetting env. episode 2714.000000, reward total was -19.000000. running mean: -19.908050\n",
            "resetting env. episode 2715.000000, reward total was -20.000000. running mean: -19.908969\n",
            "resetting env. episode 2716.000000, reward total was -20.000000. running mean: -19.909879\n",
            "resetting env. episode 2717.000000, reward total was -20.000000. running mean: -19.910781\n",
            "resetting env. episode 2718.000000, reward total was -21.000000. running mean: -19.921673\n",
            "resetting env. episode 2719.000000, reward total was -20.000000. running mean: -19.922456\n",
            "resetting env. episode 2720.000000, reward total was -19.000000. running mean: -19.913231\n",
            "resetting env. episode 2721.000000, reward total was -20.000000. running mean: -19.914099\n",
            "resetting env. episode 2722.000000, reward total was -18.000000. running mean: -19.894958\n",
            "resetting env. episode 2723.000000, reward total was -18.000000. running mean: -19.876009\n",
            "resetting env. episode 2724.000000, reward total was -18.000000. running mean: -19.857248\n",
            "resetting env. episode 2725.000000, reward total was -19.000000. running mean: -19.848676\n",
            "resetting env. episode 2726.000000, reward total was -21.000000. running mean: -19.860189\n",
            "resetting env. episode 2727.000000, reward total was -21.000000. running mean: -19.871587\n",
            "resetting env. episode 2728.000000, reward total was -21.000000. running mean: -19.882871\n",
            "resetting env. episode 2729.000000, reward total was -21.000000. running mean: -19.894043\n",
            "resetting env. episode 2730.000000, reward total was -21.000000. running mean: -19.905102\n",
            "resetting env. episode 2731.000000, reward total was -18.000000. running mean: -19.886051\n",
            "resetting env. episode 2732.000000, reward total was -20.000000. running mean: -19.887191\n",
            "resetting env. episode 2733.000000, reward total was -19.000000. running mean: -19.878319\n",
            "resetting env. episode 2734.000000, reward total was -20.000000. running mean: -19.879536\n",
            "resetting env. episode 2735.000000, reward total was -18.000000. running mean: -19.860740\n",
            "resetting env. episode 2736.000000, reward total was -20.000000. running mean: -19.862133\n",
            "resetting env. episode 2737.000000, reward total was -18.000000. running mean: -19.843512\n",
            "resetting env. episode 2738.000000, reward total was -21.000000. running mean: -19.855076\n",
            "resetting env. episode 2739.000000, reward total was -20.000000. running mean: -19.856526\n",
            "resetting env. episode 2740.000000, reward total was -19.000000. running mean: -19.847960\n",
            "resetting env. episode 2741.000000, reward total was -17.000000. running mean: -19.819481\n",
            "resetting env. episode 2742.000000, reward total was -20.000000. running mean: -19.821286\n",
            "resetting env. episode 2743.000000, reward total was -21.000000. running mean: -19.833073\n",
            "resetting env. episode 2744.000000, reward total was -18.000000. running mean: -19.814742\n",
            "resetting env. episode 2745.000000, reward total was -19.000000. running mean: -19.806595\n",
            "resetting env. episode 2746.000000, reward total was -21.000000. running mean: -19.818529\n",
            "resetting env. episode 2747.000000, reward total was -19.000000. running mean: -19.810344\n",
            "resetting env. episode 2748.000000, reward total was -20.000000. running mean: -19.812240\n",
            "resetting env. episode 2749.000000, reward total was -21.000000. running mean: -19.824118\n",
            "resetting env. episode 2750.000000, reward total was -19.000000. running mean: -19.815877\n",
            "resetting env. episode 2751.000000, reward total was -21.000000. running mean: -19.827718\n",
            "resetting env. episode 2752.000000, reward total was -21.000000. running mean: -19.839441\n",
            "resetting env. episode 2753.000000, reward total was -20.000000. running mean: -19.841046\n",
            "resetting env. episode 2754.000000, reward total was -21.000000. running mean: -19.852636\n",
            "resetting env. episode 2755.000000, reward total was -20.000000. running mean: -19.854110\n",
            "resetting env. episode 2756.000000, reward total was -17.000000. running mean: -19.825568\n",
            "resetting env. episode 2757.000000, reward total was -18.000000. running mean: -19.807313\n",
            "resetting env. episode 2758.000000, reward total was -20.000000. running mean: -19.809240\n",
            "resetting env. episode 2759.000000, reward total was -21.000000. running mean: -19.821147\n",
            "resetting env. episode 2760.000000, reward total was -20.000000. running mean: -19.822936\n",
            "resetting env. episode 2761.000000, reward total was -19.000000. running mean: -19.814706\n",
            "resetting env. episode 2762.000000, reward total was -20.000000. running mean: -19.816559\n",
            "resetting env. episode 2763.000000, reward total was -20.000000. running mean: -19.818394\n",
            "resetting env. episode 2764.000000, reward total was -19.000000. running mean: -19.810210\n",
            "resetting env. episode 2765.000000, reward total was -20.000000. running mean: -19.812108\n",
            "resetting env. episode 2766.000000, reward total was -17.000000. running mean: -19.783987\n",
            "resetting env. episode 2767.000000, reward total was -21.000000. running mean: -19.796147\n",
            "resetting env. episode 2768.000000, reward total was -18.000000. running mean: -19.778185\n",
            "resetting env. episode 2769.000000, reward total was -21.000000. running mean: -19.790403\n",
            "resetting env. episode 2770.000000, reward total was -21.000000. running mean: -19.802499\n",
            "resetting env. episode 2771.000000, reward total was -16.000000. running mean: -19.764474\n",
            "resetting env. episode 2772.000000, reward total was -20.000000. running mean: -19.766830\n",
            "resetting env. episode 2773.000000, reward total was -19.000000. running mean: -19.759161\n",
            "resetting env. episode 2774.000000, reward total was -20.000000. running mean: -19.761570\n",
            "resetting env. episode 2775.000000, reward total was -21.000000. running mean: -19.773954\n",
            "resetting env. episode 2776.000000, reward total was -19.000000. running mean: -19.766215\n",
            "resetting env. episode 2777.000000, reward total was -20.000000. running mean: -19.768552\n",
            "resetting env. episode 2778.000000, reward total was -19.000000. running mean: -19.760867\n",
            "resetting env. episode 2779.000000, reward total was -21.000000. running mean: -19.773258\n",
            "resetting env. episode 2780.000000, reward total was -21.000000. running mean: -19.785526\n",
            "resetting env. episode 2781.000000, reward total was -19.000000. running mean: -19.777670\n",
            "resetting env. episode 2782.000000, reward total was -19.000000. running mean: -19.769894\n",
            "resetting env. episode 2783.000000, reward total was -20.000000. running mean: -19.772195\n",
            "resetting env. episode 2784.000000, reward total was -19.000000. running mean: -19.764473\n",
            "resetting env. episode 2785.000000, reward total was -19.000000. running mean: -19.756828\n",
            "resetting env. episode 2786.000000, reward total was -19.000000. running mean: -19.749260\n",
            "resetting env. episode 2787.000000, reward total was -21.000000. running mean: -19.761767\n",
            "resetting env. episode 2788.000000, reward total was -18.000000. running mean: -19.744150\n",
            "resetting env. episode 2789.000000, reward total was -19.000000. running mean: -19.736708\n",
            "resetting env. episode 2790.000000, reward total was -18.000000. running mean: -19.719341\n",
            "resetting env. episode 2791.000000, reward total was -17.000000. running mean: -19.692148\n",
            "resetting env. episode 2792.000000, reward total was -21.000000. running mean: -19.705226\n",
            "resetting env. episode 2793.000000, reward total was -21.000000. running mean: -19.718174\n",
            "resetting env. episode 2794.000000, reward total was -21.000000. running mean: -19.730992\n",
            "resetting env. episode 2795.000000, reward total was -20.000000. running mean: -19.733682\n",
            "resetting env. episode 2796.000000, reward total was -19.000000. running mean: -19.726345\n",
            "resetting env. episode 2797.000000, reward total was -20.000000. running mean: -19.729082\n",
            "resetting env. episode 2798.000000, reward total was -20.000000. running mean: -19.731791\n",
            "resetting env. episode 2799.000000, reward total was -21.000000. running mean: -19.744473\n",
            "resetting env. episode 2800.000000, reward total was -21.000000. running mean: -19.757028\n",
            "resetting env. episode 2801.000000, reward total was -19.000000. running mean: -19.749458\n",
            "resetting env. episode 2802.000000, reward total was -18.000000. running mean: -19.731964\n",
            "resetting env. episode 2803.000000, reward total was -20.000000. running mean: -19.734644\n",
            "resetting env. episode 2804.000000, reward total was -21.000000. running mean: -19.747297\n",
            "resetting env. episode 2805.000000, reward total was -21.000000. running mean: -19.759824\n",
            "resetting env. episode 2806.000000, reward total was -20.000000. running mean: -19.762226\n",
            "resetting env. episode 2807.000000, reward total was -19.000000. running mean: -19.754604\n",
            "resetting env. episode 2808.000000, reward total was -19.000000. running mean: -19.747058\n",
            "resetting env. episode 2809.000000, reward total was -18.000000. running mean: -19.729587\n",
            "resetting env. episode 2810.000000, reward total was -20.000000. running mean: -19.732291\n",
            "resetting env. episode 2811.000000, reward total was -19.000000. running mean: -19.724969\n",
            "resetting env. episode 2812.000000, reward total was -19.000000. running mean: -19.717719\n",
            "resetting env. episode 2813.000000, reward total was -20.000000. running mean: -19.720542\n",
            "resetting env. episode 2814.000000, reward total was -18.000000. running mean: -19.703336\n",
            "resetting env. episode 2815.000000, reward total was -21.000000. running mean: -19.716303\n",
            "resetting env. episode 2816.000000, reward total was -18.000000. running mean: -19.699140\n",
            "resetting env. episode 2817.000000, reward total was -19.000000. running mean: -19.692148\n",
            "resetting env. episode 2818.000000, reward total was -21.000000. running mean: -19.705227\n",
            "resetting env. episode 2819.000000, reward total was -20.000000. running mean: -19.708175\n",
            "resetting env. episode 2820.000000, reward total was -19.000000. running mean: -19.701093\n",
            "resetting env. episode 2821.000000, reward total was -21.000000. running mean: -19.714082\n",
            "resetting env. episode 2822.000000, reward total was -20.000000. running mean: -19.716941\n",
            "resetting env. episode 2823.000000, reward total was -16.000000. running mean: -19.679772\n",
            "resetting env. episode 2824.000000, reward total was -19.000000. running mean: -19.672974\n",
            "resetting env. episode 2825.000000, reward total was -17.000000. running mean: -19.646244\n",
            "resetting env. episode 2826.000000, reward total was -20.000000. running mean: -19.649782\n",
            "resetting env. episode 2827.000000, reward total was -19.000000. running mean: -19.643284\n",
            "resetting env. episode 2828.000000, reward total was -19.000000. running mean: -19.636851\n",
            "resetting env. episode 2829.000000, reward total was -20.000000. running mean: -19.640483\n",
            "resetting env. episode 2830.000000, reward total was -20.000000. running mean: -19.644078\n",
            "resetting env. episode 2831.000000, reward total was -21.000000. running mean: -19.657637\n",
            "resetting env. episode 2832.000000, reward total was -19.000000. running mean: -19.651061\n",
            "resetting env. episode 2833.000000, reward total was -21.000000. running mean: -19.664550\n",
            "resetting env. episode 2834.000000, reward total was -18.000000. running mean: -19.647905\n",
            "resetting env. episode 2835.000000, reward total was -20.000000. running mean: -19.651426\n",
            "resetting env. episode 2836.000000, reward total was -19.000000. running mean: -19.644911\n",
            "resetting env. episode 2837.000000, reward total was -21.000000. running mean: -19.658462\n",
            "resetting env. episode 2838.000000, reward total was -21.000000. running mean: -19.671878\n",
            "resetting env. episode 2839.000000, reward total was -20.000000. running mean: -19.675159\n",
            "resetting env. episode 2840.000000, reward total was -18.000000. running mean: -19.658407\n",
            "resetting env. episode 2841.000000, reward total was -21.000000. running mean: -19.671823\n",
            "resetting env. episode 2842.000000, reward total was -19.000000. running mean: -19.665105\n",
            "resetting env. episode 2843.000000, reward total was -20.000000. running mean: -19.668454\n",
            "resetting env. episode 2844.000000, reward total was -21.000000. running mean: -19.681769\n",
            "resetting env. episode 2845.000000, reward total was -21.000000. running mean: -19.694952\n",
            "resetting env. episode 2846.000000, reward total was -20.000000. running mean: -19.698002\n",
            "resetting env. episode 2847.000000, reward total was -19.000000. running mean: -19.691022\n",
            "resetting env. episode 2848.000000, reward total was -19.000000. running mean: -19.684112\n",
            "resetting env. episode 2849.000000, reward total was -19.000000. running mean: -19.677271\n",
            "resetting env. episode 2850.000000, reward total was -21.000000. running mean: -19.690498\n",
            "resetting env. episode 2851.000000, reward total was -19.000000. running mean: -19.683593\n",
            "resetting env. episode 2852.000000, reward total was -20.000000. running mean: -19.686757\n",
            "resetting env. episode 2853.000000, reward total was -19.000000. running mean: -19.679890\n",
            "resetting env. episode 2854.000000, reward total was -20.000000. running mean: -19.683091\n",
            "resetting env. episode 2855.000000, reward total was -20.000000. running mean: -19.686260\n",
            "resetting env. episode 2856.000000, reward total was -21.000000. running mean: -19.699397\n",
            "resetting env. episode 2857.000000, reward total was -19.000000. running mean: -19.692403\n",
            "resetting env. episode 2858.000000, reward total was -20.000000. running mean: -19.695479\n",
            "resetting env. episode 2859.000000, reward total was -21.000000. running mean: -19.708524\n",
            "resetting env. episode 2860.000000, reward total was -21.000000. running mean: -19.721439\n",
            "resetting env. episode 2861.000000, reward total was -18.000000. running mean: -19.704225\n",
            "resetting env. episode 2862.000000, reward total was -20.000000. running mean: -19.707183\n",
            "resetting env. episode 2863.000000, reward total was -21.000000. running mean: -19.720111\n",
            "resetting env. episode 2864.000000, reward total was -20.000000. running mean: -19.722910\n",
            "resetting env. episode 2865.000000, reward total was -20.000000. running mean: -19.725680\n",
            "resetting env. episode 2866.000000, reward total was -17.000000. running mean: -19.698424\n",
            "resetting env. episode 2867.000000, reward total was -19.000000. running mean: -19.691439\n",
            "resetting env. episode 2868.000000, reward total was -20.000000. running mean: -19.694525\n",
            "resetting env. episode 2869.000000, reward total was -20.000000. running mean: -19.697580\n",
            "resetting env. episode 2870.000000, reward total was -20.000000. running mean: -19.700604\n",
            "resetting env. episode 2871.000000, reward total was -21.000000. running mean: -19.713598\n",
            "resetting env. episode 2872.000000, reward total was -21.000000. running mean: -19.726462\n",
            "resetting env. episode 2873.000000, reward total was -21.000000. running mean: -19.739197\n",
            "resetting env. episode 2874.000000, reward total was -20.000000. running mean: -19.741805\n",
            "resetting env. episode 2875.000000, reward total was -20.000000. running mean: -19.744387\n",
            "resetting env. episode 2876.000000, reward total was -19.000000. running mean: -19.736943\n",
            "resetting env. episode 2877.000000, reward total was -19.000000. running mean: -19.729574\n",
            "resetting env. episode 2878.000000, reward total was -20.000000. running mean: -19.732278\n",
            "resetting env. episode 2879.000000, reward total was -21.000000. running mean: -19.744956\n",
            "resetting env. episode 2880.000000, reward total was -18.000000. running mean: -19.727506\n",
            "resetting env. episode 2881.000000, reward total was -20.000000. running mean: -19.730231\n",
            "resetting env. episode 2882.000000, reward total was -20.000000. running mean: -19.732929\n",
            "resetting env. episode 2883.000000, reward total was -21.000000. running mean: -19.745599\n",
            "resetting env. episode 2884.000000, reward total was -20.000000. running mean: -19.748143\n",
            "resetting env. episode 2885.000000, reward total was -19.000000. running mean: -19.740662\n",
            "resetting env. episode 2886.000000, reward total was -19.000000. running mean: -19.733255\n",
            "resetting env. episode 2887.000000, reward total was -21.000000. running mean: -19.745923\n",
            "resetting env. episode 2888.000000, reward total was -21.000000. running mean: -19.758463\n",
            "resetting env. episode 2889.000000, reward total was -19.000000. running mean: -19.750879\n",
            "resetting env. episode 2890.000000, reward total was -18.000000. running mean: -19.733370\n",
            "resetting env. episode 2891.000000, reward total was -19.000000. running mean: -19.726036\n",
            "resetting env. episode 2892.000000, reward total was -21.000000. running mean: -19.738776\n",
            "resetting env. episode 2893.000000, reward total was -21.000000. running mean: -19.751388\n",
            "resetting env. episode 2894.000000, reward total was -17.000000. running mean: -19.723874\n",
            "resetting env. episode 2895.000000, reward total was -19.000000. running mean: -19.716636\n",
            "resetting env. episode 2896.000000, reward total was -20.000000. running mean: -19.719469\n",
            "resetting env. episode 2897.000000, reward total was -20.000000. running mean: -19.722275\n",
            "resetting env. episode 2898.000000, reward total was -20.000000. running mean: -19.725052\n",
            "resetting env. episode 2899.000000, reward total was -17.000000. running mean: -19.697801\n",
            "resetting env. episode 2900.000000, reward total was -20.000000. running mean: -19.700823\n",
            "resetting env. episode 2901.000000, reward total was -21.000000. running mean: -19.713815\n",
            "resetting env. episode 2902.000000, reward total was -21.000000. running mean: -19.726677\n",
            "resetting env. episode 2903.000000, reward total was -20.000000. running mean: -19.729410\n",
            "resetting env. episode 2904.000000, reward total was -18.000000. running mean: -19.712116\n",
            "resetting env. episode 2905.000000, reward total was -17.000000. running mean: -19.684995\n",
            "resetting env. episode 2906.000000, reward total was -19.000000. running mean: -19.678145\n",
            "resetting env. episode 2907.000000, reward total was -20.000000. running mean: -19.681363\n",
            "resetting env. episode 2908.000000, reward total was -20.000000. running mean: -19.684550\n",
            "resetting env. episode 2909.000000, reward total was -20.000000. running mean: -19.687704\n",
            "resetting env. episode 2910.000000, reward total was -19.000000. running mean: -19.680827\n",
            "resetting env. episode 2911.000000, reward total was -21.000000. running mean: -19.694019\n",
            "resetting env. episode 2912.000000, reward total was -19.000000. running mean: -19.687079\n",
            "resetting env. episode 2913.000000, reward total was -21.000000. running mean: -19.700208\n",
            "resetting env. episode 2914.000000, reward total was -19.000000. running mean: -19.693206\n",
            "resetting env. episode 2915.000000, reward total was -21.000000. running mean: -19.706274\n",
            "resetting env. episode 2916.000000, reward total was -18.000000. running mean: -19.689211\n",
            "resetting env. episode 2917.000000, reward total was -21.000000. running mean: -19.702319\n",
            "resetting env. episode 2918.000000, reward total was -20.000000. running mean: -19.705296\n",
            "resetting env. episode 2919.000000, reward total was -18.000000. running mean: -19.688243\n",
            "resetting env. episode 2920.000000, reward total was -20.000000. running mean: -19.691360\n",
            "resetting env. episode 2921.000000, reward total was -19.000000. running mean: -19.684447\n",
            "resetting env. episode 2922.000000, reward total was -21.000000. running mean: -19.697602\n",
            "resetting env. episode 2923.000000, reward total was -20.000000. running mean: -19.700626\n",
            "resetting env. episode 2924.000000, reward total was -21.000000. running mean: -19.713620\n",
            "resetting env. episode 2925.000000, reward total was -20.000000. running mean: -19.716484\n",
            "resetting env. episode 2926.000000, reward total was -20.000000. running mean: -19.719319\n",
            "resetting env. episode 2927.000000, reward total was -20.000000. running mean: -19.722126\n",
            "resetting env. episode 2928.000000, reward total was -21.000000. running mean: -19.734905\n",
            "resetting env. episode 2929.000000, reward total was -18.000000. running mean: -19.717556\n",
            "resetting env. episode 2930.000000, reward total was -20.000000. running mean: -19.720380\n",
            "resetting env. episode 2931.000000, reward total was -18.000000. running mean: -19.703176\n",
            "resetting env. episode 2932.000000, reward total was -20.000000. running mean: -19.706144\n",
            "resetting env. episode 2933.000000, reward total was -21.000000. running mean: -19.719083\n",
            "resetting env. episode 2934.000000, reward total was -21.000000. running mean: -19.731892\n",
            "resetting env. episode 2935.000000, reward total was -17.000000. running mean: -19.704573\n",
            "resetting env. episode 2936.000000, reward total was -20.000000. running mean: -19.707528\n",
            "resetting env. episode 2937.000000, reward total was -21.000000. running mean: -19.720452\n",
            "resetting env. episode 2938.000000, reward total was -21.000000. running mean: -19.733248\n",
            "resetting env. episode 2939.000000, reward total was -20.000000. running mean: -19.735915\n",
            "resetting env. episode 2940.000000, reward total was -19.000000. running mean: -19.728556\n",
            "resetting env. episode 2941.000000, reward total was -20.000000. running mean: -19.731271\n",
            "resetting env. episode 2942.000000, reward total was -21.000000. running mean: -19.743958\n",
            "resetting env. episode 2943.000000, reward total was -19.000000. running mean: -19.736518\n",
            "resetting env. episode 2944.000000, reward total was -18.000000. running mean: -19.719153\n",
            "resetting env. episode 2945.000000, reward total was -20.000000. running mean: -19.721962\n",
            "resetting env. episode 2946.000000, reward total was -21.000000. running mean: -19.734742\n",
            "resetting env. episode 2947.000000, reward total was -21.000000. running mean: -19.747395\n",
            "resetting env. episode 2948.000000, reward total was -19.000000. running mean: -19.739921\n",
            "resetting env. episode 2949.000000, reward total was -18.000000. running mean: -19.722521\n",
            "resetting env. episode 2950.000000, reward total was -19.000000. running mean: -19.715296\n",
            "resetting env. episode 2951.000000, reward total was -20.000000. running mean: -19.718143\n",
            "resetting env. episode 2952.000000, reward total was -19.000000. running mean: -19.710962\n",
            "resetting env. episode 2953.000000, reward total was -19.000000. running mean: -19.703852\n",
            "resetting env. episode 2954.000000, reward total was -19.000000. running mean: -19.696814\n",
            "resetting env. episode 2955.000000, reward total was -20.000000. running mean: -19.699845\n",
            "resetting env. episode 2956.000000, reward total was -20.000000. running mean: -19.702847\n",
            "resetting env. episode 2957.000000, reward total was -21.000000. running mean: -19.715819\n",
            "resetting env. episode 2958.000000, reward total was -21.000000. running mean: -19.728660\n",
            "resetting env. episode 2959.000000, reward total was -20.000000. running mean: -19.731374\n",
            "resetting env. episode 2960.000000, reward total was -20.000000. running mean: -19.734060\n",
            "resetting env. episode 2961.000000, reward total was -21.000000. running mean: -19.746719\n",
            "resetting env. episode 2962.000000, reward total was -19.000000. running mean: -19.739252\n",
            "resetting env. episode 2963.000000, reward total was -20.000000. running mean: -19.741860\n",
            "resetting env. episode 2964.000000, reward total was -21.000000. running mean: -19.754441\n",
            "resetting env. episode 2965.000000, reward total was -19.000000. running mean: -19.746897\n",
            "resetting env. episode 2966.000000, reward total was -18.000000. running mean: -19.729428\n",
            "resetting env. episode 2967.000000, reward total was -20.000000. running mean: -19.732133\n",
            "resetting env. episode 2968.000000, reward total was -18.000000. running mean: -19.714812\n",
            "resetting env. episode 2969.000000, reward total was -21.000000. running mean: -19.727664\n",
            "resetting env. episode 2970.000000, reward total was -21.000000. running mean: -19.740387\n",
            "resetting env. episode 2971.000000, reward total was -21.000000. running mean: -19.752983\n",
            "resetting env. episode 2972.000000, reward total was -21.000000. running mean: -19.765454\n",
            "resetting env. episode 2973.000000, reward total was -21.000000. running mean: -19.777799\n",
            "resetting env. episode 2974.000000, reward total was -18.000000. running mean: -19.760021\n",
            "resetting env. episode 2975.000000, reward total was -19.000000. running mean: -19.752421\n",
            "resetting env. episode 2976.000000, reward total was -16.000000. running mean: -19.714897\n",
            "resetting env. episode 2977.000000, reward total was -21.000000. running mean: -19.727748\n",
            "resetting env. episode 2978.000000, reward total was -21.000000. running mean: -19.740470\n",
            "resetting env. episode 2979.000000, reward total was -21.000000. running mean: -19.753066\n",
            "resetting env. episode 2980.000000, reward total was -20.000000. running mean: -19.755535\n",
            "resetting env. episode 2981.000000, reward total was -20.000000. running mean: -19.757980\n",
            "resetting env. episode 2982.000000, reward total was -21.000000. running mean: -19.770400\n",
            "resetting env. episode 2983.000000, reward total was -21.000000. running mean: -19.782696\n",
            "resetting env. episode 2984.000000, reward total was -19.000000. running mean: -19.774869\n",
            "resetting env. episode 2985.000000, reward total was -20.000000. running mean: -19.777120\n",
            "resetting env. episode 2986.000000, reward total was -18.000000. running mean: -19.759349\n",
            "resetting env. episode 2987.000000, reward total was -19.000000. running mean: -19.751755\n",
            "resetting env. episode 2988.000000, reward total was -17.000000. running mean: -19.724238\n",
            "resetting env. episode 2989.000000, reward total was -21.000000. running mean: -19.736995\n",
            "resetting env. episode 2990.000000, reward total was -20.000000. running mean: -19.739626\n",
            "resetting env. episode 2991.000000, reward total was -21.000000. running mean: -19.752229\n",
            "resetting env. episode 2992.000000, reward total was -21.000000. running mean: -19.764707\n",
            "resetting env. episode 2993.000000, reward total was -19.000000. running mean: -19.757060\n",
            "resetting env. episode 2994.000000, reward total was -17.000000. running mean: -19.729489\n",
            "resetting env. episode 2995.000000, reward total was -19.000000. running mean: -19.722194\n",
            "resetting env. episode 2996.000000, reward total was -16.000000. running mean: -19.684972\n",
            "resetting env. episode 2997.000000, reward total was -20.000000. running mean: -19.688123\n",
            "resetting env. episode 2998.000000, reward total was -21.000000. running mean: -19.701242\n",
            "resetting env. episode 2999.000000, reward total was -20.000000. running mean: -19.704229\n",
            "resetting env. episode 3000.000000, reward total was -21.000000. running mean: -19.717187\n",
            "resetting env. episode 3001.000000, reward total was -20.000000. running mean: -19.720015\n",
            "resetting env. episode 3002.000000, reward total was -21.000000. running mean: -19.732815\n",
            "resetting env. episode 3003.000000, reward total was -20.000000. running mean: -19.735487\n",
            "resetting env. episode 3004.000000, reward total was -20.000000. running mean: -19.738132\n",
            "resetting env. episode 3005.000000, reward total was -16.000000. running mean: -19.700750\n",
            "resetting env. episode 3006.000000, reward total was -20.000000. running mean: -19.703743\n",
            "resetting env. episode 3007.000000, reward total was -19.000000. running mean: -19.696706\n",
            "resetting env. episode 3008.000000, reward total was -17.000000. running mean: -19.669738\n",
            "resetting env. episode 3009.000000, reward total was -19.000000. running mean: -19.663041\n",
            "resetting env. episode 3010.000000, reward total was -21.000000. running mean: -19.676411\n",
            "resetting env. episode 3011.000000, reward total was -20.000000. running mean: -19.679647\n",
            "resetting env. episode 3012.000000, reward total was -20.000000. running mean: -19.682850\n",
            "resetting env. episode 3013.000000, reward total was -20.000000. running mean: -19.686022\n",
            "resetting env. episode 3014.000000, reward total was -21.000000. running mean: -19.699161\n",
            "resetting env. episode 3015.000000, reward total was -21.000000. running mean: -19.712170\n",
            "resetting env. episode 3016.000000, reward total was -19.000000. running mean: -19.705048\n",
            "resetting env. episode 3017.000000, reward total was -19.000000. running mean: -19.697998\n",
            "resetting env. episode 3018.000000, reward total was -19.000000. running mean: -19.691018\n",
            "resetting env. episode 3019.000000, reward total was -21.000000. running mean: -19.704107\n",
            "resetting env. episode 3020.000000, reward total was -21.000000. running mean: -19.717066\n",
            "resetting env. episode 3021.000000, reward total was -20.000000. running mean: -19.719896\n",
            "resetting env. episode 3022.000000, reward total was -20.000000. running mean: -19.722697\n",
            "resetting env. episode 3023.000000, reward total was -20.000000. running mean: -19.725470\n",
            "resetting env. episode 3024.000000, reward total was -21.000000. running mean: -19.738215\n",
            "resetting env. episode 3025.000000, reward total was -20.000000. running mean: -19.740833\n",
            "resetting env. episode 3026.000000, reward total was -21.000000. running mean: -19.753425\n",
            "resetting env. episode 3027.000000, reward total was -21.000000. running mean: -19.765890\n",
            "resetting env. episode 3028.000000, reward total was -20.000000. running mean: -19.768231\n",
            "resetting env. episode 3029.000000, reward total was -20.000000. running mean: -19.770549\n",
            "resetting env. episode 3030.000000, reward total was -17.000000. running mean: -19.742844\n",
            "resetting env. episode 3031.000000, reward total was -21.000000. running mean: -19.755415\n",
            "resetting env. episode 3032.000000, reward total was -21.000000. running mean: -19.767861\n",
            "resetting env. episode 3033.000000, reward total was -20.000000. running mean: -19.770182\n",
            "resetting env. episode 3034.000000, reward total was -21.000000. running mean: -19.782481\n",
            "resetting env. episode 3035.000000, reward total was -20.000000. running mean: -19.784656\n",
            "resetting env. episode 3036.000000, reward total was -20.000000. running mean: -19.786809\n",
            "resetting env. episode 3037.000000, reward total was -19.000000. running mean: -19.778941\n",
            "resetting env. episode 3038.000000, reward total was -21.000000. running mean: -19.791152\n",
            "resetting env. episode 3039.000000, reward total was -20.000000. running mean: -19.793240\n",
            "resetting env. episode 3040.000000, reward total was -21.000000. running mean: -19.805308\n",
            "resetting env. episode 3041.000000, reward total was -20.000000. running mean: -19.807255\n",
            "resetting env. episode 3042.000000, reward total was -18.000000. running mean: -19.789182\n",
            "resetting env. episode 3043.000000, reward total was -19.000000. running mean: -19.781290\n",
            "resetting env. episode 3044.000000, reward total was -21.000000. running mean: -19.793477\n",
            "resetting env. episode 3045.000000, reward total was -21.000000. running mean: -19.805543\n",
            "resetting env. episode 3046.000000, reward total was -20.000000. running mean: -19.807487\n",
            "resetting env. episode 3047.000000, reward total was -20.000000. running mean: -19.809412\n",
            "resetting env. episode 3048.000000, reward total was -20.000000. running mean: -19.811318\n",
            "resetting env. episode 3049.000000, reward total was -20.000000. running mean: -19.813205\n",
            "resetting env. episode 3050.000000, reward total was -19.000000. running mean: -19.805073\n",
            "resetting env. episode 3051.000000, reward total was -20.000000. running mean: -19.807022\n",
            "resetting env. episode 3052.000000, reward total was -20.000000. running mean: -19.808952\n",
            "resetting env. episode 3053.000000, reward total was -20.000000. running mean: -19.810863\n",
            "resetting env. episode 3054.000000, reward total was -19.000000. running mean: -19.802754\n",
            "resetting env. episode 3055.000000, reward total was -19.000000. running mean: -19.794726\n",
            "resetting env. episode 3056.000000, reward total was -21.000000. running mean: -19.806779\n",
            "resetting env. episode 3057.000000, reward total was -18.000000. running mean: -19.788711\n",
            "resetting env. episode 3058.000000, reward total was -21.000000. running mean: -19.800824\n",
            "resetting env. episode 3059.000000, reward total was -21.000000. running mean: -19.812816\n",
            "resetting env. episode 3060.000000, reward total was -19.000000. running mean: -19.804688\n",
            "resetting env. episode 3061.000000, reward total was -19.000000. running mean: -19.796641\n",
            "resetting env. episode 3062.000000, reward total was -19.000000. running mean: -19.788675\n",
            "resetting env. episode 3063.000000, reward total was -21.000000. running mean: -19.800788\n",
            "resetting env. episode 3064.000000, reward total was -20.000000. running mean: -19.802780\n",
            "resetting env. episode 3065.000000, reward total was -20.000000. running mean: -19.804752\n",
            "resetting env. episode 3066.000000, reward total was -20.000000. running mean: -19.806705\n",
            "resetting env. episode 3067.000000, reward total was -18.000000. running mean: -19.788638\n",
            "resetting env. episode 3068.000000, reward total was -21.000000. running mean: -19.800751\n",
            "resetting env. episode 3069.000000, reward total was -20.000000. running mean: -19.802744\n",
            "resetting env. episode 3070.000000, reward total was -19.000000. running mean: -19.794716\n",
            "resetting env. episode 3071.000000, reward total was -21.000000. running mean: -19.806769\n",
            "resetting env. episode 3072.000000, reward total was -19.000000. running mean: -19.798701\n",
            "resetting env. episode 3073.000000, reward total was -20.000000. running mean: -19.800714\n",
            "resetting env. episode 3074.000000, reward total was -20.000000. running mean: -19.802707\n",
            "resetting env. episode 3075.000000, reward total was -18.000000. running mean: -19.784680\n",
            "resetting env. episode 3076.000000, reward total was -19.000000. running mean: -19.776833\n",
            "resetting env. episode 3077.000000, reward total was -20.000000. running mean: -19.779065\n",
            "resetting env. episode 3078.000000, reward total was -21.000000. running mean: -19.791274\n",
            "resetting env. episode 3079.000000, reward total was -20.000000. running mean: -19.793362\n",
            "resetting env. episode 3080.000000, reward total was -21.000000. running mean: -19.805428\n",
            "resetting env. episode 3081.000000, reward total was -15.000000. running mean: -19.757374\n",
            "resetting env. episode 3082.000000, reward total was -21.000000. running mean: -19.769800\n",
            "resetting env. episode 3083.000000, reward total was -21.000000. running mean: -19.782102\n",
            "resetting env. episode 3084.000000, reward total was -21.000000. running mean: -19.794281\n",
            "resetting env. episode 3085.000000, reward total was -19.000000. running mean: -19.786338\n",
            "resetting env. episode 3086.000000, reward total was -19.000000. running mean: -19.778475\n",
            "resetting env. episode 3087.000000, reward total was -20.000000. running mean: -19.780690\n",
            "resetting env. episode 3088.000000, reward total was -21.000000. running mean: -19.792883\n",
            "resetting env. episode 3089.000000, reward total was -18.000000. running mean: -19.774954\n",
            "resetting env. episode 3090.000000, reward total was -21.000000. running mean: -19.787205\n",
            "resetting env. episode 3091.000000, reward total was -18.000000. running mean: -19.769333\n",
            "resetting env. episode 3092.000000, reward total was -20.000000. running mean: -19.771639\n",
            "resetting env. episode 3093.000000, reward total was -21.000000. running mean: -19.783923\n",
            "resetting env. episode 3094.000000, reward total was -21.000000. running mean: -19.796084\n",
            "resetting env. episode 3095.000000, reward total was -20.000000. running mean: -19.798123\n",
            "resetting env. episode 3096.000000, reward total was -20.000000. running mean: -19.800142\n",
            "resetting env. episode 3097.000000, reward total was -21.000000. running mean: -19.812140\n",
            "resetting env. episode 3098.000000, reward total was -20.000000. running mean: -19.814019\n",
            "resetting env. episode 3099.000000, reward total was -18.000000. running mean: -19.795879\n",
            "resetting env. episode 3100.000000, reward total was -21.000000. running mean: -19.807920\n",
            "resetting env. episode 3101.000000, reward total was -20.000000. running mean: -19.809841\n",
            "resetting env. episode 3102.000000, reward total was -17.000000. running mean: -19.781742\n",
            "resetting env. episode 3103.000000, reward total was -19.000000. running mean: -19.773925\n",
            "resetting env. episode 3104.000000, reward total was -21.000000. running mean: -19.786186\n",
            "resetting env. episode 3105.000000, reward total was -16.000000. running mean: -19.748324\n",
            "resetting env. episode 3106.000000, reward total was -20.000000. running mean: -19.750841\n",
            "resetting env. episode 3107.000000, reward total was -19.000000. running mean: -19.743332\n",
            "resetting env. episode 3108.000000, reward total was -19.000000. running mean: -19.735899\n",
            "resetting env. episode 3109.000000, reward total was -21.000000. running mean: -19.748540\n",
            "resetting env. episode 3110.000000, reward total was -20.000000. running mean: -19.751054\n",
            "resetting env. episode 3111.000000, reward total was -20.000000. running mean: -19.753544\n",
            "resetting env. episode 3112.000000, reward total was -21.000000. running mean: -19.766008\n",
            "resetting env. episode 3113.000000, reward total was -20.000000. running mean: -19.768348\n",
            "resetting env. episode 3114.000000, reward total was -21.000000. running mean: -19.780665\n",
            "resetting env. episode 3115.000000, reward total was -20.000000. running mean: -19.782858\n",
            "resetting env. episode 3116.000000, reward total was -19.000000. running mean: -19.775030\n",
            "resetting env. episode 3117.000000, reward total was -21.000000. running mean: -19.787279\n",
            "resetting env. episode 3118.000000, reward total was -20.000000. running mean: -19.789407\n",
            "resetting env. episode 3119.000000, reward total was -21.000000. running mean: -19.801512\n",
            "resetting env. episode 3120.000000, reward total was -21.000000. running mean: -19.813497\n",
            "resetting env. episode 3121.000000, reward total was -20.000000. running mean: -19.815362\n",
            "resetting env. episode 3122.000000, reward total was -19.000000. running mean: -19.807209\n",
            "resetting env. episode 3123.000000, reward total was -18.000000. running mean: -19.789137\n",
            "resetting env. episode 3124.000000, reward total was -19.000000. running mean: -19.781245\n",
            "resetting env. episode 3125.000000, reward total was -20.000000. running mean: -19.783433\n",
            "resetting env. episode 3126.000000, reward total was -21.000000. running mean: -19.795599\n",
            "resetting env. episode 3127.000000, reward total was -20.000000. running mean: -19.797643\n",
            "resetting env. episode 3128.000000, reward total was -20.000000. running mean: -19.799666\n",
            "resetting env. episode 3129.000000, reward total was -20.000000. running mean: -19.801669\n",
            "resetting env. episode 3130.000000, reward total was -21.000000. running mean: -19.813653\n",
            "resetting env. episode 3131.000000, reward total was -18.000000. running mean: -19.795516\n",
            "resetting env. episode 3132.000000, reward total was -18.000000. running mean: -19.777561\n",
            "resetting env. episode 3133.000000, reward total was -19.000000. running mean: -19.769785\n",
            "resetting env. episode 3134.000000, reward total was -21.000000. running mean: -19.782088\n",
            "resetting env. episode 3135.000000, reward total was -19.000000. running mean: -19.774267\n",
            "resetting env. episode 3136.000000, reward total was -20.000000. running mean: -19.776524\n",
            "resetting env. episode 3137.000000, reward total was -21.000000. running mean: -19.788759\n",
            "resetting env. episode 3138.000000, reward total was -20.000000. running mean: -19.790871\n",
            "resetting env. episode 3139.000000, reward total was -18.000000. running mean: -19.772963\n",
            "resetting env. episode 3140.000000, reward total was -21.000000. running mean: -19.785233\n",
            "resetting env. episode 3141.000000, reward total was -16.000000. running mean: -19.747381\n",
            "resetting env. episode 3142.000000, reward total was -20.000000. running mean: -19.749907\n",
            "resetting env. episode 3143.000000, reward total was -15.000000. running mean: -19.702408\n",
            "resetting env. episode 3144.000000, reward total was -19.000000. running mean: -19.695384\n",
            "resetting env. episode 3145.000000, reward total was -18.000000. running mean: -19.678430\n",
            "resetting env. episode 3146.000000, reward total was -20.000000. running mean: -19.681645\n",
            "resetting env. episode 3147.000000, reward total was -21.000000. running mean: -19.694829\n",
            "resetting env. episode 3148.000000, reward total was -21.000000. running mean: -19.707881\n",
            "resetting env. episode 3149.000000, reward total was -20.000000. running mean: -19.710802\n",
            "resetting env. episode 3150.000000, reward total was -20.000000. running mean: -19.713694\n",
            "resetting env. episode 3151.000000, reward total was -19.000000. running mean: -19.706557\n",
            "resetting env. episode 3152.000000, reward total was -18.000000. running mean: -19.689491\n",
            "resetting env. episode 3153.000000, reward total was -21.000000. running mean: -19.702596\n",
            "resetting env. episode 3154.000000, reward total was -21.000000. running mean: -19.715571\n",
            "resetting env. episode 3155.000000, reward total was -20.000000. running mean: -19.718415\n",
            "resetting env. episode 3156.000000, reward total was -21.000000. running mean: -19.731231\n",
            "resetting env. episode 3157.000000, reward total was -19.000000. running mean: -19.723918\n",
            "resetting env. episode 3158.000000, reward total was -20.000000. running mean: -19.726679\n",
            "resetting env. episode 3159.000000, reward total was -19.000000. running mean: -19.719412\n",
            "resetting env. episode 3160.000000, reward total was -20.000000. running mean: -19.722218\n",
            "resetting env. episode 3161.000000, reward total was -21.000000. running mean: -19.734996\n",
            "resetting env. episode 3162.000000, reward total was -20.000000. running mean: -19.737646\n",
            "resetting env. episode 3163.000000, reward total was -19.000000. running mean: -19.730270\n",
            "resetting env. episode 3164.000000, reward total was -20.000000. running mean: -19.732967\n",
            "resetting env. episode 3165.000000, reward total was -19.000000. running mean: -19.725637\n",
            "resetting env. episode 3166.000000, reward total was -17.000000. running mean: -19.698381\n",
            "resetting env. episode 3167.000000, reward total was -17.000000. running mean: -19.671397\n",
            "resetting env. episode 3168.000000, reward total was -21.000000. running mean: -19.684683\n",
            "resetting env. episode 3169.000000, reward total was -21.000000. running mean: -19.697836\n",
            "resetting env. episode 3170.000000, reward total was -19.000000. running mean: -19.690858\n",
            "resetting env. episode 3171.000000, reward total was -21.000000. running mean: -19.703949\n",
            "resetting env. episode 3172.000000, reward total was -20.000000. running mean: -19.706910\n",
            "resetting env. episode 3173.000000, reward total was -19.000000. running mean: -19.699841\n",
            "resetting env. episode 3174.000000, reward total was -21.000000. running mean: -19.712842\n",
            "resetting env. episode 3175.000000, reward total was -21.000000. running mean: -19.725714\n",
            "resetting env. episode 3176.000000, reward total was -21.000000. running mean: -19.738457\n",
            "resetting env. episode 3177.000000, reward total was -19.000000. running mean: -19.731072\n",
            "resetting env. episode 3178.000000, reward total was -20.000000. running mean: -19.733762\n",
            "resetting env. episode 3179.000000, reward total was -21.000000. running mean: -19.746424\n",
            "resetting env. episode 3180.000000, reward total was -19.000000. running mean: -19.738960\n",
            "resetting env. episode 3181.000000, reward total was -20.000000. running mean: -19.741570\n",
            "resetting env. episode 3182.000000, reward total was -20.000000. running mean: -19.744154\n",
            "resetting env. episode 3183.000000, reward total was -21.000000. running mean: -19.756713\n",
            "resetting env. episode 3184.000000, reward total was -18.000000. running mean: -19.739146\n",
            "resetting env. episode 3185.000000, reward total was -18.000000. running mean: -19.721754\n",
            "resetting env. episode 3186.000000, reward total was -21.000000. running mean: -19.734537\n",
            "resetting env. episode 3187.000000, reward total was -21.000000. running mean: -19.747191\n",
            "resetting env. episode 3188.000000, reward total was -20.000000. running mean: -19.749719\n",
            "resetting env. episode 3189.000000, reward total was -20.000000. running mean: -19.752222\n",
            "resetting env. episode 3190.000000, reward total was -19.000000. running mean: -19.744700\n",
            "resetting env. episode 3191.000000, reward total was -21.000000. running mean: -19.757253\n",
            "resetting env. episode 3192.000000, reward total was -21.000000. running mean: -19.769680\n",
            "resetting env. episode 3193.000000, reward total was -17.000000. running mean: -19.741984\n",
            "resetting env. episode 3194.000000, reward total was -20.000000. running mean: -19.744564\n",
            "resetting env. episode 3195.000000, reward total was -18.000000. running mean: -19.727118\n",
            "resetting env. episode 3196.000000, reward total was -21.000000. running mean: -19.739847\n",
            "resetting env. episode 3197.000000, reward total was -19.000000. running mean: -19.732449\n",
            "resetting env. episode 3198.000000, reward total was -18.000000. running mean: -19.715124\n",
            "resetting env. episode 3199.000000, reward total was -20.000000. running mean: -19.717973\n",
            "resetting env. episode 3200.000000, reward total was -20.000000. running mean: -19.720793\n",
            "resetting env. episode 3201.000000, reward total was -20.000000. running mean: -19.723585\n",
            "resetting env. episode 3202.000000, reward total was -21.000000. running mean: -19.736349\n",
            "resetting env. episode 3203.000000, reward total was -20.000000. running mean: -19.738986\n",
            "resetting env. episode 3204.000000, reward total was -21.000000. running mean: -19.751596\n",
            "resetting env. episode 3205.000000, reward total was -21.000000. running mean: -19.764080\n",
            "resetting env. episode 3206.000000, reward total was -19.000000. running mean: -19.756439\n",
            "resetting env. episode 3207.000000, reward total was -19.000000. running mean: -19.748875\n",
            "resetting env. episode 3208.000000, reward total was -20.000000. running mean: -19.751386\n",
            "resetting env. episode 3209.000000, reward total was -17.000000. running mean: -19.723872\n",
            "resetting env. episode 3210.000000, reward total was -21.000000. running mean: -19.736633\n",
            "resetting env. episode 3211.000000, reward total was -20.000000. running mean: -19.739267\n",
            "resetting env. episode 3212.000000, reward total was -18.000000. running mean: -19.721874\n",
            "resetting env. episode 3213.000000, reward total was -21.000000. running mean: -19.734656\n",
            "resetting env. episode 3214.000000, reward total was -21.000000. running mean: -19.747309\n",
            "resetting env. episode 3215.000000, reward total was -21.000000. running mean: -19.759836\n",
            "resetting env. episode 3216.000000, reward total was -20.000000. running mean: -19.762238\n",
            "resetting env. episode 3217.000000, reward total was -20.000000. running mean: -19.764615\n",
            "resetting env. episode 3218.000000, reward total was -20.000000. running mean: -19.766969\n",
            "resetting env. episode 3219.000000, reward total was -21.000000. running mean: -19.779299\n",
            "resetting env. episode 3220.000000, reward total was -19.000000. running mean: -19.771506\n",
            "resetting env. episode 3221.000000, reward total was -20.000000. running mean: -19.773791\n",
            "resetting env. episode 3222.000000, reward total was -18.000000. running mean: -19.756054\n",
            "resetting env. episode 3223.000000, reward total was -21.000000. running mean: -19.768493\n",
            "resetting env. episode 3224.000000, reward total was -20.000000. running mean: -19.770808\n",
            "resetting env. episode 3225.000000, reward total was -20.000000. running mean: -19.773100\n",
            "resetting env. episode 3226.000000, reward total was -19.000000. running mean: -19.765369\n",
            "resetting env. episode 3227.000000, reward total was -20.000000. running mean: -19.767715\n",
            "resetting env. episode 3228.000000, reward total was -21.000000. running mean: -19.780038\n",
            "resetting env. episode 3229.000000, reward total was -21.000000. running mean: -19.792238\n",
            "resetting env. episode 3230.000000, reward total was -19.000000. running mean: -19.784315\n",
            "resetting env. episode 3231.000000, reward total was -20.000000. running mean: -19.786472\n",
            "resetting env. episode 3232.000000, reward total was -20.000000. running mean: -19.788607\n",
            "resetting env. episode 3233.000000, reward total was -21.000000. running mean: -19.800721\n",
            "resetting env. episode 3234.000000, reward total was -19.000000. running mean: -19.792714\n",
            "resetting env. episode 3235.000000, reward total was -20.000000. running mean: -19.794787\n",
            "resetting env. episode 3236.000000, reward total was -20.000000. running mean: -19.796839\n",
            "resetting env. episode 3237.000000, reward total was -18.000000. running mean: -19.778871\n",
            "resetting env. episode 3238.000000, reward total was -19.000000. running mean: -19.771082\n",
            "resetting env. episode 3239.000000, reward total was -20.000000. running mean: -19.773371\n",
            "resetting env. episode 3240.000000, reward total was -20.000000. running mean: -19.775638\n",
            "resetting env. episode 3241.000000, reward total was -19.000000. running mean: -19.767881\n",
            "resetting env. episode 3242.000000, reward total was -20.000000. running mean: -19.770202\n",
            "resetting env. episode 3243.000000, reward total was -20.000000. running mean: -19.772500\n",
            "resetting env. episode 3244.000000, reward total was -21.000000. running mean: -19.784775\n",
            "resetting env. episode 3245.000000, reward total was -21.000000. running mean: -19.796928\n",
            "resetting env. episode 3246.000000, reward total was -18.000000. running mean: -19.778958\n",
            "resetting env. episode 3247.000000, reward total was -21.000000. running mean: -19.791169\n",
            "resetting env. episode 3248.000000, reward total was -21.000000. running mean: -19.803257\n",
            "resetting env. episode 3249.000000, reward total was -21.000000. running mean: -19.815224\n",
            "resetting env. episode 3250.000000, reward total was -18.000000. running mean: -19.797072\n",
            "resetting env. episode 3251.000000, reward total was -20.000000. running mean: -19.799101\n",
            "resetting env. episode 3252.000000, reward total was -21.000000. running mean: -19.811110\n",
            "resetting env. episode 3253.000000, reward total was -21.000000. running mean: -19.822999\n",
            "resetting env. episode 3254.000000, reward total was -19.000000. running mean: -19.814769\n",
            "resetting env. episode 3255.000000, reward total was -20.000000. running mean: -19.816622\n",
            "resetting env. episode 3256.000000, reward total was -19.000000. running mean: -19.808455\n",
            "resetting env. episode 3257.000000, reward total was -18.000000. running mean: -19.790371\n",
            "resetting env. episode 3258.000000, reward total was -20.000000. running mean: -19.792467\n",
            "resetting env. episode 3259.000000, reward total was -19.000000. running mean: -19.784543\n",
            "resetting env. episode 3260.000000, reward total was -21.000000. running mean: -19.796697\n",
            "resetting env. episode 3261.000000, reward total was -20.000000. running mean: -19.798730\n",
            "resetting env. episode 3262.000000, reward total was -19.000000. running mean: -19.790743\n",
            "resetting env. episode 3263.000000, reward total was -19.000000. running mean: -19.782835\n",
            "resetting env. episode 3264.000000, reward total was -20.000000. running mean: -19.785007\n",
            "resetting env. episode 3265.000000, reward total was -21.000000. running mean: -19.797157\n",
            "resetting env. episode 3266.000000, reward total was -19.000000. running mean: -19.789185\n",
            "resetting env. episode 3267.000000, reward total was -19.000000. running mean: -19.781294\n",
            "resetting env. episode 3268.000000, reward total was -19.000000. running mean: -19.773481\n",
            "resetting env. episode 3269.000000, reward total was -21.000000. running mean: -19.785746\n",
            "resetting env. episode 3270.000000, reward total was -21.000000. running mean: -19.797888\n",
            "resetting env. episode 3271.000000, reward total was -21.000000. running mean: -19.809909\n",
            "resetting env. episode 3272.000000, reward total was -20.000000. running mean: -19.811810\n",
            "resetting env. episode 3273.000000, reward total was -18.000000. running mean: -19.793692\n",
            "resetting env. episode 3274.000000, reward total was -21.000000. running mean: -19.805755\n",
            "resetting env. episode 3275.000000, reward total was -21.000000. running mean: -19.817698\n",
            "resetting env. episode 3276.000000, reward total was -21.000000. running mean: -19.829521\n",
            "resetting env. episode 3277.000000, reward total was -19.000000. running mean: -19.821226\n",
            "resetting env. episode 3278.000000, reward total was -19.000000. running mean: -19.813013\n",
            "resetting env. episode 3279.000000, reward total was -21.000000. running mean: -19.824883\n",
            "resetting env. episode 3280.000000, reward total was -20.000000. running mean: -19.826634\n",
            "resetting env. episode 3281.000000, reward total was -19.000000. running mean: -19.818368\n",
            "resetting env. episode 3282.000000, reward total was -18.000000. running mean: -19.800184\n",
            "resetting env. episode 3283.000000, reward total was -20.000000. running mean: -19.802183\n",
            "resetting env. episode 3284.000000, reward total was -21.000000. running mean: -19.814161\n",
            "resetting env. episode 3285.000000, reward total was -21.000000. running mean: -19.826019\n",
            "resetting env. episode 3286.000000, reward total was -20.000000. running mean: -19.827759\n",
            "resetting env. episode 3287.000000, reward total was -20.000000. running mean: -19.829481\n",
            "resetting env. episode 3288.000000, reward total was -21.000000. running mean: -19.841187\n",
            "resetting env. episode 3289.000000, reward total was -19.000000. running mean: -19.832775\n",
            "resetting env. episode 3290.000000, reward total was -16.000000. running mean: -19.794447\n",
            "resetting env. episode 3291.000000, reward total was -20.000000. running mean: -19.796502\n",
            "resetting env. episode 3292.000000, reward total was -21.000000. running mean: -19.808537\n",
            "resetting env. episode 3293.000000, reward total was -20.000000. running mean: -19.810452\n",
            "resetting env. episode 3294.000000, reward total was -18.000000. running mean: -19.792348\n",
            "resetting env. episode 3295.000000, reward total was -20.000000. running mean: -19.794424\n",
            "resetting env. episode 3296.000000, reward total was -19.000000. running mean: -19.786480\n",
            "resetting env. episode 3297.000000, reward total was -18.000000. running mean: -19.768615\n",
            "resetting env. episode 3298.000000, reward total was -18.000000. running mean: -19.750929\n",
            "resetting env. episode 3299.000000, reward total was -21.000000. running mean: -19.763420\n",
            "resetting env. episode 3300.000000, reward total was -18.000000. running mean: -19.745785\n",
            "resetting env. episode 3301.000000, reward total was -21.000000. running mean: -19.758328\n",
            "resetting env. episode 3302.000000, reward total was -19.000000. running mean: -19.750744\n",
            "resetting env. episode 3303.000000, reward total was -19.000000. running mean: -19.743237\n",
            "resetting env. episode 3304.000000, reward total was -19.000000. running mean: -19.735804\n",
            "resetting env. episode 3305.000000, reward total was -19.000000. running mean: -19.728446\n",
            "resetting env. episode 3306.000000, reward total was -20.000000. running mean: -19.731162\n",
            "resetting env. episode 3307.000000, reward total was -19.000000. running mean: -19.723850\n",
            "resetting env. episode 3308.000000, reward total was -19.000000. running mean: -19.716612\n",
            "resetting env. episode 3309.000000, reward total was -21.000000. running mean: -19.729446\n",
            "resetting env. episode 3310.000000, reward total was -20.000000. running mean: -19.732151\n",
            "resetting env. episode 3311.000000, reward total was -17.000000. running mean: -19.704830\n",
            "resetting env. episode 3312.000000, reward total was -20.000000. running mean: -19.707781\n",
            "resetting env. episode 3313.000000, reward total was -17.000000. running mean: -19.680704\n",
            "resetting env. episode 3314.000000, reward total was -20.000000. running mean: -19.683897\n",
            "resetting env. episode 3315.000000, reward total was -17.000000. running mean: -19.657058\n",
            "resetting env. episode 3316.000000, reward total was -19.000000. running mean: -19.650487\n",
            "resetting env. episode 3317.000000, reward total was -18.000000. running mean: -19.633982\n",
            "resetting env. episode 3318.000000, reward total was -19.000000. running mean: -19.627642\n",
            "resetting env. episode 3319.000000, reward total was -19.000000. running mean: -19.621366\n",
            "resetting env. episode 3320.000000, reward total was -21.000000. running mean: -19.635152\n",
            "resetting env. episode 3321.000000, reward total was -21.000000. running mean: -19.648801\n",
            "resetting env. episode 3322.000000, reward total was -20.000000. running mean: -19.652313\n",
            "resetting env. episode 3323.000000, reward total was -20.000000. running mean: -19.655790\n",
            "resetting env. episode 3324.000000, reward total was -21.000000. running mean: -19.669232\n",
            "resetting env. episode 3325.000000, reward total was -19.000000. running mean: -19.662539\n",
            "resetting env. episode 3326.000000, reward total was -19.000000. running mean: -19.655914\n",
            "resetting env. episode 3327.000000, reward total was -20.000000. running mean: -19.659355\n",
            "resetting env. episode 3328.000000, reward total was -20.000000. running mean: -19.662761\n",
            "resetting env. episode 3329.000000, reward total was -21.000000. running mean: -19.676134\n",
            "resetting env. episode 3330.000000, reward total was -20.000000. running mean: -19.679372\n",
            "resetting env. episode 3331.000000, reward total was -20.000000. running mean: -19.682579\n",
            "resetting env. episode 3332.000000, reward total was -19.000000. running mean: -19.675753\n",
            "resetting env. episode 3333.000000, reward total was -18.000000. running mean: -19.658995\n",
            "resetting env. episode 3334.000000, reward total was -18.000000. running mean: -19.642405\n",
            "resetting env. episode 3335.000000, reward total was -19.000000. running mean: -19.635981\n",
            "resetting env. episode 3336.000000, reward total was -20.000000. running mean: -19.639621\n",
            "resetting env. episode 3337.000000, reward total was -21.000000. running mean: -19.653225\n",
            "resetting env. episode 3338.000000, reward total was -18.000000. running mean: -19.636693\n",
            "resetting env. episode 3339.000000, reward total was -20.000000. running mean: -19.640326\n",
            "resetting env. episode 3340.000000, reward total was -21.000000. running mean: -19.653923\n",
            "resetting env. episode 3341.000000, reward total was -19.000000. running mean: -19.647384\n",
            "resetting env. episode 3342.000000, reward total was -20.000000. running mean: -19.650910\n",
            "resetting env. episode 3343.000000, reward total was -20.000000. running mean: -19.654401\n",
            "resetting env. episode 3344.000000, reward total was -20.000000. running mean: -19.657857\n",
            "resetting env. episode 3345.000000, reward total was -18.000000. running mean: -19.641278\n",
            "resetting env. episode 3346.000000, reward total was -20.000000. running mean: -19.644865\n",
            "resetting env. episode 3347.000000, reward total was -21.000000. running mean: -19.658417\n",
            "resetting env. episode 3348.000000, reward total was -18.000000. running mean: -19.641832\n",
            "resetting env. episode 3349.000000, reward total was -18.000000. running mean: -19.625414\n",
            "resetting env. episode 3350.000000, reward total was -20.000000. running mean: -19.629160\n",
            "resetting env. episode 3351.000000, reward total was -19.000000. running mean: -19.622868\n",
            "resetting env. episode 3352.000000, reward total was -21.000000. running mean: -19.636640\n",
            "resetting env. episode 3353.000000, reward total was -20.000000. running mean: -19.640273\n",
            "resetting env. episode 3354.000000, reward total was -19.000000. running mean: -19.633871\n",
            "resetting env. episode 3355.000000, reward total was -18.000000. running mean: -19.617532\n",
            "resetting env. episode 3356.000000, reward total was -18.000000. running mean: -19.601357\n",
            "resetting env. episode 3357.000000, reward total was -19.000000. running mean: -19.595343\n",
            "resetting env. episode 3358.000000, reward total was -21.000000. running mean: -19.609390\n",
            "resetting env. episode 3359.000000, reward total was -17.000000. running mean: -19.583296\n",
            "resetting env. episode 3360.000000, reward total was -21.000000. running mean: -19.597463\n",
            "resetting env. episode 3361.000000, reward total was -19.000000. running mean: -19.591488\n",
            "resetting env. episode 3362.000000, reward total was -20.000000. running mean: -19.595573\n",
            "resetting env. episode 3363.000000, reward total was -19.000000. running mean: -19.589617\n",
            "resetting env. episode 3364.000000, reward total was -18.000000. running mean: -19.573721\n",
            "resetting env. episode 3365.000000, reward total was -21.000000. running mean: -19.587984\n",
            "resetting env. episode 3366.000000, reward total was -21.000000. running mean: -19.602104\n",
            "resetting env. episode 3367.000000, reward total was -21.000000. running mean: -19.616083\n",
            "resetting env. episode 3368.000000, reward total was -20.000000. running mean: -19.619922\n",
            "resetting env. episode 3369.000000, reward total was -19.000000. running mean: -19.613723\n",
            "resetting env. episode 3370.000000, reward total was -19.000000. running mean: -19.607586\n",
            "resetting env. episode 3371.000000, reward total was -19.000000. running mean: -19.601510\n",
            "resetting env. episode 3372.000000, reward total was -21.000000. running mean: -19.615495\n",
            "resetting env. episode 3373.000000, reward total was -18.000000. running mean: -19.599340\n",
            "resetting env. episode 3374.000000, reward total was -19.000000. running mean: -19.593347\n",
            "resetting env. episode 3375.000000, reward total was -18.000000. running mean: -19.577413\n",
            "resetting env. episode 3376.000000, reward total was -17.000000. running mean: -19.551639\n",
            "resetting env. episode 3377.000000, reward total was -20.000000. running mean: -19.556123\n",
            "resetting env. episode 3378.000000, reward total was -17.000000. running mean: -19.530561\n",
            "resetting env. episode 3379.000000, reward total was -19.000000. running mean: -19.525256\n",
            "resetting env. episode 3380.000000, reward total was -19.000000. running mean: -19.520003\n",
            "resetting env. episode 3381.000000, reward total was -20.000000. running mean: -19.524803\n",
            "resetting env. episode 3382.000000, reward total was -20.000000. running mean: -19.529555\n",
            "resetting env. episode 3383.000000, reward total was -18.000000. running mean: -19.514260\n",
            "resetting env. episode 3384.000000, reward total was -21.000000. running mean: -19.529117\n",
            "resetting env. episode 3385.000000, reward total was -19.000000. running mean: -19.523826\n",
            "resetting env. episode 3386.000000, reward total was -20.000000. running mean: -19.528588\n",
            "resetting env. episode 3387.000000, reward total was -20.000000. running mean: -19.533302\n",
            "resetting env. episode 3388.000000, reward total was -20.000000. running mean: -19.537969\n",
            "resetting env. episode 3389.000000, reward total was -19.000000. running mean: -19.532589\n",
            "resetting env. episode 3390.000000, reward total was -18.000000. running mean: -19.517263\n",
            "resetting env. episode 3391.000000, reward total was -20.000000. running mean: -19.522090\n",
            "resetting env. episode 3392.000000, reward total was -20.000000. running mean: -19.526870\n",
            "resetting env. episode 3393.000000, reward total was -21.000000. running mean: -19.541601\n",
            "resetting env. episode 3394.000000, reward total was -21.000000. running mean: -19.556185\n",
            "resetting env. episode 3395.000000, reward total was -17.000000. running mean: -19.530623\n",
            "resetting env. episode 3396.000000, reward total was -20.000000. running mean: -19.535317\n",
            "resetting env. episode 3397.000000, reward total was -19.000000. running mean: -19.529964\n",
            "resetting env. episode 3398.000000, reward total was -21.000000. running mean: -19.544664\n",
            "resetting env. episode 3399.000000, reward total was -18.000000. running mean: -19.529217\n",
            "resetting env. episode 3400.000000, reward total was -20.000000. running mean: -19.533925\n",
            "resetting env. episode 3401.000000, reward total was -21.000000. running mean: -19.548586\n",
            "resetting env. episode 3402.000000, reward total was -19.000000. running mean: -19.543100\n",
            "resetting env. episode 3403.000000, reward total was -20.000000. running mean: -19.547669\n",
            "resetting env. episode 3404.000000, reward total was -19.000000. running mean: -19.542192\n",
            "resetting env. episode 3405.000000, reward total was -19.000000. running mean: -19.536770\n",
            "resetting env. episode 3406.000000, reward total was -21.000000. running mean: -19.551403\n",
            "resetting env. episode 3407.000000, reward total was -21.000000. running mean: -19.565889\n",
            "resetting env. episode 3408.000000, reward total was -19.000000. running mean: -19.560230\n",
            "resetting env. episode 3409.000000, reward total was -19.000000. running mean: -19.554628\n",
            "resetting env. episode 3410.000000, reward total was -18.000000. running mean: -19.539081\n",
            "resetting env. episode 3411.000000, reward total was -19.000000. running mean: -19.533690\n",
            "resetting env. episode 3412.000000, reward total was -20.000000. running mean: -19.538354\n",
            "resetting env. episode 3413.000000, reward total was -20.000000. running mean: -19.542970\n",
            "resetting env. episode 3414.000000, reward total was -20.000000. running mean: -19.547540\n",
            "resetting env. episode 3415.000000, reward total was -20.000000. running mean: -19.552065\n",
            "resetting env. episode 3416.000000, reward total was -20.000000. running mean: -19.556544\n",
            "resetting env. episode 3417.000000, reward total was -19.000000. running mean: -19.550979\n",
            "resetting env. episode 3418.000000, reward total was -21.000000. running mean: -19.565469\n",
            "resetting env. episode 3419.000000, reward total was -21.000000. running mean: -19.579814\n",
            "resetting env. episode 3420.000000, reward total was -20.000000. running mean: -19.584016\n",
            "resetting env. episode 3421.000000, reward total was -19.000000. running mean: -19.578176\n",
            "resetting env. episode 3422.000000, reward total was -19.000000. running mean: -19.572394\n",
            "resetting env. episode 3423.000000, reward total was -21.000000. running mean: -19.586670\n",
            "resetting env. episode 3424.000000, reward total was -19.000000. running mean: -19.580804\n",
            "resetting env. episode 3425.000000, reward total was -19.000000. running mean: -19.574996\n",
            "resetting env. episode 3426.000000, reward total was -20.000000. running mean: -19.579246\n",
            "resetting env. episode 3427.000000, reward total was -19.000000. running mean: -19.573453\n",
            "resetting env. episode 3428.000000, reward total was -21.000000. running mean: -19.587719\n",
            "resetting env. episode 3429.000000, reward total was -19.000000. running mean: -19.581841\n",
            "resetting env. episode 3430.000000, reward total was -21.000000. running mean: -19.596023\n",
            "resetting env. episode 3431.000000, reward total was -21.000000. running mean: -19.610063\n",
            "resetting env. episode 3432.000000, reward total was -21.000000. running mean: -19.623962\n",
            "resetting env. episode 3433.000000, reward total was -19.000000. running mean: -19.617723\n",
            "resetting env. episode 3434.000000, reward total was -19.000000. running mean: -19.611545\n",
            "resetting env. episode 3435.000000, reward total was -19.000000. running mean: -19.605430\n",
            "resetting env. episode 3436.000000, reward total was -19.000000. running mean: -19.599376\n",
            "resetting env. episode 3437.000000, reward total was -18.000000. running mean: -19.583382\n",
            "resetting env. episode 3438.000000, reward total was -18.000000. running mean: -19.567548\n",
            "resetting env. episode 3439.000000, reward total was -20.000000. running mean: -19.571873\n",
            "resetting env. episode 3440.000000, reward total was -19.000000. running mean: -19.566154\n",
            "resetting env. episode 3441.000000, reward total was -18.000000. running mean: -19.550492\n",
            "resetting env. episode 3442.000000, reward total was -20.000000. running mean: -19.554987\n",
            "resetting env. episode 3443.000000, reward total was -18.000000. running mean: -19.539437\n",
            "resetting env. episode 3444.000000, reward total was -18.000000. running mean: -19.524043\n",
            "resetting env. episode 3445.000000, reward total was -21.000000. running mean: -19.538803\n",
            "resetting env. episode 3446.000000, reward total was -18.000000. running mean: -19.523415\n",
            "resetting env. episode 3447.000000, reward total was -21.000000. running mean: -19.538180\n",
            "resetting env. episode 3448.000000, reward total was -19.000000. running mean: -19.532799\n",
            "resetting env. episode 3449.000000, reward total was -20.000000. running mean: -19.537471\n",
            "resetting env. episode 3450.000000, reward total was -20.000000. running mean: -19.542096\n",
            "resetting env. episode 3451.000000, reward total was -20.000000. running mean: -19.546675\n",
            "resetting env. episode 3452.000000, reward total was -21.000000. running mean: -19.561208\n",
            "resetting env. episode 3453.000000, reward total was -21.000000. running mean: -19.575596\n",
            "resetting env. episode 3454.000000, reward total was -20.000000. running mean: -19.579840\n",
            "resetting env. episode 3455.000000, reward total was -19.000000. running mean: -19.574042\n",
            "resetting env. episode 3456.000000, reward total was -19.000000. running mean: -19.568301\n",
            "resetting env. episode 3457.000000, reward total was -19.000000. running mean: -19.562618\n",
            "resetting env. episode 3458.000000, reward total was -21.000000. running mean: -19.576992\n",
            "resetting env. episode 3459.000000, reward total was -20.000000. running mean: -19.581222\n",
            "resetting env. episode 3460.000000, reward total was -21.000000. running mean: -19.595410\n",
            "resetting env. episode 3461.000000, reward total was -21.000000. running mean: -19.609456\n",
            "resetting env. episode 3462.000000, reward total was -20.000000. running mean: -19.613361\n",
            "resetting env. episode 3463.000000, reward total was -18.000000. running mean: -19.597228\n",
            "resetting env. episode 3464.000000, reward total was -20.000000. running mean: -19.601256\n",
            "resetting env. episode 3465.000000, reward total was -21.000000. running mean: -19.615243\n",
            "resetting env. episode 3466.000000, reward total was -20.000000. running mean: -19.619091\n",
            "resetting env. episode 3467.000000, reward total was -19.000000. running mean: -19.612900\n",
            "resetting env. episode 3468.000000, reward total was -18.000000. running mean: -19.596771\n",
            "resetting env. episode 3469.000000, reward total was -21.000000. running mean: -19.610803\n",
            "resetting env. episode 3470.000000, reward total was -19.000000. running mean: -19.604695\n",
            "resetting env. episode 3471.000000, reward total was -21.000000. running mean: -19.618648\n",
            "resetting env. episode 3472.000000, reward total was -21.000000. running mean: -19.632461\n",
            "resetting env. episode 3473.000000, reward total was -20.000000. running mean: -19.636137\n",
            "resetting env. episode 3474.000000, reward total was -20.000000. running mean: -19.639775\n",
            "resetting env. episode 3475.000000, reward total was -20.000000. running mean: -19.643378\n",
            "resetting env. episode 3476.000000, reward total was -21.000000. running mean: -19.656944\n",
            "resetting env. episode 3477.000000, reward total was -19.000000. running mean: -19.650375\n",
            "resetting env. episode 3478.000000, reward total was -19.000000. running mean: -19.643871\n",
            "resetting env. episode 3479.000000, reward total was -21.000000. running mean: -19.657432\n",
            "resetting env. episode 3480.000000, reward total was -20.000000. running mean: -19.660858\n",
            "resetting env. episode 3481.000000, reward total was -21.000000. running mean: -19.674249\n",
            "resetting env. episode 3482.000000, reward total was -19.000000. running mean: -19.667507\n",
            "resetting env. episode 3483.000000, reward total was -20.000000. running mean: -19.670832\n",
            "resetting env. episode 3484.000000, reward total was -21.000000. running mean: -19.684123\n",
            "resetting env. episode 3485.000000, reward total was -17.000000. running mean: -19.657282\n",
            "resetting env. episode 3486.000000, reward total was -21.000000. running mean: -19.670709\n",
            "resetting env. episode 3487.000000, reward total was -19.000000. running mean: -19.664002\n",
            "resetting env. episode 3488.000000, reward total was -21.000000. running mean: -19.677362\n",
            "resetting env. episode 3489.000000, reward total was -16.000000. running mean: -19.640589\n",
            "resetting env. episode 3490.000000, reward total was -18.000000. running mean: -19.624183\n",
            "resetting env. episode 3491.000000, reward total was -19.000000. running mean: -19.617941\n",
            "resetting env. episode 3492.000000, reward total was -19.000000. running mean: -19.611761\n",
            "resetting env. episode 3493.000000, reward total was -19.000000. running mean: -19.605644\n",
            "resetting env. episode 3494.000000, reward total was -20.000000. running mean: -19.609587\n",
            "resetting env. episode 3495.000000, reward total was -21.000000. running mean: -19.623491\n",
            "resetting env. episode 3496.000000, reward total was -20.000000. running mean: -19.627257\n",
            "resetting env. episode 3497.000000, reward total was -20.000000. running mean: -19.630984\n",
            "resetting env. episode 3498.000000, reward total was -19.000000. running mean: -19.624674\n",
            "resetting env. episode 3499.000000, reward total was -21.000000. running mean: -19.638427\n",
            "resetting env. episode 3500.000000, reward total was -21.000000. running mean: -19.652043\n",
            "CPU times: user 3h 3min 18s, sys: 1h 24min 44s, total: 4h 28min 3s\n",
            "Wall time: 2h 18min 57s\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "w2NblmwDsL3y",
        "outputId": "95ce7b90-26d6-4cde-cdff-59f4b1f79116",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        }
      },
      "cell_type": "code",
      "source": [
        "play_game(env, model)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gym/core.py:52: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
            "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
            "  \"The argument mode in render method is deprecated; \"\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode finished without success, accumulated reward = -4.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 320x420 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "ZYA0HgMoO77a"
      },
      "cell_type": "code",
      "source": [
        "# import pickle\n",
        "# pickle.dump(model, open('model.pkl', 'wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2Vu9PonFR5NA"
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}