{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pg-from-scratch.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahul1088/wired/blob/master/notebooks/rl/pg-from-scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "0l9hHvTk6ec8"
      },
      "cell_type": "markdown",
      "source": [
        "# Policy Gradient\n",
        "\n",
        "* http://karpathy.github.io/2016/05/31/rl/\n",
        "* https://gist.github.com/karpathy/a4166c7fe253700972fcbc77e4ea32c5\n",
        "* https://github.com/gameofdimension/policy-gradient-pong\n",
        "* https://www.youtube.com/watch?v=tqrcjHuNdmQ\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "mqkOdLyN9Ylm"
      },
      "cell_type": "markdown",
      "source": [
        "## Step 1: Installation for Colab - just execute these cells and do not worry too much\n",
        "\n",
        "* http://nbviewer.jupyter.org/github/patrickmineault/xcorr-notebooks/blob/master/Render%20OpenAI%20gym%20as%20GIF.ipynb \n",
        "* https://docs.microsoft.com/en-us/message-passing-interface/microsoft-mpi\n",
        "* https://nyu-cds.github.io/python-mpi/setup/\n",
        "* https://medium.com/@kaleajit27/reinforcement-learning-on-google-colab-9cb2e1ef51e\n"
      ]
    },
    {
      "metadata": {
        "id": "uF9MAVI16huj",
        "outputId": "7e990abb-63cf-4c24-fcf0-508bc56be78a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "!apt-get install python-opengl -y  >/dev/null\n",
        "!apt install xvfb -y >/dev/null"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "fSC11TfN6p69"
      },
      "cell_type": "code",
      "source": [
        "!pip install pyvirtualdisplay >/dev/null\n",
        "!pip install piglet >/dev/null"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "metadata": {
        "id": "caiHE2hy6xrf"
      },
      "cell_type": "code",
      "source": [
        "# from pyvirtualdisplay import Display\n",
        "# display = Display(visible=0, size=(1400, 900))\n",
        "# display.start()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cWACPRL869I4"
      },
      "cell_type": "code",
      "source": [
        "!pip install gym >/dev/null"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2Os6feRY6ec_"
      },
      "cell_type": "code",
      "source": [
        "!pip install JSAnimation >/dev/null"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wotUOa_e6edP"
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "from JSAnimation.IPython_display import display_animation\n",
        "from matplotlib import animation\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import HTML\n",
        "\n",
        "def display_frames_as_gif(frames):\n",
        "    \"\"\"\n",
        "    Displays a list of frames as a gif, with controls\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(frames[0].shape[1] / 72.0, frames[0].shape[0] / 72.0), dpi = 144)\n",
        "    patch = plt.imshow(frames[0])\n",
        "    plt.axis('off')\n",
        "\n",
        "    def animate(i):\n",
        "        patch.set_data(frames[i])\n",
        "\n",
        "    anim = animation.FuncAnimation(plt.gcf(), animate, frames = len(frames), interval=50)\n",
        "    HTML(anim.to_jshtml())"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "metadata": {
        "id": "R66_INeZ9nYX"
      },
      "cell_type": "markdown",
      "source": [
        "## Step 2: Playing Pong"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -U gym>=0.21.0\n",
        "%pip install -U gym[atari,accept-rom-license]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dz9Z_1D5hTVW",
        "outputId": "a7429281-816c-4991-811f-822d53a4336b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gym[accept-rom-license,atari] in /usr/local/lib/python3.7/dist-packages (0.25.1)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.7/dist-packages (from gym[accept-rom-license,atari]) (0.0.8)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.7/dist-packages (from gym[accept-rom-license,atari]) (1.21.6)\n",
            "Requirement already satisfied: importlib-metadata>=4.8.0 in /usr/local/lib/python3.7/dist-packages (from gym[accept-rom-license,atari]) (4.12.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym[accept-rom-license,atari]) (1.3.0)\n",
            "Collecting autorom[accept-rom-license]~=0.4.2\n",
            "  Downloading AutoROM-0.4.2-py3-none-any.whl (16 kB)\n",
            "Collecting ale-py~=0.7.5\n",
            "  Downloading ale_py-0.7.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 7.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from ale-py~=0.7.5->gym[accept-rom-license,atari]) (5.9.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (7.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (4.64.0)\n",
            "Collecting AutoROM.accept-rom-license\n",
            "  Downloading AutoROM.accept-rom-license-0.4.2.tar.gz (9.8 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.8.0->gym[accept-rom-license,atari]) (3.8.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.8.0->gym[accept-rom-license,atari]) (4.1.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (2.10)\n",
            "Building wheels for collected packages: AutoROM.accept-rom-license\n",
            "  Building wheel for AutoROM.accept-rom-license (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for AutoROM.accept-rom-license: filename=AutoROM.accept_rom_license-0.4.2-py3-none-any.whl size=441027 sha256=405e5895953782166cbe0888d8c86fd2a8536e716c61be59c6ce5016d4361a69\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/67/2e/6147e7912fe37f5408b80d07527dab807c1d25f5c403a9538a\n",
            "Successfully built AutoROM.accept-rom-license\n",
            "Installing collected packages: AutoROM.accept-rom-license, autorom, ale-py\n",
            "Successfully installed AutoROM.accept-rom-license-0.4.2 ale-py-0.7.5 autorom-0.4.2\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "MtT2GyK_6edc",
        "outputId": "050feebe-a7c0-4643-ab15-29aef5b915b6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "import gym\n",
        "env = gym.make('Pong-v0')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gym/envs/registration.py:594: UserWarning: \u001b[33mWARN: The environment Pong-v0 is out of date. You should consider upgrading to version `v4`.\u001b[0m\n",
            "  f\"The environment {id} is out of date. You should consider \"\n",
            "/usr/local/lib/python3.7/dist-packages/gym/core.py:330: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  \"Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\"\n",
            "/usr/local/lib/python3.7/dist-packages/gym/wrappers/step_api_compatibility.py:40: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  \"Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\"\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "oRE6WmXQJ1Z0",
        "outputId": "d20bf983-a81a-4710-9de8-420ecbb67f00",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "env.action_space"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Discrete(6)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "yl_9d4HFJ31W",
        "outputId": "b8c050cf-4ce9-47c0-a0c5-d0da9814fce7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "env.observation_space"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Box(0, 255, (210, 160, 3), uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "trwRXI-h6eeI",
        "outputId": "726f4d18-a222-4c65-9cb4-1c8c5ed50424",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "# Run a demo of the environment\n",
        "observation = env.reset()\n",
        "cumulated_reward = 0\n",
        "\n",
        "frames = []\n",
        "for t in range(1000):\n",
        "#     print(observation)\n",
        "    frames.append(env.render(mode = 'rgb_array'))\n",
        "    # very stupid agent, just makes a random action within the allowd action space\n",
        "    action = env.action_space.sample()\n",
        "#     print(\"Action: {}\".format(t+1))    \n",
        "    observation, reward, done, info = env.step(action)\n",
        "#     print(reward)\n",
        "    cumulated_reward += reward\n",
        "    if done:\n",
        "        print(\"Episode finished after {} timesteps, accumulated reward = {}\".format(t+1, cumulated_reward))\n",
        "        break\n",
        "print(\"Episode finished without success, accumulated reward = {}\".format(cumulated_reward))\n",
        "\n",
        "env.close()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gym/core.py:52: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
            "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
            "  \"The argument mode in render method is deprecated; \"\n",
            "/usr/local/lib/python3.7/dist-packages/gym/utils/passive_env_checker.py:298: UserWarning: \u001b[33mWARN: No render fps was declared in the environment (env.metadata['render_fps'] is None or not defined), rendering may occur at inconsistent fps.\u001b[0m\n",
            "  \"No render fps was declared in the environment (env.metadata['render_fps'] is None or not defined), rendering may occur at inconsistent fps.\"\n",
            "/usr/local/lib/python3.7/dist-packages/gym/utils/passive_env_checker.py:228: DeprecationWarning: \u001b[33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. \u001b[0m\n",
            "  \"Core environment is written in old step API which returns one bool instead of two. \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode finished without success, accumulated reward = -16.0\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "qUNldrqa6eeM",
        "outputId": "d48379e9-c342-4f35-d2eb-f13826a7d319",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        }
      },
      "cell_type": "code",
      "source": [
        "display_frames_as_gif(frames)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 320x420 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "3zZTecVWLLes"
      },
      "cell_type": "code",
      "source": [
        "def sigmoid(x): \n",
        "  return 1.0 / (1.0 + np.exp(-x)) # sigmoid \"squashing\" function to interval [0,1]\n",
        "\n",
        "def prepro(I):\n",
        "  \"\"\" prepro 210x160x3 uint8 frame into 6400 (80x80) 1D float vector \"\"\"\n",
        "  I = I[35:195] # crop\n",
        "  I = I[::2,::2,0] # downsample by factor of 2\n",
        "  I[I == 144] = 0 # erase background (background type 1)\n",
        "  I[I == 109] = 0 # erase background (background type 2)\n",
        "  I[I != 0] = 1 # everything else (paddles, ball) just set to 1\n",
        "  return I.astype(np.float).ravel()\n",
        "\n",
        "def policy_forward(x):\n",
        "  h = np.dot(model['W1'], x)\n",
        "  h[h<0] = 0 # ReLU nonlinearity\n",
        "  logp = np.dot(model['W2'], h)\n",
        "  p = sigmoid(logp)\n",
        "  return p, h # return probability of taking action 2, and hidden state\n",
        "\n",
        "def model_step(model, observation, prev_x):\n",
        "  # preprocess the observation, set input to network to be difference image\n",
        "  cur_x = prepro(observation)\n",
        "  x = cur_x - prev_x if prev_x is not None else np.zeros(D)\n",
        "  prev_x = cur_x\n",
        "  \n",
        "  # forward the policy network and sample an action from the returned probability\n",
        "  aprob, _ = policy_forward(x)\n",
        "  action = 2 if aprob >= 0.5 else 3 # roll the dice!\n",
        "  \n",
        "  return action, prev_x\n",
        "\n",
        "def play_game(env, model):\n",
        "  observation = env.reset()\n",
        "\n",
        "  frames = []\n",
        "  cumulated_reward = 0\n",
        "\n",
        "  prev_x = None # used in computing the difference frame\n",
        "\n",
        "  for t in range(1000):\n",
        "      frames.append(env.render(mode = 'rgb_array'))\n",
        "      action, prev_x = model_step(model, observation, prev_x)\n",
        "      observation, reward, done, info = env.step(action)\n",
        "      cumulated_reward += reward\n",
        "      if done:\n",
        "          print(\"Episode finished after {} timesteps, accumulated reward = {}\".format(t+1, cumulated_reward))\n",
        "          break\n",
        "  print(\"Episode finished without success, accumulated reward = {}\".format(cumulated_reward))\n",
        "  display_frames_as_gif(frames)\n",
        "  env.close()\n",
        "  "
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6gWvZQ7AQLQt"
      },
      "cell_type": "markdown",
      "source": [
        "## Step 3: Policy Gradient from Scratch"
      ]
    },
    {
      "metadata": {
        "id": "eqFm7hqcItWl"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# model initialization\n",
        "H = 400 # number of hidden layer neurons\n",
        "D = 80 * 80 # input dimensionality: 80x80 grid\n",
        "model = {}\n",
        "model['W1'] = np.random.randn(H,D) / np.sqrt(D) # \"Xavier\" initialization\n",
        "model['W2'] = np.random.randn(H) / np.sqrt(H)\n",
        "\n",
        "# import pickle\n",
        "# model = pickle.load(open('model.pkl', 'rb'))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IJ4SeY8tPxvn",
        "outputId": "6fe18bf2-3c7e-4eb1-f3fc-87ef5dfc31e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        }
      },
      "cell_type": "code",
      "source": [
        "# random init model\n",
        "play_game(env, model)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gym/core.py:52: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
            "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
            "  \"The argument mode in render method is deprecated; \"\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode finished without success, accumulated reward = -18.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 320x420 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQ4AAAFZCAYAAABpOsHqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAWJQAAFiUBSVIk8AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAHiUlEQVR4nO3dP29b1x3H4UNGjiRSlmRTYmM1qeImzRKgS7JmaZfkJWTt1qHI1DdQoEuHAu3eN9C1Q5Alc5b8QYNmaIomAQzYSkRbMm2RliXdLi3QhDHC7xWNS0rPMxkHuNc/GdIHPMe6ZKuqqgKQaDc9ALB4hAOICQcQEw4gJhxATDiAmHAAMeEAYsIBxIQDiAkHEBMOICYcQGyp7oVvvrw69WO17VYpb+wul86Vp9ep57Z6pbOyOrG+NxiUh6PR1PfpbW6UjbWr557n/sMHZf/ewbnvw+wd7m6Vhzeunfs+nb3DsvnF1zOYqDnvvHu3Vee62uF462eTP6RNem57u2xfm/xmeDgaheHYLLs7O+ee59adPeGYU4cv9svXr9089322/v7VwoejLlsVICYcQEw4gJhwALHah6OXzcFwWO4PH0ysX13rlmvr6w1MxKx1b98r3duTB9pHP9ooD358vYGJ5pdwTGlw76D8+9atifXdnR3huCA2vvim7Hzw+cT6ndd/KhzfYasCxIQDiAkHEBMOIOZwdEpXu51yY3t7Yn19rdvANNAs4ZhSv9cr/V6v6TFgLtiqADHhAGLCAcSEA4g5HJ3Sg6Oj731DoO7KalnrdhqYCJojHFPa2x888VmVV7q7DUwEzbFVAWLCAcSEA4gJBxBzODql1ZXlcn1jY2K9s7LSwDQ8DY82OuX+TyYfKxhveh7pu4RjSjv9ftnp95seg6do8OrzZfDq802PsRBsVYCYcAAx4QBiwgHELszh6NFoVA6XJr+cxycn0X3Gj47L4XB47nlGj8bnvgdPx/Jw9L2fnxLf53D6DzO/aFpVVdW68E9vXa93ITRslt+4rRneqwnvvHu31pdwYV5xwLQW/Yd9HjjjAGLCAcRqb1Xe+M2fZzkHsEBqH44OBgOHo7Dger1erSMfWxUgJhxATDiAmHAAMeEAYsIBxIQDiAkHEBMOICYcQEw4gJhwADHhAGK1H6v/5K9/nOUcQAN++evf17rOe47CJVb3PUdtVYCYcAAx4QBiwgHEhAOICQcQEw4gJhxATDiAmHAAMeEAYsIBxIQDiAkHEBMOICYcQEw4gJhwADHhAGLCAcSEA4gJBxATDiAmHEBMOICYcAAx4QBiwgHEhAOICQcQEw4gJhxATDiAmHAAMeEAYsIBxIQDiAkHEBMOICYcQEw4gJhwADHhAGLCAcSEA4gJBxATDiAmHEBMOICYcAAx4QBiwgHEhAOICQcQEw4gJhxATDiAmHAAMeEAYsIBxIQDiAkHEBMOICYcQEw4gJhwADHhAGLCAcSEA4gJBxATDiAmHEBMOICYcAAx4QBiwgHEhAOICQcQEw4gJhxATDiAmHAAMeEAYsIBxIQDiAkHEBMOICYcQEw4gJhwADHhAGLCAcSEA4gJBxATDiAmHEBMOICYcAAx4QBiwgHEhAOICQcQEw4gJhxATDiAmHAAMeEAYsIBxIQDiAkHEBMOICYcQEw4gJhwADHhAGLCAcSEA4gJBxATDiAmHEBMOICYcAAx4QBiwgHEhAOICQcQEw4gJhxATDiAmHAAMeEAYsIBxIQDiAkHEBMOICYcQEw4gJhwADHhAGLCAcSEA4gJBxATDiAmHEBMOICYcAAx4QBiwgHEhAOICQcQEw4gJhxATDiAmHAAMeEAYsIBxIQDiAkHEBMOICYcQEw4gJhwADHhAGLCAcSEA4gJBxATDiAmHEBMOICYcAAx4QBiwgHElpoe4Em2rm2WK0tXJtYHBwfl+PHjBiYC/mduw/HSCy+U9bW1b61VVVU+/MdnwkFtrfYz//1TVaqzs0ZnWWRzGw6YtZWNrfKL3/6lPHNluYyHd8v7f/hVOT0eNz3WQhIOLo12e6ms37hZlpZXy7MH66XVcsRXl385ICYcQEw4gJhwcIlUpZSqVNVZqaqq6WEWmsNRLo3x/UF573dvl1a7Xc5OT8qJ/1GpTTi4NM5OT8q9rz5reowLwVYFiAkHEBMOICYcQEw4gJhwADHhAGLCAcSEA4gJBxATDiAmHEBMOICYcACxuX2s/mg8Lu32ZNdOT08bmAb4f3Mbjk//+XnTIwBPYKsCxIQDiAkHEBMOICYcQEw4gJhwADHhAGLCAcTm9jdH4bIYb3bKNz/fnVh/djgq/Y+/LK0GZvohwgENO766WvZeu1lK69uJ6N4+KP2Pv2xmqB9gqwLEhAOICQcQEw4gJhxATDiAmHAAMeEAYsIBxIQDiAkHEBMOICYcQEw4gJhwADHhAGLCAcSEA4gJBxATDiAmHEBMOICYj0eAhi2Njsvmv+5MrK8cHDUwzXSEAxrW2R+Wl//2UdNjRGxVgJhwADHhAGLCAcSEA4gJBxATDiBW+/c4tl95fZZzAAukVVVVrQv39/frXQjMja2trVad62q/4mi1av19wAXgjAOICQcQEw4gJhxATDiAmHAAMeEAYsIBxIQDiAkHEBMOICYcQEw4gJhwADHhAGLCAcSEA4gJBxATDiAmHEBMOICYcACx2p+rAlxeXnEAMeEAYsIBxIQDiAkHEBMOICYcQEw4gJhwADHhAGLCAcSEA4gJBxD7D/sH5y3AT0YiAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "TwjiwKisQM19"
      },
      "cell_type": "code",
      "source": [
        "# hyperparameters\n",
        "batch_size = 10 # every how many episodes to do a param update?\n",
        "# learning_rate = 1e-4\n",
        "learning_rate = 1e-4\n",
        " \n",
        "gamma = 0.99 # discount factor for reward\n",
        "decay_rate = 0.99 # decay factor for RMSProp leaky sum of grad^2\n",
        "  \n",
        "grad_buffer = { k : np.zeros_like(v) for k,v in model.items() } # update buffers that add up gradients over a batch\n",
        "rmsprop_cache = { k : np.zeros_like(v) for k,v in model.items() } # rmsprop memory\n",
        "\n",
        "def discount_rewards(r):\n",
        "  \"\"\" take 1D float array of rewards and compute discounted reward \"\"\"\n",
        "  discounted_r = np.zeros_like(r, dtype=np.float32)\n",
        "  running_add = 0\n",
        "  for t in reversed(range(0, r.size)):\n",
        "    if r[t] != 0: running_add = 0 # reset the sum, since this was a game boundary (pong specific!)\n",
        "    running_add = running_add * gamma + r[t]\n",
        "    discounted_r[t] = running_add\n",
        "  return discounted_r\n",
        "\n",
        "def policy_backward(epx, eph, epdlogp):\n",
        "  \"\"\" backward pass. (eph is array of intermediate hidden states) \"\"\"\n",
        "  dW2 = np.dot(eph.T, epdlogp).ravel()\n",
        "  dh = np.outer(epdlogp, model['W2'])\n",
        "  dh[eph <= 0] = 0 # backpro prelu\n",
        "  dW1 = np.dot(dh.T, epx)\n",
        "  return {'W1':dW1, 'W2':dW2}\n",
        "\n",
        "def train_model(env, model, total_episodes = 100):\n",
        "  hist = []\n",
        "  observation = env.reset()\n",
        "\n",
        "  prev_x = None # used in computing the difference frame\n",
        "  xs,hs,dlogps,drs = [],[],[],[]\n",
        "  running_reward = None\n",
        "  reward_sum = 0\n",
        "  episode_number = 0\n",
        "\n",
        "  while True:\n",
        "    # preprocess the observation, set input to network to be difference image\n",
        "    cur_x = prepro(observation)\n",
        "    x = cur_x - prev_x if prev_x is not None else np.zeros(D)\n",
        "    prev_x = cur_x\n",
        "\n",
        "    # forward the policy network and sample an action from the returned probability\n",
        "    aprob, h = policy_forward(x)\n",
        "    action = 2 if np.random.uniform() < aprob else 3 # roll the dice!\n",
        "\n",
        "    # record various intermediates (needed later for backprop)\n",
        "    xs.append(x) # observation\n",
        "    hs.append(h) # hidden state\n",
        "    y = 1 if action == 2 else 0 # a \"fake label\"\n",
        "    dlogps.append(y - aprob) # grad that encourages the action that was taken to be taken (see http://cs231n.github.io/neural-networks-2/#losses if confused)\n",
        "\n",
        "    # step the environment and get new measurements\n",
        "    observation, reward, done, info = env.step(action)\n",
        "    reward_sum += reward\n",
        "\n",
        "    drs.append(reward) # record reward (has to be done after we call step() to get reward for previous action)\n",
        "\n",
        "    if done: # an episode finished\n",
        "      episode_number += 1\n",
        "\n",
        "      # stack together all inputs, hidden states, action gradients, and rewards for this episode\n",
        "      epx = np.vstack(xs)\n",
        "      eph = np.vstack(hs)\n",
        "      epdlogp = np.vstack(dlogps)\n",
        "      epr = np.vstack(drs)\n",
        "      xs,hs,dlogps,drs = [],[],[],[] # reset array memory\n",
        "\n",
        "      # compute the discounted reward backwards through time\n",
        "      discounted_epr = discount_rewards(epr)\n",
        "      # standardize the rewards to be unit normal (helps control the gradient estimator variance)\n",
        "      discounted_epr -= np.mean(discounted_epr)\n",
        "      discounted_epr /= np.std(discounted_epr)\n",
        "\n",
        "      epdlogp *= discounted_epr # modulate the gradient with advantage (PG magic happens right here.)\n",
        "      grad = policy_backward(epx, eph, epdlogp)\n",
        "      for k in model: grad_buffer[k] += grad[k] # accumulate grad over batch\n",
        "\n",
        "      # perform rmsprop parameter update every batch_size episodes\n",
        "      if episode_number % batch_size == 0:\n",
        "        for k,v in model.items():\n",
        "          g = grad_buffer[k] # gradient\n",
        "          rmsprop_cache[k] = decay_rate * rmsprop_cache[k] + (1 - decay_rate) * g**2\n",
        "          model[k] += learning_rate * g / (np.sqrt(rmsprop_cache[k]) + 1e-5)\n",
        "          grad_buffer[k] = np.zeros_like(v) # reset batch gradient buffer\n",
        "\n",
        "      # boring book-keeping\n",
        "      running_reward = reward_sum if running_reward is None else running_reward * 0.99 + reward_sum * 0.01\n",
        "      hist.append((episode_number, reward_sum, running_reward))\n",
        "      print ('resetting env. episode %f, reward total was %f. running mean: %f' % (episode_number, reward_sum, running_reward))\n",
        "      reward_sum = 0\n",
        "      observation = env.reset() # reset env\n",
        "      prev_x = None\n",
        "      if episode_number == total_episodes: return hist\n",
        "\n",
        "  #   if reward != 0: # Pong has either +1 or -1 reward exactly when game ends.\n",
        "  #     print (('ep %d: game finished, reward: %f' % (episode_number, reward)) + ('' if reward == -1 else ' !!!!!!!!'))"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G6Ka_5Vl9Orm",
        "outputId": "f6929fc2-c99f-44a4-f022-6bc5453e633d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "%time hist1 = train_model(env, model, total_episodes=500)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "resetting env. episode 1.000000, reward total was -19.000000. running mean: -19.000000\n",
            "resetting env. episode 2.000000, reward total was -20.000000. running mean: -19.010000\n",
            "resetting env. episode 3.000000, reward total was -20.000000. running mean: -19.019900\n",
            "resetting env. episode 4.000000, reward total was -19.000000. running mean: -19.019701\n",
            "resetting env. episode 5.000000, reward total was -21.000000. running mean: -19.039504\n",
            "resetting env. episode 6.000000, reward total was -21.000000. running mean: -19.059109\n",
            "resetting env. episode 7.000000, reward total was -21.000000. running mean: -19.078518\n",
            "resetting env. episode 8.000000, reward total was -20.000000. running mean: -19.087733\n",
            "resetting env. episode 9.000000, reward total was -21.000000. running mean: -19.106855\n",
            "resetting env. episode 10.000000, reward total was -21.000000. running mean: -19.125787\n",
            "resetting env. episode 11.000000, reward total was -21.000000. running mean: -19.144529\n",
            "resetting env. episode 12.000000, reward total was -20.000000. running mean: -19.153084\n",
            "resetting env. episode 13.000000, reward total was -21.000000. running mean: -19.171553\n",
            "resetting env. episode 14.000000, reward total was -21.000000. running mean: -19.189837\n",
            "resetting env. episode 15.000000, reward total was -21.000000. running mean: -19.207939\n",
            "resetting env. episode 16.000000, reward total was -21.000000. running mean: -19.225860\n",
            "resetting env. episode 17.000000, reward total was -21.000000. running mean: -19.243601\n",
            "resetting env. episode 18.000000, reward total was -20.000000. running mean: -19.251165\n",
            "resetting env. episode 19.000000, reward total was -21.000000. running mean: -19.268653\n",
            "resetting env. episode 20.000000, reward total was -21.000000. running mean: -19.285967\n",
            "resetting env. episode 21.000000, reward total was -20.000000. running mean: -19.293107\n",
            "resetting env. episode 22.000000, reward total was -21.000000. running mean: -19.310176\n",
            "resetting env. episode 23.000000, reward total was -21.000000. running mean: -19.327074\n",
            "resetting env. episode 24.000000, reward total was -21.000000. running mean: -19.343803\n",
            "resetting env. episode 25.000000, reward total was -21.000000. running mean: -19.360365\n",
            "resetting env. episode 26.000000, reward total was -21.000000. running mean: -19.376762\n",
            "resetting env. episode 27.000000, reward total was -20.000000. running mean: -19.382994\n",
            "resetting env. episode 28.000000, reward total was -20.000000. running mean: -19.389164\n",
            "resetting env. episode 29.000000, reward total was -21.000000. running mean: -19.405273\n",
            "resetting env. episode 30.000000, reward total was -20.000000. running mean: -19.411220\n",
            "resetting env. episode 31.000000, reward total was -19.000000. running mean: -19.407108\n",
            "resetting env. episode 32.000000, reward total was -21.000000. running mean: -19.423037\n",
            "resetting env. episode 33.000000, reward total was -21.000000. running mean: -19.438806\n",
            "resetting env. episode 34.000000, reward total was -21.000000. running mean: -19.454418\n",
            "resetting env. episode 35.000000, reward total was -17.000000. running mean: -19.429874\n",
            "resetting env. episode 36.000000, reward total was -20.000000. running mean: -19.435575\n",
            "resetting env. episode 37.000000, reward total was -21.000000. running mean: -19.451219\n",
            "resetting env. episode 38.000000, reward total was -20.000000. running mean: -19.456707\n",
            "resetting env. episode 39.000000, reward total was -20.000000. running mean: -19.462140\n",
            "resetting env. episode 40.000000, reward total was -21.000000. running mean: -19.477519\n",
            "resetting env. episode 41.000000, reward total was -21.000000. running mean: -19.492744\n",
            "resetting env. episode 42.000000, reward total was -21.000000. running mean: -19.507816\n",
            "resetting env. episode 43.000000, reward total was -20.000000. running mean: -19.512738\n",
            "resetting env. episode 44.000000, reward total was -20.000000. running mean: -19.517611\n",
            "resetting env. episode 45.000000, reward total was -21.000000. running mean: -19.532435\n",
            "resetting env. episode 46.000000, reward total was -18.000000. running mean: -19.517110\n",
            "resetting env. episode 47.000000, reward total was -20.000000. running mean: -19.521939\n",
            "resetting env. episode 48.000000, reward total was -18.000000. running mean: -19.506720\n",
            "resetting env. episode 49.000000, reward total was -21.000000. running mean: -19.521653\n",
            "resetting env. episode 50.000000, reward total was -21.000000. running mean: -19.536436\n",
            "resetting env. episode 51.000000, reward total was -21.000000. running mean: -19.551072\n",
            "resetting env. episode 52.000000, reward total was -21.000000. running mean: -19.565561\n",
            "resetting env. episode 53.000000, reward total was -20.000000. running mean: -19.569905\n",
            "resetting env. episode 54.000000, reward total was -20.000000. running mean: -19.574206\n",
            "resetting env. episode 55.000000, reward total was -21.000000. running mean: -19.588464\n",
            "resetting env. episode 56.000000, reward total was -20.000000. running mean: -19.592580\n",
            "resetting env. episode 57.000000, reward total was -21.000000. running mean: -19.606654\n",
            "resetting env. episode 58.000000, reward total was -20.000000. running mean: -19.610587\n",
            "resetting env. episode 59.000000, reward total was -21.000000. running mean: -19.624481\n",
            "resetting env. episode 60.000000, reward total was -21.000000. running mean: -19.638237\n",
            "resetting env. episode 61.000000, reward total was -21.000000. running mean: -19.651854\n",
            "resetting env. episode 62.000000, reward total was -17.000000. running mean: -19.625336\n",
            "resetting env. episode 63.000000, reward total was -21.000000. running mean: -19.639082\n",
            "resetting env. episode 64.000000, reward total was -21.000000. running mean: -19.652691\n",
            "resetting env. episode 65.000000, reward total was -20.000000. running mean: -19.656165\n",
            "resetting env. episode 66.000000, reward total was -20.000000. running mean: -19.659603\n",
            "resetting env. episode 67.000000, reward total was -21.000000. running mean: -19.673007\n",
            "resetting env. episode 68.000000, reward total was -21.000000. running mean: -19.686277\n",
            "resetting env. episode 69.000000, reward total was -19.000000. running mean: -19.679414\n",
            "resetting env. episode 70.000000, reward total was -21.000000. running mean: -19.692620\n",
            "resetting env. episode 71.000000, reward total was -20.000000. running mean: -19.695694\n",
            "resetting env. episode 72.000000, reward total was -21.000000. running mean: -19.708737\n",
            "resetting env. episode 73.000000, reward total was -20.000000. running mean: -19.711649\n",
            "resetting env. episode 74.000000, reward total was -21.000000. running mean: -19.724533\n",
            "resetting env. episode 75.000000, reward total was -21.000000. running mean: -19.737288\n",
            "resetting env. episode 76.000000, reward total was -20.000000. running mean: -19.739915\n",
            "resetting env. episode 77.000000, reward total was -20.000000. running mean: -19.742516\n",
            "resetting env. episode 78.000000, reward total was -19.000000. running mean: -19.735090\n",
            "resetting env. episode 79.000000, reward total was -21.000000. running mean: -19.747739\n",
            "resetting env. episode 80.000000, reward total was -21.000000. running mean: -19.760262\n",
            "resetting env. episode 81.000000, reward total was -21.000000. running mean: -19.772659\n",
            "resetting env. episode 82.000000, reward total was -21.000000. running mean: -19.784933\n",
            "resetting env. episode 83.000000, reward total was -20.000000. running mean: -19.787084\n",
            "resetting env. episode 84.000000, reward total was -21.000000. running mean: -19.799213\n",
            "resetting env. episode 85.000000, reward total was -21.000000. running mean: -19.811221\n",
            "resetting env. episode 86.000000, reward total was -21.000000. running mean: -19.823108\n",
            "resetting env. episode 87.000000, reward total was -19.000000. running mean: -19.814877\n",
            "resetting env. episode 88.000000, reward total was -20.000000. running mean: -19.816729\n",
            "resetting env. episode 89.000000, reward total was -21.000000. running mean: -19.828561\n",
            "resetting env. episode 90.000000, reward total was -20.000000. running mean: -19.830276\n",
            "resetting env. episode 91.000000, reward total was -20.000000. running mean: -19.831973\n",
            "resetting env. episode 92.000000, reward total was -21.000000. running mean: -19.843653\n",
            "resetting env. episode 93.000000, reward total was -20.000000. running mean: -19.845217\n",
            "resetting env. episode 94.000000, reward total was -20.000000. running mean: -19.846764\n",
            "resetting env. episode 95.000000, reward total was -21.000000. running mean: -19.858297\n",
            "resetting env. episode 96.000000, reward total was -20.000000. running mean: -19.859714\n",
            "resetting env. episode 97.000000, reward total was -19.000000. running mean: -19.851117\n",
            "resetting env. episode 98.000000, reward total was -21.000000. running mean: -19.862606\n",
            "resetting env. episode 99.000000, reward total was -20.000000. running mean: -19.863979\n",
            "resetting env. episode 100.000000, reward total was -20.000000. running mean: -19.865340\n",
            "resetting env. episode 101.000000, reward total was -20.000000. running mean: -19.866686\n",
            "resetting env. episode 102.000000, reward total was -21.000000. running mean: -19.878019\n",
            "resetting env. episode 103.000000, reward total was -20.000000. running mean: -19.879239\n",
            "resetting env. episode 104.000000, reward total was -20.000000. running mean: -19.880447\n",
            "resetting env. episode 105.000000, reward total was -21.000000. running mean: -19.891642\n",
            "resetting env. episode 106.000000, reward total was -21.000000. running mean: -19.902726\n",
            "resetting env. episode 107.000000, reward total was -21.000000. running mean: -19.913699\n",
            "resetting env. episode 108.000000, reward total was -21.000000. running mean: -19.924562\n",
            "resetting env. episode 109.000000, reward total was -21.000000. running mean: -19.935316\n",
            "resetting env. episode 110.000000, reward total was -21.000000. running mean: -19.945963\n",
            "resetting env. episode 111.000000, reward total was -19.000000. running mean: -19.936503\n",
            "resetting env. episode 112.000000, reward total was -20.000000. running mean: -19.937138\n",
            "resetting env. episode 113.000000, reward total was -20.000000. running mean: -19.937767\n",
            "resetting env. episode 114.000000, reward total was -20.000000. running mean: -19.938389\n",
            "resetting env. episode 115.000000, reward total was -20.000000. running mean: -19.939005\n",
            "resetting env. episode 116.000000, reward total was -21.000000. running mean: -19.949615\n",
            "resetting env. episode 117.000000, reward total was -19.000000. running mean: -19.940119\n",
            "resetting env. episode 118.000000, reward total was -21.000000. running mean: -19.950718\n",
            "resetting env. episode 119.000000, reward total was -21.000000. running mean: -19.961211\n",
            "resetting env. episode 120.000000, reward total was -18.000000. running mean: -19.941599\n",
            "resetting env. episode 121.000000, reward total was -20.000000. running mean: -19.942183\n",
            "resetting env. episode 122.000000, reward total was -20.000000. running mean: -19.942761\n",
            "resetting env. episode 123.000000, reward total was -21.000000. running mean: -19.953333\n",
            "resetting env. episode 124.000000, reward total was -21.000000. running mean: -19.963800\n",
            "resetting env. episode 125.000000, reward total was -18.000000. running mean: -19.944162\n",
            "resetting env. episode 126.000000, reward total was -21.000000. running mean: -19.954720\n",
            "resetting env. episode 127.000000, reward total was -20.000000. running mean: -19.955173\n",
            "resetting env. episode 128.000000, reward total was -20.000000. running mean: -19.955621\n",
            "resetting env. episode 129.000000, reward total was -20.000000. running mean: -19.956065\n",
            "resetting env. episode 130.000000, reward total was -21.000000. running mean: -19.966504\n",
            "resetting env. episode 131.000000, reward total was -21.000000. running mean: -19.976839\n",
            "resetting env. episode 132.000000, reward total was -21.000000. running mean: -19.987071\n",
            "resetting env. episode 133.000000, reward total was -19.000000. running mean: -19.977200\n",
            "resetting env. episode 134.000000, reward total was -21.000000. running mean: -19.987428\n",
            "resetting env. episode 135.000000, reward total was -21.000000. running mean: -19.997554\n",
            "resetting env. episode 136.000000, reward total was -21.000000. running mean: -20.007578\n",
            "resetting env. episode 137.000000, reward total was -21.000000. running mean: -20.017503\n",
            "resetting env. episode 138.000000, reward total was -21.000000. running mean: -20.027328\n",
            "resetting env. episode 139.000000, reward total was -21.000000. running mean: -20.037054\n",
            "resetting env. episode 140.000000, reward total was -20.000000. running mean: -20.036684\n",
            "resetting env. episode 141.000000, reward total was -21.000000. running mean: -20.046317\n",
            "resetting env. episode 142.000000, reward total was -19.000000. running mean: -20.035854\n",
            "resetting env. episode 143.000000, reward total was -21.000000. running mean: -20.045495\n",
            "resetting env. episode 144.000000, reward total was -20.000000. running mean: -20.045040\n",
            "resetting env. episode 145.000000, reward total was -19.000000. running mean: -20.034590\n",
            "resetting env. episode 146.000000, reward total was -21.000000. running mean: -20.044244\n",
            "resetting env. episode 147.000000, reward total was -21.000000. running mean: -20.053802\n",
            "resetting env. episode 148.000000, reward total was -19.000000. running mean: -20.043264\n",
            "resetting env. episode 149.000000, reward total was -20.000000. running mean: -20.042831\n",
            "resetting env. episode 150.000000, reward total was -20.000000. running mean: -20.042403\n",
            "resetting env. episode 151.000000, reward total was -21.000000. running mean: -20.051979\n",
            "resetting env. episode 152.000000, reward total was -20.000000. running mean: -20.051459\n",
            "resetting env. episode 153.000000, reward total was -20.000000. running mean: -20.050944\n",
            "resetting env. episode 154.000000, reward total was -21.000000. running mean: -20.060435\n",
            "resetting env. episode 155.000000, reward total was -21.000000. running mean: -20.069830\n",
            "resetting env. episode 156.000000, reward total was -19.000000. running mean: -20.059132\n",
            "resetting env. episode 157.000000, reward total was -21.000000. running mean: -20.068541\n",
            "resetting env. episode 158.000000, reward total was -19.000000. running mean: -20.057855\n",
            "resetting env. episode 159.000000, reward total was -21.000000. running mean: -20.067277\n",
            "resetting env. episode 160.000000, reward total was -18.000000. running mean: -20.046604\n",
            "resetting env. episode 161.000000, reward total was -21.000000. running mean: -20.056138\n",
            "resetting env. episode 162.000000, reward total was -20.000000. running mean: -20.055577\n",
            "resetting env. episode 163.000000, reward total was -20.000000. running mean: -20.055021\n",
            "resetting env. episode 164.000000, reward total was -21.000000. running mean: -20.064471\n",
            "resetting env. episode 165.000000, reward total was -20.000000. running mean: -20.063826\n",
            "resetting env. episode 166.000000, reward total was -20.000000. running mean: -20.063188\n",
            "resetting env. episode 167.000000, reward total was -20.000000. running mean: -20.062556\n",
            "resetting env. episode 168.000000, reward total was -19.000000. running mean: -20.051930\n",
            "resetting env. episode 169.000000, reward total was -21.000000. running mean: -20.061411\n",
            "resetting env. episode 170.000000, reward total was -21.000000. running mean: -20.070797\n",
            "resetting env. episode 171.000000, reward total was -21.000000. running mean: -20.080089\n",
            "resetting env. episode 172.000000, reward total was -21.000000. running mean: -20.089288\n",
            "resetting env. episode 173.000000, reward total was -20.000000. running mean: -20.088395\n",
            "resetting env. episode 174.000000, reward total was -21.000000. running mean: -20.097511\n",
            "resetting env. episode 175.000000, reward total was -21.000000. running mean: -20.106536\n",
            "resetting env. episode 176.000000, reward total was -21.000000. running mean: -20.115471\n",
            "resetting env. episode 177.000000, reward total was -20.000000. running mean: -20.114316\n",
            "resetting env. episode 178.000000, reward total was -21.000000. running mean: -20.123173\n",
            "resetting env. episode 179.000000, reward total was -21.000000. running mean: -20.131941\n",
            "resetting env. episode 180.000000, reward total was -19.000000. running mean: -20.120622\n",
            "resetting env. episode 181.000000, reward total was -21.000000. running mean: -20.129415\n",
            "resetting env. episode 182.000000, reward total was -21.000000. running mean: -20.138121\n",
            "resetting env. episode 183.000000, reward total was -18.000000. running mean: -20.116740\n",
            "resetting env. episode 184.000000, reward total was -20.000000. running mean: -20.115573\n",
            "resetting env. episode 185.000000, reward total was -21.000000. running mean: -20.124417\n",
            "resetting env. episode 186.000000, reward total was -19.000000. running mean: -20.113173\n",
            "resetting env. episode 187.000000, reward total was -20.000000. running mean: -20.112041\n",
            "resetting env. episode 188.000000, reward total was -21.000000. running mean: -20.120921\n",
            "resetting env. episode 189.000000, reward total was -20.000000. running mean: -20.119711\n",
            "resetting env. episode 190.000000, reward total was -21.000000. running mean: -20.128514\n",
            "resetting env. episode 191.000000, reward total was -20.000000. running mean: -20.127229\n",
            "resetting env. episode 192.000000, reward total was -19.000000. running mean: -20.115957\n",
            "resetting env. episode 193.000000, reward total was -21.000000. running mean: -20.124797\n",
            "resetting env. episode 194.000000, reward total was -18.000000. running mean: -20.103549\n",
            "resetting env. episode 195.000000, reward total was -21.000000. running mean: -20.112514\n",
            "resetting env. episode 196.000000, reward total was -19.000000. running mean: -20.101389\n",
            "resetting env. episode 197.000000, reward total was -21.000000. running mean: -20.110375\n",
            "resetting env. episode 198.000000, reward total was -20.000000. running mean: -20.109271\n",
            "resetting env. episode 199.000000, reward total was -20.000000. running mean: -20.108178\n",
            "resetting env. episode 200.000000, reward total was -20.000000. running mean: -20.107097\n",
            "resetting env. episode 201.000000, reward total was -21.000000. running mean: -20.116026\n",
            "resetting env. episode 202.000000, reward total was -21.000000. running mean: -20.124865\n",
            "resetting env. episode 203.000000, reward total was -21.000000. running mean: -20.133617\n",
            "resetting env. episode 204.000000, reward total was -17.000000. running mean: -20.102281\n",
            "resetting env. episode 205.000000, reward total was -20.000000. running mean: -20.101258\n",
            "resetting env. episode 206.000000, reward total was -20.000000. running mean: -20.100245\n",
            "resetting env. episode 207.000000, reward total was -20.000000. running mean: -20.099243\n",
            "resetting env. episode 208.000000, reward total was -20.000000. running mean: -20.098250\n",
            "resetting env. episode 209.000000, reward total was -21.000000. running mean: -20.107268\n",
            "resetting env. episode 210.000000, reward total was -20.000000. running mean: -20.106195\n",
            "resetting env. episode 211.000000, reward total was -21.000000. running mean: -20.115133\n",
            "resetting env. episode 212.000000, reward total was -21.000000. running mean: -20.123982\n",
            "resetting env. episode 213.000000, reward total was -21.000000. running mean: -20.132742\n",
            "resetting env. episode 214.000000, reward total was -21.000000. running mean: -20.141415\n",
            "resetting env. episode 215.000000, reward total was -20.000000. running mean: -20.140000\n",
            "resetting env. episode 216.000000, reward total was -18.000000. running mean: -20.118600\n",
            "resetting env. episode 217.000000, reward total was -20.000000. running mean: -20.117414\n",
            "resetting env. episode 218.000000, reward total was -21.000000. running mean: -20.126240\n",
            "resetting env. episode 219.000000, reward total was -21.000000. running mean: -20.134978\n",
            "resetting env. episode 220.000000, reward total was -21.000000. running mean: -20.143628\n",
            "resetting env. episode 221.000000, reward total was -21.000000. running mean: -20.152192\n",
            "resetting env. episode 222.000000, reward total was -21.000000. running mean: -20.160670\n",
            "resetting env. episode 223.000000, reward total was -19.000000. running mean: -20.149063\n",
            "resetting env. episode 224.000000, reward total was -21.000000. running mean: -20.157573\n",
            "resetting env. episode 225.000000, reward total was -20.000000. running mean: -20.155997\n",
            "resetting env. episode 226.000000, reward total was -20.000000. running mean: -20.154437\n",
            "resetting env. episode 227.000000, reward total was -19.000000. running mean: -20.142893\n",
            "resetting env. episode 228.000000, reward total was -21.000000. running mean: -20.151464\n",
            "resetting env. episode 229.000000, reward total was -21.000000. running mean: -20.159949\n",
            "resetting env. episode 230.000000, reward total was -19.000000. running mean: -20.148349\n",
            "resetting env. episode 231.000000, reward total was -21.000000. running mean: -20.156866\n",
            "resetting env. episode 232.000000, reward total was -21.000000. running mean: -20.165297\n",
            "resetting env. episode 233.000000, reward total was -20.000000. running mean: -20.163644\n",
            "resetting env. episode 234.000000, reward total was -21.000000. running mean: -20.172008\n",
            "resetting env. episode 235.000000, reward total was -19.000000. running mean: -20.160288\n",
            "resetting env. episode 236.000000, reward total was -21.000000. running mean: -20.168685\n",
            "resetting env. episode 237.000000, reward total was -21.000000. running mean: -20.176998\n",
            "resetting env. episode 238.000000, reward total was -21.000000. running mean: -20.185228\n",
            "resetting env. episode 239.000000, reward total was -20.000000. running mean: -20.183376\n",
            "resetting env. episode 240.000000, reward total was -21.000000. running mean: -20.191542\n",
            "resetting env. episode 241.000000, reward total was -21.000000. running mean: -20.199627\n",
            "resetting env. episode 242.000000, reward total was -21.000000. running mean: -20.207630\n",
            "resetting env. episode 243.000000, reward total was -21.000000. running mean: -20.215554\n",
            "resetting env. episode 244.000000, reward total was -19.000000. running mean: -20.203399\n",
            "resetting env. episode 245.000000, reward total was -19.000000. running mean: -20.191365\n",
            "resetting env. episode 246.000000, reward total was -20.000000. running mean: -20.189451\n",
            "resetting env. episode 247.000000, reward total was -21.000000. running mean: -20.197556\n",
            "resetting env. episode 248.000000, reward total was -20.000000. running mean: -20.195581\n",
            "resetting env. episode 249.000000, reward total was -18.000000. running mean: -20.173625\n",
            "resetting env. episode 250.000000, reward total was -21.000000. running mean: -20.181889\n",
            "resetting env. episode 251.000000, reward total was -21.000000. running mean: -20.190070\n",
            "resetting env. episode 252.000000, reward total was -20.000000. running mean: -20.188169\n",
            "resetting env. episode 253.000000, reward total was -19.000000. running mean: -20.176288\n",
            "resetting env. episode 254.000000, reward total was -19.000000. running mean: -20.164525\n",
            "resetting env. episode 255.000000, reward total was -21.000000. running mean: -20.172879\n",
            "resetting env. episode 256.000000, reward total was -21.000000. running mean: -20.181151\n",
            "resetting env. episode 257.000000, reward total was -21.000000. running mean: -20.189339\n",
            "resetting env. episode 258.000000, reward total was -21.000000. running mean: -20.197446\n",
            "resetting env. episode 259.000000, reward total was -21.000000. running mean: -20.205471\n",
            "resetting env. episode 260.000000, reward total was -21.000000. running mean: -20.213417\n",
            "resetting env. episode 261.000000, reward total was -21.000000. running mean: -20.221282\n",
            "resetting env. episode 262.000000, reward total was -21.000000. running mean: -20.229070\n",
            "resetting env. episode 263.000000, reward total was -21.000000. running mean: -20.236779\n",
            "resetting env. episode 264.000000, reward total was -21.000000. running mean: -20.244411\n",
            "resetting env. episode 265.000000, reward total was -21.000000. running mean: -20.251967\n",
            "resetting env. episode 266.000000, reward total was -21.000000. running mean: -20.259447\n",
            "resetting env. episode 267.000000, reward total was -19.000000. running mean: -20.246853\n",
            "resetting env. episode 268.000000, reward total was -20.000000. running mean: -20.244384\n",
            "resetting env. episode 269.000000, reward total was -21.000000. running mean: -20.251940\n",
            "resetting env. episode 270.000000, reward total was -21.000000. running mean: -20.259421\n",
            "resetting env. episode 271.000000, reward total was -19.000000. running mean: -20.246827\n",
            "resetting env. episode 272.000000, reward total was -19.000000. running mean: -20.234359\n",
            "resetting env. episode 273.000000, reward total was -19.000000. running mean: -20.222015\n",
            "resetting env. episode 274.000000, reward total was -20.000000. running mean: -20.219795\n",
            "resetting env. episode 275.000000, reward total was -21.000000. running mean: -20.227597\n",
            "resetting env. episode 276.000000, reward total was -21.000000. running mean: -20.235321\n",
            "resetting env. episode 277.000000, reward total was -20.000000. running mean: -20.232968\n",
            "resetting env. episode 278.000000, reward total was -21.000000. running mean: -20.240638\n",
            "resetting env. episode 279.000000, reward total was -21.000000. running mean: -20.248232\n",
            "resetting env. episode 280.000000, reward total was -21.000000. running mean: -20.255749\n",
            "resetting env. episode 281.000000, reward total was -19.000000. running mean: -20.243192\n",
            "resetting env. episode 282.000000, reward total was -20.000000. running mean: -20.240760\n",
            "resetting env. episode 283.000000, reward total was -21.000000. running mean: -20.248352\n",
            "resetting env. episode 284.000000, reward total was -21.000000. running mean: -20.255869\n",
            "resetting env. episode 285.000000, reward total was -20.000000. running mean: -20.253310\n",
            "resetting env. episode 286.000000, reward total was -20.000000. running mean: -20.250777\n",
            "resetting env. episode 287.000000, reward total was -21.000000. running mean: -20.258269\n",
            "resetting env. episode 288.000000, reward total was -21.000000. running mean: -20.265687\n",
            "resetting env. episode 289.000000, reward total was -21.000000. running mean: -20.273030\n",
            "resetting env. episode 290.000000, reward total was -20.000000. running mean: -20.270299\n",
            "resetting env. episode 291.000000, reward total was -19.000000. running mean: -20.257596\n",
            "resetting env. episode 292.000000, reward total was -21.000000. running mean: -20.265020\n",
            "resetting env. episode 293.000000, reward total was -17.000000. running mean: -20.232370\n",
            "resetting env. episode 294.000000, reward total was -21.000000. running mean: -20.240047\n",
            "resetting env. episode 295.000000, reward total was -21.000000. running mean: -20.247646\n",
            "resetting env. episode 296.000000, reward total was -21.000000. running mean: -20.255170\n",
            "resetting env. episode 297.000000, reward total was -21.000000. running mean: -20.262618\n",
            "resetting env. episode 298.000000, reward total was -19.000000. running mean: -20.249992\n",
            "resetting env. episode 299.000000, reward total was -21.000000. running mean: -20.257492\n",
            "resetting env. episode 300.000000, reward total was -19.000000. running mean: -20.244917\n",
            "resetting env. episode 301.000000, reward total was -21.000000. running mean: -20.252468\n",
            "resetting env. episode 302.000000, reward total was -21.000000. running mean: -20.259943\n",
            "resetting env. episode 303.000000, reward total was -20.000000. running mean: -20.257344\n",
            "resetting env. episode 304.000000, reward total was -21.000000. running mean: -20.264770\n",
            "resetting env. episode 305.000000, reward total was -18.000000. running mean: -20.242122\n",
            "resetting env. episode 306.000000, reward total was -21.000000. running mean: -20.249701\n",
            "resetting env. episode 307.000000, reward total was -20.000000. running mean: -20.247204\n",
            "resetting env. episode 308.000000, reward total was -19.000000. running mean: -20.234732\n",
            "resetting env. episode 309.000000, reward total was -21.000000. running mean: -20.242385\n",
            "resetting env. episode 310.000000, reward total was -21.000000. running mean: -20.249961\n",
            "resetting env. episode 311.000000, reward total was -21.000000. running mean: -20.257461\n",
            "resetting env. episode 312.000000, reward total was -21.000000. running mean: -20.264887\n",
            "resetting env. episode 313.000000, reward total was -19.000000. running mean: -20.252238\n",
            "resetting env. episode 314.000000, reward total was -20.000000. running mean: -20.249716\n",
            "resetting env. episode 315.000000, reward total was -19.000000. running mean: -20.237218\n",
            "resetting env. episode 316.000000, reward total was -21.000000. running mean: -20.244846\n",
            "resetting env. episode 317.000000, reward total was -21.000000. running mean: -20.252398\n",
            "resetting env. episode 318.000000, reward total was -21.000000. running mean: -20.259874\n",
            "resetting env. episode 319.000000, reward total was -20.000000. running mean: -20.257275\n",
            "resetting env. episode 320.000000, reward total was -19.000000. running mean: -20.244702\n",
            "resetting env. episode 321.000000, reward total was -19.000000. running mean: -20.232255\n",
            "resetting env. episode 322.000000, reward total was -20.000000. running mean: -20.229933\n",
            "resetting env. episode 323.000000, reward total was -21.000000. running mean: -20.237633\n",
            "resetting env. episode 324.000000, reward total was -20.000000. running mean: -20.235257\n",
            "resetting env. episode 325.000000, reward total was -18.000000. running mean: -20.212904\n",
            "resetting env. episode 326.000000, reward total was -20.000000. running mean: -20.210775\n",
            "resetting env. episode 327.000000, reward total was -21.000000. running mean: -20.218668\n",
            "resetting env. episode 328.000000, reward total was -21.000000. running mean: -20.226481\n",
            "resetting env. episode 329.000000, reward total was -21.000000. running mean: -20.234216\n",
            "resetting env. episode 330.000000, reward total was -21.000000. running mean: -20.241874\n",
            "resetting env. episode 331.000000, reward total was -19.000000. running mean: -20.229455\n",
            "resetting env. episode 332.000000, reward total was -21.000000. running mean: -20.237161\n",
            "resetting env. episode 333.000000, reward total was -20.000000. running mean: -20.234789\n",
            "resetting env. episode 334.000000, reward total was -21.000000. running mean: -20.242441\n",
            "resetting env. episode 335.000000, reward total was -20.000000. running mean: -20.240017\n",
            "resetting env. episode 336.000000, reward total was -19.000000. running mean: -20.227617\n",
            "resetting env. episode 337.000000, reward total was -21.000000. running mean: -20.235340\n",
            "resetting env. episode 338.000000, reward total was -20.000000. running mean: -20.232987\n",
            "resetting env. episode 339.000000, reward total was -21.000000. running mean: -20.240657\n",
            "resetting env. episode 340.000000, reward total was -19.000000. running mean: -20.228251\n",
            "resetting env. episode 341.000000, reward total was -21.000000. running mean: -20.235968\n",
            "resetting env. episode 342.000000, reward total was -19.000000. running mean: -20.223608\n",
            "resetting env. episode 343.000000, reward total was -20.000000. running mean: -20.221372\n",
            "resetting env. episode 344.000000, reward total was -21.000000. running mean: -20.229159\n",
            "resetting env. episode 345.000000, reward total was -21.000000. running mean: -20.236867\n",
            "resetting env. episode 346.000000, reward total was -20.000000. running mean: -20.234498\n",
            "resetting env. episode 347.000000, reward total was -21.000000. running mean: -20.242153\n",
            "resetting env. episode 348.000000, reward total was -19.000000. running mean: -20.229732\n",
            "resetting env. episode 349.000000, reward total was -21.000000. running mean: -20.237435\n",
            "resetting env. episode 350.000000, reward total was -19.000000. running mean: -20.225060\n",
            "resetting env. episode 351.000000, reward total was -20.000000. running mean: -20.222810\n",
            "resetting env. episode 352.000000, reward total was -21.000000. running mean: -20.230581\n",
            "resetting env. episode 353.000000, reward total was -19.000000. running mean: -20.218276\n",
            "resetting env. episode 354.000000, reward total was -21.000000. running mean: -20.226093\n",
            "resetting env. episode 355.000000, reward total was -21.000000. running mean: -20.233832\n",
            "resetting env. episode 356.000000, reward total was -21.000000. running mean: -20.241494\n",
            "resetting env. episode 357.000000, reward total was -19.000000. running mean: -20.229079\n",
            "resetting env. episode 358.000000, reward total was -21.000000. running mean: -20.236788\n",
            "resetting env. episode 359.000000, reward total was -21.000000. running mean: -20.244420\n",
            "resetting env. episode 360.000000, reward total was -21.000000. running mean: -20.251976\n",
            "resetting env. episode 361.000000, reward total was -20.000000. running mean: -20.249456\n",
            "resetting env. episode 362.000000, reward total was -21.000000. running mean: -20.256962\n",
            "resetting env. episode 363.000000, reward total was -21.000000. running mean: -20.264392\n",
            "resetting env. episode 364.000000, reward total was -18.000000. running mean: -20.241748\n",
            "resetting env. episode 365.000000, reward total was -20.000000. running mean: -20.239331\n",
            "resetting env. episode 366.000000, reward total was -21.000000. running mean: -20.246937\n",
            "resetting env. episode 367.000000, reward total was -19.000000. running mean: -20.234468\n",
            "resetting env. episode 368.000000, reward total was -19.000000. running mean: -20.222123\n",
            "resetting env. episode 369.000000, reward total was -20.000000. running mean: -20.219902\n",
            "resetting env. episode 370.000000, reward total was -19.000000. running mean: -20.207703\n",
            "resetting env. episode 371.000000, reward total was -21.000000. running mean: -20.215626\n",
            "resetting env. episode 372.000000, reward total was -21.000000. running mean: -20.223470\n",
            "resetting env. episode 373.000000, reward total was -19.000000. running mean: -20.211235\n",
            "resetting env. episode 374.000000, reward total was -21.000000. running mean: -20.219123\n",
            "resetting env. episode 375.000000, reward total was -21.000000. running mean: -20.226931\n",
            "resetting env. episode 376.000000, reward total was -21.000000. running mean: -20.234662\n",
            "resetting env. episode 377.000000, reward total was -21.000000. running mean: -20.242315\n",
            "resetting env. episode 378.000000, reward total was -20.000000. running mean: -20.239892\n",
            "resetting env. episode 379.000000, reward total was -20.000000. running mean: -20.237493\n",
            "resetting env. episode 380.000000, reward total was -21.000000. running mean: -20.245118\n",
            "resetting env. episode 381.000000, reward total was -19.000000. running mean: -20.232667\n",
            "resetting env. episode 382.000000, reward total was -21.000000. running mean: -20.240341\n",
            "resetting env. episode 383.000000, reward total was -20.000000. running mean: -20.237937\n",
            "resetting env. episode 384.000000, reward total was -20.000000. running mean: -20.235558\n",
            "resetting env. episode 385.000000, reward total was -21.000000. running mean: -20.243202\n",
            "resetting env. episode 386.000000, reward total was -21.000000. running mean: -20.250770\n",
            "resetting env. episode 387.000000, reward total was -20.000000. running mean: -20.248262\n",
            "resetting env. episode 388.000000, reward total was -21.000000. running mean: -20.255780\n",
            "resetting env. episode 389.000000, reward total was -20.000000. running mean: -20.253222\n",
            "resetting env. episode 390.000000, reward total was -20.000000. running mean: -20.250690\n",
            "resetting env. episode 391.000000, reward total was -21.000000. running mean: -20.258183\n",
            "resetting env. episode 392.000000, reward total was -20.000000. running mean: -20.255601\n",
            "resetting env. episode 393.000000, reward total was -20.000000. running mean: -20.253045\n",
            "resetting env. episode 394.000000, reward total was -21.000000. running mean: -20.260515\n",
            "resetting env. episode 395.000000, reward total was -21.000000. running mean: -20.267910\n",
            "resetting env. episode 396.000000, reward total was -21.000000. running mean: -20.275230\n",
            "resetting env. episode 397.000000, reward total was -20.000000. running mean: -20.272478\n",
            "resetting env. episode 398.000000, reward total was -21.000000. running mean: -20.279753\n",
            "resetting env. episode 399.000000, reward total was -21.000000. running mean: -20.286956\n",
            "resetting env. episode 400.000000, reward total was -18.000000. running mean: -20.264086\n",
            "resetting env. episode 401.000000, reward total was -21.000000. running mean: -20.271445\n",
            "resetting env. episode 402.000000, reward total was -21.000000. running mean: -20.278731\n",
            "resetting env. episode 403.000000, reward total was -20.000000. running mean: -20.275944\n",
            "resetting env. episode 404.000000, reward total was -19.000000. running mean: -20.263184\n",
            "resetting env. episode 405.000000, reward total was -20.000000. running mean: -20.260552\n",
            "resetting env. episode 406.000000, reward total was -20.000000. running mean: -20.257947\n",
            "resetting env. episode 407.000000, reward total was -21.000000. running mean: -20.265367\n",
            "resetting env. episode 408.000000, reward total was -19.000000. running mean: -20.252714\n",
            "resetting env. episode 409.000000, reward total was -21.000000. running mean: -20.260187\n",
            "resetting env. episode 410.000000, reward total was -21.000000. running mean: -20.267585\n",
            "resetting env. episode 411.000000, reward total was -21.000000. running mean: -20.274909\n",
            "resetting env. episode 412.000000, reward total was -20.000000. running mean: -20.272160\n",
            "resetting env. episode 413.000000, reward total was -20.000000. running mean: -20.269438\n",
            "resetting env. episode 414.000000, reward total was -21.000000. running mean: -20.276744\n",
            "resetting env. episode 415.000000, reward total was -21.000000. running mean: -20.283976\n",
            "resetting env. episode 416.000000, reward total was -21.000000. running mean: -20.291137\n",
            "resetting env. episode 417.000000, reward total was -17.000000. running mean: -20.258225\n",
            "resetting env. episode 418.000000, reward total was -21.000000. running mean: -20.265643\n",
            "resetting env. episode 419.000000, reward total was -21.000000. running mean: -20.272987\n",
            "resetting env. episode 420.000000, reward total was -21.000000. running mean: -20.280257\n",
            "resetting env. episode 421.000000, reward total was -20.000000. running mean: -20.277454\n",
            "resetting env. episode 422.000000, reward total was -21.000000. running mean: -20.284680\n",
            "resetting env. episode 423.000000, reward total was -20.000000. running mean: -20.281833\n",
            "resetting env. episode 424.000000, reward total was -19.000000. running mean: -20.269014\n",
            "resetting env. episode 425.000000, reward total was -21.000000. running mean: -20.276324\n",
            "resetting env. episode 426.000000, reward total was -21.000000. running mean: -20.283561\n",
            "resetting env. episode 427.000000, reward total was -21.000000. running mean: -20.290725\n",
            "resetting env. episode 428.000000, reward total was -19.000000. running mean: -20.277818\n",
            "resetting env. episode 429.000000, reward total was -21.000000. running mean: -20.285040\n",
            "resetting env. episode 430.000000, reward total was -19.000000. running mean: -20.272190\n",
            "resetting env. episode 431.000000, reward total was -17.000000. running mean: -20.239468\n",
            "resetting env. episode 432.000000, reward total was -21.000000. running mean: -20.247073\n",
            "resetting env. episode 433.000000, reward total was -21.000000. running mean: -20.254602\n",
            "resetting env. episode 434.000000, reward total was -20.000000. running mean: -20.252056\n",
            "resetting env. episode 435.000000, reward total was -19.000000. running mean: -20.239536\n",
            "resetting env. episode 436.000000, reward total was -21.000000. running mean: -20.247140\n",
            "resetting env. episode 437.000000, reward total was -19.000000. running mean: -20.234669\n",
            "resetting env. episode 438.000000, reward total was -21.000000. running mean: -20.242322\n",
            "resetting env. episode 439.000000, reward total was -21.000000. running mean: -20.249899\n",
            "resetting env. episode 440.000000, reward total was -21.000000. running mean: -20.257400\n",
            "resetting env. episode 441.000000, reward total was -21.000000. running mean: -20.264826\n",
            "resetting env. episode 442.000000, reward total was -20.000000. running mean: -20.262178\n",
            "resetting env. episode 443.000000, reward total was -21.000000. running mean: -20.269556\n",
            "resetting env. episode 444.000000, reward total was -21.000000. running mean: -20.276860\n",
            "resetting env. episode 445.000000, reward total was -21.000000. running mean: -20.284092\n",
            "resetting env. episode 446.000000, reward total was -18.000000. running mean: -20.261251\n",
            "resetting env. episode 447.000000, reward total was -21.000000. running mean: -20.268638\n",
            "resetting env. episode 448.000000, reward total was -21.000000. running mean: -20.275952\n",
            "resetting env. episode 449.000000, reward total was -21.000000. running mean: -20.283192\n",
            "resetting env. episode 450.000000, reward total was -20.000000. running mean: -20.280361\n",
            "resetting env. episode 451.000000, reward total was -21.000000. running mean: -20.287557\n",
            "resetting env. episode 452.000000, reward total was -21.000000. running mean: -20.294681\n",
            "resetting env. episode 453.000000, reward total was -21.000000. running mean: -20.301735\n",
            "resetting env. episode 454.000000, reward total was -20.000000. running mean: -20.298717\n",
            "resetting env. episode 455.000000, reward total was -20.000000. running mean: -20.295730\n",
            "resetting env. episode 456.000000, reward total was -20.000000. running mean: -20.292773\n",
            "resetting env. episode 457.000000, reward total was -21.000000. running mean: -20.299845\n",
            "resetting env. episode 458.000000, reward total was -20.000000. running mean: -20.296847\n",
            "resetting env. episode 459.000000, reward total was -20.000000. running mean: -20.293878\n",
            "resetting env. episode 460.000000, reward total was -20.000000. running mean: -20.290939\n",
            "resetting env. episode 461.000000, reward total was -20.000000. running mean: -20.288030\n",
            "resetting env. episode 462.000000, reward total was -20.000000. running mean: -20.285150\n",
            "resetting env. episode 463.000000, reward total was -21.000000. running mean: -20.292298\n",
            "resetting env. episode 464.000000, reward total was -21.000000. running mean: -20.299375\n",
            "resetting env. episode 465.000000, reward total was -21.000000. running mean: -20.306381\n",
            "resetting env. episode 466.000000, reward total was -18.000000. running mean: -20.283318\n",
            "resetting env. episode 467.000000, reward total was -19.000000. running mean: -20.270484\n",
            "resetting env. episode 468.000000, reward total was -21.000000. running mean: -20.277780\n",
            "resetting env. episode 469.000000, reward total was -21.000000. running mean: -20.285002\n",
            "resetting env. episode 470.000000, reward total was -21.000000. running mean: -20.292152\n",
            "resetting env. episode 471.000000, reward total was -19.000000. running mean: -20.279230\n",
            "resetting env. episode 472.000000, reward total was -21.000000. running mean: -20.286438\n",
            "resetting env. episode 473.000000, reward total was -19.000000. running mean: -20.273574\n",
            "resetting env. episode 474.000000, reward total was -20.000000. running mean: -20.270838\n",
            "resetting env. episode 475.000000, reward total was -20.000000. running mean: -20.268129\n",
            "resetting env. episode 476.000000, reward total was -20.000000. running mean: -20.265448\n",
            "resetting env. episode 477.000000, reward total was -20.000000. running mean: -20.262794\n",
            "resetting env. episode 478.000000, reward total was -18.000000. running mean: -20.240166\n",
            "resetting env. episode 479.000000, reward total was -19.000000. running mean: -20.227764\n",
            "resetting env. episode 480.000000, reward total was -20.000000. running mean: -20.225486\n",
            "resetting env. episode 481.000000, reward total was -21.000000. running mean: -20.233232\n",
            "resetting env. episode 482.000000, reward total was -19.000000. running mean: -20.220899\n",
            "resetting env. episode 483.000000, reward total was -19.000000. running mean: -20.208690\n",
            "resetting env. episode 484.000000, reward total was -19.000000. running mean: -20.196603\n",
            "resetting env. episode 485.000000, reward total was -20.000000. running mean: -20.194637\n",
            "resetting env. episode 486.000000, reward total was -21.000000. running mean: -20.202691\n",
            "resetting env. episode 487.000000, reward total was -21.000000. running mean: -20.210664\n",
            "resetting env. episode 488.000000, reward total was -20.000000. running mean: -20.208557\n",
            "resetting env. episode 489.000000, reward total was -20.000000. running mean: -20.206472\n",
            "resetting env. episode 490.000000, reward total was -21.000000. running mean: -20.214407\n",
            "resetting env. episode 491.000000, reward total was -20.000000. running mean: -20.212263\n",
            "resetting env. episode 492.000000, reward total was -20.000000. running mean: -20.210140\n",
            "resetting env. episode 493.000000, reward total was -20.000000. running mean: -20.208039\n",
            "resetting env. episode 494.000000, reward total was -21.000000. running mean: -20.215959\n",
            "resetting env. episode 495.000000, reward total was -21.000000. running mean: -20.223799\n",
            "resetting env. episode 496.000000, reward total was -21.000000. running mean: -20.231561\n",
            "resetting env. episode 497.000000, reward total was -20.000000. running mean: -20.229245\n",
            "resetting env. episode 498.000000, reward total was -20.000000. running mean: -20.226953\n",
            "resetting env. episode 499.000000, reward total was -21.000000. running mean: -20.234683\n",
            "resetting env. episode 500.000000, reward total was -21.000000. running mean: -20.242337\n",
            "CPU times: user 34min 24s, sys: 10min 59s, total: 45min 24s\n",
            "Wall time: 23min 32s\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "ZJUybWUALvQz",
        "outputId": "0895e28c-4408-4240-cc61-7af9acd71848",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        }
      },
      "cell_type": "code",
      "source": [
        "play_game(env, model)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gym/core.py:52: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
            "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
            "  \"The argument mode in render method is deprecated; \"\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode finished without success, accumulated reward = -17.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 320x420 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "cHYCDYwhlVLV",
        "outputId": "4ae47676-b926-4645-e69f-4dd441406776",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "%time hist2 = train_model(env, model, total_episodes=500)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "resetting env. episode 1.000000, reward total was -20.000000. running mean: -20.000000\n",
            "resetting env. episode 2.000000, reward total was -21.000000. running mean: -20.010000\n",
            "resetting env. episode 3.000000, reward total was -18.000000. running mean: -19.989900\n",
            "resetting env. episode 4.000000, reward total was -20.000000. running mean: -19.990001\n",
            "resetting env. episode 5.000000, reward total was -21.000000. running mean: -20.000101\n",
            "resetting env. episode 6.000000, reward total was -21.000000. running mean: -20.010100\n",
            "resetting env. episode 7.000000, reward total was -21.000000. running mean: -20.019999\n",
            "resetting env. episode 8.000000, reward total was -19.000000. running mean: -20.009799\n",
            "resetting env. episode 9.000000, reward total was -21.000000. running mean: -20.019701\n",
            "resetting env. episode 10.000000, reward total was -21.000000. running mean: -20.029504\n",
            "resetting env. episode 11.000000, reward total was -21.000000. running mean: -20.039209\n",
            "resetting env. episode 12.000000, reward total was -21.000000. running mean: -20.048817\n",
            "resetting env. episode 13.000000, reward total was -21.000000. running mean: -20.058329\n",
            "resetting env. episode 14.000000, reward total was -21.000000. running mean: -20.067745\n",
            "resetting env. episode 15.000000, reward total was -21.000000. running mean: -20.077068\n",
            "resetting env. episode 16.000000, reward total was -21.000000. running mean: -20.086297\n",
            "resetting env. episode 17.000000, reward total was -20.000000. running mean: -20.085434\n",
            "resetting env. episode 18.000000, reward total was -21.000000. running mean: -20.094580\n",
            "resetting env. episode 19.000000, reward total was -21.000000. running mean: -20.103634\n",
            "resetting env. episode 20.000000, reward total was -18.000000. running mean: -20.082598\n",
            "resetting env. episode 21.000000, reward total was -21.000000. running mean: -20.091772\n",
            "resetting env. episode 22.000000, reward total was -19.000000. running mean: -20.080854\n",
            "resetting env. episode 23.000000, reward total was -19.000000. running mean: -20.070046\n",
            "resetting env. episode 24.000000, reward total was -21.000000. running mean: -20.079345\n",
            "resetting env. episode 25.000000, reward total was -20.000000. running mean: -20.078552\n",
            "resetting env. episode 26.000000, reward total was -20.000000. running mean: -20.077766\n",
            "resetting env. episode 27.000000, reward total was -21.000000. running mean: -20.086988\n",
            "resetting env. episode 28.000000, reward total was -21.000000. running mean: -20.096119\n",
            "resetting env. episode 29.000000, reward total was -20.000000. running mean: -20.095157\n",
            "resetting env. episode 30.000000, reward total was -21.000000. running mean: -20.104206\n",
            "resetting env. episode 31.000000, reward total was -20.000000. running mean: -20.103164\n",
            "resetting env. episode 32.000000, reward total was -20.000000. running mean: -20.102132\n",
            "resetting env. episode 33.000000, reward total was -21.000000. running mean: -20.111111\n",
            "resetting env. episode 34.000000, reward total was -20.000000. running mean: -20.110000\n",
            "resetting env. episode 35.000000, reward total was -21.000000. running mean: -20.118900\n",
            "resetting env. episode 36.000000, reward total was -20.000000. running mean: -20.117711\n",
            "resetting env. episode 37.000000, reward total was -21.000000. running mean: -20.126534\n",
            "resetting env. episode 38.000000, reward total was -18.000000. running mean: -20.105268\n",
            "resetting env. episode 39.000000, reward total was -20.000000. running mean: -20.104216\n",
            "resetting env. episode 40.000000, reward total was -19.000000. running mean: -20.093173\n",
            "resetting env. episode 41.000000, reward total was -21.000000. running mean: -20.102242\n",
            "resetting env. episode 42.000000, reward total was -19.000000. running mean: -20.091219\n",
            "resetting env. episode 43.000000, reward total was -18.000000. running mean: -20.070307\n",
            "resetting env. episode 44.000000, reward total was -20.000000. running mean: -20.069604\n",
            "resetting env. episode 45.000000, reward total was -21.000000. running mean: -20.078908\n",
            "resetting env. episode 46.000000, reward total was -21.000000. running mean: -20.088119\n",
            "resetting env. episode 47.000000, reward total was -21.000000. running mean: -20.097238\n",
            "resetting env. episode 48.000000, reward total was -21.000000. running mean: -20.106265\n",
            "resetting env. episode 49.000000, reward total was -21.000000. running mean: -20.115203\n",
            "resetting env. episode 50.000000, reward total was -20.000000. running mean: -20.114051\n",
            "resetting env. episode 51.000000, reward total was -20.000000. running mean: -20.112910\n",
            "resetting env. episode 52.000000, reward total was -21.000000. running mean: -20.121781\n",
            "resetting env. episode 53.000000, reward total was -20.000000. running mean: -20.120563\n",
            "resetting env. episode 54.000000, reward total was -20.000000. running mean: -20.119358\n",
            "resetting env. episode 55.000000, reward total was -21.000000. running mean: -20.128164\n",
            "resetting env. episode 56.000000, reward total was -20.000000. running mean: -20.126882\n",
            "resetting env. episode 57.000000, reward total was -19.000000. running mean: -20.115614\n",
            "resetting env. episode 58.000000, reward total was -20.000000. running mean: -20.114457\n",
            "resetting env. episode 59.000000, reward total was -21.000000. running mean: -20.123313\n",
            "resetting env. episode 60.000000, reward total was -21.000000. running mean: -20.132080\n",
            "resetting env. episode 61.000000, reward total was -21.000000. running mean: -20.140759\n",
            "resetting env. episode 62.000000, reward total was -21.000000. running mean: -20.149351\n",
            "resetting env. episode 63.000000, reward total was -21.000000. running mean: -20.157858\n",
            "resetting env. episode 64.000000, reward total was -21.000000. running mean: -20.166279\n",
            "resetting env. episode 65.000000, reward total was -19.000000. running mean: -20.154616\n",
            "resetting env. episode 66.000000, reward total was -21.000000. running mean: -20.163070\n",
            "resetting env. episode 67.000000, reward total was -21.000000. running mean: -20.171440\n",
            "resetting env. episode 68.000000, reward total was -20.000000. running mean: -20.169725\n",
            "resetting env. episode 69.000000, reward total was -19.000000. running mean: -20.158028\n",
            "resetting env. episode 70.000000, reward total was -20.000000. running mean: -20.156448\n",
            "resetting env. episode 71.000000, reward total was -18.000000. running mean: -20.134883\n",
            "resetting env. episode 72.000000, reward total was -19.000000. running mean: -20.123534\n",
            "resetting env. episode 73.000000, reward total was -20.000000. running mean: -20.122299\n",
            "resetting env. episode 74.000000, reward total was -20.000000. running mean: -20.121076\n",
            "resetting env. episode 75.000000, reward total was -19.000000. running mean: -20.109865\n",
            "resetting env. episode 76.000000, reward total was -20.000000. running mean: -20.108767\n",
            "resetting env. episode 77.000000, reward total was -20.000000. running mean: -20.107679\n",
            "resetting env. episode 78.000000, reward total was -21.000000. running mean: -20.116602\n",
            "resetting env. episode 79.000000, reward total was -20.000000. running mean: -20.115436\n",
            "resetting env. episode 80.000000, reward total was -20.000000. running mean: -20.114282\n",
            "resetting env. episode 81.000000, reward total was -21.000000. running mean: -20.123139\n",
            "resetting env. episode 82.000000, reward total was -20.000000. running mean: -20.121908\n",
            "resetting env. episode 83.000000, reward total was -20.000000. running mean: -20.120688\n",
            "resetting env. episode 84.000000, reward total was -20.000000. running mean: -20.119482\n",
            "resetting env. episode 85.000000, reward total was -21.000000. running mean: -20.128287\n",
            "resetting env. episode 86.000000, reward total was -21.000000. running mean: -20.137004\n",
            "resetting env. episode 87.000000, reward total was -20.000000. running mean: -20.135634\n",
            "resetting env. episode 88.000000, reward total was -21.000000. running mean: -20.144278\n",
            "resetting env. episode 89.000000, reward total was -21.000000. running mean: -20.152835\n",
            "resetting env. episode 90.000000, reward total was -19.000000. running mean: -20.141306\n",
            "resetting env. episode 91.000000, reward total was -20.000000. running mean: -20.139893\n",
            "resetting env. episode 92.000000, reward total was -20.000000. running mean: -20.138494\n",
            "resetting env. episode 93.000000, reward total was -21.000000. running mean: -20.147109\n",
            "resetting env. episode 94.000000, reward total was -21.000000. running mean: -20.155638\n",
            "resetting env. episode 95.000000, reward total was -21.000000. running mean: -20.164082\n",
            "resetting env. episode 96.000000, reward total was -21.000000. running mean: -20.172441\n",
            "resetting env. episode 97.000000, reward total was -21.000000. running mean: -20.180717\n",
            "resetting env. episode 98.000000, reward total was -21.000000. running mean: -20.188910\n",
            "resetting env. episode 99.000000, reward total was -21.000000. running mean: -20.197021\n",
            "resetting env. episode 100.000000, reward total was -21.000000. running mean: -20.205050\n",
            "resetting env. episode 101.000000, reward total was -19.000000. running mean: -20.193000\n",
            "resetting env. episode 102.000000, reward total was -20.000000. running mean: -20.191070\n",
            "resetting env. episode 103.000000, reward total was -21.000000. running mean: -20.199159\n",
            "resetting env. episode 104.000000, reward total was -20.000000. running mean: -20.197168\n",
            "resetting env. episode 105.000000, reward total was -21.000000. running mean: -20.205196\n",
            "resetting env. episode 106.000000, reward total was -21.000000. running mean: -20.213144\n",
            "resetting env. episode 107.000000, reward total was -21.000000. running mean: -20.221012\n",
            "resetting env. episode 108.000000, reward total was -19.000000. running mean: -20.208802\n",
            "resetting env. episode 109.000000, reward total was -20.000000. running mean: -20.206714\n",
            "resetting env. episode 110.000000, reward total was -21.000000. running mean: -20.214647\n",
            "resetting env. episode 111.000000, reward total was -19.000000. running mean: -20.202501\n",
            "resetting env. episode 112.000000, reward total was -16.000000. running mean: -20.160476\n",
            "resetting env. episode 113.000000, reward total was -20.000000. running mean: -20.158871\n",
            "resetting env. episode 114.000000, reward total was -21.000000. running mean: -20.167282\n",
            "resetting env. episode 115.000000, reward total was -20.000000. running mean: -20.165609\n",
            "resetting env. episode 116.000000, reward total was -20.000000. running mean: -20.163953\n",
            "resetting env. episode 117.000000, reward total was -21.000000. running mean: -20.172314\n",
            "resetting env. episode 118.000000, reward total was -21.000000. running mean: -20.180591\n",
            "resetting env. episode 119.000000, reward total was -21.000000. running mean: -20.188785\n",
            "resetting env. episode 120.000000, reward total was -21.000000. running mean: -20.196897\n",
            "resetting env. episode 121.000000, reward total was -21.000000. running mean: -20.204928\n",
            "resetting env. episode 122.000000, reward total was -21.000000. running mean: -20.212879\n",
            "resetting env. episode 123.000000, reward total was -19.000000. running mean: -20.200750\n",
            "resetting env. episode 124.000000, reward total was -21.000000. running mean: -20.208742\n",
            "resetting env. episode 125.000000, reward total was -20.000000. running mean: -20.206655\n",
            "resetting env. episode 126.000000, reward total was -20.000000. running mean: -20.204588\n",
            "resetting env. episode 127.000000, reward total was -19.000000. running mean: -20.192542\n",
            "resetting env. episode 128.000000, reward total was -18.000000. running mean: -20.170617\n",
            "resetting env. episode 129.000000, reward total was -21.000000. running mean: -20.178911\n",
            "resetting env. episode 130.000000, reward total was -20.000000. running mean: -20.177122\n",
            "resetting env. episode 131.000000, reward total was -21.000000. running mean: -20.185351\n",
            "resetting env. episode 132.000000, reward total was -20.000000. running mean: -20.183497\n",
            "resetting env. episode 133.000000, reward total was -21.000000. running mean: -20.191662\n",
            "resetting env. episode 134.000000, reward total was -20.000000. running mean: -20.189745\n",
            "resetting env. episode 135.000000, reward total was -20.000000. running mean: -20.187848\n",
            "resetting env. episode 136.000000, reward total was -20.000000. running mean: -20.185970\n",
            "resetting env. episode 137.000000, reward total was -21.000000. running mean: -20.194110\n",
            "resetting env. episode 138.000000, reward total was -21.000000. running mean: -20.202169\n",
            "resetting env. episode 139.000000, reward total was -19.000000. running mean: -20.190147\n",
            "resetting env. episode 140.000000, reward total was -19.000000. running mean: -20.178246\n",
            "resetting env. episode 141.000000, reward total was -21.000000. running mean: -20.186463\n",
            "resetting env. episode 142.000000, reward total was -21.000000. running mean: -20.194598\n",
            "resetting env. episode 143.000000, reward total was -21.000000. running mean: -20.202652\n",
            "resetting env. episode 144.000000, reward total was -21.000000. running mean: -20.210626\n",
            "resetting env. episode 145.000000, reward total was -21.000000. running mean: -20.218520\n",
            "resetting env. episode 146.000000, reward total was -21.000000. running mean: -20.226335\n",
            "resetting env. episode 147.000000, reward total was -19.000000. running mean: -20.214071\n",
            "resetting env. episode 148.000000, reward total was -21.000000. running mean: -20.221930\n",
            "resetting env. episode 149.000000, reward total was -20.000000. running mean: -20.219711\n",
            "resetting env. episode 150.000000, reward total was -20.000000. running mean: -20.217514\n",
            "resetting env. episode 151.000000, reward total was -21.000000. running mean: -20.225339\n",
            "resetting env. episode 152.000000, reward total was -21.000000. running mean: -20.233086\n",
            "resetting env. episode 153.000000, reward total was -21.000000. running mean: -20.240755\n",
            "resetting env. episode 154.000000, reward total was -21.000000. running mean: -20.248347\n",
            "resetting env. episode 155.000000, reward total was -21.000000. running mean: -20.255864\n",
            "resetting env. episode 156.000000, reward total was -19.000000. running mean: -20.243305\n",
            "resetting env. episode 157.000000, reward total was -21.000000. running mean: -20.250872\n",
            "resetting env. episode 158.000000, reward total was -20.000000. running mean: -20.248363\n",
            "resetting env. episode 159.000000, reward total was -21.000000. running mean: -20.255880\n",
            "resetting env. episode 160.000000, reward total was -20.000000. running mean: -20.253321\n",
            "resetting env. episode 161.000000, reward total was -21.000000. running mean: -20.260788\n",
            "resetting env. episode 162.000000, reward total was -20.000000. running mean: -20.258180\n",
            "resetting env. episode 163.000000, reward total was -19.000000. running mean: -20.245598\n",
            "resetting env. episode 164.000000, reward total was -21.000000. running mean: -20.253142\n",
            "resetting env. episode 165.000000, reward total was -20.000000. running mean: -20.250611\n",
            "resetting env. episode 166.000000, reward total was -20.000000. running mean: -20.248104\n",
            "resetting env. episode 167.000000, reward total was -19.000000. running mean: -20.235623\n",
            "resetting env. episode 168.000000, reward total was -21.000000. running mean: -20.243267\n",
            "resetting env. episode 169.000000, reward total was -18.000000. running mean: -20.220834\n",
            "resetting env. episode 170.000000, reward total was -21.000000. running mean: -20.228626\n",
            "resetting env. episode 171.000000, reward total was -21.000000. running mean: -20.236340\n",
            "resetting env. episode 172.000000, reward total was -21.000000. running mean: -20.243976\n",
            "resetting env. episode 173.000000, reward total was -21.000000. running mean: -20.251537\n",
            "resetting env. episode 174.000000, reward total was -18.000000. running mean: -20.229021\n",
            "resetting env. episode 175.000000, reward total was -21.000000. running mean: -20.236731\n",
            "resetting env. episode 176.000000, reward total was -21.000000. running mean: -20.244364\n",
            "resetting env. episode 177.000000, reward total was -20.000000. running mean: -20.241920\n",
            "resetting env. episode 178.000000, reward total was -21.000000. running mean: -20.249501\n",
            "resetting env. episode 179.000000, reward total was -21.000000. running mean: -20.257006\n",
            "resetting env. episode 180.000000, reward total was -21.000000. running mean: -20.264436\n",
            "resetting env. episode 181.000000, reward total was -19.000000. running mean: -20.251792\n",
            "resetting env. episode 182.000000, reward total was -21.000000. running mean: -20.259274\n",
            "resetting env. episode 183.000000, reward total was -21.000000. running mean: -20.266681\n",
            "resetting env. episode 184.000000, reward total was -21.000000. running mean: -20.274014\n",
            "resetting env. episode 185.000000, reward total was -20.000000. running mean: -20.271274\n",
            "resetting env. episode 186.000000, reward total was -20.000000. running mean: -20.268561\n",
            "resetting env. episode 187.000000, reward total was -20.000000. running mean: -20.265876\n",
            "resetting env. episode 188.000000, reward total was -21.000000. running mean: -20.273217\n",
            "resetting env. episode 189.000000, reward total was -21.000000. running mean: -20.280485\n",
            "resetting env. episode 190.000000, reward total was -19.000000. running mean: -20.267680\n",
            "resetting env. episode 191.000000, reward total was -20.000000. running mean: -20.265003\n",
            "resetting env. episode 192.000000, reward total was -21.000000. running mean: -20.272353\n",
            "resetting env. episode 193.000000, reward total was -20.000000. running mean: -20.269629\n",
            "resetting env. episode 194.000000, reward total was -20.000000. running mean: -20.266933\n",
            "resetting env. episode 195.000000, reward total was -20.000000. running mean: -20.264264\n",
            "resetting env. episode 196.000000, reward total was -21.000000. running mean: -20.271621\n",
            "resetting env. episode 197.000000, reward total was -21.000000. running mean: -20.278905\n",
            "resetting env. episode 198.000000, reward total was -21.000000. running mean: -20.286116\n",
            "resetting env. episode 199.000000, reward total was -18.000000. running mean: -20.263255\n",
            "resetting env. episode 200.000000, reward total was -21.000000. running mean: -20.270622\n",
            "resetting env. episode 201.000000, reward total was -19.000000. running mean: -20.257916\n",
            "resetting env. episode 202.000000, reward total was -21.000000. running mean: -20.265337\n",
            "resetting env. episode 203.000000, reward total was -21.000000. running mean: -20.272683\n",
            "resetting env. episode 204.000000, reward total was -21.000000. running mean: -20.279957\n",
            "resetting env. episode 205.000000, reward total was -19.000000. running mean: -20.267157\n",
            "resetting env. episode 206.000000, reward total was -21.000000. running mean: -20.274486\n",
            "resetting env. episode 207.000000, reward total was -19.000000. running mean: -20.261741\n",
            "resetting env. episode 208.000000, reward total was -21.000000. running mean: -20.269123\n",
            "resetting env. episode 209.000000, reward total was -20.000000. running mean: -20.266432\n",
            "resetting env. episode 210.000000, reward total was -21.000000. running mean: -20.273768\n",
            "resetting env. episode 211.000000, reward total was -21.000000. running mean: -20.281030\n",
            "resetting env. episode 212.000000, reward total was -20.000000. running mean: -20.278220\n",
            "resetting env. episode 213.000000, reward total was -20.000000. running mean: -20.275438\n",
            "resetting env. episode 214.000000, reward total was -21.000000. running mean: -20.282683\n",
            "resetting env. episode 215.000000, reward total was -20.000000. running mean: -20.279856\n",
            "resetting env. episode 216.000000, reward total was -21.000000. running mean: -20.287058\n",
            "resetting env. episode 217.000000, reward total was -20.000000. running mean: -20.284187\n",
            "resetting env. episode 218.000000, reward total was -21.000000. running mean: -20.291345\n",
            "resetting env. episode 219.000000, reward total was -21.000000. running mean: -20.298432\n",
            "resetting env. episode 220.000000, reward total was -21.000000. running mean: -20.305448\n",
            "resetting env. episode 221.000000, reward total was -21.000000. running mean: -20.312393\n",
            "resetting env. episode 222.000000, reward total was -21.000000. running mean: -20.319269\n",
            "resetting env. episode 223.000000, reward total was -21.000000. running mean: -20.326076\n",
            "resetting env. episode 224.000000, reward total was -20.000000. running mean: -20.322816\n",
            "resetting env. episode 225.000000, reward total was -21.000000. running mean: -20.329588\n",
            "resetting env. episode 226.000000, reward total was -20.000000. running mean: -20.326292\n",
            "resetting env. episode 227.000000, reward total was -21.000000. running mean: -20.333029\n",
            "resetting env. episode 228.000000, reward total was -21.000000. running mean: -20.339698\n",
            "resetting env. episode 229.000000, reward total was -20.000000. running mean: -20.336301\n",
            "resetting env. episode 230.000000, reward total was -20.000000. running mean: -20.332938\n",
            "resetting env. episode 231.000000, reward total was -20.000000. running mean: -20.329609\n",
            "resetting env. episode 232.000000, reward total was -21.000000. running mean: -20.336313\n",
            "resetting env. episode 233.000000, reward total was -21.000000. running mean: -20.342950\n",
            "resetting env. episode 234.000000, reward total was -21.000000. running mean: -20.349520\n",
            "resetting env. episode 235.000000, reward total was -20.000000. running mean: -20.346025\n",
            "resetting env. episode 236.000000, reward total was -21.000000. running mean: -20.352565\n",
            "resetting env. episode 237.000000, reward total was -17.000000. running mean: -20.319039\n",
            "resetting env. episode 238.000000, reward total was -19.000000. running mean: -20.305849\n",
            "resetting env. episode 239.000000, reward total was -21.000000. running mean: -20.312790\n",
            "resetting env. episode 240.000000, reward total was -21.000000. running mean: -20.319662\n",
            "resetting env. episode 241.000000, reward total was -20.000000. running mean: -20.316466\n",
            "resetting env. episode 242.000000, reward total was -21.000000. running mean: -20.323301\n",
            "resetting env. episode 243.000000, reward total was -19.000000. running mean: -20.310068\n",
            "resetting env. episode 244.000000, reward total was -21.000000. running mean: -20.316967\n",
            "resetting env. episode 245.000000, reward total was -19.000000. running mean: -20.303798\n",
            "resetting env. episode 246.000000, reward total was -20.000000. running mean: -20.300760\n",
            "resetting env. episode 247.000000, reward total was -20.000000. running mean: -20.297752\n",
            "resetting env. episode 248.000000, reward total was -21.000000. running mean: -20.304775\n",
            "resetting env. episode 249.000000, reward total was -19.000000. running mean: -20.291727\n",
            "resetting env. episode 250.000000, reward total was -21.000000. running mean: -20.298810\n",
            "resetting env. episode 251.000000, reward total was -19.000000. running mean: -20.285822\n",
            "resetting env. episode 252.000000, reward total was -21.000000. running mean: -20.292963\n",
            "resetting env. episode 253.000000, reward total was -20.000000. running mean: -20.290034\n",
            "resetting env. episode 254.000000, reward total was -19.000000. running mean: -20.277133\n",
            "resetting env. episode 255.000000, reward total was -21.000000. running mean: -20.284362\n",
            "resetting env. episode 256.000000, reward total was -17.000000. running mean: -20.251518\n",
            "resetting env. episode 257.000000, reward total was -20.000000. running mean: -20.249003\n",
            "resetting env. episode 258.000000, reward total was -20.000000. running mean: -20.246513\n",
            "resetting env. episode 259.000000, reward total was -21.000000. running mean: -20.254048\n",
            "resetting env. episode 260.000000, reward total was -21.000000. running mean: -20.261508\n",
            "resetting env. episode 261.000000, reward total was -21.000000. running mean: -20.268893\n",
            "resetting env. episode 262.000000, reward total was -21.000000. running mean: -20.276204\n",
            "resetting env. episode 263.000000, reward total was -21.000000. running mean: -20.283442\n",
            "resetting env. episode 264.000000, reward total was -19.000000. running mean: -20.270607\n",
            "resetting env. episode 265.000000, reward total was -21.000000. running mean: -20.277901\n",
            "resetting env. episode 266.000000, reward total was -20.000000. running mean: -20.275122\n",
            "resetting env. episode 267.000000, reward total was -21.000000. running mean: -20.282371\n",
            "resetting env. episode 268.000000, reward total was -21.000000. running mean: -20.289547\n",
            "resetting env. episode 269.000000, reward total was -20.000000. running mean: -20.286652\n",
            "resetting env. episode 270.000000, reward total was -21.000000. running mean: -20.293785\n",
            "resetting env. episode 271.000000, reward total was -20.000000. running mean: -20.290847\n",
            "resetting env. episode 272.000000, reward total was -21.000000. running mean: -20.297939\n",
            "resetting env. episode 273.000000, reward total was -20.000000. running mean: -20.294959\n",
            "resetting env. episode 274.000000, reward total was -21.000000. running mean: -20.302010\n",
            "resetting env. episode 275.000000, reward total was -20.000000. running mean: -20.298990\n",
            "resetting env. episode 276.000000, reward total was -21.000000. running mean: -20.306000\n",
            "resetting env. episode 277.000000, reward total was -21.000000. running mean: -20.312940\n",
            "resetting env. episode 278.000000, reward total was -21.000000. running mean: -20.319810\n",
            "resetting env. episode 279.000000, reward total was -21.000000. running mean: -20.326612\n",
            "resetting env. episode 280.000000, reward total was -21.000000. running mean: -20.333346\n",
            "resetting env. episode 281.000000, reward total was -21.000000. running mean: -20.340013\n",
            "resetting env. episode 282.000000, reward total was -20.000000. running mean: -20.336613\n",
            "resetting env. episode 283.000000, reward total was -21.000000. running mean: -20.343247\n",
            "resetting env. episode 284.000000, reward total was -21.000000. running mean: -20.349814\n",
            "resetting env. episode 285.000000, reward total was -21.000000. running mean: -20.356316\n",
            "resetting env. episode 286.000000, reward total was -21.000000. running mean: -20.362753\n",
            "resetting env. episode 287.000000, reward total was -19.000000. running mean: -20.349125\n",
            "resetting env. episode 288.000000, reward total was -20.000000. running mean: -20.345634\n",
            "resetting env. episode 289.000000, reward total was -21.000000. running mean: -20.352178\n",
            "resetting env. episode 290.000000, reward total was -21.000000. running mean: -20.358656\n",
            "resetting env. episode 291.000000, reward total was -21.000000. running mean: -20.365069\n",
            "resetting env. episode 292.000000, reward total was -21.000000. running mean: -20.371419\n",
            "resetting env. episode 293.000000, reward total was -21.000000. running mean: -20.377704\n",
            "resetting env. episode 294.000000, reward total was -19.000000. running mean: -20.363927\n",
            "resetting env. episode 295.000000, reward total was -20.000000. running mean: -20.360288\n",
            "resetting env. episode 296.000000, reward total was -21.000000. running mean: -20.366685\n",
            "resetting env. episode 297.000000, reward total was -21.000000. running mean: -20.373018\n",
            "resetting env. episode 298.000000, reward total was -20.000000. running mean: -20.369288\n",
            "resetting env. episode 299.000000, reward total was -20.000000. running mean: -20.365595\n",
            "resetting env. episode 300.000000, reward total was -21.000000. running mean: -20.371939\n",
            "resetting env. episode 301.000000, reward total was -19.000000. running mean: -20.358220\n",
            "resetting env. episode 302.000000, reward total was -21.000000. running mean: -20.364638\n",
            "resetting env. episode 303.000000, reward total was -20.000000. running mean: -20.360991\n",
            "resetting env. episode 304.000000, reward total was -20.000000. running mean: -20.357381\n",
            "resetting env. episode 305.000000, reward total was -21.000000. running mean: -20.363808\n",
            "resetting env. episode 306.000000, reward total was -21.000000. running mean: -20.370170\n",
            "resetting env. episode 307.000000, reward total was -21.000000. running mean: -20.376468\n",
            "resetting env. episode 308.000000, reward total was -21.000000. running mean: -20.382703\n",
            "resetting env. episode 309.000000, reward total was -20.000000. running mean: -20.378876\n",
            "resetting env. episode 310.000000, reward total was -21.000000. running mean: -20.385087\n",
            "resetting env. episode 311.000000, reward total was -21.000000. running mean: -20.391237\n",
            "resetting env. episode 312.000000, reward total was -19.000000. running mean: -20.377324\n",
            "resetting env. episode 313.000000, reward total was -20.000000. running mean: -20.373551\n",
            "resetting env. episode 314.000000, reward total was -20.000000. running mean: -20.369815\n",
            "resetting env. episode 315.000000, reward total was -20.000000. running mean: -20.366117\n",
            "resetting env. episode 316.000000, reward total was -19.000000. running mean: -20.352456\n",
            "resetting env. episode 317.000000, reward total was -21.000000. running mean: -20.358932\n",
            "resetting env. episode 318.000000, reward total was -21.000000. running mean: -20.365342\n",
            "resetting env. episode 319.000000, reward total was -20.000000. running mean: -20.361689\n",
            "resetting env. episode 320.000000, reward total was -21.000000. running mean: -20.368072\n",
            "resetting env. episode 321.000000, reward total was -20.000000. running mean: -20.364391\n",
            "resetting env. episode 322.000000, reward total was -21.000000. running mean: -20.370747\n",
            "resetting env. episode 323.000000, reward total was -21.000000. running mean: -20.377040\n",
            "resetting env. episode 324.000000, reward total was -21.000000. running mean: -20.383269\n",
            "resetting env. episode 325.000000, reward total was -20.000000. running mean: -20.379437\n",
            "resetting env. episode 326.000000, reward total was -20.000000. running mean: -20.375642\n",
            "resetting env. episode 327.000000, reward total was -20.000000. running mean: -20.371886\n",
            "resetting env. episode 328.000000, reward total was -21.000000. running mean: -20.378167\n",
            "resetting env. episode 329.000000, reward total was -20.000000. running mean: -20.374385\n",
            "resetting env. episode 330.000000, reward total was -20.000000. running mean: -20.370642\n",
            "resetting env. episode 331.000000, reward total was -21.000000. running mean: -20.376935\n",
            "resetting env. episode 332.000000, reward total was -21.000000. running mean: -20.383166\n",
            "resetting env. episode 333.000000, reward total was -21.000000. running mean: -20.389334\n",
            "resetting env. episode 334.000000, reward total was -20.000000. running mean: -20.385441\n",
            "resetting env. episode 335.000000, reward total was -21.000000. running mean: -20.391586\n",
            "resetting env. episode 336.000000, reward total was -21.000000. running mean: -20.397670\n",
            "resetting env. episode 337.000000, reward total was -21.000000. running mean: -20.403694\n",
            "resetting env. episode 338.000000, reward total was -21.000000. running mean: -20.409657\n",
            "resetting env. episode 339.000000, reward total was -20.000000. running mean: -20.405560\n",
            "resetting env. episode 340.000000, reward total was -21.000000. running mean: -20.411505\n",
            "resetting env. episode 341.000000, reward total was -17.000000. running mean: -20.377390\n",
            "resetting env. episode 342.000000, reward total was -21.000000. running mean: -20.383616\n",
            "resetting env. episode 343.000000, reward total was -20.000000. running mean: -20.379780\n",
            "resetting env. episode 344.000000, reward total was -20.000000. running mean: -20.375982\n",
            "resetting env. episode 345.000000, reward total was -21.000000. running mean: -20.382222\n",
            "resetting env. episode 346.000000, reward total was -21.000000. running mean: -20.388400\n",
            "resetting env. episode 347.000000, reward total was -20.000000. running mean: -20.384516\n",
            "resetting env. episode 348.000000, reward total was -20.000000. running mean: -20.380671\n",
            "resetting env. episode 349.000000, reward total was -21.000000. running mean: -20.386864\n",
            "resetting env. episode 350.000000, reward total was -21.000000. running mean: -20.392995\n",
            "resetting env. episode 351.000000, reward total was -20.000000. running mean: -20.389065\n",
            "resetting env. episode 352.000000, reward total was -20.000000. running mean: -20.385175\n",
            "resetting env. episode 353.000000, reward total was -21.000000. running mean: -20.391323\n",
            "resetting env. episode 354.000000, reward total was -20.000000. running mean: -20.387410\n",
            "resetting env. episode 355.000000, reward total was -19.000000. running mean: -20.373536\n",
            "resetting env. episode 356.000000, reward total was -21.000000. running mean: -20.379800\n",
            "resetting env. episode 357.000000, reward total was -21.000000. running mean: -20.386002\n",
            "resetting env. episode 358.000000, reward total was -20.000000. running mean: -20.382142\n",
            "resetting env. episode 359.000000, reward total was -21.000000. running mean: -20.388321\n",
            "resetting env. episode 360.000000, reward total was -20.000000. running mean: -20.384438\n",
            "resetting env. episode 361.000000, reward total was -20.000000. running mean: -20.380593\n",
            "resetting env. episode 362.000000, reward total was -20.000000. running mean: -20.376787\n",
            "resetting env. episode 363.000000, reward total was -20.000000. running mean: -20.373019\n",
            "resetting env. episode 364.000000, reward total was -18.000000. running mean: -20.349289\n",
            "resetting env. episode 365.000000, reward total was -20.000000. running mean: -20.345796\n",
            "resetting env. episode 366.000000, reward total was -21.000000. running mean: -20.352338\n",
            "resetting env. episode 367.000000, reward total was -21.000000. running mean: -20.358815\n",
            "resetting env. episode 368.000000, reward total was -19.000000. running mean: -20.345227\n",
            "resetting env. episode 369.000000, reward total was -21.000000. running mean: -20.351775\n",
            "resetting env. episode 370.000000, reward total was -20.000000. running mean: -20.348257\n",
            "resetting env. episode 371.000000, reward total was -21.000000. running mean: -20.354774\n",
            "resetting env. episode 372.000000, reward total was -20.000000. running mean: -20.351226\n",
            "resetting env. episode 373.000000, reward total was -20.000000. running mean: -20.347714\n",
            "resetting env. episode 374.000000, reward total was -20.000000. running mean: -20.344237\n",
            "resetting env. episode 375.000000, reward total was -20.000000. running mean: -20.340795\n",
            "resetting env. episode 376.000000, reward total was -19.000000. running mean: -20.327387\n",
            "resetting env. episode 377.000000, reward total was -20.000000. running mean: -20.324113\n",
            "resetting env. episode 378.000000, reward total was -20.000000. running mean: -20.320872\n",
            "resetting env. episode 379.000000, reward total was -21.000000. running mean: -20.327663\n",
            "resetting env. episode 380.000000, reward total was -20.000000. running mean: -20.324386\n",
            "resetting env. episode 381.000000, reward total was -21.000000. running mean: -20.331143\n",
            "resetting env. episode 382.000000, reward total was -18.000000. running mean: -20.307831\n",
            "resetting env. episode 383.000000, reward total was -21.000000. running mean: -20.314753\n",
            "resetting env. episode 384.000000, reward total was -19.000000. running mean: -20.301605\n",
            "resetting env. episode 385.000000, reward total was -20.000000. running mean: -20.298589\n",
            "resetting env. episode 386.000000, reward total was -19.000000. running mean: -20.285603\n",
            "resetting env. episode 387.000000, reward total was -21.000000. running mean: -20.292747\n",
            "resetting env. episode 388.000000, reward total was -20.000000. running mean: -20.289820\n",
            "resetting env. episode 389.000000, reward total was -21.000000. running mean: -20.296922\n",
            "resetting env. episode 390.000000, reward total was -19.000000. running mean: -20.283952\n",
            "resetting env. episode 391.000000, reward total was -20.000000. running mean: -20.281113\n",
            "resetting env. episode 392.000000, reward total was -20.000000. running mean: -20.278302\n",
            "resetting env. episode 393.000000, reward total was -21.000000. running mean: -20.285519\n",
            "resetting env. episode 394.000000, reward total was -18.000000. running mean: -20.262664\n",
            "resetting env. episode 395.000000, reward total was -20.000000. running mean: -20.260037\n",
            "resetting env. episode 396.000000, reward total was -20.000000. running mean: -20.257437\n",
            "resetting env. episode 397.000000, reward total was -21.000000. running mean: -20.264862\n",
            "resetting env. episode 398.000000, reward total was -21.000000. running mean: -20.272214\n",
            "resetting env. episode 399.000000, reward total was -20.000000. running mean: -20.269491\n",
            "resetting env. episode 400.000000, reward total was -20.000000. running mean: -20.266797\n",
            "resetting env. episode 401.000000, reward total was -19.000000. running mean: -20.254129\n",
            "resetting env. episode 402.000000, reward total was -20.000000. running mean: -20.251587\n",
            "resetting env. episode 403.000000, reward total was -20.000000. running mean: -20.249071\n",
            "resetting env. episode 404.000000, reward total was -21.000000. running mean: -20.256581\n",
            "resetting env. episode 405.000000, reward total was -20.000000. running mean: -20.254015\n",
            "resetting env. episode 406.000000, reward total was -19.000000. running mean: -20.241475\n",
            "resetting env. episode 407.000000, reward total was -20.000000. running mean: -20.239060\n",
            "resetting env. episode 408.000000, reward total was -19.000000. running mean: -20.226669\n",
            "resetting env. episode 409.000000, reward total was -20.000000. running mean: -20.224403\n",
            "resetting env. episode 410.000000, reward total was -21.000000. running mean: -20.232159\n",
            "resetting env. episode 411.000000, reward total was -19.000000. running mean: -20.219837\n",
            "resetting env. episode 412.000000, reward total was -21.000000. running mean: -20.227639\n",
            "resetting env. episode 413.000000, reward total was -19.000000. running mean: -20.215362\n",
            "resetting env. episode 414.000000, reward total was -20.000000. running mean: -20.213209\n",
            "resetting env. episode 415.000000, reward total was -21.000000. running mean: -20.221077\n",
            "resetting env. episode 416.000000, reward total was -20.000000. running mean: -20.218866\n",
            "resetting env. episode 417.000000, reward total was -20.000000. running mean: -20.216677\n",
            "resetting env. episode 418.000000, reward total was -20.000000. running mean: -20.214510\n",
            "resetting env. episode 419.000000, reward total was -21.000000. running mean: -20.222365\n",
            "resetting env. episode 420.000000, reward total was -21.000000. running mean: -20.230142\n",
            "resetting env. episode 421.000000, reward total was -21.000000. running mean: -20.237840\n",
            "resetting env. episode 422.000000, reward total was -21.000000. running mean: -20.245462\n",
            "resetting env. episode 423.000000, reward total was -20.000000. running mean: -20.243007\n",
            "resetting env. episode 424.000000, reward total was -20.000000. running mean: -20.240577\n",
            "resetting env. episode 425.000000, reward total was -21.000000. running mean: -20.248171\n",
            "resetting env. episode 426.000000, reward total was -19.000000. running mean: -20.235690\n",
            "resetting env. episode 427.000000, reward total was -19.000000. running mean: -20.223333\n",
            "resetting env. episode 428.000000, reward total was -20.000000. running mean: -20.221099\n",
            "resetting env. episode 429.000000, reward total was -19.000000. running mean: -20.208888\n",
            "resetting env. episode 430.000000, reward total was -19.000000. running mean: -20.196800\n",
            "resetting env. episode 431.000000, reward total was -20.000000. running mean: -20.194832\n",
            "resetting env. episode 432.000000, reward total was -21.000000. running mean: -20.202883\n",
            "resetting env. episode 433.000000, reward total was -21.000000. running mean: -20.210854\n",
            "resetting env. episode 434.000000, reward total was -20.000000. running mean: -20.208746\n",
            "resetting env. episode 435.000000, reward total was -18.000000. running mean: -20.186658\n",
            "resetting env. episode 436.000000, reward total was -21.000000. running mean: -20.194792\n",
            "resetting env. episode 437.000000, reward total was -20.000000. running mean: -20.192844\n",
            "resetting env. episode 438.000000, reward total was -21.000000. running mean: -20.200915\n",
            "resetting env. episode 439.000000, reward total was -20.000000. running mean: -20.198906\n",
            "resetting env. episode 440.000000, reward total was -20.000000. running mean: -20.196917\n",
            "resetting env. episode 441.000000, reward total was -21.000000. running mean: -20.204948\n",
            "resetting env. episode 442.000000, reward total was -21.000000. running mean: -20.212899\n",
            "resetting env. episode 443.000000, reward total was -21.000000. running mean: -20.220770\n",
            "resetting env. episode 444.000000, reward total was -21.000000. running mean: -20.228562\n",
            "resetting env. episode 445.000000, reward total was -20.000000. running mean: -20.226276\n",
            "resetting env. episode 446.000000, reward total was -21.000000. running mean: -20.234014\n",
            "resetting env. episode 447.000000, reward total was -20.000000. running mean: -20.231673\n",
            "resetting env. episode 448.000000, reward total was -21.000000. running mean: -20.239357\n",
            "resetting env. episode 449.000000, reward total was -18.000000. running mean: -20.216963\n",
            "resetting env. episode 450.000000, reward total was -18.000000. running mean: -20.194793\n",
            "resetting env. episode 451.000000, reward total was -17.000000. running mean: -20.162846\n",
            "resetting env. episode 452.000000, reward total was -20.000000. running mean: -20.161217\n",
            "resetting env. episode 453.000000, reward total was -20.000000. running mean: -20.159605\n",
            "resetting env. episode 454.000000, reward total was -21.000000. running mean: -20.168009\n",
            "resetting env. episode 455.000000, reward total was -19.000000. running mean: -20.156329\n",
            "resetting env. episode 456.000000, reward total was -19.000000. running mean: -20.144765\n",
            "resetting env. episode 457.000000, reward total was -21.000000. running mean: -20.153318\n",
            "resetting env. episode 458.000000, reward total was -18.000000. running mean: -20.131785\n",
            "resetting env. episode 459.000000, reward total was -21.000000. running mean: -20.140467\n",
            "resetting env. episode 460.000000, reward total was -20.000000. running mean: -20.139062\n",
            "resetting env. episode 461.000000, reward total was -20.000000. running mean: -20.137672\n",
            "resetting env. episode 462.000000, reward total was -20.000000. running mean: -20.136295\n",
            "resetting env. episode 463.000000, reward total was -21.000000. running mean: -20.144932\n",
            "resetting env. episode 464.000000, reward total was -20.000000. running mean: -20.143483\n",
            "resetting env. episode 465.000000, reward total was -19.000000. running mean: -20.132048\n",
            "resetting env. episode 466.000000, reward total was -21.000000. running mean: -20.140727\n",
            "resetting env. episode 467.000000, reward total was -20.000000. running mean: -20.139320\n",
            "resetting env. episode 468.000000, reward total was -21.000000. running mean: -20.147927\n",
            "resetting env. episode 469.000000, reward total was -21.000000. running mean: -20.156447\n",
            "resetting env. episode 470.000000, reward total was -21.000000. running mean: -20.164883\n",
            "resetting env. episode 471.000000, reward total was -19.000000. running mean: -20.153234\n",
            "resetting env. episode 472.000000, reward total was -21.000000. running mean: -20.161702\n",
            "resetting env. episode 473.000000, reward total was -21.000000. running mean: -20.170085\n",
            "resetting env. episode 474.000000, reward total was -21.000000. running mean: -20.178384\n",
            "resetting env. episode 475.000000, reward total was -21.000000. running mean: -20.186600\n",
            "resetting env. episode 476.000000, reward total was -20.000000. running mean: -20.184734\n",
            "resetting env. episode 477.000000, reward total was -21.000000. running mean: -20.192887\n",
            "resetting env. episode 478.000000, reward total was -21.000000. running mean: -20.200958\n",
            "resetting env. episode 479.000000, reward total was -21.000000. running mean: -20.208948\n",
            "resetting env. episode 480.000000, reward total was -21.000000. running mean: -20.216859\n",
            "resetting env. episode 481.000000, reward total was -20.000000. running mean: -20.214690\n",
            "resetting env. episode 482.000000, reward total was -20.000000. running mean: -20.212543\n",
            "resetting env. episode 483.000000, reward total was -19.000000. running mean: -20.200418\n",
            "resetting env. episode 484.000000, reward total was -21.000000. running mean: -20.208414\n",
            "resetting env. episode 485.000000, reward total was -20.000000. running mean: -20.206330\n",
            "resetting env. episode 486.000000, reward total was -21.000000. running mean: -20.214266\n",
            "resetting env. episode 487.000000, reward total was -21.000000. running mean: -20.222124\n",
            "resetting env. episode 488.000000, reward total was -21.000000. running mean: -20.229902\n",
            "resetting env. episode 489.000000, reward total was -21.000000. running mean: -20.237603\n",
            "resetting env. episode 490.000000, reward total was -21.000000. running mean: -20.245227\n",
            "resetting env. episode 491.000000, reward total was -20.000000. running mean: -20.242775\n",
            "resetting env. episode 492.000000, reward total was -19.000000. running mean: -20.230347\n",
            "resetting env. episode 493.000000, reward total was -18.000000. running mean: -20.208044\n",
            "resetting env. episode 494.000000, reward total was -19.000000. running mean: -20.195963\n",
            "resetting env. episode 495.000000, reward total was -20.000000. running mean: -20.194004\n",
            "resetting env. episode 496.000000, reward total was -20.000000. running mean: -20.192064\n",
            "resetting env. episode 497.000000, reward total was -19.000000. running mean: -20.180143\n",
            "resetting env. episode 498.000000, reward total was -18.000000. running mean: -20.158342\n",
            "resetting env. episode 499.000000, reward total was -21.000000. running mean: -20.166758\n",
            "resetting env. episode 500.000000, reward total was -20.000000. running mean: -20.165091\n",
            "CPU times: user 35min 2s, sys: 11min 11s, total: 46min 13s\n",
            "Wall time: 23min 53s\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "8fheN9DRlWXQ",
        "outputId": "af3ed28a-5d54-42a5-d475-be6e1b1c6047",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        }
      },
      "cell_type": "code",
      "source": [
        "play_game(env, model)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gym/core.py:52: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
            "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
            "  \"The argument mode in render method is deprecated; \"\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode finished without success, accumulated reward = -14.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 320x420 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "9AxOcQhIsKow",
        "outputId": "66e13561-9a3d-4dc5-b83e-27159ed94ff1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "%time hist3 = train_model(env, model, total_episodes=4000)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "resetting env. episode 1.000000, reward total was -21.000000. running mean: -21.000000\n",
            "resetting env. episode 2.000000, reward total was -21.000000. running mean: -21.000000\n",
            "resetting env. episode 3.000000, reward total was -19.000000. running mean: -20.980000\n",
            "resetting env. episode 4.000000, reward total was -21.000000. running mean: -20.980200\n",
            "resetting env. episode 5.000000, reward total was -20.000000. running mean: -20.970398\n",
            "resetting env. episode 6.000000, reward total was -21.000000. running mean: -20.970694\n",
            "resetting env. episode 7.000000, reward total was -21.000000. running mean: -20.970987\n",
            "resetting env. episode 8.000000, reward total was -20.000000. running mean: -20.961277\n",
            "resetting env. episode 9.000000, reward total was -19.000000. running mean: -20.941664\n",
            "resetting env. episode 10.000000, reward total was -20.000000. running mean: -20.932248\n",
            "resetting env. episode 11.000000, reward total was -21.000000. running mean: -20.932925\n",
            "resetting env. episode 12.000000, reward total was -21.000000. running mean: -20.933596\n",
            "resetting env. episode 13.000000, reward total was -21.000000. running mean: -20.934260\n",
            "resetting env. episode 14.000000, reward total was -21.000000. running mean: -20.934917\n",
            "resetting env. episode 15.000000, reward total was -20.000000. running mean: -20.925568\n",
            "resetting env. episode 16.000000, reward total was -20.000000. running mean: -20.916313\n",
            "resetting env. episode 17.000000, reward total was -20.000000. running mean: -20.907150\n",
            "resetting env. episode 18.000000, reward total was -21.000000. running mean: -20.908078\n",
            "resetting env. episode 19.000000, reward total was -21.000000. running mean: -20.908997\n",
            "resetting env. episode 20.000000, reward total was -20.000000. running mean: -20.899907\n",
            "resetting env. episode 21.000000, reward total was -21.000000. running mean: -20.900908\n",
            "resetting env. episode 22.000000, reward total was -21.000000. running mean: -20.901899\n",
            "resetting env. episode 23.000000, reward total was -21.000000. running mean: -20.902880\n",
            "resetting env. episode 24.000000, reward total was -19.000000. running mean: -20.883851\n",
            "resetting env. episode 25.000000, reward total was -21.000000. running mean: -20.885013\n",
            "resetting env. episode 26.000000, reward total was -21.000000. running mean: -20.886163\n",
            "resetting env. episode 27.000000, reward total was -21.000000. running mean: -20.887301\n",
            "resetting env. episode 28.000000, reward total was -21.000000. running mean: -20.888428\n",
            "resetting env. episode 29.000000, reward total was -20.000000. running mean: -20.879544\n",
            "resetting env. episode 30.000000, reward total was -21.000000. running mean: -20.880748\n",
            "resetting env. episode 31.000000, reward total was -21.000000. running mean: -20.881941\n",
            "resetting env. episode 32.000000, reward total was -17.000000. running mean: -20.843121\n",
            "resetting env. episode 33.000000, reward total was -19.000000. running mean: -20.824690\n",
            "resetting env. episode 34.000000, reward total was -20.000000. running mean: -20.816443\n",
            "resetting env. episode 35.000000, reward total was -21.000000. running mean: -20.818279\n",
            "resetting env. episode 36.000000, reward total was -21.000000. running mean: -20.820096\n",
            "resetting env. episode 37.000000, reward total was -20.000000. running mean: -20.811895\n",
            "resetting env. episode 38.000000, reward total was -20.000000. running mean: -20.803776\n",
            "resetting env. episode 39.000000, reward total was -19.000000. running mean: -20.785738\n",
            "resetting env. episode 40.000000, reward total was -21.000000. running mean: -20.787881\n",
            "resetting env. episode 41.000000, reward total was -20.000000. running mean: -20.780002\n",
            "resetting env. episode 42.000000, reward total was -21.000000. running mean: -20.782202\n",
            "resetting env. episode 43.000000, reward total was -20.000000. running mean: -20.774380\n",
            "resetting env. episode 44.000000, reward total was -20.000000. running mean: -20.766636\n",
            "resetting env. episode 45.000000, reward total was -21.000000. running mean: -20.768970\n",
            "resetting env. episode 46.000000, reward total was -20.000000. running mean: -20.761280\n",
            "resetting env. episode 47.000000, reward total was -21.000000. running mean: -20.763668\n",
            "resetting env. episode 48.000000, reward total was -21.000000. running mean: -20.766031\n",
            "resetting env. episode 49.000000, reward total was -20.000000. running mean: -20.758371\n",
            "resetting env. episode 50.000000, reward total was -21.000000. running mean: -20.760787\n",
            "resetting env. episode 51.000000, reward total was -20.000000. running mean: -20.753179\n",
            "resetting env. episode 52.000000, reward total was -21.000000. running mean: -20.755647\n",
            "resetting env. episode 53.000000, reward total was -21.000000. running mean: -20.758091\n",
            "resetting env. episode 54.000000, reward total was -21.000000. running mean: -20.760510\n",
            "resetting env. episode 55.000000, reward total was -21.000000. running mean: -20.762905\n",
            "resetting env. episode 56.000000, reward total was -21.000000. running mean: -20.765276\n",
            "resetting env. episode 57.000000, reward total was -19.000000. running mean: -20.747623\n",
            "resetting env. episode 58.000000, reward total was -21.000000. running mean: -20.750147\n",
            "resetting env. episode 59.000000, reward total was -21.000000. running mean: -20.752645\n",
            "resetting env. episode 60.000000, reward total was -21.000000. running mean: -20.755119\n",
            "resetting env. episode 61.000000, reward total was -19.000000. running mean: -20.737568\n",
            "resetting env. episode 62.000000, reward total was -20.000000. running mean: -20.730192\n",
            "resetting env. episode 63.000000, reward total was -20.000000. running mean: -20.722890\n",
            "resetting env. episode 64.000000, reward total was -21.000000. running mean: -20.725661\n",
            "resetting env. episode 65.000000, reward total was -21.000000. running mean: -20.728404\n",
            "resetting env. episode 66.000000, reward total was -20.000000. running mean: -20.721120\n",
            "resetting env. episode 67.000000, reward total was -21.000000. running mean: -20.723909\n",
            "resetting env. episode 68.000000, reward total was -21.000000. running mean: -20.726670\n",
            "resetting env. episode 69.000000, reward total was -20.000000. running mean: -20.719403\n",
            "resetting env. episode 70.000000, reward total was -21.000000. running mean: -20.722209\n",
            "resetting env. episode 71.000000, reward total was -18.000000. running mean: -20.694987\n",
            "resetting env. episode 72.000000, reward total was -21.000000. running mean: -20.698037\n",
            "resetting env. episode 73.000000, reward total was -21.000000. running mean: -20.701057\n",
            "resetting env. episode 74.000000, reward total was -19.000000. running mean: -20.684046\n",
            "resetting env. episode 75.000000, reward total was -19.000000. running mean: -20.667206\n",
            "resetting env. episode 76.000000, reward total was -20.000000. running mean: -20.660534\n",
            "resetting env. episode 77.000000, reward total was -21.000000. running mean: -20.663929\n",
            "resetting env. episode 78.000000, reward total was -20.000000. running mean: -20.657289\n",
            "resetting env. episode 79.000000, reward total was -21.000000. running mean: -20.660716\n",
            "resetting env. episode 80.000000, reward total was -20.000000. running mean: -20.654109\n",
            "resetting env. episode 81.000000, reward total was -21.000000. running mean: -20.657568\n",
            "resetting env. episode 82.000000, reward total was -20.000000. running mean: -20.650992\n",
            "resetting env. episode 83.000000, reward total was -21.000000. running mean: -20.654483\n",
            "resetting env. episode 84.000000, reward total was -21.000000. running mean: -20.657938\n",
            "resetting env. episode 85.000000, reward total was -21.000000. running mean: -20.661358\n",
            "resetting env. episode 86.000000, reward total was -20.000000. running mean: -20.654745\n",
            "resetting env. episode 87.000000, reward total was -21.000000. running mean: -20.658197\n",
            "resetting env. episode 88.000000, reward total was -21.000000. running mean: -20.661615\n",
            "resetting env. episode 89.000000, reward total was -21.000000. running mean: -20.664999\n",
            "resetting env. episode 90.000000, reward total was -21.000000. running mean: -20.668349\n",
            "resetting env. episode 91.000000, reward total was -20.000000. running mean: -20.661666\n",
            "resetting env. episode 92.000000, reward total was -21.000000. running mean: -20.665049\n",
            "resetting env. episode 93.000000, reward total was -18.000000. running mean: -20.638399\n",
            "resetting env. episode 94.000000, reward total was -19.000000. running mean: -20.622015\n",
            "resetting env. episode 95.000000, reward total was -21.000000. running mean: -20.625794\n",
            "resetting env. episode 96.000000, reward total was -21.000000. running mean: -20.629536\n",
            "resetting env. episode 97.000000, reward total was -20.000000. running mean: -20.623241\n",
            "resetting env. episode 98.000000, reward total was -21.000000. running mean: -20.627009\n",
            "resetting env. episode 99.000000, reward total was -20.000000. running mean: -20.620739\n",
            "resetting env. episode 100.000000, reward total was -20.000000. running mean: -20.614531\n",
            "resetting env. episode 101.000000, reward total was -21.000000. running mean: -20.618386\n",
            "resetting env. episode 102.000000, reward total was -21.000000. running mean: -20.622202\n",
            "resetting env. episode 103.000000, reward total was -20.000000. running mean: -20.615980\n",
            "resetting env. episode 104.000000, reward total was -20.000000. running mean: -20.609820\n",
            "resetting env. episode 105.000000, reward total was -21.000000. running mean: -20.613722\n",
            "resetting env. episode 106.000000, reward total was -20.000000. running mean: -20.607585\n",
            "resetting env. episode 107.000000, reward total was -21.000000. running mean: -20.611509\n",
            "resetting env. episode 108.000000, reward total was -21.000000. running mean: -20.615394\n",
            "resetting env. episode 109.000000, reward total was -21.000000. running mean: -20.619240\n",
            "resetting env. episode 110.000000, reward total was -21.000000. running mean: -20.623048\n",
            "resetting env. episode 111.000000, reward total was -20.000000. running mean: -20.616817\n",
            "resetting env. episode 112.000000, reward total was -18.000000. running mean: -20.590649\n",
            "resetting env. episode 113.000000, reward total was -20.000000. running mean: -20.584742\n",
            "resetting env. episode 114.000000, reward total was -19.000000. running mean: -20.568895\n",
            "resetting env. episode 115.000000, reward total was -21.000000. running mean: -20.573206\n",
            "resetting env. episode 116.000000, reward total was -21.000000. running mean: -20.577474\n",
            "resetting env. episode 117.000000, reward total was -21.000000. running mean: -20.581699\n",
            "resetting env. episode 118.000000, reward total was -21.000000. running mean: -20.585882\n",
            "resetting env. episode 119.000000, reward total was -21.000000. running mean: -20.590023\n",
            "resetting env. episode 120.000000, reward total was -19.000000. running mean: -20.574123\n",
            "resetting env. episode 121.000000, reward total was -21.000000. running mean: -20.578382\n",
            "resetting env. episode 122.000000, reward total was -18.000000. running mean: -20.552598\n",
            "resetting env. episode 123.000000, reward total was -21.000000. running mean: -20.557072\n",
            "resetting env. episode 124.000000, reward total was -21.000000. running mean: -20.561501\n",
            "resetting env. episode 125.000000, reward total was -21.000000. running mean: -20.565886\n",
            "resetting env. episode 126.000000, reward total was -20.000000. running mean: -20.560228\n",
            "resetting env. episode 127.000000, reward total was -21.000000. running mean: -20.564625\n",
            "resetting env. episode 128.000000, reward total was -21.000000. running mean: -20.568979\n",
            "resetting env. episode 129.000000, reward total was -20.000000. running mean: -20.563289\n",
            "resetting env. episode 130.000000, reward total was -21.000000. running mean: -20.567656\n",
            "resetting env. episode 131.000000, reward total was -20.000000. running mean: -20.561980\n",
            "resetting env. episode 132.000000, reward total was -21.000000. running mean: -20.566360\n",
            "resetting env. episode 133.000000, reward total was -19.000000. running mean: -20.550696\n",
            "resetting env. episode 134.000000, reward total was -21.000000. running mean: -20.555189\n",
            "resetting env. episode 135.000000, reward total was -21.000000. running mean: -20.559638\n",
            "resetting env. episode 136.000000, reward total was -21.000000. running mean: -20.564041\n",
            "resetting env. episode 137.000000, reward total was -20.000000. running mean: -20.558401\n",
            "resetting env. episode 138.000000, reward total was -21.000000. running mean: -20.562817\n",
            "resetting env. episode 139.000000, reward total was -20.000000. running mean: -20.557189\n",
            "resetting env. episode 140.000000, reward total was -21.000000. running mean: -20.561617\n",
            "resetting env. episode 141.000000, reward total was -20.000000. running mean: -20.556001\n",
            "resetting env. episode 142.000000, reward total was -21.000000. running mean: -20.560441\n",
            "resetting env. episode 143.000000, reward total was -20.000000. running mean: -20.554836\n",
            "resetting env. episode 144.000000, reward total was -20.000000. running mean: -20.549288\n",
            "resetting env. episode 145.000000, reward total was -20.000000. running mean: -20.543795\n",
            "resetting env. episode 146.000000, reward total was -21.000000. running mean: -20.548357\n",
            "resetting env. episode 147.000000, reward total was -18.000000. running mean: -20.522873\n",
            "resetting env. episode 148.000000, reward total was -20.000000. running mean: -20.517645\n",
            "resetting env. episode 149.000000, reward total was -21.000000. running mean: -20.522468\n",
            "resetting env. episode 150.000000, reward total was -20.000000. running mean: -20.517243\n",
            "resetting env. episode 151.000000, reward total was -21.000000. running mean: -20.522071\n",
            "resetting env. episode 152.000000, reward total was -21.000000. running mean: -20.526850\n",
            "resetting env. episode 153.000000, reward total was -21.000000. running mean: -20.531582\n",
            "resetting env. episode 154.000000, reward total was -20.000000. running mean: -20.526266\n",
            "resetting env. episode 155.000000, reward total was -21.000000. running mean: -20.531003\n",
            "resetting env. episode 156.000000, reward total was -21.000000. running mean: -20.535693\n",
            "resetting env. episode 157.000000, reward total was -20.000000. running mean: -20.530336\n",
            "resetting env. episode 158.000000, reward total was -19.000000. running mean: -20.515033\n",
            "resetting env. episode 159.000000, reward total was -20.000000. running mean: -20.509883\n",
            "resetting env. episode 160.000000, reward total was -21.000000. running mean: -20.514784\n",
            "resetting env. episode 161.000000, reward total was -21.000000. running mean: -20.519636\n",
            "resetting env. episode 162.000000, reward total was -21.000000. running mean: -20.524440\n",
            "resetting env. episode 163.000000, reward total was -18.000000. running mean: -20.499195\n",
            "resetting env. episode 164.000000, reward total was -21.000000. running mean: -20.504203\n",
            "resetting env. episode 165.000000, reward total was -21.000000. running mean: -20.509161\n",
            "resetting env. episode 166.000000, reward total was -21.000000. running mean: -20.514070\n",
            "resetting env. episode 167.000000, reward total was -21.000000. running mean: -20.518929\n",
            "resetting env. episode 168.000000, reward total was -21.000000. running mean: -20.523740\n",
            "resetting env. episode 169.000000, reward total was -20.000000. running mean: -20.518502\n",
            "resetting env. episode 170.000000, reward total was -21.000000. running mean: -20.523317\n",
            "resetting env. episode 171.000000, reward total was -20.000000. running mean: -20.518084\n",
            "resetting env. episode 172.000000, reward total was -20.000000. running mean: -20.512903\n",
            "resetting env. episode 173.000000, reward total was -20.000000. running mean: -20.507774\n",
            "resetting env. episode 174.000000, reward total was -21.000000. running mean: -20.512696\n",
            "resetting env. episode 175.000000, reward total was -21.000000. running mean: -20.517570\n",
            "resetting env. episode 176.000000, reward total was -21.000000. running mean: -20.522394\n",
            "resetting env. episode 177.000000, reward total was -20.000000. running mean: -20.517170\n",
            "resetting env. episode 178.000000, reward total was -20.000000. running mean: -20.511998\n",
            "resetting env. episode 179.000000, reward total was -20.000000. running mean: -20.506878\n",
            "resetting env. episode 180.000000, reward total was -21.000000. running mean: -20.511809\n",
            "resetting env. episode 181.000000, reward total was -21.000000. running mean: -20.516691\n",
            "resetting env. episode 182.000000, reward total was -21.000000. running mean: -20.521524\n",
            "resetting env. episode 183.000000, reward total was -21.000000. running mean: -20.526309\n",
            "resetting env. episode 184.000000, reward total was -21.000000. running mean: -20.531046\n",
            "resetting env. episode 185.000000, reward total was -21.000000. running mean: -20.535736\n",
            "resetting env. episode 186.000000, reward total was -19.000000. running mean: -20.520378\n",
            "resetting env. episode 187.000000, reward total was -20.000000. running mean: -20.515174\n",
            "resetting env. episode 188.000000, reward total was -21.000000. running mean: -20.520023\n",
            "resetting env. episode 189.000000, reward total was -20.000000. running mean: -20.514823\n",
            "resetting env. episode 190.000000, reward total was -20.000000. running mean: -20.509674\n",
            "resetting env. episode 191.000000, reward total was -19.000000. running mean: -20.494578\n",
            "resetting env. episode 192.000000, reward total was -19.000000. running mean: -20.479632\n",
            "resetting env. episode 193.000000, reward total was -21.000000. running mean: -20.484835\n",
            "resetting env. episode 194.000000, reward total was -21.000000. running mean: -20.489987\n",
            "resetting env. episode 195.000000, reward total was -19.000000. running mean: -20.475087\n",
            "resetting env. episode 196.000000, reward total was -20.000000. running mean: -20.470336\n",
            "resetting env. episode 197.000000, reward total was -20.000000. running mean: -20.465633\n",
            "resetting env. episode 198.000000, reward total was -21.000000. running mean: -20.470977\n",
            "resetting env. episode 199.000000, reward total was -20.000000. running mean: -20.466267\n",
            "resetting env. episode 200.000000, reward total was -20.000000. running mean: -20.461604\n",
            "resetting env. episode 201.000000, reward total was -20.000000. running mean: -20.456988\n",
            "resetting env. episode 202.000000, reward total was -21.000000. running mean: -20.462418\n",
            "resetting env. episode 203.000000, reward total was -21.000000. running mean: -20.467794\n",
            "resetting env. episode 204.000000, reward total was -21.000000. running mean: -20.473116\n",
            "resetting env. episode 205.000000, reward total was -20.000000. running mean: -20.468385\n",
            "resetting env. episode 206.000000, reward total was -21.000000. running mean: -20.473701\n",
            "resetting env. episode 207.000000, reward total was -20.000000. running mean: -20.468964\n",
            "resetting env. episode 208.000000, reward total was -21.000000. running mean: -20.474275\n",
            "resetting env. episode 209.000000, reward total was -19.000000. running mean: -20.459532\n",
            "resetting env. episode 210.000000, reward total was -21.000000. running mean: -20.464936\n",
            "resetting env. episode 211.000000, reward total was -21.000000. running mean: -20.470287\n",
            "resetting env. episode 212.000000, reward total was -19.000000. running mean: -20.455584\n",
            "resetting env. episode 213.000000, reward total was -21.000000. running mean: -20.461028\n",
            "resetting env. episode 214.000000, reward total was -18.000000. running mean: -20.436418\n",
            "resetting env. episode 215.000000, reward total was -21.000000. running mean: -20.442054\n",
            "resetting env. episode 216.000000, reward total was -21.000000. running mean: -20.447633\n",
            "resetting env. episode 217.000000, reward total was -21.000000. running mean: -20.453157\n",
            "resetting env. episode 218.000000, reward total was -21.000000. running mean: -20.458625\n",
            "resetting env. episode 219.000000, reward total was -20.000000. running mean: -20.454039\n",
            "resetting env. episode 220.000000, reward total was -19.000000. running mean: -20.439499\n",
            "resetting env. episode 221.000000, reward total was -20.000000. running mean: -20.435104\n",
            "resetting env. episode 222.000000, reward total was -20.000000. running mean: -20.430753\n",
            "resetting env. episode 223.000000, reward total was -19.000000. running mean: -20.416445\n",
            "resetting env. episode 224.000000, reward total was -21.000000. running mean: -20.422281\n",
            "resetting env. episode 225.000000, reward total was -21.000000. running mean: -20.428058\n",
            "resetting env. episode 226.000000, reward total was -19.000000. running mean: -20.413777\n",
            "resetting env. episode 227.000000, reward total was -19.000000. running mean: -20.399640\n",
            "resetting env. episode 228.000000, reward total was -21.000000. running mean: -20.405643\n",
            "resetting env. episode 229.000000, reward total was -20.000000. running mean: -20.401587\n",
            "resetting env. episode 230.000000, reward total was -21.000000. running mean: -20.407571\n",
            "resetting env. episode 231.000000, reward total was -20.000000. running mean: -20.403495\n",
            "resetting env. episode 232.000000, reward total was -21.000000. running mean: -20.409460\n",
            "resetting env. episode 233.000000, reward total was -21.000000. running mean: -20.415366\n",
            "resetting env. episode 234.000000, reward total was -21.000000. running mean: -20.421212\n",
            "resetting env. episode 235.000000, reward total was -20.000000. running mean: -20.417000\n",
            "resetting env. episode 236.000000, reward total was -21.000000. running mean: -20.422830\n",
            "resetting env. episode 237.000000, reward total was -21.000000. running mean: -20.428602\n",
            "resetting env. episode 238.000000, reward total was -20.000000. running mean: -20.424316\n",
            "resetting env. episode 239.000000, reward total was -19.000000. running mean: -20.410072\n",
            "resetting env. episode 240.000000, reward total was -21.000000. running mean: -20.415972\n",
            "resetting env. episode 241.000000, reward total was -20.000000. running mean: -20.411812\n",
            "resetting env. episode 242.000000, reward total was -18.000000. running mean: -20.387694\n",
            "resetting env. episode 243.000000, reward total was -21.000000. running mean: -20.393817\n",
            "resetting env. episode 244.000000, reward total was -21.000000. running mean: -20.399879\n",
            "resetting env. episode 245.000000, reward total was -21.000000. running mean: -20.405880\n",
            "resetting env. episode 246.000000, reward total was -21.000000. running mean: -20.411821\n",
            "resetting env. episode 247.000000, reward total was -20.000000. running mean: -20.407703\n",
            "resetting env. episode 248.000000, reward total was -21.000000. running mean: -20.413626\n",
            "resetting env. episode 249.000000, reward total was -17.000000. running mean: -20.379490\n",
            "resetting env. episode 250.000000, reward total was -21.000000. running mean: -20.385695\n",
            "resetting env. episode 251.000000, reward total was -21.000000. running mean: -20.391838\n",
            "resetting env. episode 252.000000, reward total was -20.000000. running mean: -20.387919\n",
            "resetting env. episode 253.000000, reward total was -20.000000. running mean: -20.384040\n",
            "resetting env. episode 254.000000, reward total was -21.000000. running mean: -20.390200\n",
            "resetting env. episode 255.000000, reward total was -21.000000. running mean: -20.396298\n",
            "resetting env. episode 256.000000, reward total was -18.000000. running mean: -20.372335\n",
            "resetting env. episode 257.000000, reward total was -21.000000. running mean: -20.378612\n",
            "resetting env. episode 258.000000, reward total was -21.000000. running mean: -20.384825\n",
            "resetting env. episode 259.000000, reward total was -21.000000. running mean: -20.390977\n",
            "resetting env. episode 260.000000, reward total was -20.000000. running mean: -20.387067\n",
            "resetting env. episode 261.000000, reward total was -20.000000. running mean: -20.383197\n",
            "resetting env. episode 262.000000, reward total was -20.000000. running mean: -20.379365\n",
            "resetting env. episode 263.000000, reward total was -16.000000. running mean: -20.335571\n",
            "resetting env. episode 264.000000, reward total was -19.000000. running mean: -20.322215\n",
            "resetting env. episode 265.000000, reward total was -21.000000. running mean: -20.328993\n",
            "resetting env. episode 266.000000, reward total was -20.000000. running mean: -20.325703\n",
            "resetting env. episode 267.000000, reward total was -21.000000. running mean: -20.332446\n",
            "resetting env. episode 268.000000, reward total was -21.000000. running mean: -20.339122\n",
            "resetting env. episode 269.000000, reward total was -21.000000. running mean: -20.345731\n",
            "resetting env. episode 270.000000, reward total was -18.000000. running mean: -20.322273\n",
            "resetting env. episode 271.000000, reward total was -20.000000. running mean: -20.319051\n",
            "resetting env. episode 272.000000, reward total was -20.000000. running mean: -20.315860\n",
            "resetting env. episode 273.000000, reward total was -20.000000. running mean: -20.312701\n",
            "resetting env. episode 274.000000, reward total was -20.000000. running mean: -20.309574\n",
            "resetting env. episode 275.000000, reward total was -21.000000. running mean: -20.316479\n",
            "resetting env. episode 276.000000, reward total was -20.000000. running mean: -20.313314\n",
            "resetting env. episode 277.000000, reward total was -19.000000. running mean: -20.300181\n",
            "resetting env. episode 278.000000, reward total was -21.000000. running mean: -20.307179\n",
            "resetting env. episode 279.000000, reward total was -21.000000. running mean: -20.314107\n",
            "resetting env. episode 280.000000, reward total was -19.000000. running mean: -20.300966\n",
            "resetting env. episode 281.000000, reward total was -20.000000. running mean: -20.297956\n",
            "resetting env. episode 282.000000, reward total was -21.000000. running mean: -20.304977\n",
            "resetting env. episode 283.000000, reward total was -19.000000. running mean: -20.291927\n",
            "resetting env. episode 284.000000, reward total was -20.000000. running mean: -20.289008\n",
            "resetting env. episode 285.000000, reward total was -21.000000. running mean: -20.296118\n",
            "resetting env. episode 286.000000, reward total was -21.000000. running mean: -20.303157\n",
            "resetting env. episode 287.000000, reward total was -21.000000. running mean: -20.310125\n",
            "resetting env. episode 288.000000, reward total was -21.000000. running mean: -20.317024\n",
            "resetting env. episode 289.000000, reward total was -19.000000. running mean: -20.303854\n",
            "resetting env. episode 290.000000, reward total was -19.000000. running mean: -20.290815\n",
            "resetting env. episode 291.000000, reward total was -21.000000. running mean: -20.297907\n",
            "resetting env. episode 292.000000, reward total was -19.000000. running mean: -20.284928\n",
            "resetting env. episode 293.000000, reward total was -21.000000. running mean: -20.292078\n",
            "resetting env. episode 294.000000, reward total was -21.000000. running mean: -20.299158\n",
            "resetting env. episode 295.000000, reward total was -20.000000. running mean: -20.296166\n",
            "resetting env. episode 296.000000, reward total was -19.000000. running mean: -20.283204\n",
            "resetting env. episode 297.000000, reward total was -19.000000. running mean: -20.270372\n",
            "resetting env. episode 298.000000, reward total was -20.000000. running mean: -20.267669\n",
            "resetting env. episode 299.000000, reward total was -20.000000. running mean: -20.264992\n",
            "resetting env. episode 300.000000, reward total was -20.000000. running mean: -20.262342\n",
            "resetting env. episode 301.000000, reward total was -20.000000. running mean: -20.259719\n",
            "resetting env. episode 302.000000, reward total was -21.000000. running mean: -20.267121\n",
            "resetting env. episode 303.000000, reward total was -21.000000. running mean: -20.274450\n",
            "resetting env. episode 304.000000, reward total was -21.000000. running mean: -20.281706\n",
            "resetting env. episode 305.000000, reward total was -21.000000. running mean: -20.288889\n",
            "resetting env. episode 306.000000, reward total was -21.000000. running mean: -20.296000\n",
            "resetting env. episode 307.000000, reward total was -19.000000. running mean: -20.283040\n",
            "resetting env. episode 308.000000, reward total was -21.000000. running mean: -20.290209\n",
            "resetting env. episode 309.000000, reward total was -21.000000. running mean: -20.297307\n",
            "resetting env. episode 310.000000, reward total was -21.000000. running mean: -20.304334\n",
            "resetting env. episode 311.000000, reward total was -20.000000. running mean: -20.301291\n",
            "resetting env. episode 312.000000, reward total was -21.000000. running mean: -20.308278\n",
            "resetting env. episode 313.000000, reward total was -19.000000. running mean: -20.295195\n",
            "resetting env. episode 314.000000, reward total was -21.000000. running mean: -20.302243\n",
            "resetting env. episode 315.000000, reward total was -20.000000. running mean: -20.299221\n",
            "resetting env. episode 316.000000, reward total was -20.000000. running mean: -20.296229\n",
            "resetting env. episode 317.000000, reward total was -21.000000. running mean: -20.303266\n",
            "resetting env. episode 318.000000, reward total was -21.000000. running mean: -20.310234\n",
            "resetting env. episode 319.000000, reward total was -20.000000. running mean: -20.307131\n",
            "resetting env. episode 320.000000, reward total was -20.000000. running mean: -20.304060\n",
            "resetting env. episode 321.000000, reward total was -21.000000. running mean: -20.311019\n",
            "resetting env. episode 322.000000, reward total was -21.000000. running mean: -20.317909\n",
            "resetting env. episode 323.000000, reward total was -20.000000. running mean: -20.314730\n",
            "resetting env. episode 324.000000, reward total was -20.000000. running mean: -20.311583\n",
            "resetting env. episode 325.000000, reward total was -21.000000. running mean: -20.318467\n",
            "resetting env. episode 326.000000, reward total was -19.000000. running mean: -20.305282\n",
            "resetting env. episode 327.000000, reward total was -20.000000. running mean: -20.302230\n",
            "resetting env. episode 328.000000, reward total was -21.000000. running mean: -20.309207\n",
            "resetting env. episode 329.000000, reward total was -21.000000. running mean: -20.316115\n",
            "resetting env. episode 330.000000, reward total was -19.000000. running mean: -20.302954\n",
            "resetting env. episode 331.000000, reward total was -21.000000. running mean: -20.309924\n",
            "resetting env. episode 332.000000, reward total was -20.000000. running mean: -20.306825\n",
            "resetting env. episode 333.000000, reward total was -21.000000. running mean: -20.313757\n",
            "resetting env. episode 334.000000, reward total was -20.000000. running mean: -20.310619\n",
            "resetting env. episode 335.000000, reward total was -21.000000. running mean: -20.317513\n",
            "resetting env. episode 336.000000, reward total was -21.000000. running mean: -20.324338\n",
            "resetting env. episode 337.000000, reward total was -21.000000. running mean: -20.331095\n",
            "resetting env. episode 338.000000, reward total was -20.000000. running mean: -20.327784\n",
            "resetting env. episode 339.000000, reward total was -21.000000. running mean: -20.334506\n",
            "resetting env. episode 340.000000, reward total was -18.000000. running mean: -20.311161\n",
            "resetting env. episode 341.000000, reward total was -20.000000. running mean: -20.308049\n",
            "resetting env. episode 342.000000, reward total was -21.000000. running mean: -20.314969\n",
            "resetting env. episode 343.000000, reward total was -20.000000. running mean: -20.311819\n",
            "resetting env. episode 344.000000, reward total was -21.000000. running mean: -20.318701\n",
            "resetting env. episode 345.000000, reward total was -21.000000. running mean: -20.325514\n",
            "resetting env. episode 346.000000, reward total was -21.000000. running mean: -20.332259\n",
            "resetting env. episode 347.000000, reward total was -18.000000. running mean: -20.308936\n",
            "resetting env. episode 348.000000, reward total was -19.000000. running mean: -20.295847\n",
            "resetting env. episode 349.000000, reward total was -19.000000. running mean: -20.282888\n",
            "resetting env. episode 350.000000, reward total was -21.000000. running mean: -20.290059\n",
            "resetting env. episode 351.000000, reward total was -20.000000. running mean: -20.287159\n",
            "resetting env. episode 352.000000, reward total was -21.000000. running mean: -20.294287\n",
            "resetting env. episode 353.000000, reward total was -20.000000. running mean: -20.291344\n",
            "resetting env. episode 354.000000, reward total was -21.000000. running mean: -20.298431\n",
            "resetting env. episode 355.000000, reward total was -20.000000. running mean: -20.295447\n",
            "resetting env. episode 356.000000, reward total was -21.000000. running mean: -20.302492\n",
            "resetting env. episode 357.000000, reward total was -21.000000. running mean: -20.309467\n",
            "resetting env. episode 358.000000, reward total was -21.000000. running mean: -20.316373\n",
            "resetting env. episode 359.000000, reward total was -20.000000. running mean: -20.313209\n",
            "resetting env. episode 360.000000, reward total was -20.000000. running mean: -20.310077\n",
            "resetting env. episode 361.000000, reward total was -20.000000. running mean: -20.306976\n",
            "resetting env. episode 362.000000, reward total was -20.000000. running mean: -20.303906\n",
            "resetting env. episode 363.000000, reward total was -18.000000. running mean: -20.280867\n",
            "resetting env. episode 364.000000, reward total was -20.000000. running mean: -20.278058\n",
            "resetting env. episode 365.000000, reward total was -20.000000. running mean: -20.275278\n",
            "resetting env. episode 366.000000, reward total was -17.000000. running mean: -20.242525\n",
            "resetting env. episode 367.000000, reward total was -21.000000. running mean: -20.250100\n",
            "resetting env. episode 368.000000, reward total was -21.000000. running mean: -20.257599\n",
            "resetting env. episode 369.000000, reward total was -20.000000. running mean: -20.255023\n",
            "resetting env. episode 370.000000, reward total was -21.000000. running mean: -20.262473\n",
            "resetting env. episode 371.000000, reward total was -21.000000. running mean: -20.269848\n",
            "resetting env. episode 372.000000, reward total was -21.000000. running mean: -20.277149\n",
            "resetting env. episode 373.000000, reward total was -21.000000. running mean: -20.284378\n",
            "resetting env. episode 374.000000, reward total was -19.000000. running mean: -20.271534\n",
            "resetting env. episode 375.000000, reward total was -20.000000. running mean: -20.268819\n",
            "resetting env. episode 376.000000, reward total was -20.000000. running mean: -20.266131\n",
            "resetting env. episode 377.000000, reward total was -19.000000. running mean: -20.253469\n",
            "resetting env. episode 378.000000, reward total was -20.000000. running mean: -20.250935\n",
            "resetting env. episode 379.000000, reward total was -21.000000. running mean: -20.258425\n",
            "resetting env. episode 380.000000, reward total was -21.000000. running mean: -20.265841\n",
            "resetting env. episode 381.000000, reward total was -21.000000. running mean: -20.273183\n",
            "resetting env. episode 382.000000, reward total was -21.000000. running mean: -20.280451\n",
            "resetting env. episode 383.000000, reward total was -20.000000. running mean: -20.277646\n",
            "resetting env. episode 384.000000, reward total was -21.000000. running mean: -20.284870\n",
            "resetting env. episode 385.000000, reward total was -20.000000. running mean: -20.282021\n",
            "resetting env. episode 386.000000, reward total was -18.000000. running mean: -20.259201\n",
            "resetting env. episode 387.000000, reward total was -21.000000. running mean: -20.266609\n",
            "resetting env. episode 388.000000, reward total was -18.000000. running mean: -20.243943\n",
            "resetting env. episode 389.000000, reward total was -21.000000. running mean: -20.251503\n",
            "resetting env. episode 390.000000, reward total was -21.000000. running mean: -20.258988\n",
            "resetting env. episode 391.000000, reward total was -21.000000. running mean: -20.266398\n",
            "resetting env. episode 392.000000, reward total was -21.000000. running mean: -20.273734\n",
            "resetting env. episode 393.000000, reward total was -20.000000. running mean: -20.270997\n",
            "resetting env. episode 394.000000, reward total was -21.000000. running mean: -20.278287\n",
            "resetting env. episode 395.000000, reward total was -19.000000. running mean: -20.265504\n",
            "resetting env. episode 396.000000, reward total was -20.000000. running mean: -20.262849\n",
            "resetting env. episode 397.000000, reward total was -20.000000. running mean: -20.260221\n",
            "resetting env. episode 398.000000, reward total was -21.000000. running mean: -20.267619\n",
            "resetting env. episode 399.000000, reward total was -21.000000. running mean: -20.274942\n",
            "resetting env. episode 400.000000, reward total was -20.000000. running mean: -20.272193\n",
            "resetting env. episode 401.000000, reward total was -19.000000. running mean: -20.259471\n",
            "resetting env. episode 402.000000, reward total was -20.000000. running mean: -20.256876\n",
            "resetting env. episode 403.000000, reward total was -20.000000. running mean: -20.254308\n",
            "resetting env. episode 404.000000, reward total was -21.000000. running mean: -20.261764\n",
            "resetting env. episode 405.000000, reward total was -20.000000. running mean: -20.259147\n",
            "resetting env. episode 406.000000, reward total was -20.000000. running mean: -20.256555\n",
            "resetting env. episode 407.000000, reward total was -19.000000. running mean: -20.243990\n",
            "resetting env. episode 408.000000, reward total was -21.000000. running mean: -20.251550\n",
            "resetting env. episode 409.000000, reward total was -21.000000. running mean: -20.259034\n",
            "resetting env. episode 410.000000, reward total was -21.000000. running mean: -20.266444\n",
            "resetting env. episode 411.000000, reward total was -21.000000. running mean: -20.273780\n",
            "resetting env. episode 412.000000, reward total was -20.000000. running mean: -20.271042\n",
            "resetting env. episode 413.000000, reward total was -18.000000. running mean: -20.248331\n",
            "resetting env. episode 414.000000, reward total was -21.000000. running mean: -20.255848\n",
            "resetting env. episode 415.000000, reward total was -21.000000. running mean: -20.263290\n",
            "resetting env. episode 416.000000, reward total was -21.000000. running mean: -20.270657\n",
            "resetting env. episode 417.000000, reward total was -20.000000. running mean: -20.267950\n",
            "resetting env. episode 418.000000, reward total was -21.000000. running mean: -20.275271\n",
            "resetting env. episode 419.000000, reward total was -19.000000. running mean: -20.262518\n",
            "resetting env. episode 420.000000, reward total was -20.000000. running mean: -20.259893\n",
            "resetting env. episode 421.000000, reward total was -21.000000. running mean: -20.267294\n",
            "resetting env. episode 422.000000, reward total was -20.000000. running mean: -20.264621\n",
            "resetting env. episode 423.000000, reward total was -20.000000. running mean: -20.261975\n",
            "resetting env. episode 424.000000, reward total was -19.000000. running mean: -20.249355\n",
            "resetting env. episode 425.000000, reward total was -21.000000. running mean: -20.256861\n",
            "resetting env. episode 426.000000, reward total was -20.000000. running mean: -20.254293\n",
            "resetting env. episode 427.000000, reward total was -20.000000. running mean: -20.251750\n",
            "resetting env. episode 428.000000, reward total was -19.000000. running mean: -20.239232\n",
            "resetting env. episode 429.000000, reward total was -20.000000. running mean: -20.236840\n",
            "resetting env. episode 430.000000, reward total was -21.000000. running mean: -20.244472\n",
            "resetting env. episode 431.000000, reward total was -21.000000. running mean: -20.252027\n",
            "resetting env. episode 432.000000, reward total was -21.000000. running mean: -20.259507\n",
            "resetting env. episode 433.000000, reward total was -21.000000. running mean: -20.266912\n",
            "resetting env. episode 434.000000, reward total was -21.000000. running mean: -20.274242\n",
            "resetting env. episode 435.000000, reward total was -21.000000. running mean: -20.281500\n",
            "resetting env. episode 436.000000, reward total was -21.000000. running mean: -20.288685\n",
            "resetting env. episode 437.000000, reward total was -21.000000. running mean: -20.295798\n",
            "resetting env. episode 438.000000, reward total was -20.000000. running mean: -20.292840\n",
            "resetting env. episode 439.000000, reward total was -20.000000. running mean: -20.289912\n",
            "resetting env. episode 440.000000, reward total was -20.000000. running mean: -20.287013\n",
            "resetting env. episode 441.000000, reward total was -20.000000. running mean: -20.284143\n",
            "resetting env. episode 442.000000, reward total was -20.000000. running mean: -20.281301\n",
            "resetting env. episode 443.000000, reward total was -21.000000. running mean: -20.288488\n",
            "resetting env. episode 444.000000, reward total was -20.000000. running mean: -20.285603\n",
            "resetting env. episode 445.000000, reward total was -21.000000. running mean: -20.292747\n",
            "resetting env. episode 446.000000, reward total was -20.000000. running mean: -20.289820\n",
            "resetting env. episode 447.000000, reward total was -19.000000. running mean: -20.276922\n",
            "resetting env. episode 448.000000, reward total was -20.000000. running mean: -20.274152\n",
            "resetting env. episode 449.000000, reward total was -21.000000. running mean: -20.281411\n",
            "resetting env. episode 450.000000, reward total was -21.000000. running mean: -20.288597\n",
            "resetting env. episode 451.000000, reward total was -20.000000. running mean: -20.285711\n",
            "resetting env. episode 452.000000, reward total was -20.000000. running mean: -20.282854\n",
            "resetting env. episode 453.000000, reward total was -21.000000. running mean: -20.290025\n",
            "resetting env. episode 454.000000, reward total was -21.000000. running mean: -20.297125\n",
            "resetting env. episode 455.000000, reward total was -21.000000. running mean: -20.304154\n",
            "resetting env. episode 456.000000, reward total was -21.000000. running mean: -20.311112\n",
            "resetting env. episode 457.000000, reward total was -21.000000. running mean: -20.318001\n",
            "resetting env. episode 458.000000, reward total was -20.000000. running mean: -20.314821\n",
            "resetting env. episode 459.000000, reward total was -18.000000. running mean: -20.291673\n",
            "resetting env. episode 460.000000, reward total was -21.000000. running mean: -20.298756\n",
            "resetting env. episode 461.000000, reward total was -19.000000. running mean: -20.285768\n",
            "resetting env. episode 462.000000, reward total was -21.000000. running mean: -20.292911\n",
            "resetting env. episode 463.000000, reward total was -21.000000. running mean: -20.299982\n",
            "resetting env. episode 464.000000, reward total was -21.000000. running mean: -20.306982\n",
            "resetting env. episode 465.000000, reward total was -21.000000. running mean: -20.313912\n",
            "resetting env. episode 466.000000, reward total was -21.000000. running mean: -20.320773\n",
            "resetting env. episode 467.000000, reward total was -19.000000. running mean: -20.307565\n",
            "resetting env. episode 468.000000, reward total was -18.000000. running mean: -20.284489\n",
            "resetting env. episode 469.000000, reward total was -20.000000. running mean: -20.281645\n",
            "resetting env. episode 470.000000, reward total was -21.000000. running mean: -20.288828\n",
            "resetting env. episode 471.000000, reward total was -18.000000. running mean: -20.265940\n",
            "resetting env. episode 472.000000, reward total was -18.000000. running mean: -20.243280\n",
            "resetting env. episode 473.000000, reward total was -20.000000. running mean: -20.240848\n",
            "resetting env. episode 474.000000, reward total was -20.000000. running mean: -20.238439\n",
            "resetting env. episode 475.000000, reward total was -19.000000. running mean: -20.226055\n",
            "resetting env. episode 476.000000, reward total was -20.000000. running mean: -20.223794\n",
            "resetting env. episode 477.000000, reward total was -20.000000. running mean: -20.221556\n",
            "resetting env. episode 478.000000, reward total was -21.000000. running mean: -20.229341\n",
            "resetting env. episode 479.000000, reward total was -18.000000. running mean: -20.207047\n",
            "resetting env. episode 480.000000, reward total was -20.000000. running mean: -20.204977\n",
            "resetting env. episode 481.000000, reward total was -20.000000. running mean: -20.202927\n",
            "resetting env. episode 482.000000, reward total was -18.000000. running mean: -20.180898\n",
            "resetting env. episode 483.000000, reward total was -21.000000. running mean: -20.189089\n",
            "resetting env. episode 484.000000, reward total was -19.000000. running mean: -20.177198\n",
            "resetting env. episode 485.000000, reward total was -19.000000. running mean: -20.165426\n",
            "resetting env. episode 486.000000, reward total was -19.000000. running mean: -20.153772\n",
            "resetting env. episode 487.000000, reward total was -21.000000. running mean: -20.162234\n",
            "resetting env. episode 488.000000, reward total was -20.000000. running mean: -20.160612\n",
            "resetting env. episode 489.000000, reward total was -20.000000. running mean: -20.159006\n",
            "resetting env. episode 490.000000, reward total was -21.000000. running mean: -20.167415\n",
            "resetting env. episode 491.000000, reward total was -21.000000. running mean: -20.175741\n",
            "resetting env. episode 492.000000, reward total was -21.000000. running mean: -20.183984\n",
            "resetting env. episode 493.000000, reward total was -20.000000. running mean: -20.182144\n",
            "resetting env. episode 494.000000, reward total was -19.000000. running mean: -20.170323\n",
            "resetting env. episode 495.000000, reward total was -21.000000. running mean: -20.178619\n",
            "resetting env. episode 496.000000, reward total was -20.000000. running mean: -20.176833\n",
            "resetting env. episode 497.000000, reward total was -21.000000. running mean: -20.185065\n",
            "resetting env. episode 498.000000, reward total was -21.000000. running mean: -20.193214\n",
            "resetting env. episode 499.000000, reward total was -20.000000. running mean: -20.191282\n",
            "resetting env. episode 500.000000, reward total was -21.000000. running mean: -20.199369\n",
            "resetting env. episode 501.000000, reward total was -19.000000. running mean: -20.187376\n",
            "resetting env. episode 502.000000, reward total was -20.000000. running mean: -20.185502\n",
            "resetting env. episode 503.000000, reward total was -20.000000. running mean: -20.183647\n",
            "resetting env. episode 504.000000, reward total was -20.000000. running mean: -20.181810\n",
            "resetting env. episode 505.000000, reward total was -21.000000. running mean: -20.189992\n",
            "resetting env. episode 506.000000, reward total was -21.000000. running mean: -20.198092\n",
            "resetting env. episode 507.000000, reward total was -21.000000. running mean: -20.206111\n",
            "resetting env. episode 508.000000, reward total was -20.000000. running mean: -20.204050\n",
            "resetting env. episode 509.000000, reward total was -21.000000. running mean: -20.212010\n",
            "resetting env. episode 510.000000, reward total was -21.000000. running mean: -20.219890\n",
            "resetting env. episode 511.000000, reward total was -21.000000. running mean: -20.227691\n",
            "resetting env. episode 512.000000, reward total was -21.000000. running mean: -20.235414\n",
            "resetting env. episode 513.000000, reward total was -19.000000. running mean: -20.223060\n",
            "resetting env. episode 514.000000, reward total was -21.000000. running mean: -20.230829\n",
            "resetting env. episode 515.000000, reward total was -20.000000. running mean: -20.228521\n",
            "resetting env. episode 516.000000, reward total was -20.000000. running mean: -20.226236\n",
            "resetting env. episode 517.000000, reward total was -21.000000. running mean: -20.233973\n",
            "resetting env. episode 518.000000, reward total was -21.000000. running mean: -20.241634\n",
            "resetting env. episode 519.000000, reward total was -19.000000. running mean: -20.229217\n",
            "resetting env. episode 520.000000, reward total was -21.000000. running mean: -20.236925\n",
            "resetting env. episode 521.000000, reward total was -19.000000. running mean: -20.224556\n",
            "resetting env. episode 522.000000, reward total was -21.000000. running mean: -20.232310\n",
            "resetting env. episode 523.000000, reward total was -21.000000. running mean: -20.239987\n",
            "resetting env. episode 524.000000, reward total was -21.000000. running mean: -20.247587\n",
            "resetting env. episode 525.000000, reward total was -20.000000. running mean: -20.245111\n",
            "resetting env. episode 526.000000, reward total was -21.000000. running mean: -20.252660\n",
            "resetting env. episode 527.000000, reward total was -21.000000. running mean: -20.260134\n",
            "resetting env. episode 528.000000, reward total was -21.000000. running mean: -20.267532\n",
            "resetting env. episode 529.000000, reward total was -19.000000. running mean: -20.254857\n",
            "resetting env. episode 530.000000, reward total was -18.000000. running mean: -20.232308\n",
            "resetting env. episode 531.000000, reward total was -21.000000. running mean: -20.239985\n",
            "resetting env. episode 532.000000, reward total was -21.000000. running mean: -20.247586\n",
            "resetting env. episode 533.000000, reward total was -19.000000. running mean: -20.235110\n",
            "resetting env. episode 534.000000, reward total was -18.000000. running mean: -20.212759\n",
            "resetting env. episode 535.000000, reward total was -21.000000. running mean: -20.220631\n",
            "resetting env. episode 536.000000, reward total was -19.000000. running mean: -20.208425\n",
            "resetting env. episode 537.000000, reward total was -18.000000. running mean: -20.186340\n",
            "resetting env. episode 538.000000, reward total was -21.000000. running mean: -20.194477\n",
            "resetting env. episode 539.000000, reward total was -21.000000. running mean: -20.202532\n",
            "resetting env. episode 540.000000, reward total was -19.000000. running mean: -20.190507\n",
            "resetting env. episode 541.000000, reward total was -21.000000. running mean: -20.198602\n",
            "resetting env. episode 542.000000, reward total was -18.000000. running mean: -20.176616\n",
            "resetting env. episode 543.000000, reward total was -18.000000. running mean: -20.154850\n",
            "resetting env. episode 544.000000, reward total was -20.000000. running mean: -20.153301\n",
            "resetting env. episode 545.000000, reward total was -19.000000. running mean: -20.141768\n",
            "resetting env. episode 546.000000, reward total was -21.000000. running mean: -20.150350\n",
            "resetting env. episode 547.000000, reward total was -21.000000. running mean: -20.158847\n",
            "resetting env. episode 548.000000, reward total was -20.000000. running mean: -20.157259\n",
            "resetting env. episode 549.000000, reward total was -21.000000. running mean: -20.165686\n",
            "resetting env. episode 550.000000, reward total was -21.000000. running mean: -20.174029\n",
            "resetting env. episode 551.000000, reward total was -19.000000. running mean: -20.162289\n",
            "resetting env. episode 552.000000, reward total was -20.000000. running mean: -20.160666\n",
            "resetting env. episode 553.000000, reward total was -19.000000. running mean: -20.149059\n",
            "resetting env. episode 554.000000, reward total was -21.000000. running mean: -20.157569\n",
            "resetting env. episode 555.000000, reward total was -18.000000. running mean: -20.135993\n",
            "resetting env. episode 556.000000, reward total was -19.000000. running mean: -20.124633\n",
            "resetting env. episode 557.000000, reward total was -18.000000. running mean: -20.103387\n",
            "resetting env. episode 558.000000, reward total was -19.000000. running mean: -20.092353\n",
            "resetting env. episode 559.000000, reward total was -19.000000. running mean: -20.081429\n",
            "resetting env. episode 560.000000, reward total was -17.000000. running mean: -20.050615\n",
            "resetting env. episode 561.000000, reward total was -21.000000. running mean: -20.060109\n",
            "resetting env. episode 562.000000, reward total was -21.000000. running mean: -20.069508\n",
            "resetting env. episode 563.000000, reward total was -21.000000. running mean: -20.078813\n",
            "resetting env. episode 564.000000, reward total was -21.000000. running mean: -20.088025\n",
            "resetting env. episode 565.000000, reward total was -19.000000. running mean: -20.077144\n",
            "resetting env. episode 566.000000, reward total was -21.000000. running mean: -20.086373\n",
            "resetting env. episode 567.000000, reward total was -21.000000. running mean: -20.095509\n",
            "resetting env. episode 568.000000, reward total was -21.000000. running mean: -20.104554\n",
            "resetting env. episode 569.000000, reward total was -20.000000. running mean: -20.103509\n",
            "resetting env. episode 570.000000, reward total was -21.000000. running mean: -20.112473\n",
            "resetting env. episode 571.000000, reward total was -19.000000. running mean: -20.101349\n",
            "resetting env. episode 572.000000, reward total was -19.000000. running mean: -20.090335\n",
            "resetting env. episode 573.000000, reward total was -21.000000. running mean: -20.099432\n",
            "resetting env. episode 574.000000, reward total was -19.000000. running mean: -20.088438\n",
            "resetting env. episode 575.000000, reward total was -21.000000. running mean: -20.097553\n",
            "resetting env. episode 576.000000, reward total was -21.000000. running mean: -20.106578\n",
            "resetting env. episode 577.000000, reward total was -15.000000. running mean: -20.055512\n",
            "resetting env. episode 578.000000, reward total was -20.000000. running mean: -20.054957\n",
            "resetting env. episode 579.000000, reward total was -21.000000. running mean: -20.064407\n",
            "resetting env. episode 580.000000, reward total was -20.000000. running mean: -20.063763\n",
            "resetting env. episode 581.000000, reward total was -21.000000. running mean: -20.073125\n",
            "resetting env. episode 582.000000, reward total was -20.000000. running mean: -20.072394\n",
            "resetting env. episode 583.000000, reward total was -19.000000. running mean: -20.061670\n",
            "resetting env. episode 584.000000, reward total was -19.000000. running mean: -20.051054\n",
            "resetting env. episode 585.000000, reward total was -20.000000. running mean: -20.050543\n",
            "resetting env. episode 586.000000, reward total was -21.000000. running mean: -20.060038\n",
            "resetting env. episode 587.000000, reward total was -20.000000. running mean: -20.059437\n",
            "resetting env. episode 588.000000, reward total was -20.000000. running mean: -20.058843\n",
            "resetting env. episode 589.000000, reward total was -21.000000. running mean: -20.068254\n",
            "resetting env. episode 590.000000, reward total was -21.000000. running mean: -20.077572\n",
            "resetting env. episode 591.000000, reward total was -19.000000. running mean: -20.066796\n",
            "resetting env. episode 592.000000, reward total was -19.000000. running mean: -20.056128\n",
            "resetting env. episode 593.000000, reward total was -20.000000. running mean: -20.055567\n",
            "resetting env. episode 594.000000, reward total was -21.000000. running mean: -20.065011\n",
            "resetting env. episode 595.000000, reward total was -21.000000. running mean: -20.074361\n",
            "resetting env. episode 596.000000, reward total was -20.000000. running mean: -20.073618\n",
            "resetting env. episode 597.000000, reward total was -20.000000. running mean: -20.072881\n",
            "resetting env. episode 598.000000, reward total was -21.000000. running mean: -20.082153\n",
            "resetting env. episode 599.000000, reward total was -20.000000. running mean: -20.081331\n",
            "resetting env. episode 600.000000, reward total was -21.000000. running mean: -20.090518\n",
            "resetting env. episode 601.000000, reward total was -19.000000. running mean: -20.079613\n",
            "resetting env. episode 602.000000, reward total was -21.000000. running mean: -20.088816\n",
            "resetting env. episode 603.000000, reward total was -19.000000. running mean: -20.077928\n",
            "resetting env. episode 604.000000, reward total was -20.000000. running mean: -20.077149\n",
            "resetting env. episode 605.000000, reward total was -19.000000. running mean: -20.066377\n",
            "resetting env. episode 606.000000, reward total was -21.000000. running mean: -20.075714\n",
            "resetting env. episode 607.000000, reward total was -21.000000. running mean: -20.084957\n",
            "resetting env. episode 608.000000, reward total was -21.000000. running mean: -20.094107\n",
            "resetting env. episode 609.000000, reward total was -20.000000. running mean: -20.093166\n",
            "resetting env. episode 610.000000, reward total was -21.000000. running mean: -20.102234\n",
            "resetting env. episode 611.000000, reward total was -21.000000. running mean: -20.111212\n",
            "resetting env. episode 612.000000, reward total was -21.000000. running mean: -20.120100\n",
            "resetting env. episode 613.000000, reward total was -21.000000. running mean: -20.128899\n",
            "resetting env. episode 614.000000, reward total was -21.000000. running mean: -20.137610\n",
            "resetting env. episode 615.000000, reward total was -21.000000. running mean: -20.146234\n",
            "resetting env. episode 616.000000, reward total was -21.000000. running mean: -20.154771\n",
            "resetting env. episode 617.000000, reward total was -19.000000. running mean: -20.143224\n",
            "resetting env. episode 618.000000, reward total was -19.000000. running mean: -20.131791\n",
            "resetting env. episode 619.000000, reward total was -21.000000. running mean: -20.140474\n",
            "resetting env. episode 620.000000, reward total was -21.000000. running mean: -20.149069\n",
            "resetting env. episode 621.000000, reward total was -21.000000. running mean: -20.157578\n",
            "resetting env. episode 622.000000, reward total was -21.000000. running mean: -20.166002\n",
            "resetting env. episode 623.000000, reward total was -21.000000. running mean: -20.174342\n",
            "resetting env. episode 624.000000, reward total was -21.000000. running mean: -20.182599\n",
            "resetting env. episode 625.000000, reward total was -19.000000. running mean: -20.170773\n",
            "resetting env. episode 626.000000, reward total was -21.000000. running mean: -20.179065\n",
            "resetting env. episode 627.000000, reward total was -19.000000. running mean: -20.167274\n",
            "resetting env. episode 628.000000, reward total was -20.000000. running mean: -20.165602\n",
            "resetting env. episode 629.000000, reward total was -20.000000. running mean: -20.163946\n",
            "resetting env. episode 630.000000, reward total was -20.000000. running mean: -20.162306\n",
            "resetting env. episode 631.000000, reward total was -21.000000. running mean: -20.170683\n",
            "resetting env. episode 632.000000, reward total was -19.000000. running mean: -20.158976\n",
            "resetting env. episode 633.000000, reward total was -21.000000. running mean: -20.167387\n",
            "resetting env. episode 634.000000, reward total was -20.000000. running mean: -20.165713\n",
            "resetting env. episode 635.000000, reward total was -18.000000. running mean: -20.144056\n",
            "resetting env. episode 636.000000, reward total was -20.000000. running mean: -20.142615\n",
            "resetting env. episode 637.000000, reward total was -21.000000. running mean: -20.151189\n",
            "resetting env. episode 638.000000, reward total was -19.000000. running mean: -20.139677\n",
            "resetting env. episode 639.000000, reward total was -21.000000. running mean: -20.148280\n",
            "resetting env. episode 640.000000, reward total was -20.000000. running mean: -20.146797\n",
            "resetting env. episode 641.000000, reward total was -21.000000. running mean: -20.155329\n",
            "resetting env. episode 642.000000, reward total was -20.000000. running mean: -20.153776\n",
            "resetting env. episode 643.000000, reward total was -21.000000. running mean: -20.162238\n",
            "resetting env. episode 644.000000, reward total was -21.000000. running mean: -20.170616\n",
            "resetting env. episode 645.000000, reward total was -20.000000. running mean: -20.168910\n",
            "resetting env. episode 646.000000, reward total was -19.000000. running mean: -20.157221\n",
            "resetting env. episode 647.000000, reward total was -20.000000. running mean: -20.155649\n",
            "resetting env. episode 648.000000, reward total was -21.000000. running mean: -20.164092\n",
            "resetting env. episode 649.000000, reward total was -21.000000. running mean: -20.172451\n",
            "resetting env. episode 650.000000, reward total was -20.000000. running mean: -20.170727\n",
            "resetting env. episode 651.000000, reward total was -20.000000. running mean: -20.169019\n",
            "resetting env. episode 652.000000, reward total was -21.000000. running mean: -20.177329\n",
            "resetting env. episode 653.000000, reward total was -18.000000. running mean: -20.155556\n",
            "resetting env. episode 654.000000, reward total was -20.000000. running mean: -20.154000\n",
            "resetting env. episode 655.000000, reward total was -20.000000. running mean: -20.152460\n",
            "resetting env. episode 656.000000, reward total was -21.000000. running mean: -20.160936\n",
            "resetting env. episode 657.000000, reward total was -20.000000. running mean: -20.159326\n",
            "resetting env. episode 658.000000, reward total was -19.000000. running mean: -20.147733\n",
            "resetting env. episode 659.000000, reward total was -19.000000. running mean: -20.136256\n",
            "resetting env. episode 660.000000, reward total was -21.000000. running mean: -20.144893\n",
            "resetting env. episode 661.000000, reward total was -19.000000. running mean: -20.133444\n",
            "resetting env. episode 662.000000, reward total was -18.000000. running mean: -20.112110\n",
            "resetting env. episode 663.000000, reward total was -21.000000. running mean: -20.120989\n",
            "resetting env. episode 664.000000, reward total was -20.000000. running mean: -20.119779\n",
            "resetting env. episode 665.000000, reward total was -16.000000. running mean: -20.078581\n",
            "resetting env. episode 666.000000, reward total was -21.000000. running mean: -20.087795\n",
            "resetting env. episode 667.000000, reward total was -20.000000. running mean: -20.086917\n",
            "resetting env. episode 668.000000, reward total was -20.000000. running mean: -20.086048\n",
            "resetting env. episode 669.000000, reward total was -21.000000. running mean: -20.095188\n",
            "resetting env. episode 670.000000, reward total was -20.000000. running mean: -20.094236\n",
            "resetting env. episode 671.000000, reward total was -21.000000. running mean: -20.103293\n",
            "resetting env. episode 672.000000, reward total was -19.000000. running mean: -20.092260\n",
            "resetting env. episode 673.000000, reward total was -21.000000. running mean: -20.101338\n",
            "resetting env. episode 674.000000, reward total was -21.000000. running mean: -20.110324\n",
            "resetting env. episode 675.000000, reward total was -20.000000. running mean: -20.109221\n",
            "resetting env. episode 676.000000, reward total was -21.000000. running mean: -20.118129\n",
            "resetting env. episode 677.000000, reward total was -20.000000. running mean: -20.116948\n",
            "resetting env. episode 678.000000, reward total was -21.000000. running mean: -20.125778\n",
            "resetting env. episode 679.000000, reward total was -21.000000. running mean: -20.134520\n",
            "resetting env. episode 680.000000, reward total was -21.000000. running mean: -20.143175\n",
            "resetting env. episode 681.000000, reward total was -20.000000. running mean: -20.141744\n",
            "resetting env. episode 682.000000, reward total was -21.000000. running mean: -20.150326\n",
            "resetting env. episode 683.000000, reward total was -21.000000. running mean: -20.158823\n",
            "resetting env. episode 684.000000, reward total was -21.000000. running mean: -20.167235\n",
            "resetting env. episode 685.000000, reward total was -21.000000. running mean: -20.175562\n",
            "resetting env. episode 686.000000, reward total was -21.000000. running mean: -20.183807\n",
            "resetting env. episode 687.000000, reward total was -21.000000. running mean: -20.191969\n",
            "resetting env. episode 688.000000, reward total was -20.000000. running mean: -20.190049\n",
            "resetting env. episode 689.000000, reward total was -21.000000. running mean: -20.198148\n",
            "resetting env. episode 690.000000, reward total was -21.000000. running mean: -20.206167\n",
            "resetting env. episode 691.000000, reward total was -20.000000. running mean: -20.204105\n",
            "resetting env. episode 692.000000, reward total was -21.000000. running mean: -20.212064\n",
            "resetting env. episode 693.000000, reward total was -21.000000. running mean: -20.219944\n",
            "resetting env. episode 694.000000, reward total was -20.000000. running mean: -20.217744\n",
            "resetting env. episode 695.000000, reward total was -21.000000. running mean: -20.225567\n",
            "resetting env. episode 696.000000, reward total was -18.000000. running mean: -20.203311\n",
            "resetting env. episode 697.000000, reward total was -21.000000. running mean: -20.211278\n",
            "resetting env. episode 698.000000, reward total was -20.000000. running mean: -20.209165\n",
            "resetting env. episode 699.000000, reward total was -20.000000. running mean: -20.207073\n",
            "resetting env. episode 700.000000, reward total was -16.000000. running mean: -20.165003\n",
            "resetting env. episode 701.000000, reward total was -21.000000. running mean: -20.173353\n",
            "resetting env. episode 702.000000, reward total was -21.000000. running mean: -20.181619\n",
            "resetting env. episode 703.000000, reward total was -21.000000. running mean: -20.189803\n",
            "resetting env. episode 704.000000, reward total was -21.000000. running mean: -20.197905\n",
            "resetting env. episode 705.000000, reward total was -21.000000. running mean: -20.205926\n",
            "resetting env. episode 706.000000, reward total was -20.000000. running mean: -20.203867\n",
            "resetting env. episode 707.000000, reward total was -21.000000. running mean: -20.211828\n",
            "resetting env. episode 708.000000, reward total was -20.000000. running mean: -20.209710\n",
            "resetting env. episode 709.000000, reward total was -20.000000. running mean: -20.207613\n",
            "resetting env. episode 710.000000, reward total was -20.000000. running mean: -20.205536\n",
            "resetting env. episode 711.000000, reward total was -20.000000. running mean: -20.203481\n",
            "resetting env. episode 712.000000, reward total was -21.000000. running mean: -20.211446\n",
            "resetting env. episode 713.000000, reward total was -20.000000. running mean: -20.209332\n",
            "resetting env. episode 714.000000, reward total was -20.000000. running mean: -20.207239\n",
            "resetting env. episode 715.000000, reward total was -20.000000. running mean: -20.205166\n",
            "resetting env. episode 716.000000, reward total was -21.000000. running mean: -20.213114\n",
            "resetting env. episode 717.000000, reward total was -20.000000. running mean: -20.210983\n",
            "resetting env. episode 718.000000, reward total was -21.000000. running mean: -20.218873\n",
            "resetting env. episode 719.000000, reward total was -20.000000. running mean: -20.216685\n",
            "resetting env. episode 720.000000, reward total was -21.000000. running mean: -20.224518\n",
            "resetting env. episode 721.000000, reward total was -21.000000. running mean: -20.232273\n",
            "resetting env. episode 722.000000, reward total was -19.000000. running mean: -20.219950\n",
            "resetting env. episode 723.000000, reward total was -21.000000. running mean: -20.227751\n",
            "resetting env. episode 724.000000, reward total was -20.000000. running mean: -20.225473\n",
            "resetting env. episode 725.000000, reward total was -19.000000. running mean: -20.213218\n",
            "resetting env. episode 726.000000, reward total was -21.000000. running mean: -20.221086\n",
            "resetting env. episode 727.000000, reward total was -19.000000. running mean: -20.208875\n",
            "resetting env. episode 728.000000, reward total was -19.000000. running mean: -20.196786\n",
            "resetting env. episode 729.000000, reward total was -19.000000. running mean: -20.184819\n",
            "resetting env. episode 730.000000, reward total was -21.000000. running mean: -20.192970\n",
            "resetting env. episode 731.000000, reward total was -19.000000. running mean: -20.181041\n",
            "resetting env. episode 732.000000, reward total was -21.000000. running mean: -20.189230\n",
            "resetting env. episode 733.000000, reward total was -20.000000. running mean: -20.187338\n",
            "resetting env. episode 734.000000, reward total was -21.000000. running mean: -20.195465\n",
            "resetting env. episode 735.000000, reward total was -21.000000. running mean: -20.203510\n",
            "resetting env. episode 736.000000, reward total was -21.000000. running mean: -20.211475\n",
            "resetting env. episode 737.000000, reward total was -21.000000. running mean: -20.219360\n",
            "resetting env. episode 738.000000, reward total was -21.000000. running mean: -20.227167\n",
            "resetting env. episode 739.000000, reward total was -21.000000. running mean: -20.234895\n",
            "resetting env. episode 740.000000, reward total was -19.000000. running mean: -20.222546\n",
            "resetting env. episode 741.000000, reward total was -21.000000. running mean: -20.230320\n",
            "resetting env. episode 742.000000, reward total was -18.000000. running mean: -20.208017\n",
            "resetting env. episode 743.000000, reward total was -20.000000. running mean: -20.205937\n",
            "resetting env. episode 744.000000, reward total was -21.000000. running mean: -20.213878\n",
            "resetting env. episode 745.000000, reward total was -20.000000. running mean: -20.211739\n",
            "resetting env. episode 746.000000, reward total was -17.000000. running mean: -20.179622\n",
            "resetting env. episode 747.000000, reward total was -20.000000. running mean: -20.177825\n",
            "resetting env. episode 748.000000, reward total was -19.000000. running mean: -20.166047\n",
            "resetting env. episode 749.000000, reward total was -21.000000. running mean: -20.174387\n",
            "resetting env. episode 750.000000, reward total was -17.000000. running mean: -20.142643\n",
            "resetting env. episode 751.000000, reward total was -21.000000. running mean: -20.151216\n",
            "resetting env. episode 752.000000, reward total was -19.000000. running mean: -20.139704\n",
            "resetting env. episode 753.000000, reward total was -20.000000. running mean: -20.138307\n",
            "resetting env. episode 754.000000, reward total was -19.000000. running mean: -20.126924\n",
            "resetting env. episode 755.000000, reward total was -18.000000. running mean: -20.105655\n",
            "resetting env. episode 756.000000, reward total was -20.000000. running mean: -20.104598\n",
            "resetting env. episode 757.000000, reward total was -20.000000. running mean: -20.103552\n",
            "resetting env. episode 758.000000, reward total was -21.000000. running mean: -20.112517\n",
            "resetting env. episode 759.000000, reward total was -20.000000. running mean: -20.111392\n",
            "resetting env. episode 760.000000, reward total was -21.000000. running mean: -20.120278\n",
            "resetting env. episode 761.000000, reward total was -19.000000. running mean: -20.109075\n",
            "resetting env. episode 762.000000, reward total was -21.000000. running mean: -20.117984\n",
            "resetting env. episode 763.000000, reward total was -20.000000. running mean: -20.116804\n",
            "resetting env. episode 764.000000, reward total was -21.000000. running mean: -20.125636\n",
            "resetting env. episode 765.000000, reward total was -20.000000. running mean: -20.124380\n",
            "resetting env. episode 766.000000, reward total was -20.000000. running mean: -20.123136\n",
            "resetting env. episode 767.000000, reward total was -21.000000. running mean: -20.131905\n",
            "resetting env. episode 768.000000, reward total was -17.000000. running mean: -20.100586\n",
            "resetting env. episode 769.000000, reward total was -18.000000. running mean: -20.079580\n",
            "resetting env. episode 770.000000, reward total was -20.000000. running mean: -20.078784\n",
            "resetting env. episode 771.000000, reward total was -20.000000. running mean: -20.077996\n",
            "resetting env. episode 772.000000, reward total was -21.000000. running mean: -20.087216\n",
            "resetting env. episode 773.000000, reward total was -19.000000. running mean: -20.076344\n",
            "resetting env. episode 774.000000, reward total was -20.000000. running mean: -20.075581\n",
            "resetting env. episode 775.000000, reward total was -18.000000. running mean: -20.054825\n",
            "resetting env. episode 776.000000, reward total was -21.000000. running mean: -20.064277\n",
            "resetting env. episode 777.000000, reward total was -21.000000. running mean: -20.073634\n",
            "resetting env. episode 778.000000, reward total was -21.000000. running mean: -20.082897\n",
            "resetting env. episode 779.000000, reward total was -17.000000. running mean: -20.052068\n",
            "resetting env. episode 780.000000, reward total was -21.000000. running mean: -20.061548\n",
            "resetting env. episode 781.000000, reward total was -21.000000. running mean: -20.070932\n",
            "resetting env. episode 782.000000, reward total was -21.000000. running mean: -20.080223\n",
            "resetting env. episode 783.000000, reward total was -20.000000. running mean: -20.079421\n",
            "resetting env. episode 784.000000, reward total was -19.000000. running mean: -20.068627\n",
            "resetting env. episode 785.000000, reward total was -20.000000. running mean: -20.067940\n",
            "resetting env. episode 786.000000, reward total was -19.000000. running mean: -20.057261\n",
            "resetting env. episode 787.000000, reward total was -20.000000. running mean: -20.056688\n",
            "resetting env. episode 788.000000, reward total was -21.000000. running mean: -20.066121\n",
            "resetting env. episode 789.000000, reward total was -21.000000. running mean: -20.075460\n",
            "resetting env. episode 790.000000, reward total was -20.000000. running mean: -20.074706\n",
            "resetting env. episode 791.000000, reward total was -21.000000. running mean: -20.083959\n",
            "resetting env. episode 792.000000, reward total was -19.000000. running mean: -20.073119\n",
            "resetting env. episode 793.000000, reward total was -21.000000. running mean: -20.082388\n",
            "resetting env. episode 794.000000, reward total was -19.000000. running mean: -20.071564\n",
            "resetting env. episode 795.000000, reward total was -20.000000. running mean: -20.070848\n",
            "resetting env. episode 796.000000, reward total was -19.000000. running mean: -20.060140\n",
            "resetting env. episode 797.000000, reward total was -20.000000. running mean: -20.059538\n",
            "resetting env. episode 798.000000, reward total was -20.000000. running mean: -20.058943\n",
            "resetting env. episode 799.000000, reward total was -18.000000. running mean: -20.038354\n",
            "resetting env. episode 800.000000, reward total was -21.000000. running mean: -20.047970\n",
            "resetting env. episode 801.000000, reward total was -21.000000. running mean: -20.057490\n",
            "resetting env. episode 802.000000, reward total was -21.000000. running mean: -20.066915\n",
            "resetting env. episode 803.000000, reward total was -19.000000. running mean: -20.056246\n",
            "resetting env. episode 804.000000, reward total was -20.000000. running mean: -20.055684\n",
            "resetting env. episode 805.000000, reward total was -20.000000. running mean: -20.055127\n",
            "resetting env. episode 806.000000, reward total was -21.000000. running mean: -20.064576\n",
            "resetting env. episode 807.000000, reward total was -20.000000. running mean: -20.063930\n",
            "resetting env. episode 808.000000, reward total was -20.000000. running mean: -20.063291\n",
            "resetting env. episode 809.000000, reward total was -19.000000. running mean: -20.052658\n",
            "resetting env. episode 810.000000, reward total was -19.000000. running mean: -20.042131\n",
            "resetting env. episode 811.000000, reward total was -20.000000. running mean: -20.041710\n",
            "resetting env. episode 812.000000, reward total was -21.000000. running mean: -20.051293\n",
            "resetting env. episode 813.000000, reward total was -20.000000. running mean: -20.050780\n",
            "resetting env. episode 814.000000, reward total was -20.000000. running mean: -20.050272\n",
            "resetting env. episode 815.000000, reward total was -20.000000. running mean: -20.049769\n",
            "resetting env. episode 816.000000, reward total was -21.000000. running mean: -20.059272\n",
            "resetting env. episode 817.000000, reward total was -21.000000. running mean: -20.068679\n",
            "resetting env. episode 818.000000, reward total was -19.000000. running mean: -20.057992\n",
            "resetting env. episode 819.000000, reward total was -20.000000. running mean: -20.057412\n",
            "resetting env. episode 820.000000, reward total was -20.000000. running mean: -20.056838\n",
            "resetting env. episode 821.000000, reward total was -19.000000. running mean: -20.046270\n",
            "resetting env. episode 822.000000, reward total was -21.000000. running mean: -20.055807\n",
            "resetting env. episode 823.000000, reward total was -21.000000. running mean: -20.065249\n",
            "resetting env. episode 824.000000, reward total was -21.000000. running mean: -20.074596\n",
            "resetting env. episode 825.000000, reward total was -21.000000. running mean: -20.083850\n",
            "resetting env. episode 826.000000, reward total was -20.000000. running mean: -20.083012\n",
            "resetting env. episode 827.000000, reward total was -21.000000. running mean: -20.092182\n",
            "resetting env. episode 828.000000, reward total was -20.000000. running mean: -20.091260\n",
            "resetting env. episode 829.000000, reward total was -17.000000. running mean: -20.060347\n",
            "resetting env. episode 830.000000, reward total was -20.000000. running mean: -20.059744\n",
            "resetting env. episode 831.000000, reward total was -20.000000. running mean: -20.059146\n",
            "resetting env. episode 832.000000, reward total was -20.000000. running mean: -20.058555\n",
            "resetting env. episode 833.000000, reward total was -20.000000. running mean: -20.057969\n",
            "resetting env. episode 834.000000, reward total was -20.000000. running mean: -20.057390\n",
            "resetting env. episode 835.000000, reward total was -19.000000. running mean: -20.046816\n",
            "resetting env. episode 836.000000, reward total was -19.000000. running mean: -20.036348\n",
            "resetting env. episode 837.000000, reward total was -20.000000. running mean: -20.035984\n",
            "resetting env. episode 838.000000, reward total was -20.000000. running mean: -20.035624\n",
            "resetting env. episode 839.000000, reward total was -19.000000. running mean: -20.025268\n",
            "resetting env. episode 840.000000, reward total was -21.000000. running mean: -20.035015\n",
            "resetting env. episode 841.000000, reward total was -21.000000. running mean: -20.044665\n",
            "resetting env. episode 842.000000, reward total was -19.000000. running mean: -20.034219\n",
            "resetting env. episode 843.000000, reward total was -19.000000. running mean: -20.023876\n",
            "resetting env. episode 844.000000, reward total was -20.000000. running mean: -20.023638\n",
            "resetting env. episode 845.000000, reward total was -21.000000. running mean: -20.033401\n",
            "resetting env. episode 846.000000, reward total was -20.000000. running mean: -20.033067\n",
            "resetting env. episode 847.000000, reward total was -21.000000. running mean: -20.042737\n",
            "resetting env. episode 848.000000, reward total was -21.000000. running mean: -20.052309\n",
            "resetting env. episode 849.000000, reward total was -20.000000. running mean: -20.051786\n",
            "resetting env. episode 850.000000, reward total was -17.000000. running mean: -20.021268\n",
            "resetting env. episode 851.000000, reward total was -21.000000. running mean: -20.031056\n",
            "resetting env. episode 852.000000, reward total was -20.000000. running mean: -20.030745\n",
            "resetting env. episode 853.000000, reward total was -21.000000. running mean: -20.040438\n",
            "resetting env. episode 854.000000, reward total was -21.000000. running mean: -20.050033\n",
            "resetting env. episode 855.000000, reward total was -20.000000. running mean: -20.049533\n",
            "resetting env. episode 856.000000, reward total was -21.000000. running mean: -20.059038\n",
            "resetting env. episode 857.000000, reward total was -20.000000. running mean: -20.058447\n",
            "resetting env. episode 858.000000, reward total was -17.000000. running mean: -20.027863\n",
            "resetting env. episode 859.000000, reward total was -20.000000. running mean: -20.027584\n",
            "resetting env. episode 860.000000, reward total was -16.000000. running mean: -19.987308\n",
            "resetting env. episode 861.000000, reward total was -19.000000. running mean: -19.977435\n",
            "resetting env. episode 862.000000, reward total was -21.000000. running mean: -19.987661\n",
            "resetting env. episode 863.000000, reward total was -20.000000. running mean: -19.987784\n",
            "resetting env. episode 864.000000, reward total was -20.000000. running mean: -19.987906\n",
            "resetting env. episode 865.000000, reward total was -20.000000. running mean: -19.988027\n",
            "resetting env. episode 866.000000, reward total was -20.000000. running mean: -19.988147\n",
            "resetting env. episode 867.000000, reward total was -20.000000. running mean: -19.988266\n",
            "resetting env. episode 868.000000, reward total was -20.000000. running mean: -19.988383\n",
            "resetting env. episode 869.000000, reward total was -20.000000. running mean: -19.988499\n",
            "resetting env. episode 870.000000, reward total was -20.000000. running mean: -19.988614\n",
            "resetting env. episode 871.000000, reward total was -21.000000. running mean: -19.998728\n",
            "resetting env. episode 872.000000, reward total was -19.000000. running mean: -19.988741\n",
            "resetting env. episode 873.000000, reward total was -21.000000. running mean: -19.998853\n",
            "resetting env. episode 874.000000, reward total was -21.000000. running mean: -20.008865\n",
            "resetting env. episode 875.000000, reward total was -19.000000. running mean: -19.998776\n",
            "resetting env. episode 876.000000, reward total was -20.000000. running mean: -19.998788\n",
            "resetting env. episode 877.000000, reward total was -20.000000. running mean: -19.998800\n",
            "resetting env. episode 878.000000, reward total was -19.000000. running mean: -19.988812\n",
            "resetting env. episode 879.000000, reward total was -21.000000. running mean: -19.998924\n",
            "resetting env. episode 880.000000, reward total was -19.000000. running mean: -19.988935\n",
            "resetting env. episode 881.000000, reward total was -21.000000. running mean: -19.999046\n",
            "resetting env. episode 882.000000, reward total was -19.000000. running mean: -19.989055\n",
            "resetting env. episode 883.000000, reward total was -18.000000. running mean: -19.969165\n",
            "resetting env. episode 884.000000, reward total was -19.000000. running mean: -19.959473\n",
            "resetting env. episode 885.000000, reward total was -21.000000. running mean: -19.969878\n",
            "resetting env. episode 886.000000, reward total was -20.000000. running mean: -19.970180\n",
            "resetting env. episode 887.000000, reward total was -19.000000. running mean: -19.960478\n",
            "resetting env. episode 888.000000, reward total was -21.000000. running mean: -19.970873\n",
            "resetting env. episode 889.000000, reward total was -21.000000. running mean: -19.981164\n",
            "resetting env. episode 890.000000, reward total was -21.000000. running mean: -19.991353\n",
            "resetting env. episode 891.000000, reward total was -20.000000. running mean: -19.991439\n",
            "resetting env. episode 892.000000, reward total was -21.000000. running mean: -20.001525\n",
            "resetting env. episode 893.000000, reward total was -21.000000. running mean: -20.011509\n",
            "resetting env. episode 894.000000, reward total was -21.000000. running mean: -20.021394\n",
            "resetting env. episode 895.000000, reward total was -18.000000. running mean: -20.001180\n",
            "resetting env. episode 896.000000, reward total was -20.000000. running mean: -20.001169\n",
            "resetting env. episode 897.000000, reward total was -19.000000. running mean: -19.991157\n",
            "resetting env. episode 898.000000, reward total was -21.000000. running mean: -20.001245\n",
            "resetting env. episode 899.000000, reward total was -21.000000. running mean: -20.011233\n",
            "resetting env. episode 900.000000, reward total was -20.000000. running mean: -20.011121\n",
            "resetting env. episode 901.000000, reward total was -21.000000. running mean: -20.021009\n",
            "resetting env. episode 902.000000, reward total was -21.000000. running mean: -20.030799\n",
            "resetting env. episode 903.000000, reward total was -21.000000. running mean: -20.040491\n",
            "resetting env. episode 904.000000, reward total was -20.000000. running mean: -20.040086\n",
            "resetting env. episode 905.000000, reward total was -19.000000. running mean: -20.029686\n",
            "resetting env. episode 906.000000, reward total was -20.000000. running mean: -20.029389\n",
            "resetting env. episode 907.000000, reward total was -21.000000. running mean: -20.039095\n",
            "resetting env. episode 908.000000, reward total was -20.000000. running mean: -20.038704\n",
            "resetting env. episode 909.000000, reward total was -21.000000. running mean: -20.048317\n",
            "resetting env. episode 910.000000, reward total was -21.000000. running mean: -20.057834\n",
            "resetting env. episode 911.000000, reward total was -21.000000. running mean: -20.067255\n",
            "resetting env. episode 912.000000, reward total was -20.000000. running mean: -20.066583\n",
            "resetting env. episode 913.000000, reward total was -20.000000. running mean: -20.065917\n",
            "resetting env. episode 914.000000, reward total was -19.000000. running mean: -20.055258\n",
            "resetting env. episode 915.000000, reward total was -19.000000. running mean: -20.044705\n",
            "resetting env. episode 916.000000, reward total was -19.000000. running mean: -20.034258\n",
            "resetting env. episode 917.000000, reward total was -21.000000. running mean: -20.043916\n",
            "resetting env. episode 918.000000, reward total was -21.000000. running mean: -20.053476\n",
            "resetting env. episode 919.000000, reward total was -20.000000. running mean: -20.052942\n",
            "resetting env. episode 920.000000, reward total was -21.000000. running mean: -20.062412\n",
            "resetting env. episode 921.000000, reward total was -20.000000. running mean: -20.061788\n",
            "resetting env. episode 922.000000, reward total was -20.000000. running mean: -20.061170\n",
            "resetting env. episode 923.000000, reward total was -21.000000. running mean: -20.070558\n",
            "resetting env. episode 924.000000, reward total was -20.000000. running mean: -20.069853\n",
            "resetting env. episode 925.000000, reward total was -21.000000. running mean: -20.079154\n",
            "resetting env. episode 926.000000, reward total was -21.000000. running mean: -20.088363\n",
            "resetting env. episode 927.000000, reward total was -20.000000. running mean: -20.087479\n",
            "resetting env. episode 928.000000, reward total was -21.000000. running mean: -20.096604\n",
            "resetting env. episode 929.000000, reward total was -21.000000. running mean: -20.105638\n",
            "resetting env. episode 930.000000, reward total was -21.000000. running mean: -20.114582\n",
            "resetting env. episode 931.000000, reward total was -20.000000. running mean: -20.113436\n",
            "resetting env. episode 932.000000, reward total was -20.000000. running mean: -20.112302\n",
            "resetting env. episode 933.000000, reward total was -19.000000. running mean: -20.101179\n",
            "resetting env. episode 934.000000, reward total was -20.000000. running mean: -20.100167\n",
            "resetting env. episode 935.000000, reward total was -20.000000. running mean: -20.099165\n",
            "resetting env. episode 936.000000, reward total was -20.000000. running mean: -20.098174\n",
            "resetting env. episode 937.000000, reward total was -18.000000. running mean: -20.077192\n",
            "resetting env. episode 938.000000, reward total was -21.000000. running mean: -20.086420\n",
            "resetting env. episode 939.000000, reward total was -19.000000. running mean: -20.075556\n",
            "resetting env. episode 940.000000, reward total was -21.000000. running mean: -20.084800\n",
            "resetting env. episode 941.000000, reward total was -17.000000. running mean: -20.053952\n",
            "resetting env. episode 942.000000, reward total was -21.000000. running mean: -20.063413\n",
            "resetting env. episode 943.000000, reward total was -21.000000. running mean: -20.072779\n",
            "resetting env. episode 944.000000, reward total was -21.000000. running mean: -20.082051\n",
            "resetting env. episode 945.000000, reward total was -20.000000. running mean: -20.081230\n",
            "resetting env. episode 946.000000, reward total was -18.000000. running mean: -20.060418\n",
            "resetting env. episode 947.000000, reward total was -19.000000. running mean: -20.049814\n",
            "resetting env. episode 948.000000, reward total was -20.000000. running mean: -20.049316\n",
            "resetting env. episode 949.000000, reward total was -21.000000. running mean: -20.058823\n",
            "resetting env. episode 950.000000, reward total was -21.000000. running mean: -20.068234\n",
            "resetting env. episode 951.000000, reward total was -21.000000. running mean: -20.077552\n",
            "resetting env. episode 952.000000, reward total was -21.000000. running mean: -20.086776\n",
            "resetting env. episode 953.000000, reward total was -20.000000. running mean: -20.085909\n",
            "resetting env. episode 954.000000, reward total was -20.000000. running mean: -20.085050\n",
            "resetting env. episode 955.000000, reward total was -21.000000. running mean: -20.094199\n",
            "resetting env. episode 956.000000, reward total was -21.000000. running mean: -20.103257\n",
            "resetting env. episode 957.000000, reward total was -21.000000. running mean: -20.112225\n",
            "resetting env. episode 958.000000, reward total was -20.000000. running mean: -20.111102\n",
            "resetting env. episode 959.000000, reward total was -21.000000. running mean: -20.119991\n",
            "resetting env. episode 960.000000, reward total was -21.000000. running mean: -20.128791\n",
            "resetting env. episode 961.000000, reward total was -20.000000. running mean: -20.127503\n",
            "resetting env. episode 962.000000, reward total was -20.000000. running mean: -20.126228\n",
            "resetting env. episode 963.000000, reward total was -19.000000. running mean: -20.114966\n",
            "resetting env. episode 964.000000, reward total was -20.000000. running mean: -20.113816\n",
            "resetting env. episode 965.000000, reward total was -19.000000. running mean: -20.102678\n",
            "resetting env. episode 966.000000, reward total was -20.000000. running mean: -20.101652\n",
            "resetting env. episode 967.000000, reward total was -21.000000. running mean: -20.110635\n",
            "resetting env. episode 968.000000, reward total was -21.000000. running mean: -20.119529\n",
            "resetting env. episode 969.000000, reward total was -19.000000. running mean: -20.108333\n",
            "resetting env. episode 970.000000, reward total was -20.000000. running mean: -20.107250\n",
            "resetting env. episode 971.000000, reward total was -20.000000. running mean: -20.106178\n",
            "resetting env. episode 972.000000, reward total was -21.000000. running mean: -20.115116\n",
            "resetting env. episode 973.000000, reward total was -20.000000. running mean: -20.113965\n",
            "resetting env. episode 974.000000, reward total was -20.000000. running mean: -20.112825\n",
            "resetting env. episode 975.000000, reward total was -21.000000. running mean: -20.121697\n",
            "resetting env. episode 976.000000, reward total was -21.000000. running mean: -20.130480\n",
            "resetting env. episode 977.000000, reward total was -19.000000. running mean: -20.119175\n",
            "resetting env. episode 978.000000, reward total was -21.000000. running mean: -20.127983\n",
            "resetting env. episode 979.000000, reward total was -21.000000. running mean: -20.136703\n",
            "resetting env. episode 980.000000, reward total was -21.000000. running mean: -20.145336\n",
            "resetting env. episode 981.000000, reward total was -20.000000. running mean: -20.143883\n",
            "resetting env. episode 982.000000, reward total was -21.000000. running mean: -20.152444\n",
            "resetting env. episode 983.000000, reward total was -21.000000. running mean: -20.160920\n",
            "resetting env. episode 984.000000, reward total was -21.000000. running mean: -20.169310\n",
            "resetting env. episode 985.000000, reward total was -19.000000. running mean: -20.157617\n",
            "resetting env. episode 986.000000, reward total was -21.000000. running mean: -20.166041\n",
            "resetting env. episode 987.000000, reward total was -21.000000. running mean: -20.174381\n",
            "resetting env. episode 988.000000, reward total was -19.000000. running mean: -20.162637\n",
            "resetting env. episode 989.000000, reward total was -21.000000. running mean: -20.171011\n",
            "resetting env. episode 990.000000, reward total was -20.000000. running mean: -20.169301\n",
            "resetting env. episode 991.000000, reward total was -21.000000. running mean: -20.177608\n",
            "resetting env. episode 992.000000, reward total was -21.000000. running mean: -20.185831\n",
            "resetting env. episode 993.000000, reward total was -21.000000. running mean: -20.193973\n",
            "resetting env. episode 994.000000, reward total was -20.000000. running mean: -20.192033\n",
            "resetting env. episode 995.000000, reward total was -19.000000. running mean: -20.180113\n",
            "resetting env. episode 996.000000, reward total was -20.000000. running mean: -20.178312\n",
            "resetting env. episode 997.000000, reward total was -20.000000. running mean: -20.176529\n",
            "resetting env. episode 998.000000, reward total was -19.000000. running mean: -20.164764\n",
            "resetting env. episode 999.000000, reward total was -19.000000. running mean: -20.153116\n",
            "resetting env. episode 1000.000000, reward total was -20.000000. running mean: -20.151585\n",
            "resetting env. episode 1001.000000, reward total was -19.000000. running mean: -20.140069\n",
            "resetting env. episode 1002.000000, reward total was -20.000000. running mean: -20.138668\n",
            "resetting env. episode 1003.000000, reward total was -21.000000. running mean: -20.147282\n",
            "resetting env. episode 1004.000000, reward total was -19.000000. running mean: -20.135809\n",
            "resetting env. episode 1005.000000, reward total was -21.000000. running mean: -20.144451\n",
            "resetting env. episode 1006.000000, reward total was -20.000000. running mean: -20.143006\n",
            "resetting env. episode 1007.000000, reward total was -19.000000. running mean: -20.131576\n",
            "resetting env. episode 1008.000000, reward total was -20.000000. running mean: -20.130260\n",
            "resetting env. episode 1009.000000, reward total was -21.000000. running mean: -20.138958\n",
            "resetting env. episode 1010.000000, reward total was -21.000000. running mean: -20.147568\n",
            "resetting env. episode 1011.000000, reward total was -20.000000. running mean: -20.146092\n",
            "resetting env. episode 1012.000000, reward total was -21.000000. running mean: -20.154631\n",
            "resetting env. episode 1013.000000, reward total was -20.000000. running mean: -20.153085\n",
            "resetting env. episode 1014.000000, reward total was -21.000000. running mean: -20.161554\n",
            "resetting env. episode 1015.000000, reward total was -20.000000. running mean: -20.159939\n",
            "resetting env. episode 1016.000000, reward total was -20.000000. running mean: -20.158339\n",
            "resetting env. episode 1017.000000, reward total was -21.000000. running mean: -20.166756\n",
            "resetting env. episode 1018.000000, reward total was -21.000000. running mean: -20.175088\n",
            "resetting env. episode 1019.000000, reward total was -20.000000. running mean: -20.173338\n",
            "resetting env. episode 1020.000000, reward total was -21.000000. running mean: -20.181604\n",
            "resetting env. episode 1021.000000, reward total was -20.000000. running mean: -20.179788\n",
            "resetting env. episode 1022.000000, reward total was -21.000000. running mean: -20.187990\n",
            "resetting env. episode 1023.000000, reward total was -21.000000. running mean: -20.196110\n",
            "resetting env. episode 1024.000000, reward total was -18.000000. running mean: -20.174149\n",
            "resetting env. episode 1025.000000, reward total was -19.000000. running mean: -20.162408\n",
            "resetting env. episode 1026.000000, reward total was -21.000000. running mean: -20.170784\n",
            "resetting env. episode 1027.000000, reward total was -20.000000. running mean: -20.169076\n",
            "resetting env. episode 1028.000000, reward total was -19.000000. running mean: -20.157385\n",
            "resetting env. episode 1029.000000, reward total was -20.000000. running mean: -20.155811\n",
            "resetting env. episode 1030.000000, reward total was -21.000000. running mean: -20.164253\n",
            "resetting env. episode 1031.000000, reward total was -20.000000. running mean: -20.162611\n",
            "resetting env. episode 1032.000000, reward total was -21.000000. running mean: -20.170984\n",
            "resetting env. episode 1033.000000, reward total was -19.000000. running mean: -20.159275\n",
            "resetting env. episode 1034.000000, reward total was -21.000000. running mean: -20.167682\n",
            "resetting env. episode 1035.000000, reward total was -19.000000. running mean: -20.156005\n",
            "resetting env. episode 1036.000000, reward total was -20.000000. running mean: -20.154445\n",
            "resetting env. episode 1037.000000, reward total was -21.000000. running mean: -20.162901\n",
            "resetting env. episode 1038.000000, reward total was -19.000000. running mean: -20.151272\n",
            "resetting env. episode 1039.000000, reward total was -19.000000. running mean: -20.139759\n",
            "resetting env. episode 1040.000000, reward total was -21.000000. running mean: -20.148361\n",
            "resetting env. episode 1041.000000, reward total was -20.000000. running mean: -20.146878\n",
            "resetting env. episode 1042.000000, reward total was -18.000000. running mean: -20.125409\n",
            "resetting env. episode 1043.000000, reward total was -21.000000. running mean: -20.134155\n",
            "resetting env. episode 1044.000000, reward total was -20.000000. running mean: -20.132813\n",
            "resetting env. episode 1045.000000, reward total was -21.000000. running mean: -20.141485\n",
            "resetting env. episode 1046.000000, reward total was -18.000000. running mean: -20.120070\n",
            "resetting env. episode 1047.000000, reward total was -21.000000. running mean: -20.128870\n",
            "resetting env. episode 1048.000000, reward total was -21.000000. running mean: -20.137581\n",
            "resetting env. episode 1049.000000, reward total was -21.000000. running mean: -20.146205\n",
            "resetting env. episode 1050.000000, reward total was -19.000000. running mean: -20.134743\n",
            "resetting env. episode 1051.000000, reward total was -18.000000. running mean: -20.113396\n",
            "resetting env. episode 1052.000000, reward total was -20.000000. running mean: -20.112262\n",
            "resetting env. episode 1053.000000, reward total was -20.000000. running mean: -20.111139\n",
            "resetting env. episode 1054.000000, reward total was -20.000000. running mean: -20.110028\n",
            "resetting env. episode 1055.000000, reward total was -20.000000. running mean: -20.108927\n",
            "resetting env. episode 1056.000000, reward total was -21.000000. running mean: -20.117838\n",
            "resetting env. episode 1057.000000, reward total was -21.000000. running mean: -20.126660\n",
            "resetting env. episode 1058.000000, reward total was -19.000000. running mean: -20.115393\n",
            "resetting env. episode 1059.000000, reward total was -17.000000. running mean: -20.084239\n",
            "resetting env. episode 1060.000000, reward total was -21.000000. running mean: -20.093397\n",
            "resetting env. episode 1061.000000, reward total was -19.000000. running mean: -20.082463\n",
            "resetting env. episode 1062.000000, reward total was -20.000000. running mean: -20.081638\n",
            "resetting env. episode 1063.000000, reward total was -20.000000. running mean: -20.080822\n",
            "resetting env. episode 1064.000000, reward total was -21.000000. running mean: -20.090014\n",
            "resetting env. episode 1065.000000, reward total was -21.000000. running mean: -20.099113\n",
            "resetting env. episode 1066.000000, reward total was -19.000000. running mean: -20.088122\n",
            "resetting env. episode 1067.000000, reward total was -20.000000. running mean: -20.087241\n",
            "resetting env. episode 1068.000000, reward total was -21.000000. running mean: -20.096369\n",
            "resetting env. episode 1069.000000, reward total was -21.000000. running mean: -20.105405\n",
            "resetting env. episode 1070.000000, reward total was -21.000000. running mean: -20.114351\n",
            "resetting env. episode 1071.000000, reward total was -21.000000. running mean: -20.123207\n",
            "resetting env. episode 1072.000000, reward total was -19.000000. running mean: -20.111975\n",
            "resetting env. episode 1073.000000, reward total was -20.000000. running mean: -20.110856\n",
            "resetting env. episode 1074.000000, reward total was -21.000000. running mean: -20.119747\n",
            "resetting env. episode 1075.000000, reward total was -21.000000. running mean: -20.128550\n",
            "resetting env. episode 1076.000000, reward total was -20.000000. running mean: -20.127264\n",
            "resetting env. episode 1077.000000, reward total was -19.000000. running mean: -20.115991\n",
            "resetting env. episode 1078.000000, reward total was -21.000000. running mean: -20.124832\n",
            "resetting env. episode 1079.000000, reward total was -21.000000. running mean: -20.133583\n",
            "resetting env. episode 1080.000000, reward total was -21.000000. running mean: -20.142247\n",
            "resetting env. episode 1081.000000, reward total was -20.000000. running mean: -20.140825\n",
            "resetting env. episode 1082.000000, reward total was -20.000000. running mean: -20.139417\n",
            "resetting env. episode 1083.000000, reward total was -21.000000. running mean: -20.148022\n",
            "resetting env. episode 1084.000000, reward total was -19.000000. running mean: -20.136542\n",
            "resetting env. episode 1085.000000, reward total was -20.000000. running mean: -20.135177\n",
            "resetting env. episode 1086.000000, reward total was -21.000000. running mean: -20.143825\n",
            "resetting env. episode 1087.000000, reward total was -21.000000. running mean: -20.152387\n",
            "resetting env. episode 1088.000000, reward total was -21.000000. running mean: -20.160863\n",
            "resetting env. episode 1089.000000, reward total was -18.000000. running mean: -20.139254\n",
            "resetting env. episode 1090.000000, reward total was -21.000000. running mean: -20.147862\n",
            "resetting env. episode 1091.000000, reward total was -20.000000. running mean: -20.146383\n",
            "resetting env. episode 1092.000000, reward total was -21.000000. running mean: -20.154919\n",
            "resetting env. episode 1093.000000, reward total was -21.000000. running mean: -20.163370\n",
            "resetting env. episode 1094.000000, reward total was -21.000000. running mean: -20.171736\n",
            "resetting env. episode 1095.000000, reward total was -19.000000. running mean: -20.160019\n",
            "resetting env. episode 1096.000000, reward total was -21.000000. running mean: -20.168419\n",
            "resetting env. episode 1097.000000, reward total was -20.000000. running mean: -20.166735\n",
            "resetting env. episode 1098.000000, reward total was -18.000000. running mean: -20.145067\n",
            "resetting env. episode 1099.000000, reward total was -21.000000. running mean: -20.153617\n",
            "resetting env. episode 1100.000000, reward total was -20.000000. running mean: -20.152080\n",
            "resetting env. episode 1101.000000, reward total was -21.000000. running mean: -20.160560\n",
            "resetting env. episode 1102.000000, reward total was -20.000000. running mean: -20.158954\n",
            "resetting env. episode 1103.000000, reward total was -21.000000. running mean: -20.167365\n",
            "resetting env. episode 1104.000000, reward total was -20.000000. running mean: -20.165691\n",
            "resetting env. episode 1105.000000, reward total was -21.000000. running mean: -20.174034\n",
            "resetting env. episode 1106.000000, reward total was -20.000000. running mean: -20.172294\n",
            "resetting env. episode 1107.000000, reward total was -21.000000. running mean: -20.180571\n",
            "resetting env. episode 1108.000000, reward total was -21.000000. running mean: -20.188765\n",
            "resetting env. episode 1109.000000, reward total was -19.000000. running mean: -20.176877\n",
            "resetting env. episode 1110.000000, reward total was -21.000000. running mean: -20.185109\n",
            "resetting env. episode 1111.000000, reward total was -21.000000. running mean: -20.193258\n",
            "resetting env. episode 1112.000000, reward total was -20.000000. running mean: -20.191325\n",
            "resetting env. episode 1113.000000, reward total was -21.000000. running mean: -20.199412\n",
            "resetting env. episode 1114.000000, reward total was -21.000000. running mean: -20.207418\n",
            "resetting env. episode 1115.000000, reward total was -21.000000. running mean: -20.215343\n",
            "resetting env. episode 1116.000000, reward total was -20.000000. running mean: -20.213190\n",
            "resetting env. episode 1117.000000, reward total was -20.000000. running mean: -20.211058\n",
            "resetting env. episode 1118.000000, reward total was -20.000000. running mean: -20.208947\n",
            "resetting env. episode 1119.000000, reward total was -21.000000. running mean: -20.216858\n",
            "resetting env. episode 1120.000000, reward total was -21.000000. running mean: -20.224689\n",
            "resetting env. episode 1121.000000, reward total was -21.000000. running mean: -20.232443\n",
            "resetting env. episode 1122.000000, reward total was -20.000000. running mean: -20.230118\n",
            "resetting env. episode 1123.000000, reward total was -20.000000. running mean: -20.227817\n",
            "resetting env. episode 1124.000000, reward total was -20.000000. running mean: -20.225539\n",
            "resetting env. episode 1125.000000, reward total was -19.000000. running mean: -20.213283\n",
            "resetting env. episode 1126.000000, reward total was -20.000000. running mean: -20.211151\n",
            "resetting env. episode 1127.000000, reward total was -21.000000. running mean: -20.219039\n",
            "resetting env. episode 1128.000000, reward total was -21.000000. running mean: -20.226849\n",
            "resetting env. episode 1129.000000, reward total was -19.000000. running mean: -20.214580\n",
            "resetting env. episode 1130.000000, reward total was -17.000000. running mean: -20.182434\n",
            "resetting env. episode 1131.000000, reward total was -19.000000. running mean: -20.170610\n",
            "resetting env. episode 1132.000000, reward total was -20.000000. running mean: -20.168904\n",
            "resetting env. episode 1133.000000, reward total was -21.000000. running mean: -20.177215\n",
            "resetting env. episode 1134.000000, reward total was -21.000000. running mean: -20.185443\n",
            "resetting env. episode 1135.000000, reward total was -21.000000. running mean: -20.193588\n",
            "resetting env. episode 1136.000000, reward total was -21.000000. running mean: -20.201652\n",
            "resetting env. episode 1137.000000, reward total was -21.000000. running mean: -20.209636\n",
            "resetting env. episode 1138.000000, reward total was -17.000000. running mean: -20.177540\n",
            "resetting env. episode 1139.000000, reward total was -21.000000. running mean: -20.185764\n",
            "resetting env. episode 1140.000000, reward total was -19.000000. running mean: -20.173906\n",
            "resetting env. episode 1141.000000, reward total was -17.000000. running mean: -20.142167\n",
            "resetting env. episode 1142.000000, reward total was -21.000000. running mean: -20.150746\n",
            "resetting env. episode 1143.000000, reward total was -20.000000. running mean: -20.149238\n",
            "resetting env. episode 1144.000000, reward total was -21.000000. running mean: -20.157746\n",
            "resetting env. episode 1145.000000, reward total was -18.000000. running mean: -20.136168\n",
            "resetting env. episode 1146.000000, reward total was -21.000000. running mean: -20.144807\n",
            "resetting env. episode 1147.000000, reward total was -21.000000. running mean: -20.153359\n",
            "resetting env. episode 1148.000000, reward total was -21.000000. running mean: -20.161825\n",
            "resetting env. episode 1149.000000, reward total was -21.000000. running mean: -20.170207\n",
            "resetting env. episode 1150.000000, reward total was -20.000000. running mean: -20.168505\n",
            "resetting env. episode 1151.000000, reward total was -19.000000. running mean: -20.156820\n",
            "resetting env. episode 1152.000000, reward total was -20.000000. running mean: -20.155252\n",
            "resetting env. episode 1153.000000, reward total was -19.000000. running mean: -20.143699\n",
            "resetting env. episode 1154.000000, reward total was -20.000000. running mean: -20.142262\n",
            "resetting env. episode 1155.000000, reward total was -20.000000. running mean: -20.140839\n",
            "resetting env. episode 1156.000000, reward total was -20.000000. running mean: -20.139431\n",
            "resetting env. episode 1157.000000, reward total was -20.000000. running mean: -20.138037\n",
            "resetting env. episode 1158.000000, reward total was -21.000000. running mean: -20.146656\n",
            "resetting env. episode 1159.000000, reward total was -20.000000. running mean: -20.145190\n",
            "resetting env. episode 1160.000000, reward total was -20.000000. running mean: -20.143738\n",
            "resetting env. episode 1161.000000, reward total was -20.000000. running mean: -20.142301\n",
            "resetting env. episode 1162.000000, reward total was -18.000000. running mean: -20.120877\n",
            "resetting env. episode 1163.000000, reward total was -19.000000. running mean: -20.109669\n",
            "resetting env. episode 1164.000000, reward total was -21.000000. running mean: -20.118572\n",
            "resetting env. episode 1165.000000, reward total was -21.000000. running mean: -20.127386\n",
            "resetting env. episode 1166.000000, reward total was -21.000000. running mean: -20.136112\n",
            "resetting env. episode 1167.000000, reward total was -21.000000. running mean: -20.144751\n",
            "resetting env. episode 1168.000000, reward total was -19.000000. running mean: -20.133304\n",
            "resetting env. episode 1169.000000, reward total was -20.000000. running mean: -20.131971\n",
            "resetting env. episode 1170.000000, reward total was -21.000000. running mean: -20.140651\n",
            "resetting env. episode 1171.000000, reward total was -20.000000. running mean: -20.139245\n",
            "resetting env. episode 1172.000000, reward total was -21.000000. running mean: -20.147852\n",
            "resetting env. episode 1173.000000, reward total was -21.000000. running mean: -20.156374\n",
            "resetting env. episode 1174.000000, reward total was -21.000000. running mean: -20.164810\n",
            "resetting env. episode 1175.000000, reward total was -21.000000. running mean: -20.173162\n",
            "resetting env. episode 1176.000000, reward total was -21.000000. running mean: -20.181430\n",
            "resetting env. episode 1177.000000, reward total was -21.000000. running mean: -20.189616\n",
            "resetting env. episode 1178.000000, reward total was -21.000000. running mean: -20.197720\n",
            "resetting env. episode 1179.000000, reward total was -21.000000. running mean: -20.205742\n",
            "resetting env. episode 1180.000000, reward total was -21.000000. running mean: -20.213685\n",
            "resetting env. episode 1181.000000, reward total was -21.000000. running mean: -20.221548\n",
            "resetting env. episode 1182.000000, reward total was -20.000000. running mean: -20.219333\n",
            "resetting env. episode 1183.000000, reward total was -19.000000. running mean: -20.207139\n",
            "resetting env. episode 1184.000000, reward total was -21.000000. running mean: -20.215068\n",
            "resetting env. episode 1185.000000, reward total was -20.000000. running mean: -20.212917\n",
            "resetting env. episode 1186.000000, reward total was -21.000000. running mean: -20.220788\n",
            "resetting env. episode 1187.000000, reward total was -20.000000. running mean: -20.218580\n",
            "resetting env. episode 1188.000000, reward total was -18.000000. running mean: -20.196394\n",
            "resetting env. episode 1189.000000, reward total was -21.000000. running mean: -20.204431\n",
            "resetting env. episode 1190.000000, reward total was -19.000000. running mean: -20.192386\n",
            "resetting env. episode 1191.000000, reward total was -20.000000. running mean: -20.190462\n",
            "resetting env. episode 1192.000000, reward total was -19.000000. running mean: -20.178558\n",
            "resetting env. episode 1193.000000, reward total was -21.000000. running mean: -20.186772\n",
            "resetting env. episode 1194.000000, reward total was -21.000000. running mean: -20.194904\n",
            "resetting env. episode 1195.000000, reward total was -20.000000. running mean: -20.192955\n",
            "resetting env. episode 1196.000000, reward total was -21.000000. running mean: -20.201026\n",
            "resetting env. episode 1197.000000, reward total was -21.000000. running mean: -20.209016\n",
            "resetting env. episode 1198.000000, reward total was -19.000000. running mean: -20.196925\n",
            "resetting env. episode 1199.000000, reward total was -19.000000. running mean: -20.184956\n",
            "resetting env. episode 1200.000000, reward total was -21.000000. running mean: -20.193107\n",
            "resetting env. episode 1201.000000, reward total was -21.000000. running mean: -20.201176\n",
            "resetting env. episode 1202.000000, reward total was -19.000000. running mean: -20.189164\n",
            "resetting env. episode 1203.000000, reward total was -21.000000. running mean: -20.197272\n",
            "resetting env. episode 1204.000000, reward total was -19.000000. running mean: -20.185299\n",
            "resetting env. episode 1205.000000, reward total was -20.000000. running mean: -20.183446\n",
            "resetting env. episode 1206.000000, reward total was -20.000000. running mean: -20.181612\n",
            "resetting env. episode 1207.000000, reward total was -20.000000. running mean: -20.179796\n",
            "resetting env. episode 1208.000000, reward total was -20.000000. running mean: -20.177998\n",
            "resetting env. episode 1209.000000, reward total was -20.000000. running mean: -20.176218\n",
            "resetting env. episode 1210.000000, reward total was -21.000000. running mean: -20.184456\n",
            "resetting env. episode 1211.000000, reward total was -19.000000. running mean: -20.172611\n",
            "resetting env. episode 1212.000000, reward total was -19.000000. running mean: -20.160885\n",
            "resetting env. episode 1213.000000, reward total was -21.000000. running mean: -20.169276\n",
            "resetting env. episode 1214.000000, reward total was -20.000000. running mean: -20.167583\n",
            "resetting env. episode 1215.000000, reward total was -21.000000. running mean: -20.175908\n",
            "resetting env. episode 1216.000000, reward total was -20.000000. running mean: -20.174149\n",
            "resetting env. episode 1217.000000, reward total was -19.000000. running mean: -20.162407\n",
            "resetting env. episode 1218.000000, reward total was -20.000000. running mean: -20.160783\n",
            "resetting env. episode 1219.000000, reward total was -19.000000. running mean: -20.149175\n",
            "resetting env. episode 1220.000000, reward total was -20.000000. running mean: -20.147683\n",
            "resetting env. episode 1221.000000, reward total was -20.000000. running mean: -20.146207\n",
            "resetting env. episode 1222.000000, reward total was -21.000000. running mean: -20.154744\n",
            "resetting env. episode 1223.000000, reward total was -18.000000. running mean: -20.133197\n",
            "resetting env. episode 1224.000000, reward total was -15.000000. running mean: -20.081865\n",
            "resetting env. episode 1225.000000, reward total was -19.000000. running mean: -20.071046\n",
            "resetting env. episode 1226.000000, reward total was -20.000000. running mean: -20.070336\n",
            "resetting env. episode 1227.000000, reward total was -20.000000. running mean: -20.069633\n",
            "resetting env. episode 1228.000000, reward total was -20.000000. running mean: -20.068936\n",
            "resetting env. episode 1229.000000, reward total was -21.000000. running mean: -20.078247\n",
            "resetting env. episode 1230.000000, reward total was -21.000000. running mean: -20.087464\n",
            "resetting env. episode 1231.000000, reward total was -21.000000. running mean: -20.096590\n",
            "resetting env. episode 1232.000000, reward total was -20.000000. running mean: -20.095624\n",
            "resetting env. episode 1233.000000, reward total was -18.000000. running mean: -20.074668\n",
            "resetting env. episode 1234.000000, reward total was -19.000000. running mean: -20.063921\n",
            "resetting env. episode 1235.000000, reward total was -21.000000. running mean: -20.073282\n",
            "resetting env. episode 1236.000000, reward total was -21.000000. running mean: -20.082549\n",
            "resetting env. episode 1237.000000, reward total was -20.000000. running mean: -20.081723\n",
            "resetting env. episode 1238.000000, reward total was -20.000000. running mean: -20.080906\n",
            "resetting env. episode 1239.000000, reward total was -20.000000. running mean: -20.080097\n",
            "resetting env. episode 1240.000000, reward total was -20.000000. running mean: -20.079296\n",
            "resetting env. episode 1241.000000, reward total was -21.000000. running mean: -20.088503\n",
            "resetting env. episode 1242.000000, reward total was -18.000000. running mean: -20.067618\n",
            "resetting env. episode 1243.000000, reward total was -20.000000. running mean: -20.066942\n",
            "resetting env. episode 1244.000000, reward total was -20.000000. running mean: -20.066273\n",
            "resetting env. episode 1245.000000, reward total was -21.000000. running mean: -20.075610\n",
            "resetting env. episode 1246.000000, reward total was -21.000000. running mean: -20.084854\n",
            "resetting env. episode 1247.000000, reward total was -20.000000. running mean: -20.084005\n",
            "resetting env. episode 1248.000000, reward total was -21.000000. running mean: -20.093165\n",
            "resetting env. episode 1249.000000, reward total was -20.000000. running mean: -20.092234\n",
            "resetting env. episode 1250.000000, reward total was -21.000000. running mean: -20.101311\n",
            "resetting env. episode 1251.000000, reward total was -19.000000. running mean: -20.090298\n",
            "resetting env. episode 1252.000000, reward total was -20.000000. running mean: -20.089395\n",
            "resetting env. episode 1253.000000, reward total was -21.000000. running mean: -20.098501\n",
            "resetting env. episode 1254.000000, reward total was -21.000000. running mean: -20.107516\n",
            "resetting env. episode 1255.000000, reward total was -17.000000. running mean: -20.076441\n",
            "resetting env. episode 1256.000000, reward total was -19.000000. running mean: -20.065677\n",
            "resetting env. episode 1257.000000, reward total was -18.000000. running mean: -20.045020\n",
            "resetting env. episode 1258.000000, reward total was -19.000000. running mean: -20.034570\n",
            "resetting env. episode 1259.000000, reward total was -19.000000. running mean: -20.024224\n",
            "resetting env. episode 1260.000000, reward total was -21.000000. running mean: -20.033982\n",
            "resetting env. episode 1261.000000, reward total was -21.000000. running mean: -20.043642\n",
            "resetting env. episode 1262.000000, reward total was -19.000000. running mean: -20.033205\n",
            "resetting env. episode 1263.000000, reward total was -21.000000. running mean: -20.042873\n",
            "resetting env. episode 1264.000000, reward total was -20.000000. running mean: -20.042445\n",
            "resetting env. episode 1265.000000, reward total was -20.000000. running mean: -20.042020\n",
            "resetting env. episode 1266.000000, reward total was -20.000000. running mean: -20.041600\n",
            "resetting env. episode 1267.000000, reward total was -20.000000. running mean: -20.041184\n",
            "resetting env. episode 1268.000000, reward total was -20.000000. running mean: -20.040772\n",
            "resetting env. episode 1269.000000, reward total was -20.000000. running mean: -20.040364\n",
            "resetting env. episode 1270.000000, reward total was -21.000000. running mean: -20.049961\n",
            "resetting env. episode 1271.000000, reward total was -18.000000. running mean: -20.029461\n",
            "resetting env. episode 1272.000000, reward total was -21.000000. running mean: -20.039167\n",
            "resetting env. episode 1273.000000, reward total was -21.000000. running mean: -20.048775\n",
            "resetting env. episode 1274.000000, reward total was -17.000000. running mean: -20.018287\n",
            "resetting env. episode 1275.000000, reward total was -21.000000. running mean: -20.028104\n",
            "resetting env. episode 1276.000000, reward total was -21.000000. running mean: -20.037823\n",
            "resetting env. episode 1277.000000, reward total was -21.000000. running mean: -20.047445\n",
            "resetting env. episode 1278.000000, reward total was -20.000000. running mean: -20.046971\n",
            "resetting env. episode 1279.000000, reward total was -21.000000. running mean: -20.056501\n",
            "resetting env. episode 1280.000000, reward total was -21.000000. running mean: -20.065936\n",
            "resetting env. episode 1281.000000, reward total was -21.000000. running mean: -20.075276\n",
            "resetting env. episode 1282.000000, reward total was -21.000000. running mean: -20.084524\n",
            "resetting env. episode 1283.000000, reward total was -18.000000. running mean: -20.063678\n",
            "resetting env. episode 1284.000000, reward total was -20.000000. running mean: -20.063042\n",
            "resetting env. episode 1285.000000, reward total was -20.000000. running mean: -20.062411\n",
            "resetting env. episode 1286.000000, reward total was -21.000000. running mean: -20.071787\n",
            "resetting env. episode 1287.000000, reward total was -21.000000. running mean: -20.081069\n",
            "resetting env. episode 1288.000000, reward total was -21.000000. running mean: -20.090259\n",
            "resetting env. episode 1289.000000, reward total was -20.000000. running mean: -20.089356\n",
            "resetting env. episode 1290.000000, reward total was -19.000000. running mean: -20.078462\n",
            "resetting env. episode 1291.000000, reward total was -21.000000. running mean: -20.087678\n",
            "resetting env. episode 1292.000000, reward total was -20.000000. running mean: -20.086801\n",
            "resetting env. episode 1293.000000, reward total was -17.000000. running mean: -20.055933\n",
            "resetting env. episode 1294.000000, reward total was -19.000000. running mean: -20.045374\n",
            "resetting env. episode 1295.000000, reward total was -20.000000. running mean: -20.044920\n",
            "resetting env. episode 1296.000000, reward total was -21.000000. running mean: -20.054471\n",
            "resetting env. episode 1297.000000, reward total was -19.000000. running mean: -20.043926\n",
            "resetting env. episode 1298.000000, reward total was -21.000000. running mean: -20.053487\n",
            "resetting env. episode 1299.000000, reward total was -21.000000. running mean: -20.062952\n",
            "resetting env. episode 1300.000000, reward total was -21.000000. running mean: -20.072322\n",
            "resetting env. episode 1301.000000, reward total was -21.000000. running mean: -20.081599\n",
            "resetting env. episode 1302.000000, reward total was -21.000000. running mean: -20.090783\n",
            "resetting env. episode 1303.000000, reward total was -18.000000. running mean: -20.069875\n",
            "resetting env. episode 1304.000000, reward total was -19.000000. running mean: -20.059177\n",
            "resetting env. episode 1305.000000, reward total was -20.000000. running mean: -20.058585\n",
            "resetting env. episode 1306.000000, reward total was -21.000000. running mean: -20.067999\n",
            "resetting env. episode 1307.000000, reward total was -20.000000. running mean: -20.067319\n",
            "resetting env. episode 1308.000000, reward total was -20.000000. running mean: -20.066646\n",
            "resetting env. episode 1309.000000, reward total was -20.000000. running mean: -20.065979\n",
            "resetting env. episode 1310.000000, reward total was -21.000000. running mean: -20.075320\n",
            "resetting env. episode 1311.000000, reward total was -21.000000. running mean: -20.084566\n",
            "resetting env. episode 1312.000000, reward total was -21.000000. running mean: -20.093721\n",
            "resetting env. episode 1313.000000, reward total was -19.000000. running mean: -20.082784\n",
            "resetting env. episode 1314.000000, reward total was -21.000000. running mean: -20.091956\n",
            "resetting env. episode 1315.000000, reward total was -20.000000. running mean: -20.091036\n",
            "resetting env. episode 1316.000000, reward total was -21.000000. running mean: -20.100126\n",
            "resetting env. episode 1317.000000, reward total was -19.000000. running mean: -20.089125\n",
            "resetting env. episode 1318.000000, reward total was -21.000000. running mean: -20.098233\n",
            "resetting env. episode 1319.000000, reward total was -21.000000. running mean: -20.107251\n",
            "resetting env. episode 1320.000000, reward total was -20.000000. running mean: -20.106178\n",
            "resetting env. episode 1321.000000, reward total was -20.000000. running mean: -20.105117\n",
            "resetting env. episode 1322.000000, reward total was -19.000000. running mean: -20.094065\n",
            "resetting env. episode 1323.000000, reward total was -20.000000. running mean: -20.093125\n",
            "resetting env. episode 1324.000000, reward total was -21.000000. running mean: -20.102194\n",
            "resetting env. episode 1325.000000, reward total was -18.000000. running mean: -20.081172\n",
            "resetting env. episode 1326.000000, reward total was -21.000000. running mean: -20.090360\n",
            "resetting env. episode 1327.000000, reward total was -21.000000. running mean: -20.099456\n",
            "resetting env. episode 1328.000000, reward total was -18.000000. running mean: -20.078462\n",
            "resetting env. episode 1329.000000, reward total was -20.000000. running mean: -20.077677\n",
            "resetting env. episode 1330.000000, reward total was -21.000000. running mean: -20.086900\n",
            "resetting env. episode 1331.000000, reward total was -19.000000. running mean: -20.076031\n",
            "resetting env. episode 1332.000000, reward total was -20.000000. running mean: -20.075271\n",
            "resetting env. episode 1333.000000, reward total was -20.000000. running mean: -20.074518\n",
            "resetting env. episode 1334.000000, reward total was -21.000000. running mean: -20.083773\n",
            "resetting env. episode 1335.000000, reward total was -20.000000. running mean: -20.082935\n",
            "resetting env. episode 1336.000000, reward total was -21.000000. running mean: -20.092106\n",
            "resetting env. episode 1337.000000, reward total was -21.000000. running mean: -20.101185\n",
            "resetting env. episode 1338.000000, reward total was -21.000000. running mean: -20.110173\n",
            "resetting env. episode 1339.000000, reward total was -19.000000. running mean: -20.099071\n",
            "resetting env. episode 1340.000000, reward total was -21.000000. running mean: -20.108081\n",
            "resetting env. episode 1341.000000, reward total was -21.000000. running mean: -20.117000\n",
            "resetting env. episode 1342.000000, reward total was -21.000000. running mean: -20.125830\n",
            "resetting env. episode 1343.000000, reward total was -20.000000. running mean: -20.124572\n",
            "resetting env. episode 1344.000000, reward total was -19.000000. running mean: -20.113326\n",
            "resetting env. episode 1345.000000, reward total was -18.000000. running mean: -20.092193\n",
            "resetting env. episode 1346.000000, reward total was -20.000000. running mean: -20.091271\n",
            "resetting env. episode 1347.000000, reward total was -21.000000. running mean: -20.100358\n",
            "resetting env. episode 1348.000000, reward total was -17.000000. running mean: -20.069354\n",
            "resetting env. episode 1349.000000, reward total was -19.000000. running mean: -20.058661\n",
            "resetting env. episode 1350.000000, reward total was -21.000000. running mean: -20.068074\n",
            "resetting env. episode 1351.000000, reward total was -21.000000. running mean: -20.077394\n",
            "resetting env. episode 1352.000000, reward total was -21.000000. running mean: -20.086620\n",
            "resetting env. episode 1353.000000, reward total was -20.000000. running mean: -20.085753\n",
            "resetting env. episode 1354.000000, reward total was -20.000000. running mean: -20.084896\n",
            "resetting env. episode 1355.000000, reward total was -21.000000. running mean: -20.094047\n",
            "resetting env. episode 1356.000000, reward total was -19.000000. running mean: -20.083106\n",
            "resetting env. episode 1357.000000, reward total was -21.000000. running mean: -20.092275\n",
            "resetting env. episode 1358.000000, reward total was -20.000000. running mean: -20.091353\n",
            "resetting env. episode 1359.000000, reward total was -21.000000. running mean: -20.100439\n",
            "resetting env. episode 1360.000000, reward total was -20.000000. running mean: -20.099435\n",
            "resetting env. episode 1361.000000, reward total was -20.000000. running mean: -20.098440\n",
            "resetting env. episode 1362.000000, reward total was -21.000000. running mean: -20.107456\n",
            "resetting env. episode 1363.000000, reward total was -20.000000. running mean: -20.106381\n",
            "resetting env. episode 1364.000000, reward total was -21.000000. running mean: -20.115318\n",
            "resetting env. episode 1365.000000, reward total was -19.000000. running mean: -20.104164\n",
            "resetting env. episode 1366.000000, reward total was -20.000000. running mean: -20.103123\n",
            "resetting env. episode 1367.000000, reward total was -19.000000. running mean: -20.092092\n",
            "resetting env. episode 1368.000000, reward total was -21.000000. running mean: -20.101171\n",
            "resetting env. episode 1369.000000, reward total was -19.000000. running mean: -20.090159\n",
            "resetting env. episode 1370.000000, reward total was -20.000000. running mean: -20.089257\n",
            "resetting env. episode 1371.000000, reward total was -18.000000. running mean: -20.068365\n",
            "resetting env. episode 1372.000000, reward total was -19.000000. running mean: -20.057681\n",
            "resetting env. episode 1373.000000, reward total was -19.000000. running mean: -20.047104\n",
            "resetting env. episode 1374.000000, reward total was -20.000000. running mean: -20.046633\n",
            "resetting env. episode 1375.000000, reward total was -20.000000. running mean: -20.046167\n",
            "resetting env. episode 1376.000000, reward total was -21.000000. running mean: -20.055705\n",
            "resetting env. episode 1377.000000, reward total was -19.000000. running mean: -20.045148\n",
            "resetting env. episode 1378.000000, reward total was -21.000000. running mean: -20.054697\n",
            "resetting env. episode 1379.000000, reward total was -21.000000. running mean: -20.064150\n",
            "resetting env. episode 1380.000000, reward total was -21.000000. running mean: -20.073508\n",
            "resetting env. episode 1381.000000, reward total was -20.000000. running mean: -20.072773\n",
            "resetting env. episode 1382.000000, reward total was -20.000000. running mean: -20.072045\n",
            "resetting env. episode 1383.000000, reward total was -20.000000. running mean: -20.071325\n",
            "resetting env. episode 1384.000000, reward total was -21.000000. running mean: -20.080612\n",
            "resetting env. episode 1385.000000, reward total was -20.000000. running mean: -20.079806\n",
            "resetting env. episode 1386.000000, reward total was -20.000000. running mean: -20.079008\n",
            "resetting env. episode 1387.000000, reward total was -19.000000. running mean: -20.068217\n",
            "resetting env. episode 1388.000000, reward total was -19.000000. running mean: -20.057535\n",
            "resetting env. episode 1389.000000, reward total was -19.000000. running mean: -20.046960\n",
            "resetting env. episode 1390.000000, reward total was -20.000000. running mean: -20.046490\n",
            "resetting env. episode 1391.000000, reward total was -20.000000. running mean: -20.046025\n",
            "resetting env. episode 1392.000000, reward total was -20.000000. running mean: -20.045565\n",
            "resetting env. episode 1393.000000, reward total was -21.000000. running mean: -20.055110\n",
            "resetting env. episode 1394.000000, reward total was -19.000000. running mean: -20.044558\n",
            "resetting env. episode 1395.000000, reward total was -20.000000. running mean: -20.044113\n",
            "resetting env. episode 1396.000000, reward total was -21.000000. running mean: -20.053672\n",
            "resetting env. episode 1397.000000, reward total was -21.000000. running mean: -20.063135\n",
            "resetting env. episode 1398.000000, reward total was -21.000000. running mean: -20.072504\n",
            "resetting env. episode 1399.000000, reward total was -19.000000. running mean: -20.061779\n",
            "resetting env. episode 1400.000000, reward total was -21.000000. running mean: -20.071161\n",
            "resetting env. episode 1401.000000, reward total was -18.000000. running mean: -20.050449\n",
            "resetting env. episode 1402.000000, reward total was -21.000000. running mean: -20.059945\n",
            "resetting env. episode 1403.000000, reward total was -21.000000. running mean: -20.069345\n",
            "resetting env. episode 1404.000000, reward total was -21.000000. running mean: -20.078652\n",
            "resetting env. episode 1405.000000, reward total was -21.000000. running mean: -20.087865\n",
            "resetting env. episode 1406.000000, reward total was -21.000000. running mean: -20.096987\n",
            "resetting env. episode 1407.000000, reward total was -20.000000. running mean: -20.096017\n",
            "resetting env. episode 1408.000000, reward total was -21.000000. running mean: -20.105057\n",
            "resetting env. episode 1409.000000, reward total was -20.000000. running mean: -20.104006\n",
            "resetting env. episode 1410.000000, reward total was -21.000000. running mean: -20.112966\n",
            "resetting env. episode 1411.000000, reward total was -21.000000. running mean: -20.121836\n",
            "resetting env. episode 1412.000000, reward total was -21.000000. running mean: -20.130618\n",
            "resetting env. episode 1413.000000, reward total was -19.000000. running mean: -20.119312\n",
            "resetting env. episode 1414.000000, reward total was -19.000000. running mean: -20.108119\n",
            "resetting env. episode 1415.000000, reward total was -21.000000. running mean: -20.117037\n",
            "resetting env. episode 1416.000000, reward total was -19.000000. running mean: -20.105867\n",
            "resetting env. episode 1417.000000, reward total was -19.000000. running mean: -20.094808\n",
            "resetting env. episode 1418.000000, reward total was -20.000000. running mean: -20.093860\n",
            "resetting env. episode 1419.000000, reward total was -20.000000. running mean: -20.092922\n",
            "resetting env. episode 1420.000000, reward total was -19.000000. running mean: -20.081993\n",
            "resetting env. episode 1421.000000, reward total was -20.000000. running mean: -20.081173\n",
            "resetting env. episode 1422.000000, reward total was -20.000000. running mean: -20.080361\n",
            "resetting env. episode 1423.000000, reward total was -21.000000. running mean: -20.089557\n",
            "resetting env. episode 1424.000000, reward total was -19.000000. running mean: -20.078662\n",
            "resetting env. episode 1425.000000, reward total was -20.000000. running mean: -20.077875\n",
            "resetting env. episode 1426.000000, reward total was -20.000000. running mean: -20.077096\n",
            "resetting env. episode 1427.000000, reward total was -20.000000. running mean: -20.076325\n",
            "resetting env. episode 1428.000000, reward total was -21.000000. running mean: -20.085562\n",
            "resetting env. episode 1429.000000, reward total was -21.000000. running mean: -20.094707\n",
            "resetting env. episode 1430.000000, reward total was -19.000000. running mean: -20.083759\n",
            "resetting env. episode 1431.000000, reward total was -19.000000. running mean: -20.072922\n",
            "resetting env. episode 1432.000000, reward total was -20.000000. running mean: -20.072193\n",
            "resetting env. episode 1433.000000, reward total was -20.000000. running mean: -20.071471\n",
            "resetting env. episode 1434.000000, reward total was -20.000000. running mean: -20.070756\n",
            "resetting env. episode 1435.000000, reward total was -20.000000. running mean: -20.070048\n",
            "resetting env. episode 1436.000000, reward total was -20.000000. running mean: -20.069348\n",
            "resetting env. episode 1437.000000, reward total was -19.000000. running mean: -20.058654\n",
            "resetting env. episode 1438.000000, reward total was -20.000000. running mean: -20.058068\n",
            "resetting env. episode 1439.000000, reward total was -18.000000. running mean: -20.037487\n",
            "resetting env. episode 1440.000000, reward total was -21.000000. running mean: -20.047112\n",
            "resetting env. episode 1441.000000, reward total was -18.000000. running mean: -20.026641\n",
            "resetting env. episode 1442.000000, reward total was -21.000000. running mean: -20.036375\n",
            "resetting env. episode 1443.000000, reward total was -21.000000. running mean: -20.046011\n",
            "resetting env. episode 1444.000000, reward total was -20.000000. running mean: -20.045551\n",
            "resetting env. episode 1445.000000, reward total was -20.000000. running mean: -20.045095\n",
            "resetting env. episode 1446.000000, reward total was -19.000000. running mean: -20.034645\n",
            "resetting env. episode 1447.000000, reward total was -18.000000. running mean: -20.014298\n",
            "resetting env. episode 1448.000000, reward total was -21.000000. running mean: -20.024155\n",
            "resetting env. episode 1449.000000, reward total was -18.000000. running mean: -20.003914\n",
            "resetting env. episode 1450.000000, reward total was -20.000000. running mean: -20.003874\n",
            "resetting env. episode 1451.000000, reward total was -21.000000. running mean: -20.013836\n",
            "resetting env. episode 1452.000000, reward total was -20.000000. running mean: -20.013697\n",
            "resetting env. episode 1453.000000, reward total was -15.000000. running mean: -19.963560\n",
            "resetting env. episode 1454.000000, reward total was -19.000000. running mean: -19.953925\n",
            "resetting env. episode 1455.000000, reward total was -21.000000. running mean: -19.964385\n",
            "resetting env. episode 1456.000000, reward total was -21.000000. running mean: -19.974742\n",
            "resetting env. episode 1457.000000, reward total was -19.000000. running mean: -19.964994\n",
            "resetting env. episode 1458.000000, reward total was -21.000000. running mean: -19.975344\n",
            "resetting env. episode 1459.000000, reward total was -21.000000. running mean: -19.985591\n",
            "resetting env. episode 1460.000000, reward total was -18.000000. running mean: -19.965735\n",
            "resetting env. episode 1461.000000, reward total was -19.000000. running mean: -19.956078\n",
            "resetting env. episode 1462.000000, reward total was -19.000000. running mean: -19.946517\n",
            "resetting env. episode 1463.000000, reward total was -20.000000. running mean: -19.947052\n",
            "resetting env. episode 1464.000000, reward total was -21.000000. running mean: -19.957581\n",
            "resetting env. episode 1465.000000, reward total was -21.000000. running mean: -19.968005\n",
            "resetting env. episode 1466.000000, reward total was -20.000000. running mean: -19.968325\n",
            "resetting env. episode 1467.000000, reward total was -20.000000. running mean: -19.968642\n",
            "resetting env. episode 1468.000000, reward total was -20.000000. running mean: -19.968956\n",
            "resetting env. episode 1469.000000, reward total was -20.000000. running mean: -19.969266\n",
            "resetting env. episode 1470.000000, reward total was -21.000000. running mean: -19.979573\n",
            "resetting env. episode 1471.000000, reward total was -21.000000. running mean: -19.989778\n",
            "resetting env. episode 1472.000000, reward total was -19.000000. running mean: -19.979880\n",
            "resetting env. episode 1473.000000, reward total was -20.000000. running mean: -19.980081\n",
            "resetting env. episode 1474.000000, reward total was -20.000000. running mean: -19.980280\n",
            "resetting env. episode 1475.000000, reward total was -21.000000. running mean: -19.990477\n",
            "resetting env. episode 1476.000000, reward total was -20.000000. running mean: -19.990573\n",
            "resetting env. episode 1477.000000, reward total was -19.000000. running mean: -19.980667\n",
            "resetting env. episode 1478.000000, reward total was -21.000000. running mean: -19.990860\n",
            "resetting env. episode 1479.000000, reward total was -21.000000. running mean: -20.000952\n",
            "resetting env. episode 1480.000000, reward total was -19.000000. running mean: -19.990942\n",
            "resetting env. episode 1481.000000, reward total was -21.000000. running mean: -20.001033\n",
            "resetting env. episode 1482.000000, reward total was -20.000000. running mean: -20.001022\n",
            "resetting env. episode 1483.000000, reward total was -18.000000. running mean: -19.981012\n",
            "resetting env. episode 1484.000000, reward total was -19.000000. running mean: -19.971202\n",
            "resetting env. episode 1485.000000, reward total was -19.000000. running mean: -19.961490\n",
            "resetting env. episode 1486.000000, reward total was -21.000000. running mean: -19.971875\n",
            "resetting env. episode 1487.000000, reward total was -21.000000. running mean: -19.982156\n",
            "resetting env. episode 1488.000000, reward total was -21.000000. running mean: -19.992335\n",
            "resetting env. episode 1489.000000, reward total was -20.000000. running mean: -19.992411\n",
            "resetting env. episode 1490.000000, reward total was -20.000000. running mean: -19.992487\n",
            "resetting env. episode 1491.000000, reward total was -21.000000. running mean: -20.002562\n",
            "resetting env. episode 1492.000000, reward total was -20.000000. running mean: -20.002537\n",
            "resetting env. episode 1493.000000, reward total was -18.000000. running mean: -19.982511\n",
            "resetting env. episode 1494.000000, reward total was -21.000000. running mean: -19.992686\n",
            "resetting env. episode 1495.000000, reward total was -19.000000. running mean: -19.982760\n",
            "resetting env. episode 1496.000000, reward total was -19.000000. running mean: -19.972932\n",
            "resetting env. episode 1497.000000, reward total was -20.000000. running mean: -19.973203\n",
            "resetting env. episode 1498.000000, reward total was -19.000000. running mean: -19.963471\n",
            "resetting env. episode 1499.000000, reward total was -20.000000. running mean: -19.963836\n",
            "resetting env. episode 1500.000000, reward total was -21.000000. running mean: -19.974197\n",
            "resetting env. episode 1501.000000, reward total was -21.000000. running mean: -19.984456\n",
            "resetting env. episode 1502.000000, reward total was -19.000000. running mean: -19.974611\n",
            "resetting env. episode 1503.000000, reward total was -21.000000. running mean: -19.984865\n",
            "resetting env. episode 1504.000000, reward total was -21.000000. running mean: -19.995016\n",
            "resetting env. episode 1505.000000, reward total was -18.000000. running mean: -19.975066\n",
            "resetting env. episode 1506.000000, reward total was -21.000000. running mean: -19.985315\n",
            "resetting env. episode 1507.000000, reward total was -21.000000. running mean: -19.995462\n",
            "resetting env. episode 1508.000000, reward total was -20.000000. running mean: -19.995508\n",
            "resetting env. episode 1509.000000, reward total was -21.000000. running mean: -20.005553\n",
            "resetting env. episode 1510.000000, reward total was -21.000000. running mean: -20.015497\n",
            "resetting env. episode 1511.000000, reward total was -21.000000. running mean: -20.025342\n",
            "resetting env. episode 1512.000000, reward total was -19.000000. running mean: -20.015089\n",
            "resetting env. episode 1513.000000, reward total was -18.000000. running mean: -19.994938\n",
            "resetting env. episode 1514.000000, reward total was -21.000000. running mean: -20.004988\n",
            "resetting env. episode 1515.000000, reward total was -20.000000. running mean: -20.004938\n",
            "resetting env. episode 1516.000000, reward total was -21.000000. running mean: -20.014889\n",
            "resetting env. episode 1517.000000, reward total was -20.000000. running mean: -20.014740\n",
            "resetting env. episode 1518.000000, reward total was -21.000000. running mean: -20.024593\n",
            "resetting env. episode 1519.000000, reward total was -20.000000. running mean: -20.024347\n",
            "resetting env. episode 1520.000000, reward total was -21.000000. running mean: -20.034103\n",
            "resetting env. episode 1521.000000, reward total was -21.000000. running mean: -20.043762\n",
            "resetting env. episode 1522.000000, reward total was -19.000000. running mean: -20.033325\n",
            "resetting env. episode 1523.000000, reward total was -20.000000. running mean: -20.032991\n",
            "resetting env. episode 1524.000000, reward total was -21.000000. running mean: -20.042662\n",
            "resetting env. episode 1525.000000, reward total was -21.000000. running mean: -20.052235\n",
            "resetting env. episode 1526.000000, reward total was -21.000000. running mean: -20.061713\n",
            "resetting env. episode 1527.000000, reward total was -20.000000. running mean: -20.061095\n",
            "resetting env. episode 1528.000000, reward total was -19.000000. running mean: -20.050485\n",
            "resetting env. episode 1529.000000, reward total was -21.000000. running mean: -20.059980\n",
            "resetting env. episode 1530.000000, reward total was -20.000000. running mean: -20.059380\n",
            "resetting env. episode 1531.000000, reward total was -20.000000. running mean: -20.058786\n",
            "resetting env. episode 1532.000000, reward total was -21.000000. running mean: -20.068198\n",
            "resetting env. episode 1533.000000, reward total was -21.000000. running mean: -20.077516\n",
            "resetting env. episode 1534.000000, reward total was -21.000000. running mean: -20.086741\n",
            "resetting env. episode 1535.000000, reward total was -20.000000. running mean: -20.085874\n",
            "resetting env. episode 1536.000000, reward total was -21.000000. running mean: -20.095015\n",
            "resetting env. episode 1537.000000, reward total was -20.000000. running mean: -20.094065\n",
            "resetting env. episode 1538.000000, reward total was -20.000000. running mean: -20.093124\n",
            "resetting env. episode 1539.000000, reward total was -21.000000. running mean: -20.102193\n",
            "resetting env. episode 1540.000000, reward total was -21.000000. running mean: -20.111171\n",
            "resetting env. episode 1541.000000, reward total was -20.000000. running mean: -20.110059\n",
            "resetting env. episode 1542.000000, reward total was -21.000000. running mean: -20.118959\n",
            "resetting env. episode 1543.000000, reward total was -18.000000. running mean: -20.097769\n",
            "resetting env. episode 1544.000000, reward total was -18.000000. running mean: -20.076791\n",
            "resetting env. episode 1545.000000, reward total was -19.000000. running mean: -20.066023\n",
            "resetting env. episode 1546.000000, reward total was -20.000000. running mean: -20.065363\n",
            "resetting env. episode 1547.000000, reward total was -19.000000. running mean: -20.054710\n",
            "resetting env. episode 1548.000000, reward total was -20.000000. running mean: -20.054163\n",
            "resetting env. episode 1549.000000, reward total was -21.000000. running mean: -20.063621\n",
            "resetting env. episode 1550.000000, reward total was -20.000000. running mean: -20.062985\n",
            "resetting env. episode 1551.000000, reward total was -20.000000. running mean: -20.062355\n",
            "resetting env. episode 1552.000000, reward total was -20.000000. running mean: -20.061731\n",
            "resetting env. episode 1553.000000, reward total was -20.000000. running mean: -20.061114\n",
            "resetting env. episode 1554.000000, reward total was -18.000000. running mean: -20.040503\n",
            "resetting env. episode 1555.000000, reward total was -20.000000. running mean: -20.040098\n",
            "resetting env. episode 1556.000000, reward total was -21.000000. running mean: -20.049697\n",
            "resetting env. episode 1557.000000, reward total was -18.000000. running mean: -20.029200\n",
            "resetting env. episode 1558.000000, reward total was -21.000000. running mean: -20.038908\n",
            "resetting env. episode 1559.000000, reward total was -20.000000. running mean: -20.038519\n",
            "resetting env. episode 1560.000000, reward total was -21.000000. running mean: -20.048134\n",
            "resetting env. episode 1561.000000, reward total was -20.000000. running mean: -20.047652\n",
            "resetting env. episode 1562.000000, reward total was -21.000000. running mean: -20.057176\n",
            "resetting env. episode 1563.000000, reward total was -21.000000. running mean: -20.066604\n",
            "resetting env. episode 1564.000000, reward total was -20.000000. running mean: -20.065938\n",
            "resetting env. episode 1565.000000, reward total was -21.000000. running mean: -20.075279\n",
            "resetting env. episode 1566.000000, reward total was -21.000000. running mean: -20.084526\n",
            "resetting env. episode 1567.000000, reward total was -20.000000. running mean: -20.083681\n",
            "resetting env. episode 1568.000000, reward total was -20.000000. running mean: -20.082844\n",
            "resetting env. episode 1569.000000, reward total was -21.000000. running mean: -20.092015\n",
            "resetting env. episode 1570.000000, reward total was -21.000000. running mean: -20.101095\n",
            "resetting env. episode 1571.000000, reward total was -20.000000. running mean: -20.100084\n",
            "resetting env. episode 1572.000000, reward total was -21.000000. running mean: -20.109083\n",
            "resetting env. episode 1573.000000, reward total was -21.000000. running mean: -20.117992\n",
            "resetting env. episode 1574.000000, reward total was -20.000000. running mean: -20.116813\n",
            "resetting env. episode 1575.000000, reward total was -21.000000. running mean: -20.125644\n",
            "resetting env. episode 1576.000000, reward total was -20.000000. running mean: -20.124388\n",
            "resetting env. episode 1577.000000, reward total was -19.000000. running mean: -20.113144\n",
            "resetting env. episode 1578.000000, reward total was -19.000000. running mean: -20.102013\n",
            "resetting env. episode 1579.000000, reward total was -18.000000. running mean: -20.080993\n",
            "resetting env. episode 1580.000000, reward total was -20.000000. running mean: -20.080183\n",
            "resetting env. episode 1581.000000, reward total was -20.000000. running mean: -20.079381\n",
            "resetting env. episode 1582.000000, reward total was -20.000000. running mean: -20.078587\n",
            "resetting env. episode 1583.000000, reward total was -21.000000. running mean: -20.087801\n",
            "resetting env. episode 1584.000000, reward total was -19.000000. running mean: -20.076923\n",
            "resetting env. episode 1585.000000, reward total was -19.000000. running mean: -20.066154\n",
            "resetting env. episode 1586.000000, reward total was -19.000000. running mean: -20.055492\n",
            "resetting env. episode 1587.000000, reward total was -17.000000. running mean: -20.024937\n",
            "resetting env. episode 1588.000000, reward total was -20.000000. running mean: -20.024688\n",
            "resetting env. episode 1589.000000, reward total was -20.000000. running mean: -20.024441\n",
            "resetting env. episode 1590.000000, reward total was -21.000000. running mean: -20.034197\n",
            "resetting env. episode 1591.000000, reward total was -20.000000. running mean: -20.033855\n",
            "resetting env. episode 1592.000000, reward total was -17.000000. running mean: -20.003516\n",
            "resetting env. episode 1593.000000, reward total was -20.000000. running mean: -20.003481\n",
            "resetting env. episode 1594.000000, reward total was -21.000000. running mean: -20.013446\n",
            "resetting env. episode 1595.000000, reward total was -20.000000. running mean: -20.013312\n",
            "resetting env. episode 1596.000000, reward total was -19.000000. running mean: -20.003179\n",
            "resetting env. episode 1597.000000, reward total was -21.000000. running mean: -20.013147\n",
            "resetting env. episode 1598.000000, reward total was -18.000000. running mean: -19.993015\n",
            "resetting env. episode 1599.000000, reward total was -20.000000. running mean: -19.993085\n",
            "resetting env. episode 1600.000000, reward total was -19.000000. running mean: -19.983154\n",
            "resetting env. episode 1601.000000, reward total was -21.000000. running mean: -19.993323\n",
            "resetting env. episode 1602.000000, reward total was -17.000000. running mean: -19.963390\n",
            "resetting env. episode 1603.000000, reward total was -20.000000. running mean: -19.963756\n",
            "resetting env. episode 1604.000000, reward total was -21.000000. running mean: -19.974118\n",
            "resetting env. episode 1605.000000, reward total was -21.000000. running mean: -19.984377\n",
            "resetting env. episode 1606.000000, reward total was -21.000000. running mean: -19.994533\n",
            "resetting env. episode 1607.000000, reward total was -21.000000. running mean: -20.004588\n",
            "resetting env. episode 1608.000000, reward total was -19.000000. running mean: -19.994542\n",
            "resetting env. episode 1609.000000, reward total was -21.000000. running mean: -20.004597\n",
            "resetting env. episode 1610.000000, reward total was -21.000000. running mean: -20.014551\n",
            "resetting env. episode 1611.000000, reward total was -21.000000. running mean: -20.024405\n",
            "resetting env. episode 1612.000000, reward total was -21.000000. running mean: -20.034161\n",
            "resetting env. episode 1613.000000, reward total was -19.000000. running mean: -20.023819\n",
            "resetting env. episode 1614.000000, reward total was -21.000000. running mean: -20.033581\n",
            "resetting env. episode 1615.000000, reward total was -21.000000. running mean: -20.043245\n",
            "resetting env. episode 1616.000000, reward total was -19.000000. running mean: -20.032813\n",
            "resetting env. episode 1617.000000, reward total was -18.000000. running mean: -20.012485\n",
            "resetting env. episode 1618.000000, reward total was -19.000000. running mean: -20.002360\n",
            "resetting env. episode 1619.000000, reward total was -21.000000. running mean: -20.012336\n",
            "resetting env. episode 1620.000000, reward total was -21.000000. running mean: -20.022213\n",
            "resetting env. episode 1621.000000, reward total was -20.000000. running mean: -20.021991\n",
            "resetting env. episode 1622.000000, reward total was -21.000000. running mean: -20.031771\n",
            "resetting env. episode 1623.000000, reward total was -21.000000. running mean: -20.041453\n",
            "resetting env. episode 1624.000000, reward total was -19.000000. running mean: -20.031039\n",
            "resetting env. episode 1625.000000, reward total was -21.000000. running mean: -20.040728\n",
            "resetting env. episode 1626.000000, reward total was -19.000000. running mean: -20.030321\n",
            "resetting env. episode 1627.000000, reward total was -21.000000. running mean: -20.040018\n",
            "resetting env. episode 1628.000000, reward total was -20.000000. running mean: -20.039618\n",
            "resetting env. episode 1629.000000, reward total was -21.000000. running mean: -20.049222\n",
            "resetting env. episode 1630.000000, reward total was -20.000000. running mean: -20.048729\n",
            "resetting env. episode 1631.000000, reward total was -20.000000. running mean: -20.048242\n",
            "resetting env. episode 1632.000000, reward total was -20.000000. running mean: -20.047760\n",
            "resetting env. episode 1633.000000, reward total was -18.000000. running mean: -20.027282\n",
            "resetting env. episode 1634.000000, reward total was -20.000000. running mean: -20.027009\n",
            "resetting env. episode 1635.000000, reward total was -19.000000. running mean: -20.016739\n",
            "resetting env. episode 1636.000000, reward total was -20.000000. running mean: -20.016572\n",
            "resetting env. episode 1637.000000, reward total was -18.000000. running mean: -19.996406\n",
            "resetting env. episode 1638.000000, reward total was -21.000000. running mean: -20.006442\n",
            "resetting env. episode 1639.000000, reward total was -21.000000. running mean: -20.016378\n",
            "resetting env. episode 1640.000000, reward total was -21.000000. running mean: -20.026214\n",
            "resetting env. episode 1641.000000, reward total was -20.000000. running mean: -20.025952\n",
            "resetting env. episode 1642.000000, reward total was -17.000000. running mean: -19.995692\n",
            "resetting env. episode 1643.000000, reward total was -19.000000. running mean: -19.985735\n",
            "resetting env. episode 1644.000000, reward total was -20.000000. running mean: -19.985878\n",
            "resetting env. episode 1645.000000, reward total was -21.000000. running mean: -19.996019\n",
            "resetting env. episode 1646.000000, reward total was -18.000000. running mean: -19.976059\n",
            "resetting env. episode 1647.000000, reward total was -19.000000. running mean: -19.966298\n",
            "resetting env. episode 1648.000000, reward total was -20.000000. running mean: -19.966635\n",
            "resetting env. episode 1649.000000, reward total was -19.000000. running mean: -19.956969\n",
            "resetting env. episode 1650.000000, reward total was -21.000000. running mean: -19.967399\n",
            "resetting env. episode 1651.000000, reward total was -20.000000. running mean: -19.967725\n",
            "resetting env. episode 1652.000000, reward total was -20.000000. running mean: -19.968048\n",
            "resetting env. episode 1653.000000, reward total was -21.000000. running mean: -19.978368\n",
            "resetting env. episode 1654.000000, reward total was -21.000000. running mean: -19.988584\n",
            "resetting env. episode 1655.000000, reward total was -19.000000. running mean: -19.978698\n",
            "resetting env. episode 1656.000000, reward total was -19.000000. running mean: -19.968911\n",
            "resetting env. episode 1657.000000, reward total was -20.000000. running mean: -19.969222\n",
            "resetting env. episode 1658.000000, reward total was -20.000000. running mean: -19.969530\n",
            "resetting env. episode 1659.000000, reward total was -21.000000. running mean: -19.979834\n",
            "resetting env. episode 1660.000000, reward total was -18.000000. running mean: -19.960036\n",
            "resetting env. episode 1661.000000, reward total was -20.000000. running mean: -19.960436\n",
            "resetting env. episode 1662.000000, reward total was -21.000000. running mean: -19.970831\n",
            "resetting env. episode 1663.000000, reward total was -18.000000. running mean: -19.951123\n",
            "resetting env. episode 1664.000000, reward total was -21.000000. running mean: -19.961612\n",
            "resetting env. episode 1665.000000, reward total was -21.000000. running mean: -19.971996\n",
            "resetting env. episode 1666.000000, reward total was -20.000000. running mean: -19.972276\n",
            "resetting env. episode 1667.000000, reward total was -20.000000. running mean: -19.972553\n",
            "resetting env. episode 1668.000000, reward total was -20.000000. running mean: -19.972827\n",
            "resetting env. episode 1669.000000, reward total was -21.000000. running mean: -19.983099\n",
            "resetting env. episode 1670.000000, reward total was -21.000000. running mean: -19.993268\n",
            "resetting env. episode 1671.000000, reward total was -21.000000. running mean: -20.003335\n",
            "resetting env. episode 1672.000000, reward total was -19.000000. running mean: -19.993302\n",
            "resetting env. episode 1673.000000, reward total was -19.000000. running mean: -19.983369\n",
            "resetting env. episode 1674.000000, reward total was -20.000000. running mean: -19.983535\n",
            "resetting env. episode 1675.000000, reward total was -18.000000. running mean: -19.963700\n",
            "resetting env. episode 1676.000000, reward total was -20.000000. running mean: -19.964063\n",
            "resetting env. episode 1677.000000, reward total was -21.000000. running mean: -19.974422\n",
            "resetting env. episode 1678.000000, reward total was -20.000000. running mean: -19.974678\n",
            "resetting env. episode 1679.000000, reward total was -18.000000. running mean: -19.954931\n",
            "resetting env. episode 1680.000000, reward total was -19.000000. running mean: -19.945382\n",
            "resetting env. episode 1681.000000, reward total was -20.000000. running mean: -19.945928\n",
            "resetting env. episode 1682.000000, reward total was -18.000000. running mean: -19.926469\n",
            "resetting env. episode 1683.000000, reward total was -19.000000. running mean: -19.917204\n",
            "resetting env. episode 1684.000000, reward total was -17.000000. running mean: -19.888032\n",
            "resetting env. episode 1685.000000, reward total was -17.000000. running mean: -19.859152\n",
            "resetting env. episode 1686.000000, reward total was -19.000000. running mean: -19.850560\n",
            "resetting env. episode 1687.000000, reward total was -21.000000. running mean: -19.862055\n",
            "resetting env. episode 1688.000000, reward total was -19.000000. running mean: -19.853434\n",
            "resetting env. episode 1689.000000, reward total was -21.000000. running mean: -19.864900\n",
            "resetting env. episode 1690.000000, reward total was -20.000000. running mean: -19.866251\n",
            "resetting env. episode 1691.000000, reward total was -20.000000. running mean: -19.867588\n",
            "resetting env. episode 1692.000000, reward total was -18.000000. running mean: -19.848913\n",
            "resetting env. episode 1693.000000, reward total was -19.000000. running mean: -19.840423\n",
            "resetting env. episode 1694.000000, reward total was -20.000000. running mean: -19.842019\n",
            "resetting env. episode 1695.000000, reward total was -20.000000. running mean: -19.843599\n",
            "resetting env. episode 1696.000000, reward total was -21.000000. running mean: -19.855163\n",
            "resetting env. episode 1697.000000, reward total was -19.000000. running mean: -19.846611\n",
            "resetting env. episode 1698.000000, reward total was -21.000000. running mean: -19.858145\n",
            "resetting env. episode 1699.000000, reward total was -21.000000. running mean: -19.869564\n",
            "resetting env. episode 1700.000000, reward total was -20.000000. running mean: -19.870868\n",
            "resetting env. episode 1701.000000, reward total was -19.000000. running mean: -19.862159\n",
            "resetting env. episode 1702.000000, reward total was -17.000000. running mean: -19.833538\n",
            "resetting env. episode 1703.000000, reward total was -19.000000. running mean: -19.825203\n",
            "resetting env. episode 1704.000000, reward total was -20.000000. running mean: -19.826950\n",
            "resetting env. episode 1705.000000, reward total was -18.000000. running mean: -19.808681\n",
            "resetting env. episode 1706.000000, reward total was -21.000000. running mean: -19.820594\n",
            "resetting env. episode 1707.000000, reward total was -21.000000. running mean: -19.832388\n",
            "resetting env. episode 1708.000000, reward total was -21.000000. running mean: -19.844064\n",
            "resetting env. episode 1709.000000, reward total was -19.000000. running mean: -19.835624\n",
            "resetting env. episode 1710.000000, reward total was -20.000000. running mean: -19.837267\n",
            "resetting env. episode 1711.000000, reward total was -21.000000. running mean: -19.848895\n",
            "resetting env. episode 1712.000000, reward total was -20.000000. running mean: -19.850406\n",
            "resetting env. episode 1713.000000, reward total was -21.000000. running mean: -19.861902\n",
            "resetting env. episode 1714.000000, reward total was -20.000000. running mean: -19.863283\n",
            "resetting env. episode 1715.000000, reward total was -19.000000. running mean: -19.854650\n",
            "resetting env. episode 1716.000000, reward total was -18.000000. running mean: -19.836103\n",
            "resetting env. episode 1717.000000, reward total was -20.000000. running mean: -19.837742\n",
            "resetting env. episode 1718.000000, reward total was -16.000000. running mean: -19.799365\n",
            "resetting env. episode 1719.000000, reward total was -18.000000. running mean: -19.781371\n",
            "resetting env. episode 1720.000000, reward total was -19.000000. running mean: -19.773558\n",
            "resetting env. episode 1721.000000, reward total was -21.000000. running mean: -19.785822\n",
            "resetting env. episode 1722.000000, reward total was -19.000000. running mean: -19.777964\n",
            "resetting env. episode 1723.000000, reward total was -20.000000. running mean: -19.780184\n",
            "resetting env. episode 1724.000000, reward total was -19.000000. running mean: -19.772382\n",
            "resetting env. episode 1725.000000, reward total was -20.000000. running mean: -19.774659\n",
            "resetting env. episode 1726.000000, reward total was -15.000000. running mean: -19.726912\n",
            "resetting env. episode 1727.000000, reward total was -21.000000. running mean: -19.739643\n",
            "resetting env. episode 1728.000000, reward total was -21.000000. running mean: -19.752246\n",
            "resetting env. episode 1729.000000, reward total was -20.000000. running mean: -19.754724\n",
            "resetting env. episode 1730.000000, reward total was -18.000000. running mean: -19.737177\n",
            "resetting env. episode 1731.000000, reward total was -21.000000. running mean: -19.749805\n",
            "resetting env. episode 1732.000000, reward total was -17.000000. running mean: -19.722307\n",
            "resetting env. episode 1733.000000, reward total was -21.000000. running mean: -19.735084\n",
            "resetting env. episode 1734.000000, reward total was -19.000000. running mean: -19.727733\n",
            "resetting env. episode 1735.000000, reward total was -21.000000. running mean: -19.740456\n",
            "resetting env. episode 1736.000000, reward total was -21.000000. running mean: -19.753051\n",
            "resetting env. episode 1737.000000, reward total was -19.000000. running mean: -19.745521\n",
            "resetting env. episode 1738.000000, reward total was -20.000000. running mean: -19.748065\n",
            "resetting env. episode 1739.000000, reward total was -21.000000. running mean: -19.760585\n",
            "resetting env. episode 1740.000000, reward total was -21.000000. running mean: -19.772979\n",
            "resetting env. episode 1741.000000, reward total was -20.000000. running mean: -19.775249\n",
            "resetting env. episode 1742.000000, reward total was -21.000000. running mean: -19.787497\n",
            "resetting env. episode 1743.000000, reward total was -19.000000. running mean: -19.779622\n",
            "resetting env. episode 1744.000000, reward total was -21.000000. running mean: -19.791825\n",
            "resetting env. episode 1745.000000, reward total was -21.000000. running mean: -19.803907\n",
            "resetting env. episode 1746.000000, reward total was -20.000000. running mean: -19.805868\n",
            "resetting env. episode 1747.000000, reward total was -20.000000. running mean: -19.807809\n",
            "resetting env. episode 1748.000000, reward total was -21.000000. running mean: -19.819731\n",
            "resetting env. episode 1749.000000, reward total was -21.000000. running mean: -19.831534\n",
            "resetting env. episode 1750.000000, reward total was -20.000000. running mean: -19.833219\n",
            "resetting env. episode 1751.000000, reward total was -20.000000. running mean: -19.834886\n",
            "resetting env. episode 1752.000000, reward total was -20.000000. running mean: -19.836538\n",
            "resetting env. episode 1753.000000, reward total was -20.000000. running mean: -19.838172\n",
            "resetting env. episode 1754.000000, reward total was -21.000000. running mean: -19.849790\n",
            "resetting env. episode 1755.000000, reward total was -20.000000. running mean: -19.851293\n",
            "resetting env. episode 1756.000000, reward total was -20.000000. running mean: -19.852780\n",
            "resetting env. episode 1757.000000, reward total was -19.000000. running mean: -19.844252\n",
            "resetting env. episode 1758.000000, reward total was -20.000000. running mean: -19.845809\n",
            "resetting env. episode 1759.000000, reward total was -20.000000. running mean: -19.847351\n",
            "resetting env. episode 1760.000000, reward total was -19.000000. running mean: -19.838878\n",
            "resetting env. episode 1761.000000, reward total was -21.000000. running mean: -19.850489\n",
            "resetting env. episode 1762.000000, reward total was -21.000000. running mean: -19.861984\n",
            "resetting env. episode 1763.000000, reward total was -17.000000. running mean: -19.833364\n",
            "resetting env. episode 1764.000000, reward total was -21.000000. running mean: -19.845031\n",
            "resetting env. episode 1765.000000, reward total was -21.000000. running mean: -19.856580\n",
            "resetting env. episode 1766.000000, reward total was -18.000000. running mean: -19.838014\n",
            "resetting env. episode 1767.000000, reward total was -20.000000. running mean: -19.839634\n",
            "resetting env. episode 1768.000000, reward total was -21.000000. running mean: -19.851238\n",
            "resetting env. episode 1769.000000, reward total was -21.000000. running mean: -19.862726\n",
            "resetting env. episode 1770.000000, reward total was -21.000000. running mean: -19.874098\n",
            "resetting env. episode 1771.000000, reward total was -21.000000. running mean: -19.885357\n",
            "resetting env. episode 1772.000000, reward total was -21.000000. running mean: -19.896504\n",
            "resetting env. episode 1773.000000, reward total was -21.000000. running mean: -19.907539\n",
            "resetting env. episode 1774.000000, reward total was -21.000000. running mean: -19.918463\n",
            "resetting env. episode 1775.000000, reward total was -21.000000. running mean: -19.929279\n",
            "resetting env. episode 1776.000000, reward total was -21.000000. running mean: -19.939986\n",
            "resetting env. episode 1777.000000, reward total was -21.000000. running mean: -19.950586\n",
            "resetting env. episode 1778.000000, reward total was -21.000000. running mean: -19.961080\n",
            "resetting env. episode 1779.000000, reward total was -19.000000. running mean: -19.951469\n",
            "resetting env. episode 1780.000000, reward total was -21.000000. running mean: -19.961955\n",
            "resetting env. episode 1781.000000, reward total was -19.000000. running mean: -19.952335\n",
            "resetting env. episode 1782.000000, reward total was -20.000000. running mean: -19.952812\n",
            "resetting env. episode 1783.000000, reward total was -20.000000. running mean: -19.953284\n",
            "resetting env. episode 1784.000000, reward total was -19.000000. running mean: -19.943751\n",
            "resetting env. episode 1785.000000, reward total was -19.000000. running mean: -19.934313\n",
            "resetting env. episode 1786.000000, reward total was -17.000000. running mean: -19.904970\n",
            "resetting env. episode 1787.000000, reward total was -21.000000. running mean: -19.915921\n",
            "resetting env. episode 1788.000000, reward total was -18.000000. running mean: -19.896761\n",
            "resetting env. episode 1789.000000, reward total was -21.000000. running mean: -19.907794\n",
            "resetting env. episode 1790.000000, reward total was -21.000000. running mean: -19.918716\n",
            "resetting env. episode 1791.000000, reward total was -20.000000. running mean: -19.919529\n",
            "resetting env. episode 1792.000000, reward total was -21.000000. running mean: -19.930333\n",
            "resetting env. episode 1793.000000, reward total was -19.000000. running mean: -19.921030\n",
            "resetting env. episode 1794.000000, reward total was -21.000000. running mean: -19.931820\n",
            "resetting env. episode 1795.000000, reward total was -21.000000. running mean: -19.942502\n",
            "resetting env. episode 1796.000000, reward total was -20.000000. running mean: -19.943076\n",
            "resetting env. episode 1797.000000, reward total was -19.000000. running mean: -19.933646\n",
            "resetting env. episode 1798.000000, reward total was -21.000000. running mean: -19.944309\n",
            "resetting env. episode 1799.000000, reward total was -19.000000. running mean: -19.934866\n",
            "resetting env. episode 1800.000000, reward total was -18.000000. running mean: -19.915518\n",
            "resetting env. episode 1801.000000, reward total was -20.000000. running mean: -19.916362\n",
            "resetting env. episode 1802.000000, reward total was -20.000000. running mean: -19.917199\n",
            "resetting env. episode 1803.000000, reward total was -19.000000. running mean: -19.908027\n",
            "resetting env. episode 1804.000000, reward total was -21.000000. running mean: -19.918946\n",
            "resetting env. episode 1805.000000, reward total was -20.000000. running mean: -19.919757\n",
            "resetting env. episode 1806.000000, reward total was -20.000000. running mean: -19.920559\n",
            "resetting env. episode 1807.000000, reward total was -20.000000. running mean: -19.921354\n",
            "resetting env. episode 1808.000000, reward total was -21.000000. running mean: -19.932140\n",
            "resetting env. episode 1809.000000, reward total was -21.000000. running mean: -19.942819\n",
            "resetting env. episode 1810.000000, reward total was -19.000000. running mean: -19.933391\n",
            "resetting env. episode 1811.000000, reward total was -20.000000. running mean: -19.934057\n",
            "resetting env. episode 1812.000000, reward total was -21.000000. running mean: -19.944716\n",
            "resetting env. episode 1813.000000, reward total was -20.000000. running mean: -19.945269\n",
            "resetting env. episode 1814.000000, reward total was -20.000000. running mean: -19.945816\n",
            "resetting env. episode 1815.000000, reward total was -19.000000. running mean: -19.936358\n",
            "resetting env. episode 1816.000000, reward total was -21.000000. running mean: -19.946995\n",
            "resetting env. episode 1817.000000, reward total was -19.000000. running mean: -19.937525\n",
            "resetting env. episode 1818.000000, reward total was -20.000000. running mean: -19.938149\n",
            "resetting env. episode 1819.000000, reward total was -21.000000. running mean: -19.948768\n",
            "resetting env. episode 1820.000000, reward total was -21.000000. running mean: -19.959280\n",
            "resetting env. episode 1821.000000, reward total was -21.000000. running mean: -19.969687\n",
            "resetting env. episode 1822.000000, reward total was -20.000000. running mean: -19.969991\n",
            "resetting env. episode 1823.000000, reward total was -20.000000. running mean: -19.970291\n",
            "resetting env. episode 1824.000000, reward total was -21.000000. running mean: -19.980588\n",
            "resetting env. episode 1825.000000, reward total was -19.000000. running mean: -19.970782\n",
            "resetting env. episode 1826.000000, reward total was -20.000000. running mean: -19.971074\n",
            "resetting env. episode 1827.000000, reward total was -20.000000. running mean: -19.971363\n",
            "resetting env. episode 1828.000000, reward total was -20.000000. running mean: -19.971650\n",
            "resetting env. episode 1829.000000, reward total was -21.000000. running mean: -19.981933\n",
            "resetting env. episode 1830.000000, reward total was -20.000000. running mean: -19.982114\n",
            "resetting env. episode 1831.000000, reward total was -21.000000. running mean: -19.992293\n",
            "resetting env. episode 1832.000000, reward total was -21.000000. running mean: -20.002370\n",
            "resetting env. episode 1833.000000, reward total was -21.000000. running mean: -20.012346\n",
            "resetting env. episode 1834.000000, reward total was -21.000000. running mean: -20.022223\n",
            "resetting env. episode 1835.000000, reward total was -21.000000. running mean: -20.032000\n",
            "resetting env. episode 1836.000000, reward total was -20.000000. running mean: -20.031680\n",
            "resetting env. episode 1837.000000, reward total was -21.000000. running mean: -20.041364\n",
            "resetting env. episode 1838.000000, reward total was -21.000000. running mean: -20.050950\n",
            "resetting env. episode 1839.000000, reward total was -21.000000. running mean: -20.060440\n",
            "resetting env. episode 1840.000000, reward total was -19.000000. running mean: -20.049836\n",
            "resetting env. episode 1841.000000, reward total was -21.000000. running mean: -20.059338\n",
            "resetting env. episode 1842.000000, reward total was -16.000000. running mean: -20.018744\n",
            "resetting env. episode 1843.000000, reward total was -19.000000. running mean: -20.008557\n",
            "resetting env. episode 1844.000000, reward total was -20.000000. running mean: -20.008471\n",
            "resetting env. episode 1845.000000, reward total was -20.000000. running mean: -20.008387\n",
            "resetting env. episode 1846.000000, reward total was -21.000000. running mean: -20.018303\n",
            "resetting env. episode 1847.000000, reward total was -20.000000. running mean: -20.018120\n",
            "resetting env. episode 1848.000000, reward total was -20.000000. running mean: -20.017939\n",
            "resetting env. episode 1849.000000, reward total was -21.000000. running mean: -20.027759\n",
            "resetting env. episode 1850.000000, reward total was -20.000000. running mean: -20.027482\n",
            "resetting env. episode 1851.000000, reward total was -20.000000. running mean: -20.027207\n",
            "resetting env. episode 1852.000000, reward total was -21.000000. running mean: -20.036935\n",
            "resetting env. episode 1853.000000, reward total was -18.000000. running mean: -20.016565\n",
            "resetting env. episode 1854.000000, reward total was -17.000000. running mean: -19.986400\n",
            "resetting env. episode 1855.000000, reward total was -21.000000. running mean: -19.996536\n",
            "resetting env. episode 1856.000000, reward total was -21.000000. running mean: -20.006570\n",
            "resetting env. episode 1857.000000, reward total was -18.000000. running mean: -19.986505\n",
            "resetting env. episode 1858.000000, reward total was -20.000000. running mean: -19.986640\n",
            "resetting env. episode 1859.000000, reward total was -19.000000. running mean: -19.976773\n",
            "resetting env. episode 1860.000000, reward total was -20.000000. running mean: -19.977005\n",
            "resetting env. episode 1861.000000, reward total was -19.000000. running mean: -19.967235\n",
            "resetting env. episode 1862.000000, reward total was -20.000000. running mean: -19.967563\n",
            "resetting env. episode 1863.000000, reward total was -21.000000. running mean: -19.977887\n",
            "resetting env. episode 1864.000000, reward total was -18.000000. running mean: -19.958109\n",
            "resetting env. episode 1865.000000, reward total was -20.000000. running mean: -19.958527\n",
            "resetting env. episode 1866.000000, reward total was -19.000000. running mean: -19.948942\n",
            "resetting env. episode 1867.000000, reward total was -21.000000. running mean: -19.959453\n",
            "resetting env. episode 1868.000000, reward total was -20.000000. running mean: -19.959858\n",
            "resetting env. episode 1869.000000, reward total was -20.000000. running mean: -19.960260\n",
            "resetting env. episode 1870.000000, reward total was -21.000000. running mean: -19.970657\n",
            "resetting env. episode 1871.000000, reward total was -21.000000. running mean: -19.980950\n",
            "resetting env. episode 1872.000000, reward total was -19.000000. running mean: -19.971141\n",
            "resetting env. episode 1873.000000, reward total was -20.000000. running mean: -19.971430\n",
            "resetting env. episode 1874.000000, reward total was -20.000000. running mean: -19.971715\n",
            "resetting env. episode 1875.000000, reward total was -19.000000. running mean: -19.961998\n",
            "resetting env. episode 1876.000000, reward total was -21.000000. running mean: -19.972378\n",
            "resetting env. episode 1877.000000, reward total was -20.000000. running mean: -19.972654\n",
            "resetting env. episode 1878.000000, reward total was -21.000000. running mean: -19.982928\n",
            "resetting env. episode 1879.000000, reward total was -21.000000. running mean: -19.993099\n",
            "resetting env. episode 1880.000000, reward total was -20.000000. running mean: -19.993168\n",
            "resetting env. episode 1881.000000, reward total was -20.000000. running mean: -19.993236\n",
            "resetting env. episode 1882.000000, reward total was -17.000000. running mean: -19.963303\n",
            "resetting env. episode 1883.000000, reward total was -17.000000. running mean: -19.933670\n",
            "resetting env. episode 1884.000000, reward total was -21.000000. running mean: -19.944334\n",
            "resetting env. episode 1885.000000, reward total was -21.000000. running mean: -19.954890\n",
            "resetting env. episode 1886.000000, reward total was -19.000000. running mean: -19.945342\n",
            "resetting env. episode 1887.000000, reward total was -18.000000. running mean: -19.925888\n",
            "resetting env. episode 1888.000000, reward total was -18.000000. running mean: -19.906629\n",
            "resetting env. episode 1889.000000, reward total was -20.000000. running mean: -19.907563\n",
            "resetting env. episode 1890.000000, reward total was -19.000000. running mean: -19.898487\n",
            "resetting env. episode 1891.000000, reward total was -19.000000. running mean: -19.889502\n",
            "resetting env. episode 1892.000000, reward total was -18.000000. running mean: -19.870607\n",
            "resetting env. episode 1893.000000, reward total was -19.000000. running mean: -19.861901\n",
            "resetting env. episode 1894.000000, reward total was -21.000000. running mean: -19.873282\n",
            "resetting env. episode 1895.000000, reward total was -21.000000. running mean: -19.884549\n",
            "resetting env. episode 1896.000000, reward total was -20.000000. running mean: -19.885704\n",
            "resetting env. episode 1897.000000, reward total was -19.000000. running mean: -19.876847\n",
            "resetting env. episode 1898.000000, reward total was -19.000000. running mean: -19.868078\n",
            "resetting env. episode 1899.000000, reward total was -20.000000. running mean: -19.869398\n",
            "resetting env. episode 1900.000000, reward total was -21.000000. running mean: -19.880704\n",
            "resetting env. episode 1901.000000, reward total was -20.000000. running mean: -19.881897\n",
            "resetting env. episode 1902.000000, reward total was -19.000000. running mean: -19.873078\n",
            "resetting env. episode 1903.000000, reward total was -21.000000. running mean: -19.884347\n",
            "resetting env. episode 1904.000000, reward total was -20.000000. running mean: -19.885503\n",
            "resetting env. episode 1905.000000, reward total was -19.000000. running mean: -19.876648\n",
            "resetting env. episode 1906.000000, reward total was -21.000000. running mean: -19.887882\n",
            "resetting env. episode 1907.000000, reward total was -19.000000. running mean: -19.879003\n",
            "resetting env. episode 1908.000000, reward total was -21.000000. running mean: -19.890213\n",
            "resetting env. episode 1909.000000, reward total was -19.000000. running mean: -19.881311\n",
            "resetting env. episode 1910.000000, reward total was -20.000000. running mean: -19.882498\n",
            "resetting env. episode 1911.000000, reward total was -21.000000. running mean: -19.893673\n",
            "resetting env. episode 1912.000000, reward total was -21.000000. running mean: -19.904736\n",
            "resetting env. episode 1913.000000, reward total was -20.000000. running mean: -19.905689\n",
            "resetting env. episode 1914.000000, reward total was -20.000000. running mean: -19.906632\n",
            "resetting env. episode 1915.000000, reward total was -19.000000. running mean: -19.897566\n",
            "resetting env. episode 1916.000000, reward total was -20.000000. running mean: -19.898590\n",
            "resetting env. episode 1917.000000, reward total was -20.000000. running mean: -19.899604\n",
            "resetting env. episode 1918.000000, reward total was -17.000000. running mean: -19.870608\n",
            "resetting env. episode 1919.000000, reward total was -21.000000. running mean: -19.881902\n",
            "resetting env. episode 1920.000000, reward total was -21.000000. running mean: -19.893083\n",
            "resetting env. episode 1921.000000, reward total was -21.000000. running mean: -19.904152\n",
            "resetting env. episode 1922.000000, reward total was -20.000000. running mean: -19.905111\n",
            "resetting env. episode 1923.000000, reward total was -21.000000. running mean: -19.916059\n",
            "resetting env. episode 1924.000000, reward total was -21.000000. running mean: -19.926899\n",
            "resetting env. episode 1925.000000, reward total was -19.000000. running mean: -19.917630\n",
            "resetting env. episode 1926.000000, reward total was -20.000000. running mean: -19.918454\n",
            "resetting env. episode 1927.000000, reward total was -20.000000. running mean: -19.919269\n",
            "resetting env. episode 1928.000000, reward total was -18.000000. running mean: -19.900076\n",
            "resetting env. episode 1929.000000, reward total was -19.000000. running mean: -19.891076\n",
            "resetting env. episode 1930.000000, reward total was -19.000000. running mean: -19.882165\n",
            "resetting env. episode 1931.000000, reward total was -20.000000. running mean: -19.883343\n",
            "resetting env. episode 1932.000000, reward total was -21.000000. running mean: -19.894510\n",
            "resetting env. episode 1933.000000, reward total was -19.000000. running mean: -19.885565\n",
            "resetting env. episode 1934.000000, reward total was -19.000000. running mean: -19.876709\n",
            "resetting env. episode 1935.000000, reward total was -21.000000. running mean: -19.887942\n",
            "resetting env. episode 1936.000000, reward total was -20.000000. running mean: -19.889062\n",
            "resetting env. episode 1937.000000, reward total was -21.000000. running mean: -19.900172\n",
            "resetting env. episode 1938.000000, reward total was -18.000000. running mean: -19.881170\n",
            "resetting env. episode 1939.000000, reward total was -20.000000. running mean: -19.882358\n",
            "resetting env. episode 1940.000000, reward total was -21.000000. running mean: -19.893535\n",
            "resetting env. episode 1941.000000, reward total was -17.000000. running mean: -19.864600\n",
            "resetting env. episode 1942.000000, reward total was -20.000000. running mean: -19.865954\n",
            "resetting env. episode 1943.000000, reward total was -19.000000. running mean: -19.857294\n",
            "resetting env. episode 1944.000000, reward total was -20.000000. running mean: -19.858721\n",
            "resetting env. episode 1945.000000, reward total was -21.000000. running mean: -19.870134\n",
            "resetting env. episode 1946.000000, reward total was -21.000000. running mean: -19.881432\n",
            "resetting env. episode 1947.000000, reward total was -19.000000. running mean: -19.872618\n",
            "resetting env. episode 1948.000000, reward total was -19.000000. running mean: -19.863892\n",
            "resetting env. episode 1949.000000, reward total was -21.000000. running mean: -19.875253\n",
            "resetting env. episode 1950.000000, reward total was -19.000000. running mean: -19.866501\n",
            "resetting env. episode 1951.000000, reward total was -21.000000. running mean: -19.877836\n",
            "resetting env. episode 1952.000000, reward total was -20.000000. running mean: -19.879057\n",
            "resetting env. episode 1953.000000, reward total was -19.000000. running mean: -19.870267\n",
            "resetting env. episode 1954.000000, reward total was -21.000000. running mean: -19.881564\n",
            "resetting env. episode 1955.000000, reward total was -21.000000. running mean: -19.892748\n",
            "resetting env. episode 1956.000000, reward total was -20.000000. running mean: -19.893821\n",
            "resetting env. episode 1957.000000, reward total was -21.000000. running mean: -19.904883\n",
            "resetting env. episode 1958.000000, reward total was -20.000000. running mean: -19.905834\n",
            "resetting env. episode 1959.000000, reward total was -17.000000. running mean: -19.876775\n",
            "resetting env. episode 1960.000000, reward total was -21.000000. running mean: -19.888008\n",
            "resetting env. episode 1961.000000, reward total was -21.000000. running mean: -19.899128\n",
            "resetting env. episode 1962.000000, reward total was -19.000000. running mean: -19.890136\n",
            "resetting env. episode 1963.000000, reward total was -20.000000. running mean: -19.891235\n",
            "resetting env. episode 1964.000000, reward total was -20.000000. running mean: -19.892323\n",
            "resetting env. episode 1965.000000, reward total was -20.000000. running mean: -19.893399\n",
            "resetting env. episode 1966.000000, reward total was -21.000000. running mean: -19.904465\n",
            "resetting env. episode 1967.000000, reward total was -20.000000. running mean: -19.905421\n",
            "resetting env. episode 1968.000000, reward total was -19.000000. running mean: -19.896367\n",
            "resetting env. episode 1969.000000, reward total was -19.000000. running mean: -19.887403\n",
            "resetting env. episode 1970.000000, reward total was -21.000000. running mean: -19.898529\n",
            "resetting env. episode 1971.000000, reward total was -21.000000. running mean: -19.909544\n",
            "resetting env. episode 1972.000000, reward total was -20.000000. running mean: -19.910448\n",
            "resetting env. episode 1973.000000, reward total was -20.000000. running mean: -19.911344\n",
            "resetting env. episode 1974.000000, reward total was -20.000000. running mean: -19.912230\n",
            "resetting env. episode 1975.000000, reward total was -18.000000. running mean: -19.893108\n",
            "resetting env. episode 1976.000000, reward total was -21.000000. running mean: -19.904177\n",
            "resetting env. episode 1977.000000, reward total was -21.000000. running mean: -19.915135\n",
            "resetting env. episode 1978.000000, reward total was -19.000000. running mean: -19.905984\n",
            "resetting env. episode 1979.000000, reward total was -21.000000. running mean: -19.916924\n",
            "resetting env. episode 1980.000000, reward total was -20.000000. running mean: -19.917755\n",
            "resetting env. episode 1981.000000, reward total was -19.000000. running mean: -19.908577\n",
            "resetting env. episode 1982.000000, reward total was -20.000000. running mean: -19.909491\n",
            "resetting env. episode 1983.000000, reward total was -19.000000. running mean: -19.900396\n",
            "resetting env. episode 1984.000000, reward total was -19.000000. running mean: -19.891392\n",
            "resetting env. episode 1985.000000, reward total was -21.000000. running mean: -19.902479\n",
            "resetting env. episode 1986.000000, reward total was -17.000000. running mean: -19.873454\n",
            "resetting env. episode 1987.000000, reward total was -19.000000. running mean: -19.864719\n",
            "resetting env. episode 1988.000000, reward total was -19.000000. running mean: -19.856072\n",
            "resetting env. episode 1989.000000, reward total was -19.000000. running mean: -19.847511\n",
            "resetting env. episode 1990.000000, reward total was -20.000000. running mean: -19.849036\n",
            "resetting env. episode 1991.000000, reward total was -21.000000. running mean: -19.860546\n",
            "resetting env. episode 1992.000000, reward total was -19.000000. running mean: -19.851940\n",
            "resetting env. episode 1993.000000, reward total was -19.000000. running mean: -19.843421\n",
            "resetting env. episode 1994.000000, reward total was -19.000000. running mean: -19.834987\n",
            "resetting env. episode 1995.000000, reward total was -18.000000. running mean: -19.816637\n",
            "resetting env. episode 1996.000000, reward total was -19.000000. running mean: -19.808470\n",
            "resetting env. episode 1997.000000, reward total was -18.000000. running mean: -19.790386\n",
            "resetting env. episode 1998.000000, reward total was -18.000000. running mean: -19.772482\n",
            "resetting env. episode 1999.000000, reward total was -19.000000. running mean: -19.764757\n",
            "resetting env. episode 2000.000000, reward total was -19.000000. running mean: -19.757110\n",
            "resetting env. episode 2001.000000, reward total was -20.000000. running mean: -19.759538\n",
            "resetting env. episode 2002.000000, reward total was -20.000000. running mean: -19.761943\n",
            "resetting env. episode 2003.000000, reward total was -21.000000. running mean: -19.774324\n",
            "resetting env. episode 2004.000000, reward total was -16.000000. running mean: -19.736580\n",
            "resetting env. episode 2005.000000, reward total was -20.000000. running mean: -19.739215\n",
            "resetting env. episode 2006.000000, reward total was -20.000000. running mean: -19.741822\n",
            "resetting env. episode 2007.000000, reward total was -20.000000. running mean: -19.744404\n",
            "resetting env. episode 2008.000000, reward total was -19.000000. running mean: -19.736960\n",
            "resetting env. episode 2009.000000, reward total was -20.000000. running mean: -19.739591\n",
            "resetting env. episode 2010.000000, reward total was -19.000000. running mean: -19.732195\n",
            "resetting env. episode 2011.000000, reward total was -19.000000. running mean: -19.724873\n",
            "resetting env. episode 2012.000000, reward total was -20.000000. running mean: -19.727624\n",
            "resetting env. episode 2013.000000, reward total was -19.000000. running mean: -19.720348\n",
            "resetting env. episode 2014.000000, reward total was -21.000000. running mean: -19.733144\n",
            "resetting env. episode 2015.000000, reward total was -20.000000. running mean: -19.735813\n",
            "resetting env. episode 2016.000000, reward total was -20.000000. running mean: -19.738455\n",
            "resetting env. episode 2017.000000, reward total was -19.000000. running mean: -19.731070\n",
            "resetting env. episode 2018.000000, reward total was -16.000000. running mean: -19.693759\n",
            "resetting env. episode 2019.000000, reward total was -21.000000. running mean: -19.706822\n",
            "resetting env. episode 2020.000000, reward total was -19.000000. running mean: -19.699754\n",
            "resetting env. episode 2021.000000, reward total was -19.000000. running mean: -19.692756\n",
            "resetting env. episode 2022.000000, reward total was -20.000000. running mean: -19.695829\n",
            "resetting env. episode 2023.000000, reward total was -21.000000. running mean: -19.708870\n",
            "resetting env. episode 2024.000000, reward total was -21.000000. running mean: -19.721782\n",
            "resetting env. episode 2025.000000, reward total was -19.000000. running mean: -19.714564\n",
            "resetting env. episode 2026.000000, reward total was -19.000000. running mean: -19.707418\n",
            "resetting env. episode 2027.000000, reward total was -21.000000. running mean: -19.720344\n",
            "resetting env. episode 2028.000000, reward total was -21.000000. running mean: -19.733140\n",
            "resetting env. episode 2029.000000, reward total was -19.000000. running mean: -19.725809\n",
            "resetting env. episode 2030.000000, reward total was -20.000000. running mean: -19.728551\n",
            "resetting env. episode 2031.000000, reward total was -18.000000. running mean: -19.711265\n",
            "resetting env. episode 2032.000000, reward total was -20.000000. running mean: -19.714153\n",
            "resetting env. episode 2033.000000, reward total was -21.000000. running mean: -19.727011\n",
            "resetting env. episode 2034.000000, reward total was -19.000000. running mean: -19.719741\n",
            "resetting env. episode 2035.000000, reward total was -20.000000. running mean: -19.722544\n",
            "resetting env. episode 2036.000000, reward total was -21.000000. running mean: -19.735318\n",
            "resetting env. episode 2037.000000, reward total was -19.000000. running mean: -19.727965\n",
            "resetting env. episode 2038.000000, reward total was -20.000000. running mean: -19.730685\n",
            "resetting env. episode 2039.000000, reward total was -18.000000. running mean: -19.713379\n",
            "resetting env. episode 2040.000000, reward total was -20.000000. running mean: -19.716245\n",
            "resetting env. episode 2041.000000, reward total was -17.000000. running mean: -19.689082\n",
            "resetting env. episode 2042.000000, reward total was -21.000000. running mean: -19.702192\n",
            "resetting env. episode 2043.000000, reward total was -21.000000. running mean: -19.715170\n",
            "resetting env. episode 2044.000000, reward total was -19.000000. running mean: -19.708018\n",
            "resetting env. episode 2045.000000, reward total was -18.000000. running mean: -19.690938\n",
            "resetting env. episode 2046.000000, reward total was -17.000000. running mean: -19.664028\n",
            "resetting env. episode 2047.000000, reward total was -21.000000. running mean: -19.677388\n",
            "resetting env. episode 2048.000000, reward total was -21.000000. running mean: -19.690614\n",
            "resetting env. episode 2049.000000, reward total was -20.000000. running mean: -19.693708\n",
            "resetting env. episode 2050.000000, reward total was -20.000000. running mean: -19.696771\n",
            "resetting env. episode 2051.000000, reward total was -21.000000. running mean: -19.709803\n",
            "resetting env. episode 2052.000000, reward total was -21.000000. running mean: -19.722705\n",
            "resetting env. episode 2053.000000, reward total was -20.000000. running mean: -19.725478\n",
            "resetting env. episode 2054.000000, reward total was -18.000000. running mean: -19.708223\n",
            "resetting env. episode 2055.000000, reward total was -20.000000. running mean: -19.711141\n",
            "resetting env. episode 2056.000000, reward total was -20.000000. running mean: -19.714030\n",
            "resetting env. episode 2057.000000, reward total was -19.000000. running mean: -19.706890\n",
            "resetting env. episode 2058.000000, reward total was -17.000000. running mean: -19.679821\n",
            "resetting env. episode 2059.000000, reward total was -18.000000. running mean: -19.663022\n",
            "resetting env. episode 2060.000000, reward total was -19.000000. running mean: -19.656392\n",
            "resetting env. episode 2061.000000, reward total was -20.000000. running mean: -19.659828\n",
            "resetting env. episode 2062.000000, reward total was -19.000000. running mean: -19.653230\n",
            "resetting env. episode 2063.000000, reward total was -20.000000. running mean: -19.656698\n",
            "resetting env. episode 2064.000000, reward total was -16.000000. running mean: -19.620131\n",
            "resetting env. episode 2065.000000, reward total was -20.000000. running mean: -19.623929\n",
            "resetting env. episode 2066.000000, reward total was -21.000000. running mean: -19.637690\n",
            "resetting env. episode 2067.000000, reward total was -20.000000. running mean: -19.641313\n",
            "resetting env. episode 2068.000000, reward total was -20.000000. running mean: -19.644900\n",
            "resetting env. episode 2069.000000, reward total was -19.000000. running mean: -19.638451\n",
            "resetting env. episode 2070.000000, reward total was -21.000000. running mean: -19.652067\n",
            "resetting env. episode 2071.000000, reward total was -20.000000. running mean: -19.655546\n",
            "resetting env. episode 2072.000000, reward total was -19.000000. running mean: -19.648990\n",
            "resetting env. episode 2073.000000, reward total was -19.000000. running mean: -19.642501\n",
            "resetting env. episode 2074.000000, reward total was -21.000000. running mean: -19.656076\n",
            "resetting env. episode 2075.000000, reward total was -21.000000. running mean: -19.669515\n",
            "resetting env. episode 2076.000000, reward total was -21.000000. running mean: -19.682820\n",
            "resetting env. episode 2077.000000, reward total was -20.000000. running mean: -19.685991\n",
            "resetting env. episode 2078.000000, reward total was -20.000000. running mean: -19.689132\n",
            "resetting env. episode 2079.000000, reward total was -20.000000. running mean: -19.692240\n",
            "resetting env. episode 2080.000000, reward total was -19.000000. running mean: -19.685318\n",
            "resetting env. episode 2081.000000, reward total was -21.000000. running mean: -19.698465\n",
            "resetting env. episode 2082.000000, reward total was -20.000000. running mean: -19.701480\n",
            "resetting env. episode 2083.000000, reward total was -21.000000. running mean: -19.714465\n",
            "resetting env. episode 2084.000000, reward total was -20.000000. running mean: -19.717321\n",
            "resetting env. episode 2085.000000, reward total was -21.000000. running mean: -19.730147\n",
            "resetting env. episode 2086.000000, reward total was -21.000000. running mean: -19.742846\n",
            "resetting env. episode 2087.000000, reward total was -20.000000. running mean: -19.745417\n",
            "resetting env. episode 2088.000000, reward total was -17.000000. running mean: -19.717963\n",
            "resetting env. episode 2089.000000, reward total was -20.000000. running mean: -19.720784\n",
            "resetting env. episode 2090.000000, reward total was -20.000000. running mean: -19.723576\n",
            "resetting env. episode 2091.000000, reward total was -18.000000. running mean: -19.706340\n",
            "resetting env. episode 2092.000000, reward total was -19.000000. running mean: -19.699277\n",
            "resetting env. episode 2093.000000, reward total was -19.000000. running mean: -19.692284\n",
            "resetting env. episode 2094.000000, reward total was -17.000000. running mean: -19.665361\n",
            "resetting env. episode 2095.000000, reward total was -19.000000. running mean: -19.658707\n",
            "resetting env. episode 2096.000000, reward total was -20.000000. running mean: -19.662120\n",
            "resetting env. episode 2097.000000, reward total was -19.000000. running mean: -19.655499\n",
            "resetting env. episode 2098.000000, reward total was -19.000000. running mean: -19.648944\n",
            "resetting env. episode 2099.000000, reward total was -18.000000. running mean: -19.632455\n",
            "resetting env. episode 2100.000000, reward total was -19.000000. running mean: -19.626130\n",
            "resetting env. episode 2101.000000, reward total was -21.000000. running mean: -19.639869\n",
            "resetting env. episode 2102.000000, reward total was -17.000000. running mean: -19.613470\n",
            "resetting env. episode 2103.000000, reward total was -20.000000. running mean: -19.617335\n",
            "resetting env. episode 2104.000000, reward total was -21.000000. running mean: -19.631162\n",
            "resetting env. episode 2105.000000, reward total was -21.000000. running mean: -19.644850\n",
            "resetting env. episode 2106.000000, reward total was -19.000000. running mean: -19.638402\n",
            "resetting env. episode 2107.000000, reward total was -19.000000. running mean: -19.632018\n",
            "resetting env. episode 2108.000000, reward total was -20.000000. running mean: -19.635698\n",
            "resetting env. episode 2109.000000, reward total was -20.000000. running mean: -19.639341\n",
            "resetting env. episode 2110.000000, reward total was -20.000000. running mean: -19.642947\n",
            "resetting env. episode 2111.000000, reward total was -19.000000. running mean: -19.636518\n",
            "resetting env. episode 2112.000000, reward total was -19.000000. running mean: -19.630153\n",
            "resetting env. episode 2113.000000, reward total was -21.000000. running mean: -19.643851\n",
            "resetting env. episode 2114.000000, reward total was -18.000000. running mean: -19.627413\n",
            "resetting env. episode 2115.000000, reward total was -20.000000. running mean: -19.631139\n",
            "resetting env. episode 2116.000000, reward total was -21.000000. running mean: -19.644827\n",
            "resetting env. episode 2117.000000, reward total was -20.000000. running mean: -19.648379\n",
            "resetting env. episode 2118.000000, reward total was -19.000000. running mean: -19.641895\n",
            "resetting env. episode 2119.000000, reward total was -20.000000. running mean: -19.645476\n",
            "resetting env. episode 2120.000000, reward total was -19.000000. running mean: -19.639021\n",
            "resetting env. episode 2121.000000, reward total was -21.000000. running mean: -19.652631\n",
            "resetting env. episode 2122.000000, reward total was -18.000000. running mean: -19.636105\n",
            "resetting env. episode 2123.000000, reward total was -21.000000. running mean: -19.649744\n",
            "resetting env. episode 2124.000000, reward total was -20.000000. running mean: -19.653246\n",
            "resetting env. episode 2125.000000, reward total was -21.000000. running mean: -19.666714\n",
            "resetting env. episode 2126.000000, reward total was -19.000000. running mean: -19.660047\n",
            "resetting env. episode 2127.000000, reward total was -21.000000. running mean: -19.673446\n",
            "resetting env. episode 2128.000000, reward total was -17.000000. running mean: -19.646712\n",
            "resetting env. episode 2129.000000, reward total was -20.000000. running mean: -19.650245\n",
            "resetting env. episode 2130.000000, reward total was -18.000000. running mean: -19.633742\n",
            "resetting env. episode 2131.000000, reward total was -20.000000. running mean: -19.637405\n",
            "resetting env. episode 2132.000000, reward total was -17.000000. running mean: -19.611031\n",
            "resetting env. episode 2133.000000, reward total was -21.000000. running mean: -19.624920\n",
            "resetting env. episode 2134.000000, reward total was -18.000000. running mean: -19.608671\n",
            "resetting env. episode 2135.000000, reward total was -19.000000. running mean: -19.602585\n",
            "resetting env. episode 2136.000000, reward total was -19.000000. running mean: -19.596559\n",
            "resetting env. episode 2137.000000, reward total was -21.000000. running mean: -19.610593\n",
            "resetting env. episode 2138.000000, reward total was -21.000000. running mean: -19.624487\n",
            "resetting env. episode 2139.000000, reward total was -19.000000. running mean: -19.618242\n",
            "resetting env. episode 2140.000000, reward total was -21.000000. running mean: -19.632060\n",
            "resetting env. episode 2141.000000, reward total was -20.000000. running mean: -19.635739\n",
            "resetting env. episode 2142.000000, reward total was -19.000000. running mean: -19.629382\n",
            "resetting env. episode 2143.000000, reward total was -20.000000. running mean: -19.633088\n",
            "resetting env. episode 2144.000000, reward total was -21.000000. running mean: -19.646757\n",
            "resetting env. episode 2145.000000, reward total was -18.000000. running mean: -19.630290\n",
            "resetting env. episode 2146.000000, reward total was -19.000000. running mean: -19.623987\n",
            "resetting env. episode 2147.000000, reward total was -20.000000. running mean: -19.627747\n",
            "resetting env. episode 2148.000000, reward total was -21.000000. running mean: -19.641469\n",
            "resetting env. episode 2149.000000, reward total was -21.000000. running mean: -19.655055\n",
            "resetting env. episode 2150.000000, reward total was -21.000000. running mean: -19.668504\n",
            "resetting env. episode 2151.000000, reward total was -20.000000. running mean: -19.671819\n",
            "resetting env. episode 2152.000000, reward total was -18.000000. running mean: -19.655101\n",
            "resetting env. episode 2153.000000, reward total was -18.000000. running mean: -19.638550\n",
            "resetting env. episode 2154.000000, reward total was -18.000000. running mean: -19.622164\n",
            "resetting env. episode 2155.000000, reward total was -19.000000. running mean: -19.615943\n",
            "resetting env. episode 2156.000000, reward total was -19.000000. running mean: -19.609783\n",
            "resetting env. episode 2157.000000, reward total was -20.000000. running mean: -19.613686\n",
            "resetting env. episode 2158.000000, reward total was -21.000000. running mean: -19.627549\n",
            "resetting env. episode 2159.000000, reward total was -20.000000. running mean: -19.631273\n",
            "resetting env. episode 2160.000000, reward total was -18.000000. running mean: -19.614960\n",
            "resetting env. episode 2161.000000, reward total was -20.000000. running mean: -19.618811\n",
            "resetting env. episode 2162.000000, reward total was -19.000000. running mean: -19.612623\n",
            "resetting env. episode 2163.000000, reward total was -19.000000. running mean: -19.606497\n",
            "resetting env. episode 2164.000000, reward total was -21.000000. running mean: -19.620432\n",
            "resetting env. episode 2165.000000, reward total was -18.000000. running mean: -19.604227\n",
            "resetting env. episode 2166.000000, reward total was -21.000000. running mean: -19.618185\n",
            "resetting env. episode 2167.000000, reward total was -17.000000. running mean: -19.592003\n",
            "resetting env. episode 2168.000000, reward total was -21.000000. running mean: -19.606083\n",
            "resetting env. episode 2169.000000, reward total was -20.000000. running mean: -19.610022\n",
            "resetting env. episode 2170.000000, reward total was -19.000000. running mean: -19.603922\n",
            "resetting env. episode 2171.000000, reward total was -19.000000. running mean: -19.597883\n",
            "resetting env. episode 2172.000000, reward total was -20.000000. running mean: -19.601904\n",
            "resetting env. episode 2173.000000, reward total was -19.000000. running mean: -19.595885\n",
            "resetting env. episode 2174.000000, reward total was -21.000000. running mean: -19.609926\n",
            "resetting env. episode 2175.000000, reward total was -18.000000. running mean: -19.593827\n",
            "resetting env. episode 2176.000000, reward total was -21.000000. running mean: -19.607889\n",
            "resetting env. episode 2177.000000, reward total was -20.000000. running mean: -19.611810\n",
            "resetting env. episode 2178.000000, reward total was -21.000000. running mean: -19.625692\n",
            "resetting env. episode 2179.000000, reward total was -19.000000. running mean: -19.619435\n",
            "resetting env. episode 2180.000000, reward total was -17.000000. running mean: -19.593240\n",
            "resetting env. episode 2181.000000, reward total was -19.000000. running mean: -19.587308\n",
            "resetting env. episode 2182.000000, reward total was -21.000000. running mean: -19.601435\n",
            "resetting env. episode 2183.000000, reward total was -21.000000. running mean: -19.615420\n",
            "resetting env. episode 2184.000000, reward total was -20.000000. running mean: -19.619266\n",
            "resetting env. episode 2185.000000, reward total was -21.000000. running mean: -19.633074\n",
            "resetting env. episode 2186.000000, reward total was -21.000000. running mean: -19.646743\n",
            "resetting env. episode 2187.000000, reward total was -21.000000. running mean: -19.660275\n",
            "resetting env. episode 2188.000000, reward total was -21.000000. running mean: -19.673673\n",
            "resetting env. episode 2189.000000, reward total was -21.000000. running mean: -19.686936\n",
            "resetting env. episode 2190.000000, reward total was -19.000000. running mean: -19.680067\n",
            "resetting env. episode 2191.000000, reward total was -19.000000. running mean: -19.673266\n",
            "resetting env. episode 2192.000000, reward total was -21.000000. running mean: -19.686533\n",
            "resetting env. episode 2193.000000, reward total was -17.000000. running mean: -19.659668\n",
            "resetting env. episode 2194.000000, reward total was -16.000000. running mean: -19.623071\n",
            "resetting env. episode 2195.000000, reward total was -21.000000. running mean: -19.636841\n",
            "resetting env. episode 2196.000000, reward total was -21.000000. running mean: -19.650472\n",
            "resetting env. episode 2197.000000, reward total was -21.000000. running mean: -19.663967\n",
            "resetting env. episode 2198.000000, reward total was -20.000000. running mean: -19.667328\n",
            "resetting env. episode 2199.000000, reward total was -21.000000. running mean: -19.680654\n",
            "resetting env. episode 2200.000000, reward total was -19.000000. running mean: -19.673848\n",
            "resetting env. episode 2201.000000, reward total was -21.000000. running mean: -19.687109\n",
            "resetting env. episode 2202.000000, reward total was -21.000000. running mean: -19.700238\n",
            "resetting env. episode 2203.000000, reward total was -20.000000. running mean: -19.703236\n",
            "resetting env. episode 2204.000000, reward total was -20.000000. running mean: -19.706204\n",
            "resetting env. episode 2205.000000, reward total was -20.000000. running mean: -19.709142\n",
            "resetting env. episode 2206.000000, reward total was -21.000000. running mean: -19.722050\n",
            "resetting env. episode 2207.000000, reward total was -17.000000. running mean: -19.694830\n",
            "resetting env. episode 2208.000000, reward total was -21.000000. running mean: -19.707881\n",
            "resetting env. episode 2209.000000, reward total was -20.000000. running mean: -19.710803\n",
            "resetting env. episode 2210.000000, reward total was -21.000000. running mean: -19.723695\n",
            "resetting env. episode 2211.000000, reward total was -20.000000. running mean: -19.726458\n",
            "resetting env. episode 2212.000000, reward total was -21.000000. running mean: -19.739193\n",
            "resetting env. episode 2213.000000, reward total was -19.000000. running mean: -19.731801\n",
            "resetting env. episode 2214.000000, reward total was -21.000000. running mean: -19.744483\n",
            "resetting env. episode 2215.000000, reward total was -21.000000. running mean: -19.757038\n",
            "resetting env. episode 2216.000000, reward total was -20.000000. running mean: -19.759468\n",
            "resetting env. episode 2217.000000, reward total was -20.000000. running mean: -19.761873\n",
            "resetting env. episode 2218.000000, reward total was -21.000000. running mean: -19.774254\n",
            "resetting env. episode 2219.000000, reward total was -18.000000. running mean: -19.756512\n",
            "resetting env. episode 2220.000000, reward total was -20.000000. running mean: -19.758947\n",
            "resetting env. episode 2221.000000, reward total was -21.000000. running mean: -19.771357\n",
            "resetting env. episode 2222.000000, reward total was -18.000000. running mean: -19.753644\n",
            "resetting env. episode 2223.000000, reward total was -20.000000. running mean: -19.756107\n",
            "resetting env. episode 2224.000000, reward total was -21.000000. running mean: -19.768546\n",
            "resetting env. episode 2225.000000, reward total was -20.000000. running mean: -19.770861\n",
            "resetting env. episode 2226.000000, reward total was -21.000000. running mean: -19.783152\n",
            "resetting env. episode 2227.000000, reward total was -19.000000. running mean: -19.775321\n",
            "resetting env. episode 2228.000000, reward total was -20.000000. running mean: -19.777567\n",
            "resetting env. episode 2229.000000, reward total was -19.000000. running mean: -19.769792\n",
            "resetting env. episode 2230.000000, reward total was -14.000000. running mean: -19.712094\n",
            "resetting env. episode 2231.000000, reward total was -19.000000. running mean: -19.704973\n",
            "resetting env. episode 2232.000000, reward total was -16.000000. running mean: -19.667923\n",
            "resetting env. episode 2233.000000, reward total was -21.000000. running mean: -19.681244\n",
            "resetting env. episode 2234.000000, reward total was -19.000000. running mean: -19.674431\n",
            "resetting env. episode 2235.000000, reward total was -18.000000. running mean: -19.657687\n",
            "resetting env. episode 2236.000000, reward total was -20.000000. running mean: -19.661110\n",
            "resetting env. episode 2237.000000, reward total was -20.000000. running mean: -19.664499\n",
            "resetting env. episode 2238.000000, reward total was -21.000000. running mean: -19.677854\n",
            "resetting env. episode 2239.000000, reward total was -21.000000. running mean: -19.691076\n",
            "resetting env. episode 2240.000000, reward total was -20.000000. running mean: -19.694165\n",
            "resetting env. episode 2241.000000, reward total was -16.000000. running mean: -19.657223\n",
            "resetting env. episode 2242.000000, reward total was -19.000000. running mean: -19.650651\n",
            "resetting env. episode 2243.000000, reward total was -21.000000. running mean: -19.664145\n",
            "resetting env. episode 2244.000000, reward total was -21.000000. running mean: -19.677503\n",
            "resetting env. episode 2245.000000, reward total was -19.000000. running mean: -19.670728\n",
            "resetting env. episode 2246.000000, reward total was -21.000000. running mean: -19.684021\n",
            "resetting env. episode 2247.000000, reward total was -20.000000. running mean: -19.687181\n",
            "resetting env. episode 2248.000000, reward total was -21.000000. running mean: -19.700309\n",
            "resetting env. episode 2249.000000, reward total was -20.000000. running mean: -19.703306\n",
            "resetting env. episode 2250.000000, reward total was -18.000000. running mean: -19.686273\n",
            "resetting env. episode 2251.000000, reward total was -21.000000. running mean: -19.699410\n",
            "resetting env. episode 2252.000000, reward total was -21.000000. running mean: -19.712416\n",
            "resetting env. episode 2253.000000, reward total was -20.000000. running mean: -19.715292\n",
            "resetting env. episode 2254.000000, reward total was -17.000000. running mean: -19.688139\n",
            "resetting env. episode 2255.000000, reward total was -20.000000. running mean: -19.691257\n",
            "resetting env. episode 2256.000000, reward total was -19.000000. running mean: -19.684345\n",
            "resetting env. episode 2257.000000, reward total was -20.000000. running mean: -19.687501\n",
            "resetting env. episode 2258.000000, reward total was -21.000000. running mean: -19.700626\n",
            "resetting env. episode 2259.000000, reward total was -20.000000. running mean: -19.703620\n",
            "resetting env. episode 2260.000000, reward total was -18.000000. running mean: -19.686584\n",
            "resetting env. episode 2261.000000, reward total was -19.000000. running mean: -19.679718\n",
            "resetting env. episode 2262.000000, reward total was -19.000000. running mean: -19.672921\n",
            "resetting env. episode 2263.000000, reward total was -19.000000. running mean: -19.666192\n",
            "resetting env. episode 2264.000000, reward total was -20.000000. running mean: -19.669530\n",
            "resetting env. episode 2265.000000, reward total was -19.000000. running mean: -19.662834\n",
            "resetting env. episode 2266.000000, reward total was -20.000000. running mean: -19.666206\n",
            "resetting env. episode 2267.000000, reward total was -20.000000. running mean: -19.669544\n",
            "resetting env. episode 2268.000000, reward total was -20.000000. running mean: -19.672849\n",
            "resetting env. episode 2269.000000, reward total was -19.000000. running mean: -19.666120\n",
            "resetting env. episode 2270.000000, reward total was -20.000000. running mean: -19.669459\n",
            "resetting env. episode 2271.000000, reward total was -20.000000. running mean: -19.672764\n",
            "resetting env. episode 2272.000000, reward total was -21.000000. running mean: -19.686037\n",
            "resetting env. episode 2273.000000, reward total was -20.000000. running mean: -19.689176\n",
            "resetting env. episode 2274.000000, reward total was -17.000000. running mean: -19.662284\n",
            "resetting env. episode 2275.000000, reward total was -19.000000. running mean: -19.655662\n",
            "resetting env. episode 2276.000000, reward total was -20.000000. running mean: -19.659105\n",
            "resetting env. episode 2277.000000, reward total was -14.000000. running mean: -19.602514\n",
            "resetting env. episode 2278.000000, reward total was -19.000000. running mean: -19.596489\n",
            "resetting env. episode 2279.000000, reward total was -20.000000. running mean: -19.600524\n",
            "resetting env. episode 2280.000000, reward total was -20.000000. running mean: -19.604519\n",
            "resetting env. episode 2281.000000, reward total was -21.000000. running mean: -19.618474\n",
            "resetting env. episode 2282.000000, reward total was -21.000000. running mean: -19.632289\n",
            "resetting env. episode 2283.000000, reward total was -20.000000. running mean: -19.635966\n",
            "resetting env. episode 2284.000000, reward total was -21.000000. running mean: -19.649606\n",
            "resetting env. episode 2285.000000, reward total was -21.000000. running mean: -19.663110\n",
            "resetting env. episode 2286.000000, reward total was -17.000000. running mean: -19.636479\n",
            "resetting env. episode 2287.000000, reward total was -20.000000. running mean: -19.640114\n",
            "resetting env. episode 2288.000000, reward total was -20.000000. running mean: -19.643713\n",
            "resetting env. episode 2289.000000, reward total was -18.000000. running mean: -19.627276\n",
            "resetting env. episode 2290.000000, reward total was -20.000000. running mean: -19.631003\n",
            "resetting env. episode 2291.000000, reward total was -17.000000. running mean: -19.604693\n",
            "resetting env. episode 2292.000000, reward total was -17.000000. running mean: -19.578646\n",
            "resetting env. episode 2293.000000, reward total was -20.000000. running mean: -19.582860\n",
            "resetting env. episode 2294.000000, reward total was -20.000000. running mean: -19.587031\n",
            "resetting env. episode 2295.000000, reward total was -21.000000. running mean: -19.601161\n",
            "resetting env. episode 2296.000000, reward total was -21.000000. running mean: -19.615149\n",
            "resetting env. episode 2297.000000, reward total was -21.000000. running mean: -19.628998\n",
            "resetting env. episode 2298.000000, reward total was -20.000000. running mean: -19.632708\n",
            "resetting env. episode 2299.000000, reward total was -21.000000. running mean: -19.646381\n",
            "resetting env. episode 2300.000000, reward total was -21.000000. running mean: -19.659917\n",
            "resetting env. episode 2301.000000, reward total was -21.000000. running mean: -19.673318\n",
            "resetting env. episode 2302.000000, reward total was -21.000000. running mean: -19.686585\n",
            "resetting env. episode 2303.000000, reward total was -19.000000. running mean: -19.679719\n",
            "resetting env. episode 2304.000000, reward total was -21.000000. running mean: -19.692922\n",
            "resetting env. episode 2305.000000, reward total was -17.000000. running mean: -19.665992\n",
            "resetting env. episode 2306.000000, reward total was -19.000000. running mean: -19.659332\n",
            "resetting env. episode 2307.000000, reward total was -20.000000. running mean: -19.662739\n",
            "resetting env. episode 2308.000000, reward total was -20.000000. running mean: -19.666112\n",
            "resetting env. episode 2309.000000, reward total was -19.000000. running mean: -19.659451\n",
            "resetting env. episode 2310.000000, reward total was -21.000000. running mean: -19.672856\n",
            "resetting env. episode 2311.000000, reward total was -19.000000. running mean: -19.666128\n",
            "resetting env. episode 2312.000000, reward total was -18.000000. running mean: -19.649466\n",
            "resetting env. episode 2313.000000, reward total was -20.000000. running mean: -19.652972\n",
            "resetting env. episode 2314.000000, reward total was -20.000000. running mean: -19.656442\n",
            "resetting env. episode 2315.000000, reward total was -21.000000. running mean: -19.669877\n",
            "resetting env. episode 2316.000000, reward total was -19.000000. running mean: -19.663179\n",
            "resetting env. episode 2317.000000, reward total was -19.000000. running mean: -19.656547\n",
            "resetting env. episode 2318.000000, reward total was -20.000000. running mean: -19.659981\n",
            "resetting env. episode 2319.000000, reward total was -19.000000. running mean: -19.653382\n",
            "resetting env. episode 2320.000000, reward total was -19.000000. running mean: -19.646848\n",
            "resetting env. episode 2321.000000, reward total was -19.000000. running mean: -19.640379\n",
            "resetting env. episode 2322.000000, reward total was -21.000000. running mean: -19.653976\n",
            "resetting env. episode 2323.000000, reward total was -17.000000. running mean: -19.627436\n",
            "resetting env. episode 2324.000000, reward total was -21.000000. running mean: -19.641161\n",
            "resetting env. episode 2325.000000, reward total was -20.000000. running mean: -19.644750\n",
            "resetting env. episode 2326.000000, reward total was -20.000000. running mean: -19.648302\n",
            "resetting env. episode 2327.000000, reward total was -19.000000. running mean: -19.641819\n",
            "resetting env. episode 2328.000000, reward total was -20.000000. running mean: -19.645401\n",
            "resetting env. episode 2329.000000, reward total was -19.000000. running mean: -19.638947\n",
            "resetting env. episode 2330.000000, reward total was -19.000000. running mean: -19.632558\n",
            "resetting env. episode 2331.000000, reward total was -18.000000. running mean: -19.616232\n",
            "resetting env. episode 2332.000000, reward total was -21.000000. running mean: -19.630070\n",
            "resetting env. episode 2333.000000, reward total was -21.000000. running mean: -19.643769\n",
            "resetting env. episode 2334.000000, reward total was -18.000000. running mean: -19.627331\n",
            "resetting env. episode 2335.000000, reward total was -17.000000. running mean: -19.601058\n",
            "resetting env. episode 2336.000000, reward total was -19.000000. running mean: -19.595047\n",
            "resetting env. episode 2337.000000, reward total was -20.000000. running mean: -19.599097\n",
            "resetting env. episode 2338.000000, reward total was -21.000000. running mean: -19.613106\n",
            "resetting env. episode 2339.000000, reward total was -17.000000. running mean: -19.586975\n",
            "resetting env. episode 2340.000000, reward total was -19.000000. running mean: -19.581105\n",
            "resetting env. episode 2341.000000, reward total was -19.000000. running mean: -19.575294\n",
            "resetting env. episode 2342.000000, reward total was -20.000000. running mean: -19.579541\n",
            "resetting env. episode 2343.000000, reward total was -20.000000. running mean: -19.583746\n",
            "resetting env. episode 2344.000000, reward total was -18.000000. running mean: -19.567908\n",
            "resetting env. episode 2345.000000, reward total was -19.000000. running mean: -19.562229\n",
            "resetting env. episode 2346.000000, reward total was -20.000000. running mean: -19.566607\n",
            "resetting env. episode 2347.000000, reward total was -20.000000. running mean: -19.570941\n",
            "resetting env. episode 2348.000000, reward total was -21.000000. running mean: -19.585231\n",
            "resetting env. episode 2349.000000, reward total was -21.000000. running mean: -19.599379\n",
            "resetting env. episode 2350.000000, reward total was -17.000000. running mean: -19.573385\n",
            "resetting env. episode 2351.000000, reward total was -18.000000. running mean: -19.557652\n",
            "resetting env. episode 2352.000000, reward total was -20.000000. running mean: -19.562075\n",
            "resetting env. episode 2353.000000, reward total was -21.000000. running mean: -19.576454\n",
            "resetting env. episode 2354.000000, reward total was -20.000000. running mean: -19.580690\n",
            "resetting env. episode 2355.000000, reward total was -21.000000. running mean: -19.594883\n",
            "resetting env. episode 2356.000000, reward total was -21.000000. running mean: -19.608934\n",
            "resetting env. episode 2357.000000, reward total was -19.000000. running mean: -19.602845\n",
            "resetting env. episode 2358.000000, reward total was -18.000000. running mean: -19.586816\n",
            "resetting env. episode 2359.000000, reward total was -20.000000. running mean: -19.590948\n",
            "resetting env. episode 2360.000000, reward total was -21.000000. running mean: -19.605039\n",
            "resetting env. episode 2361.000000, reward total was -19.000000. running mean: -19.598988\n",
            "resetting env. episode 2362.000000, reward total was -20.000000. running mean: -19.602998\n",
            "resetting env. episode 2363.000000, reward total was -20.000000. running mean: -19.606968\n",
            "resetting env. episode 2364.000000, reward total was -21.000000. running mean: -19.620899\n",
            "resetting env. episode 2365.000000, reward total was -20.000000. running mean: -19.624690\n",
            "resetting env. episode 2366.000000, reward total was -19.000000. running mean: -19.618443\n",
            "resetting env. episode 2367.000000, reward total was -18.000000. running mean: -19.602258\n",
            "resetting env. episode 2368.000000, reward total was -20.000000. running mean: -19.606236\n",
            "resetting env. episode 2369.000000, reward total was -21.000000. running mean: -19.620173\n",
            "resetting env. episode 2370.000000, reward total was -19.000000. running mean: -19.613972\n",
            "resetting env. episode 2371.000000, reward total was -20.000000. running mean: -19.617832\n",
            "resetting env. episode 2372.000000, reward total was -18.000000. running mean: -19.601654\n",
            "resetting env. episode 2373.000000, reward total was -20.000000. running mean: -19.605637\n",
            "resetting env. episode 2374.000000, reward total was -18.000000. running mean: -19.589581\n",
            "resetting env. episode 2375.000000, reward total was -20.000000. running mean: -19.593685\n",
            "resetting env. episode 2376.000000, reward total was -20.000000. running mean: -19.597748\n",
            "resetting env. episode 2377.000000, reward total was -19.000000. running mean: -19.591771\n",
            "resetting env. episode 2378.000000, reward total was -19.000000. running mean: -19.585853\n",
            "resetting env. episode 2379.000000, reward total was -21.000000. running mean: -19.599994\n",
            "resetting env. episode 2380.000000, reward total was -19.000000. running mean: -19.593994\n",
            "resetting env. episode 2381.000000, reward total was -19.000000. running mean: -19.588054\n",
            "resetting env. episode 2382.000000, reward total was -21.000000. running mean: -19.602174\n",
            "resetting env. episode 2383.000000, reward total was -19.000000. running mean: -19.596152\n",
            "resetting env. episode 2384.000000, reward total was -20.000000. running mean: -19.600191\n",
            "resetting env. episode 2385.000000, reward total was -21.000000. running mean: -19.614189\n",
            "resetting env. episode 2386.000000, reward total was -20.000000. running mean: -19.618047\n",
            "resetting env. episode 2387.000000, reward total was -18.000000. running mean: -19.601866\n",
            "resetting env. episode 2388.000000, reward total was -19.000000. running mean: -19.595848\n",
            "resetting env. episode 2389.000000, reward total was -19.000000. running mean: -19.589889\n",
            "resetting env. episode 2390.000000, reward total was -20.000000. running mean: -19.593990\n",
            "resetting env. episode 2391.000000, reward total was -20.000000. running mean: -19.598050\n",
            "resetting env. episode 2392.000000, reward total was -16.000000. running mean: -19.562070\n",
            "resetting env. episode 2393.000000, reward total was -18.000000. running mean: -19.546449\n",
            "resetting env. episode 2394.000000, reward total was -20.000000. running mean: -19.550985\n",
            "resetting env. episode 2395.000000, reward total was -18.000000. running mean: -19.535475\n",
            "resetting env. episode 2396.000000, reward total was -20.000000. running mean: -19.540120\n",
            "resetting env. episode 2397.000000, reward total was -21.000000. running mean: -19.554719\n",
            "resetting env. episode 2398.000000, reward total was -20.000000. running mean: -19.559172\n",
            "resetting env. episode 2399.000000, reward total was -21.000000. running mean: -19.573580\n",
            "resetting env. episode 2400.000000, reward total was -18.000000. running mean: -19.557844\n",
            "resetting env. episode 2401.000000, reward total was -21.000000. running mean: -19.572266\n",
            "resetting env. episode 2402.000000, reward total was -19.000000. running mean: -19.566543\n",
            "resetting env. episode 2403.000000, reward total was -18.000000. running mean: -19.550878\n",
            "resetting env. episode 2404.000000, reward total was -20.000000. running mean: -19.555369\n",
            "resetting env. episode 2405.000000, reward total was -19.000000. running mean: -19.549815\n",
            "resetting env. episode 2406.000000, reward total was -20.000000. running mean: -19.554317\n",
            "resetting env. episode 2407.000000, reward total was -19.000000. running mean: -19.548774\n",
            "resetting env. episode 2408.000000, reward total was -20.000000. running mean: -19.553286\n",
            "resetting env. episode 2409.000000, reward total was -20.000000. running mean: -19.557753\n",
            "resetting env. episode 2410.000000, reward total was -20.000000. running mean: -19.562176\n",
            "resetting env. episode 2411.000000, reward total was -20.000000. running mean: -19.566554\n",
            "resetting env. episode 2412.000000, reward total was -21.000000. running mean: -19.580888\n",
            "resetting env. episode 2413.000000, reward total was -20.000000. running mean: -19.585080\n",
            "resetting env. episode 2414.000000, reward total was -20.000000. running mean: -19.589229\n",
            "resetting env. episode 2415.000000, reward total was -20.000000. running mean: -19.593337\n",
            "resetting env. episode 2416.000000, reward total was -20.000000. running mean: -19.597403\n",
            "resetting env. episode 2417.000000, reward total was -20.000000. running mean: -19.601429\n",
            "resetting env. episode 2418.000000, reward total was -20.000000. running mean: -19.605415\n",
            "resetting env. episode 2419.000000, reward total was -19.000000. running mean: -19.599361\n",
            "resetting env. episode 2420.000000, reward total was -20.000000. running mean: -19.603367\n",
            "resetting env. episode 2421.000000, reward total was -20.000000. running mean: -19.607333\n",
            "resetting env. episode 2422.000000, reward total was -18.000000. running mean: -19.591260\n",
            "resetting env. episode 2423.000000, reward total was -20.000000. running mean: -19.595347\n",
            "resetting env. episode 2424.000000, reward total was -21.000000. running mean: -19.609394\n",
            "resetting env. episode 2425.000000, reward total was -19.000000. running mean: -19.603300\n",
            "resetting env. episode 2426.000000, reward total was -19.000000. running mean: -19.597267\n",
            "resetting env. episode 2427.000000, reward total was -20.000000. running mean: -19.601294\n",
            "resetting env. episode 2428.000000, reward total was -19.000000. running mean: -19.595281\n",
            "resetting env. episode 2429.000000, reward total was -19.000000. running mean: -19.589329\n",
            "resetting env. episode 2430.000000, reward total was -20.000000. running mean: -19.593435\n",
            "resetting env. episode 2431.000000, reward total was -20.000000. running mean: -19.597501\n",
            "resetting env. episode 2432.000000, reward total was -21.000000. running mean: -19.611526\n",
            "resetting env. episode 2433.000000, reward total was -21.000000. running mean: -19.625411\n",
            "resetting env. episode 2434.000000, reward total was -19.000000. running mean: -19.619157\n",
            "resetting env. episode 2435.000000, reward total was -20.000000. running mean: -19.622965\n",
            "resetting env. episode 2436.000000, reward total was -21.000000. running mean: -19.636735\n",
            "resetting env. episode 2437.000000, reward total was -17.000000. running mean: -19.610368\n",
            "resetting env. episode 2438.000000, reward total was -19.000000. running mean: -19.604264\n",
            "resetting env. episode 2439.000000, reward total was -18.000000. running mean: -19.588222\n",
            "resetting env. episode 2440.000000, reward total was -21.000000. running mean: -19.602339\n",
            "resetting env. episode 2441.000000, reward total was -20.000000. running mean: -19.606316\n",
            "resetting env. episode 2442.000000, reward total was -21.000000. running mean: -19.620253\n",
            "resetting env. episode 2443.000000, reward total was -19.000000. running mean: -19.614050\n",
            "resetting env. episode 2444.000000, reward total was -16.000000. running mean: -19.577910\n",
            "resetting env. episode 2445.000000, reward total was -20.000000. running mean: -19.582131\n",
            "resetting env. episode 2446.000000, reward total was -19.000000. running mean: -19.576309\n",
            "resetting env. episode 2447.000000, reward total was -19.000000. running mean: -19.570546\n",
            "resetting env. episode 2448.000000, reward total was -20.000000. running mean: -19.574841\n",
            "resetting env. episode 2449.000000, reward total was -21.000000. running mean: -19.589093\n",
            "resetting env. episode 2450.000000, reward total was -21.000000. running mean: -19.603202\n",
            "resetting env. episode 2451.000000, reward total was -20.000000. running mean: -19.607170\n",
            "resetting env. episode 2452.000000, reward total was -21.000000. running mean: -19.621098\n",
            "resetting env. episode 2453.000000, reward total was -21.000000. running mean: -19.634887\n",
            "resetting env. episode 2454.000000, reward total was -20.000000. running mean: -19.638538\n",
            "resetting env. episode 2455.000000, reward total was -19.000000. running mean: -19.632153\n",
            "resetting env. episode 2456.000000, reward total was -21.000000. running mean: -19.645831\n",
            "resetting env. episode 2457.000000, reward total was -17.000000. running mean: -19.619373\n",
            "resetting env. episode 2458.000000, reward total was -17.000000. running mean: -19.593179\n",
            "resetting env. episode 2459.000000, reward total was -21.000000. running mean: -19.607247\n",
            "resetting env. episode 2460.000000, reward total was -21.000000. running mean: -19.621175\n",
            "resetting env. episode 2461.000000, reward total was -21.000000. running mean: -19.634963\n",
            "resetting env. episode 2462.000000, reward total was -21.000000. running mean: -19.648613\n",
            "resetting env. episode 2463.000000, reward total was -21.000000. running mean: -19.662127\n",
            "resetting env. episode 2464.000000, reward total was -20.000000. running mean: -19.665506\n",
            "resetting env. episode 2465.000000, reward total was -17.000000. running mean: -19.638851\n",
            "resetting env. episode 2466.000000, reward total was -19.000000. running mean: -19.632462\n",
            "resetting env. episode 2467.000000, reward total was -21.000000. running mean: -19.646138\n",
            "resetting env. episode 2468.000000, reward total was -21.000000. running mean: -19.659676\n",
            "resetting env. episode 2469.000000, reward total was -20.000000. running mean: -19.663080\n",
            "resetting env. episode 2470.000000, reward total was -19.000000. running mean: -19.656449\n",
            "resetting env. episode 2471.000000, reward total was -18.000000. running mean: -19.639884\n",
            "resetting env. episode 2472.000000, reward total was -21.000000. running mean: -19.653486\n",
            "resetting env. episode 2473.000000, reward total was -17.000000. running mean: -19.626951\n",
            "resetting env. episode 2474.000000, reward total was -21.000000. running mean: -19.640681\n",
            "resetting env. episode 2475.000000, reward total was -20.000000. running mean: -19.644274\n",
            "resetting env. episode 2476.000000, reward total was -17.000000. running mean: -19.617832\n",
            "resetting env. episode 2477.000000, reward total was -20.000000. running mean: -19.621653\n",
            "resetting env. episode 2478.000000, reward total was -20.000000. running mean: -19.625437\n",
            "resetting env. episode 2479.000000, reward total was -18.000000. running mean: -19.609182\n",
            "resetting env. episode 2480.000000, reward total was -21.000000. running mean: -19.623091\n",
            "resetting env. episode 2481.000000, reward total was -21.000000. running mean: -19.636860\n",
            "resetting env. episode 2482.000000, reward total was -18.000000. running mean: -19.620491\n",
            "resetting env. episode 2483.000000, reward total was -20.000000. running mean: -19.624286\n",
            "resetting env. episode 2484.000000, reward total was -21.000000. running mean: -19.638043\n",
            "resetting env. episode 2485.000000, reward total was -20.000000. running mean: -19.641663\n",
            "resetting env. episode 2486.000000, reward total was -21.000000. running mean: -19.655246\n",
            "resetting env. episode 2487.000000, reward total was -18.000000. running mean: -19.638694\n",
            "resetting env. episode 2488.000000, reward total was -21.000000. running mean: -19.652307\n",
            "resetting env. episode 2489.000000, reward total was -21.000000. running mean: -19.665784\n",
            "resetting env. episode 2490.000000, reward total was -19.000000. running mean: -19.659126\n",
            "resetting env. episode 2491.000000, reward total was -20.000000. running mean: -19.662535\n",
            "resetting env. episode 2492.000000, reward total was -19.000000. running mean: -19.655909\n",
            "resetting env. episode 2493.000000, reward total was -20.000000. running mean: -19.659350\n",
            "resetting env. episode 2494.000000, reward total was -21.000000. running mean: -19.672757\n",
            "resetting env. episode 2495.000000, reward total was -20.000000. running mean: -19.676029\n",
            "resetting env. episode 2496.000000, reward total was -19.000000. running mean: -19.669269\n",
            "resetting env. episode 2497.000000, reward total was -19.000000. running mean: -19.662576\n",
            "resetting env. episode 2498.000000, reward total was -19.000000. running mean: -19.655950\n",
            "resetting env. episode 2499.000000, reward total was -20.000000. running mean: -19.659391\n",
            "resetting env. episode 2500.000000, reward total was -21.000000. running mean: -19.672797\n",
            "resetting env. episode 2501.000000, reward total was -21.000000. running mean: -19.686069\n",
            "resetting env. episode 2502.000000, reward total was -21.000000. running mean: -19.699208\n",
            "resetting env. episode 2503.000000, reward total was -18.000000. running mean: -19.682216\n",
            "resetting env. episode 2504.000000, reward total was -20.000000. running mean: -19.685394\n",
            "resetting env. episode 2505.000000, reward total was -19.000000. running mean: -19.678540\n",
            "resetting env. episode 2506.000000, reward total was -20.000000. running mean: -19.681755\n",
            "resetting env. episode 2507.000000, reward total was -19.000000. running mean: -19.674937\n",
            "resetting env. episode 2508.000000, reward total was -19.000000. running mean: -19.668188\n",
            "resetting env. episode 2509.000000, reward total was -20.000000. running mean: -19.671506\n",
            "resetting env. episode 2510.000000, reward total was -19.000000. running mean: -19.664791\n",
            "resetting env. episode 2511.000000, reward total was -21.000000. running mean: -19.678143\n",
            "resetting env. episode 2512.000000, reward total was -19.000000. running mean: -19.671362\n",
            "resetting env. episode 2513.000000, reward total was -20.000000. running mean: -19.674648\n",
            "resetting env. episode 2514.000000, reward total was -21.000000. running mean: -19.687901\n",
            "resetting env. episode 2515.000000, reward total was -21.000000. running mean: -19.701022\n",
            "resetting env. episode 2516.000000, reward total was -19.000000. running mean: -19.694012\n",
            "resetting env. episode 2517.000000, reward total was -18.000000. running mean: -19.677072\n",
            "resetting env. episode 2518.000000, reward total was -20.000000. running mean: -19.680301\n",
            "resetting env. episode 2519.000000, reward total was -19.000000. running mean: -19.673498\n",
            "resetting env. episode 2520.000000, reward total was -20.000000. running mean: -19.676763\n",
            "resetting env. episode 2521.000000, reward total was -21.000000. running mean: -19.689996\n",
            "resetting env. episode 2522.000000, reward total was -20.000000. running mean: -19.693096\n",
            "resetting env. episode 2523.000000, reward total was -20.000000. running mean: -19.696165\n",
            "resetting env. episode 2524.000000, reward total was -21.000000. running mean: -19.709203\n",
            "resetting env. episode 2525.000000, reward total was -19.000000. running mean: -19.702111\n",
            "resetting env. episode 2526.000000, reward total was -20.000000. running mean: -19.705090\n",
            "resetting env. episode 2527.000000, reward total was -20.000000. running mean: -19.708039\n",
            "resetting env. episode 2528.000000, reward total was -20.000000. running mean: -19.710959\n",
            "resetting env. episode 2529.000000, reward total was -19.000000. running mean: -19.703849\n",
            "resetting env. episode 2530.000000, reward total was -16.000000. running mean: -19.666811\n",
            "resetting env. episode 2531.000000, reward total was -19.000000. running mean: -19.660143\n",
            "resetting env. episode 2532.000000, reward total was -19.000000. running mean: -19.653541\n",
            "resetting env. episode 2533.000000, reward total was -20.000000. running mean: -19.657006\n",
            "resetting env. episode 2534.000000, reward total was -20.000000. running mean: -19.660436\n",
            "resetting env. episode 2535.000000, reward total was -21.000000. running mean: -19.673831\n",
            "resetting env. episode 2536.000000, reward total was -18.000000. running mean: -19.657093\n",
            "resetting env. episode 2537.000000, reward total was -19.000000. running mean: -19.650522\n",
            "resetting env. episode 2538.000000, reward total was -18.000000. running mean: -19.634017\n",
            "resetting env. episode 2539.000000, reward total was -21.000000. running mean: -19.647677\n",
            "resetting env. episode 2540.000000, reward total was -20.000000. running mean: -19.651200\n",
            "resetting env. episode 2541.000000, reward total was -20.000000. running mean: -19.654688\n",
            "resetting env. episode 2542.000000, reward total was -21.000000. running mean: -19.668141\n",
            "resetting env. episode 2543.000000, reward total was -18.000000. running mean: -19.651460\n",
            "resetting env. episode 2544.000000, reward total was -20.000000. running mean: -19.654945\n",
            "resetting env. episode 2545.000000, reward total was -20.000000. running mean: -19.658396\n",
            "resetting env. episode 2546.000000, reward total was -19.000000. running mean: -19.651812\n",
            "resetting env. episode 2547.000000, reward total was -20.000000. running mean: -19.655294\n",
            "resetting env. episode 2548.000000, reward total was -20.000000. running mean: -19.658741\n",
            "resetting env. episode 2549.000000, reward total was -18.000000. running mean: -19.642153\n",
            "resetting env. episode 2550.000000, reward total was -21.000000. running mean: -19.655732\n",
            "resetting env. episode 2551.000000, reward total was -20.000000. running mean: -19.659174\n",
            "resetting env. episode 2552.000000, reward total was -20.000000. running mean: -19.662583\n",
            "resetting env. episode 2553.000000, reward total was -19.000000. running mean: -19.655957\n",
            "resetting env. episode 2554.000000, reward total was -20.000000. running mean: -19.659397\n",
            "resetting env. episode 2555.000000, reward total was -20.000000. running mean: -19.662803\n",
            "resetting env. episode 2556.000000, reward total was -18.000000. running mean: -19.646175\n",
            "resetting env. episode 2557.000000, reward total was -19.000000. running mean: -19.639713\n",
            "resetting env. episode 2558.000000, reward total was -19.000000. running mean: -19.633316\n",
            "resetting env. episode 2559.000000, reward total was -19.000000. running mean: -19.626983\n",
            "resetting env. episode 2560.000000, reward total was -19.000000. running mean: -19.620713\n",
            "resetting env. episode 2561.000000, reward total was -21.000000. running mean: -19.634506\n",
            "resetting env. episode 2562.000000, reward total was -20.000000. running mean: -19.638161\n",
            "resetting env. episode 2563.000000, reward total was -20.000000. running mean: -19.641780\n",
            "resetting env. episode 2564.000000, reward total was -20.000000. running mean: -19.645362\n",
            "resetting env. episode 2565.000000, reward total was -20.000000. running mean: -19.648908\n",
            "resetting env. episode 2566.000000, reward total was -19.000000. running mean: -19.642419\n",
            "resetting env. episode 2567.000000, reward total was -20.000000. running mean: -19.645995\n",
            "resetting env. episode 2568.000000, reward total was -20.000000. running mean: -19.649535\n",
            "resetting env. episode 2569.000000, reward total was -21.000000. running mean: -19.663040\n",
            "resetting env. episode 2570.000000, reward total was -19.000000. running mean: -19.656409\n",
            "resetting env. episode 2571.000000, reward total was -21.000000. running mean: -19.669845\n",
            "resetting env. episode 2572.000000, reward total was -21.000000. running mean: -19.683147\n",
            "resetting env. episode 2573.000000, reward total was -18.000000. running mean: -19.666315\n",
            "resetting env. episode 2574.000000, reward total was -19.000000. running mean: -19.659652\n",
            "resetting env. episode 2575.000000, reward total was -20.000000. running mean: -19.663055\n",
            "resetting env. episode 2576.000000, reward total was -20.000000. running mean: -19.666425\n",
            "resetting env. episode 2577.000000, reward total was -21.000000. running mean: -19.679761\n",
            "resetting env. episode 2578.000000, reward total was -19.000000. running mean: -19.672963\n",
            "resetting env. episode 2579.000000, reward total was -21.000000. running mean: -19.686233\n",
            "resetting env. episode 2580.000000, reward total was -21.000000. running mean: -19.699371\n",
            "resetting env. episode 2581.000000, reward total was -19.000000. running mean: -19.692377\n",
            "resetting env. episode 2582.000000, reward total was -20.000000. running mean: -19.695454\n",
            "resetting env. episode 2583.000000, reward total was -19.000000. running mean: -19.688499\n",
            "resetting env. episode 2584.000000, reward total was -20.000000. running mean: -19.691614\n",
            "resetting env. episode 2585.000000, reward total was -21.000000. running mean: -19.704698\n",
            "resetting env. episode 2586.000000, reward total was -19.000000. running mean: -19.697651\n",
            "resetting env. episode 2587.000000, reward total was -18.000000. running mean: -19.680674\n",
            "resetting env. episode 2588.000000, reward total was -18.000000. running mean: -19.663868\n",
            "resetting env. episode 2589.000000, reward total was -21.000000. running mean: -19.677229\n",
            "resetting env. episode 2590.000000, reward total was -19.000000. running mean: -19.670457\n",
            "resetting env. episode 2591.000000, reward total was -17.000000. running mean: -19.643752\n",
            "resetting env. episode 2592.000000, reward total was -19.000000. running mean: -19.637315\n",
            "resetting env. episode 2593.000000, reward total was -19.000000. running mean: -19.630941\n",
            "resetting env. episode 2594.000000, reward total was -20.000000. running mean: -19.634632\n",
            "resetting env. episode 2595.000000, reward total was -19.000000. running mean: -19.628286\n",
            "resetting env. episode 2596.000000, reward total was -20.000000. running mean: -19.632003\n",
            "resetting env. episode 2597.000000, reward total was -20.000000. running mean: -19.635683\n",
            "resetting env. episode 2598.000000, reward total was -20.000000. running mean: -19.639326\n",
            "resetting env. episode 2599.000000, reward total was -19.000000. running mean: -19.632933\n",
            "resetting env. episode 2600.000000, reward total was -21.000000. running mean: -19.646603\n",
            "resetting env. episode 2601.000000, reward total was -19.000000. running mean: -19.640137\n",
            "resetting env. episode 2602.000000, reward total was -18.000000. running mean: -19.623736\n",
            "resetting env. episode 2603.000000, reward total was -18.000000. running mean: -19.607499\n",
            "resetting env. episode 2604.000000, reward total was -21.000000. running mean: -19.621424\n",
            "resetting env. episode 2605.000000, reward total was -17.000000. running mean: -19.595209\n",
            "resetting env. episode 2606.000000, reward total was -16.000000. running mean: -19.559257\n",
            "resetting env. episode 2607.000000, reward total was -21.000000. running mean: -19.573665\n",
            "resetting env. episode 2608.000000, reward total was -19.000000. running mean: -19.567928\n",
            "resetting env. episode 2609.000000, reward total was -20.000000. running mean: -19.572249\n",
            "resetting env. episode 2610.000000, reward total was -20.000000. running mean: -19.576526\n",
            "resetting env. episode 2611.000000, reward total was -20.000000. running mean: -19.580761\n",
            "resetting env. episode 2612.000000, reward total was -21.000000. running mean: -19.594954\n",
            "resetting env. episode 2613.000000, reward total was -19.000000. running mean: -19.589004\n",
            "resetting env. episode 2614.000000, reward total was -21.000000. running mean: -19.603114\n",
            "resetting env. episode 2615.000000, reward total was -21.000000. running mean: -19.617083\n",
            "resetting env. episode 2616.000000, reward total was -19.000000. running mean: -19.610912\n",
            "resetting env. episode 2617.000000, reward total was -20.000000. running mean: -19.614803\n",
            "resetting env. episode 2618.000000, reward total was -19.000000. running mean: -19.608655\n",
            "resetting env. episode 2619.000000, reward total was -20.000000. running mean: -19.612568\n",
            "resetting env. episode 2620.000000, reward total was -21.000000. running mean: -19.626443\n",
            "resetting env. episode 2621.000000, reward total was -20.000000. running mean: -19.630178\n",
            "resetting env. episode 2622.000000, reward total was -19.000000. running mean: -19.623876\n",
            "resetting env. episode 2623.000000, reward total was -20.000000. running mean: -19.627638\n",
            "resetting env. episode 2624.000000, reward total was -20.000000. running mean: -19.631361\n",
            "resetting env. episode 2625.000000, reward total was -21.000000. running mean: -19.645048\n",
            "resetting env. episode 2626.000000, reward total was -20.000000. running mean: -19.648597\n",
            "resetting env. episode 2627.000000, reward total was -21.000000. running mean: -19.662111\n",
            "resetting env. episode 2628.000000, reward total was -20.000000. running mean: -19.665490\n",
            "resetting env. episode 2629.000000, reward total was -17.000000. running mean: -19.638835\n",
            "resetting env. episode 2630.000000, reward total was -21.000000. running mean: -19.652447\n",
            "resetting env. episode 2631.000000, reward total was -19.000000. running mean: -19.645922\n",
            "resetting env. episode 2632.000000, reward total was -19.000000. running mean: -19.639463\n",
            "resetting env. episode 2633.000000, reward total was -19.000000. running mean: -19.633068\n",
            "resetting env. episode 2634.000000, reward total was -20.000000. running mean: -19.636738\n",
            "resetting env. episode 2635.000000, reward total was -21.000000. running mean: -19.650370\n",
            "resetting env. episode 2636.000000, reward total was -20.000000. running mean: -19.653867\n",
            "resetting env. episode 2637.000000, reward total was -18.000000. running mean: -19.637328\n",
            "resetting env. episode 2638.000000, reward total was -21.000000. running mean: -19.650955\n",
            "resetting env. episode 2639.000000, reward total was -19.000000. running mean: -19.644445\n",
            "resetting env. episode 2640.000000, reward total was -17.000000. running mean: -19.618001\n",
            "resetting env. episode 2641.000000, reward total was -18.000000. running mean: -19.601821\n",
            "resetting env. episode 2642.000000, reward total was -21.000000. running mean: -19.615803\n",
            "resetting env. episode 2643.000000, reward total was -20.000000. running mean: -19.619645\n",
            "resetting env. episode 2644.000000, reward total was -21.000000. running mean: -19.633448\n",
            "resetting env. episode 2645.000000, reward total was -18.000000. running mean: -19.617114\n",
            "resetting env. episode 2646.000000, reward total was -20.000000. running mean: -19.620942\n",
            "resetting env. episode 2647.000000, reward total was -20.000000. running mean: -19.624733\n",
            "resetting env. episode 2648.000000, reward total was -21.000000. running mean: -19.638486\n",
            "resetting env. episode 2649.000000, reward total was -19.000000. running mean: -19.632101\n",
            "resetting env. episode 2650.000000, reward total was -18.000000. running mean: -19.615780\n",
            "resetting env. episode 2651.000000, reward total was -18.000000. running mean: -19.599622\n",
            "resetting env. episode 2652.000000, reward total was -21.000000. running mean: -19.613626\n",
            "resetting env. episode 2653.000000, reward total was -20.000000. running mean: -19.617490\n",
            "resetting env. episode 2654.000000, reward total was -20.000000. running mean: -19.621315\n",
            "resetting env. episode 2655.000000, reward total was -19.000000. running mean: -19.615102\n",
            "resetting env. episode 2656.000000, reward total was -18.000000. running mean: -19.598951\n",
            "resetting env. episode 2657.000000, reward total was -20.000000. running mean: -19.602961\n",
            "resetting env. episode 2658.000000, reward total was -21.000000. running mean: -19.616931\n",
            "resetting env. episode 2659.000000, reward total was -20.000000. running mean: -19.620762\n",
            "resetting env. episode 2660.000000, reward total was -20.000000. running mean: -19.624554\n",
            "resetting env. episode 2661.000000, reward total was -20.000000. running mean: -19.628309\n",
            "resetting env. episode 2662.000000, reward total was -20.000000. running mean: -19.632026\n",
            "resetting env. episode 2663.000000, reward total was -19.000000. running mean: -19.625706\n",
            "resetting env. episode 2664.000000, reward total was -19.000000. running mean: -19.619449\n",
            "resetting env. episode 2665.000000, reward total was -21.000000. running mean: -19.633254\n",
            "resetting env. episode 2666.000000, reward total was -20.000000. running mean: -19.636921\n",
            "resetting env. episode 2667.000000, reward total was -18.000000. running mean: -19.620552\n",
            "resetting env. episode 2668.000000, reward total was -21.000000. running mean: -19.634347\n",
            "resetting env. episode 2669.000000, reward total was -21.000000. running mean: -19.648003\n",
            "resetting env. episode 2670.000000, reward total was -21.000000. running mean: -19.661523\n",
            "resetting env. episode 2671.000000, reward total was -20.000000. running mean: -19.664908\n",
            "resetting env. episode 2672.000000, reward total was -19.000000. running mean: -19.658259\n",
            "resetting env. episode 2673.000000, reward total was -20.000000. running mean: -19.661676\n",
            "resetting env. episode 2674.000000, reward total was -18.000000. running mean: -19.645060\n",
            "resetting env. episode 2675.000000, reward total was -20.000000. running mean: -19.648609\n",
            "resetting env. episode 2676.000000, reward total was -18.000000. running mean: -19.632123\n",
            "resetting env. episode 2677.000000, reward total was -21.000000. running mean: -19.645802\n",
            "resetting env. episode 2678.000000, reward total was -17.000000. running mean: -19.619344\n",
            "resetting env. episode 2679.000000, reward total was -19.000000. running mean: -19.613150\n",
            "resetting env. episode 2680.000000, reward total was -18.000000. running mean: -19.597019\n",
            "resetting env. episode 2681.000000, reward total was -17.000000. running mean: -19.571049\n",
            "resetting env. episode 2682.000000, reward total was -21.000000. running mean: -19.585338\n",
            "resetting env. episode 2683.000000, reward total was -18.000000. running mean: -19.569485\n",
            "resetting env. episode 2684.000000, reward total was -20.000000. running mean: -19.573790\n",
            "resetting env. episode 2685.000000, reward total was -21.000000. running mean: -19.588052\n",
            "resetting env. episode 2686.000000, reward total was -19.000000. running mean: -19.582171\n",
            "resetting env. episode 2687.000000, reward total was -18.000000. running mean: -19.566350\n",
            "resetting env. episode 2688.000000, reward total was -20.000000. running mean: -19.570686\n",
            "resetting env. episode 2689.000000, reward total was -19.000000. running mean: -19.564979\n",
            "resetting env. episode 2690.000000, reward total was -20.000000. running mean: -19.569330\n",
            "resetting env. episode 2691.000000, reward total was -20.000000. running mean: -19.573636\n",
            "resetting env. episode 2692.000000, reward total was -19.000000. running mean: -19.567900\n",
            "resetting env. episode 2693.000000, reward total was -21.000000. running mean: -19.582221\n",
            "resetting env. episode 2694.000000, reward total was -21.000000. running mean: -19.596399\n",
            "resetting env. episode 2695.000000, reward total was -21.000000. running mean: -19.610435\n",
            "resetting env. episode 2696.000000, reward total was -19.000000. running mean: -19.604330\n",
            "resetting env. episode 2697.000000, reward total was -21.000000. running mean: -19.618287\n",
            "resetting env. episode 2698.000000, reward total was -20.000000. running mean: -19.622104\n",
            "resetting env. episode 2699.000000, reward total was -19.000000. running mean: -19.615883\n",
            "resetting env. episode 2700.000000, reward total was -20.000000. running mean: -19.619724\n",
            "resetting env. episode 2701.000000, reward total was -20.000000. running mean: -19.623527\n",
            "resetting env. episode 2702.000000, reward total was -18.000000. running mean: -19.607292\n",
            "resetting env. episode 2703.000000, reward total was -21.000000. running mean: -19.621219\n",
            "resetting env. episode 2704.000000, reward total was -20.000000. running mean: -19.625007\n",
            "resetting env. episode 2705.000000, reward total was -17.000000. running mean: -19.598757\n",
            "resetting env. episode 2706.000000, reward total was -19.000000. running mean: -19.592769\n",
            "resetting env. episode 2707.000000, reward total was -20.000000. running mean: -19.596841\n",
            "resetting env. episode 2708.000000, reward total was -19.000000. running mean: -19.590873\n",
            "resetting env. episode 2709.000000, reward total was -18.000000. running mean: -19.574964\n",
            "resetting env. episode 2710.000000, reward total was -20.000000. running mean: -19.579215\n",
            "resetting env. episode 2711.000000, reward total was -18.000000. running mean: -19.563422\n",
            "resetting env. episode 2712.000000, reward total was -21.000000. running mean: -19.577788\n",
            "resetting env. episode 2713.000000, reward total was -18.000000. running mean: -19.562010\n",
            "resetting env. episode 2714.000000, reward total was -21.000000. running mean: -19.576390\n",
            "resetting env. episode 2715.000000, reward total was -20.000000. running mean: -19.580626\n",
            "resetting env. episode 2716.000000, reward total was -20.000000. running mean: -19.584820\n",
            "resetting env. episode 2717.000000, reward total was -20.000000. running mean: -19.588972\n",
            "resetting env. episode 2718.000000, reward total was -20.000000. running mean: -19.593082\n",
            "resetting env. episode 2719.000000, reward total was -19.000000. running mean: -19.587151\n",
            "resetting env. episode 2720.000000, reward total was -19.000000. running mean: -19.581280\n",
            "resetting env. episode 2721.000000, reward total was -21.000000. running mean: -19.595467\n",
            "resetting env. episode 2722.000000, reward total was -20.000000. running mean: -19.599512\n",
            "resetting env. episode 2723.000000, reward total was -19.000000. running mean: -19.593517\n",
            "resetting env. episode 2724.000000, reward total was -17.000000. running mean: -19.567582\n",
            "resetting env. episode 2725.000000, reward total was -19.000000. running mean: -19.561906\n",
            "resetting env. episode 2726.000000, reward total was -21.000000. running mean: -19.576287\n",
            "resetting env. episode 2727.000000, reward total was -19.000000. running mean: -19.570524\n",
            "resetting env. episode 2728.000000, reward total was -19.000000. running mean: -19.564819\n",
            "resetting env. episode 2729.000000, reward total was -19.000000. running mean: -19.559171\n",
            "resetting env. episode 2730.000000, reward total was -21.000000. running mean: -19.573579\n",
            "resetting env. episode 2731.000000, reward total was -20.000000. running mean: -19.577843\n",
            "resetting env. episode 2732.000000, reward total was -17.000000. running mean: -19.552065\n",
            "resetting env. episode 2733.000000, reward total was -19.000000. running mean: -19.546544\n",
            "resetting env. episode 2734.000000, reward total was -20.000000. running mean: -19.551079\n",
            "resetting env. episode 2735.000000, reward total was -21.000000. running mean: -19.565568\n",
            "resetting env. episode 2736.000000, reward total was -20.000000. running mean: -19.569912\n",
            "resetting env. episode 2737.000000, reward total was -20.000000. running mean: -19.574213\n",
            "resetting env. episode 2738.000000, reward total was -20.000000. running mean: -19.578471\n",
            "resetting env. episode 2739.000000, reward total was -20.000000. running mean: -19.582686\n",
            "resetting env. episode 2740.000000, reward total was -21.000000. running mean: -19.596860\n",
            "resetting env. episode 2741.000000, reward total was -19.000000. running mean: -19.590891\n",
            "resetting env. episode 2742.000000, reward total was -19.000000. running mean: -19.584982\n",
            "resetting env. episode 2743.000000, reward total was -19.000000. running mean: -19.579132\n",
            "resetting env. episode 2744.000000, reward total was -21.000000. running mean: -19.593341\n",
            "resetting env. episode 2745.000000, reward total was -19.000000. running mean: -19.587407\n",
            "resetting env. episode 2746.000000, reward total was -21.000000. running mean: -19.601533\n",
            "resetting env. episode 2747.000000, reward total was -20.000000. running mean: -19.605518\n",
            "resetting env. episode 2748.000000, reward total was -21.000000. running mean: -19.619463\n",
            "resetting env. episode 2749.000000, reward total was -17.000000. running mean: -19.593268\n",
            "resetting env. episode 2750.000000, reward total was -18.000000. running mean: -19.577336\n",
            "resetting env. episode 2751.000000, reward total was -20.000000. running mean: -19.581562\n",
            "resetting env. episode 2752.000000, reward total was -19.000000. running mean: -19.575747\n",
            "resetting env. episode 2753.000000, reward total was -17.000000. running mean: -19.549989\n",
            "resetting env. episode 2754.000000, reward total was -15.000000. running mean: -19.504489\n",
            "resetting env. episode 2755.000000, reward total was -19.000000. running mean: -19.499444\n",
            "resetting env. episode 2756.000000, reward total was -19.000000. running mean: -19.494450\n",
            "resetting env. episode 2757.000000, reward total was -19.000000. running mean: -19.489505\n",
            "resetting env. episode 2758.000000, reward total was -20.000000. running mean: -19.494610\n",
            "resetting env. episode 2759.000000, reward total was -21.000000. running mean: -19.509664\n",
            "resetting env. episode 2760.000000, reward total was -21.000000. running mean: -19.524568\n",
            "resetting env. episode 2761.000000, reward total was -21.000000. running mean: -19.539322\n",
            "resetting env. episode 2762.000000, reward total was -21.000000. running mean: -19.553929\n",
            "resetting env. episode 2763.000000, reward total was -15.000000. running mean: -19.508389\n",
            "resetting env. episode 2764.000000, reward total was -18.000000. running mean: -19.493306\n",
            "resetting env. episode 2765.000000, reward total was -18.000000. running mean: -19.478372\n",
            "resetting env. episode 2766.000000, reward total was -21.000000. running mean: -19.493589\n",
            "resetting env. episode 2767.000000, reward total was -19.000000. running mean: -19.488653\n",
            "resetting env. episode 2768.000000, reward total was -20.000000. running mean: -19.493766\n",
            "resetting env. episode 2769.000000, reward total was -19.000000. running mean: -19.488829\n",
            "resetting env. episode 2770.000000, reward total was -18.000000. running mean: -19.473940\n",
            "resetting env. episode 2771.000000, reward total was -17.000000. running mean: -19.449201\n",
            "resetting env. episode 2772.000000, reward total was -20.000000. running mean: -19.454709\n",
            "resetting env. episode 2773.000000, reward total was -14.000000. running mean: -19.400162\n",
            "resetting env. episode 2774.000000, reward total was -18.000000. running mean: -19.386160\n",
            "resetting env. episode 2775.000000, reward total was -21.000000. running mean: -19.402299\n",
            "resetting env. episode 2776.000000, reward total was -21.000000. running mean: -19.418276\n",
            "resetting env. episode 2777.000000, reward total was -19.000000. running mean: -19.414093\n",
            "resetting env. episode 2778.000000, reward total was -19.000000. running mean: -19.409952\n",
            "resetting env. episode 2779.000000, reward total was -21.000000. running mean: -19.425852\n",
            "resetting env. episode 2780.000000, reward total was -18.000000. running mean: -19.411594\n",
            "resetting env. episode 2781.000000, reward total was -21.000000. running mean: -19.427478\n",
            "resetting env. episode 2782.000000, reward total was -18.000000. running mean: -19.413203\n",
            "resetting env. episode 2783.000000, reward total was -21.000000. running mean: -19.429071\n",
            "resetting env. episode 2784.000000, reward total was -19.000000. running mean: -19.424780\n",
            "resetting env. episode 2785.000000, reward total was -20.000000. running mean: -19.430533\n",
            "resetting env. episode 2786.000000, reward total was -20.000000. running mean: -19.436227\n",
            "resetting env. episode 2787.000000, reward total was -21.000000. running mean: -19.451865\n",
            "resetting env. episode 2788.000000, reward total was -20.000000. running mean: -19.457346\n",
            "resetting env. episode 2789.000000, reward total was -19.000000. running mean: -19.452773\n",
            "resetting env. episode 2790.000000, reward total was -20.000000. running mean: -19.458245\n",
            "resetting env. episode 2791.000000, reward total was -20.000000. running mean: -19.463663\n",
            "resetting env. episode 2792.000000, reward total was -19.000000. running mean: -19.459026\n",
            "resetting env. episode 2793.000000, reward total was -20.000000. running mean: -19.464436\n",
            "resetting env. episode 2794.000000, reward total was -20.000000. running mean: -19.469792\n",
            "resetting env. episode 2795.000000, reward total was -21.000000. running mean: -19.485094\n",
            "resetting env. episode 2796.000000, reward total was -21.000000. running mean: -19.500243\n",
            "resetting env. episode 2797.000000, reward total was -21.000000. running mean: -19.515240\n",
            "resetting env. episode 2798.000000, reward total was -19.000000. running mean: -19.510088\n",
            "resetting env. episode 2799.000000, reward total was -21.000000. running mean: -19.524987\n",
            "resetting env. episode 2800.000000, reward total was -19.000000. running mean: -19.519737\n",
            "resetting env. episode 2801.000000, reward total was -17.000000. running mean: -19.494540\n",
            "resetting env. episode 2802.000000, reward total was -21.000000. running mean: -19.509594\n",
            "resetting env. episode 2803.000000, reward total was -18.000000. running mean: -19.494498\n",
            "resetting env. episode 2804.000000, reward total was -18.000000. running mean: -19.479553\n",
            "resetting env. episode 2805.000000, reward total was -17.000000. running mean: -19.454758\n",
            "resetting env. episode 2806.000000, reward total was -20.000000. running mean: -19.460210\n",
            "resetting env. episode 2807.000000, reward total was -21.000000. running mean: -19.475608\n",
            "resetting env. episode 2808.000000, reward total was -19.000000. running mean: -19.470852\n",
            "resetting env. episode 2809.000000, reward total was -20.000000. running mean: -19.476144\n",
            "resetting env. episode 2810.000000, reward total was -21.000000. running mean: -19.491382\n",
            "resetting env. episode 2811.000000, reward total was -21.000000. running mean: -19.506468\n",
            "resetting env. episode 2812.000000, reward total was -20.000000. running mean: -19.511404\n",
            "resetting env. episode 2813.000000, reward total was -19.000000. running mean: -19.506290\n",
            "resetting env. episode 2814.000000, reward total was -19.000000. running mean: -19.501227\n",
            "resetting env. episode 2815.000000, reward total was -18.000000. running mean: -19.486214\n",
            "resetting env. episode 2816.000000, reward total was -17.000000. running mean: -19.461352\n",
            "resetting env. episode 2817.000000, reward total was -18.000000. running mean: -19.446739\n",
            "resetting env. episode 2818.000000, reward total was -20.000000. running mean: -19.452271\n",
            "resetting env. episode 2819.000000, reward total was -19.000000. running mean: -19.447749\n",
            "resetting env. episode 2820.000000, reward total was -21.000000. running mean: -19.463271\n",
            "resetting env. episode 2821.000000, reward total was -19.000000. running mean: -19.458638\n",
            "resetting env. episode 2822.000000, reward total was -21.000000. running mean: -19.474052\n",
            "resetting env. episode 2823.000000, reward total was -20.000000. running mean: -19.479312\n",
            "resetting env. episode 2824.000000, reward total was -21.000000. running mean: -19.494518\n",
            "resetting env. episode 2825.000000, reward total was -20.000000. running mean: -19.499573\n",
            "resetting env. episode 2826.000000, reward total was -21.000000. running mean: -19.514578\n",
            "resetting env. episode 2827.000000, reward total was -21.000000. running mean: -19.529432\n",
            "resetting env. episode 2828.000000, reward total was -21.000000. running mean: -19.544137\n",
            "resetting env. episode 2829.000000, reward total was -20.000000. running mean: -19.548696\n",
            "resetting env. episode 2830.000000, reward total was -19.000000. running mean: -19.543209\n",
            "resetting env. episode 2831.000000, reward total was -21.000000. running mean: -19.557777\n",
            "resetting env. episode 2832.000000, reward total was -18.000000. running mean: -19.542199\n",
            "resetting env. episode 2833.000000, reward total was -21.000000. running mean: -19.556777\n",
            "resetting env. episode 2834.000000, reward total was -19.000000. running mean: -19.551209\n",
            "resetting env. episode 2835.000000, reward total was -21.000000. running mean: -19.565697\n",
            "resetting env. episode 2836.000000, reward total was -18.000000. running mean: -19.550040\n",
            "resetting env. episode 2837.000000, reward total was -20.000000. running mean: -19.554540\n",
            "resetting env. episode 2838.000000, reward total was -20.000000. running mean: -19.558995\n",
            "resetting env. episode 2839.000000, reward total was -18.000000. running mean: -19.543405\n",
            "resetting env. episode 2840.000000, reward total was -19.000000. running mean: -19.537971\n",
            "resetting env. episode 2841.000000, reward total was -20.000000. running mean: -19.542591\n",
            "resetting env. episode 2842.000000, reward total was -18.000000. running mean: -19.527165\n",
            "resetting env. episode 2843.000000, reward total was -19.000000. running mean: -19.521893\n",
            "resetting env. episode 2844.000000, reward total was -20.000000. running mean: -19.526674\n",
            "resetting env. episode 2845.000000, reward total was -19.000000. running mean: -19.521408\n",
            "resetting env. episode 2846.000000, reward total was -19.000000. running mean: -19.516194\n",
            "resetting env. episode 2847.000000, reward total was -20.000000. running mean: -19.521032\n",
            "resetting env. episode 2848.000000, reward total was -17.000000. running mean: -19.495821\n",
            "resetting env. episode 2849.000000, reward total was -20.000000. running mean: -19.500863\n",
            "resetting env. episode 2850.000000, reward total was -18.000000. running mean: -19.485854\n",
            "resetting env. episode 2851.000000, reward total was -21.000000. running mean: -19.500996\n",
            "resetting env. episode 2852.000000, reward total was -17.000000. running mean: -19.475986\n",
            "resetting env. episode 2853.000000, reward total was -21.000000. running mean: -19.491226\n",
            "resetting env. episode 2854.000000, reward total was -20.000000. running mean: -19.496314\n",
            "resetting env. episode 2855.000000, reward total was -20.000000. running mean: -19.501351\n",
            "resetting env. episode 2856.000000, reward total was -21.000000. running mean: -19.516337\n",
            "resetting env. episode 2857.000000, reward total was -20.000000. running mean: -19.521174\n",
            "resetting env. episode 2858.000000, reward total was -18.000000. running mean: -19.505962\n",
            "resetting env. episode 2859.000000, reward total was -19.000000. running mean: -19.500902\n",
            "resetting env. episode 2860.000000, reward total was -21.000000. running mean: -19.515893\n",
            "resetting env. episode 2861.000000, reward total was -21.000000. running mean: -19.530735\n",
            "resetting env. episode 2862.000000, reward total was -21.000000. running mean: -19.545427\n",
            "resetting env. episode 2863.000000, reward total was -20.000000. running mean: -19.549973\n",
            "resetting env. episode 2864.000000, reward total was -18.000000. running mean: -19.534473\n",
            "resetting env. episode 2865.000000, reward total was -17.000000. running mean: -19.509128\n",
            "resetting env. episode 2866.000000, reward total was -19.000000. running mean: -19.504037\n",
            "resetting env. episode 2867.000000, reward total was -19.000000. running mean: -19.498997\n",
            "resetting env. episode 2868.000000, reward total was -20.000000. running mean: -19.504007\n",
            "resetting env. episode 2869.000000, reward total was -21.000000. running mean: -19.518967\n",
            "resetting env. episode 2870.000000, reward total was -19.000000. running mean: -19.513777\n",
            "resetting env. episode 2871.000000, reward total was -20.000000. running mean: -19.518639\n",
            "resetting env. episode 2872.000000, reward total was -19.000000. running mean: -19.513453\n",
            "resetting env. episode 2873.000000, reward total was -19.000000. running mean: -19.508318\n",
            "resetting env. episode 2874.000000, reward total was -18.000000. running mean: -19.493235\n",
            "resetting env. episode 2875.000000, reward total was -17.000000. running mean: -19.468303\n",
            "resetting env. episode 2876.000000, reward total was -19.000000. running mean: -19.463620\n",
            "resetting env. episode 2877.000000, reward total was -21.000000. running mean: -19.478984\n",
            "resetting env. episode 2878.000000, reward total was -18.000000. running mean: -19.464194\n",
            "resetting env. episode 2879.000000, reward total was -19.000000. running mean: -19.459552\n",
            "resetting env. episode 2880.000000, reward total was -20.000000. running mean: -19.464956\n",
            "resetting env. episode 2881.000000, reward total was -20.000000. running mean: -19.470307\n",
            "resetting env. episode 2882.000000, reward total was -18.000000. running mean: -19.455604\n",
            "resetting env. episode 2883.000000, reward total was -21.000000. running mean: -19.471048\n",
            "resetting env. episode 2884.000000, reward total was -21.000000. running mean: -19.486337\n",
            "resetting env. episode 2885.000000, reward total was -21.000000. running mean: -19.501474\n",
            "resetting env. episode 2886.000000, reward total was -19.000000. running mean: -19.496459\n",
            "resetting env. episode 2887.000000, reward total was -18.000000. running mean: -19.481494\n",
            "resetting env. episode 2888.000000, reward total was -20.000000. running mean: -19.486680\n",
            "resetting env. episode 2889.000000, reward total was -17.000000. running mean: -19.461813\n",
            "resetting env. episode 2890.000000, reward total was -19.000000. running mean: -19.457195\n",
            "resetting env. episode 2891.000000, reward total was -20.000000. running mean: -19.462623\n",
            "resetting env. episode 2892.000000, reward total was -20.000000. running mean: -19.467996\n",
            "resetting env. episode 2893.000000, reward total was -18.000000. running mean: -19.453316\n",
            "resetting env. episode 2894.000000, reward total was -20.000000. running mean: -19.458783\n",
            "resetting env. episode 2895.000000, reward total was -20.000000. running mean: -19.464195\n",
            "resetting env. episode 2896.000000, reward total was -17.000000. running mean: -19.439554\n",
            "resetting env. episode 2897.000000, reward total was -21.000000. running mean: -19.455158\n",
            "resetting env. episode 2898.000000, reward total was -21.000000. running mean: -19.470606\n",
            "resetting env. episode 2899.000000, reward total was -17.000000. running mean: -19.445900\n",
            "resetting env. episode 2900.000000, reward total was -21.000000. running mean: -19.461441\n",
            "resetting env. episode 2901.000000, reward total was -19.000000. running mean: -19.456827\n",
            "resetting env. episode 2902.000000, reward total was -21.000000. running mean: -19.472259\n",
            "resetting env. episode 2903.000000, reward total was -19.000000. running mean: -19.467536\n",
            "resetting env. episode 2904.000000, reward total was -20.000000. running mean: -19.472861\n",
            "resetting env. episode 2905.000000, reward total was -21.000000. running mean: -19.488132\n",
            "resetting env. episode 2906.000000, reward total was -21.000000. running mean: -19.503251\n",
            "resetting env. episode 2907.000000, reward total was -18.000000. running mean: -19.488218\n",
            "resetting env. episode 2908.000000, reward total was -21.000000. running mean: -19.503336\n",
            "resetting env. episode 2909.000000, reward total was -19.000000. running mean: -19.498303\n",
            "resetting env. episode 2910.000000, reward total was -20.000000. running mean: -19.503320\n",
            "resetting env. episode 2911.000000, reward total was -21.000000. running mean: -19.518287\n",
            "resetting env. episode 2912.000000, reward total was -19.000000. running mean: -19.513104\n",
            "resetting env. episode 2913.000000, reward total was -20.000000. running mean: -19.517973\n",
            "resetting env. episode 2914.000000, reward total was -21.000000. running mean: -19.532793\n",
            "resetting env. episode 2915.000000, reward total was -18.000000. running mean: -19.517465\n",
            "resetting env. episode 2916.000000, reward total was -20.000000. running mean: -19.522290\n",
            "resetting env. episode 2917.000000, reward total was -20.000000. running mean: -19.527067\n",
            "resetting env. episode 2918.000000, reward total was -18.000000. running mean: -19.511797\n",
            "resetting env. episode 2919.000000, reward total was -19.000000. running mean: -19.506679\n",
            "resetting env. episode 2920.000000, reward total was -20.000000. running mean: -19.511612\n",
            "resetting env. episode 2921.000000, reward total was -21.000000. running mean: -19.526496\n",
            "resetting env. episode 2922.000000, reward total was -21.000000. running mean: -19.541231\n",
            "resetting env. episode 2923.000000, reward total was -20.000000. running mean: -19.545819\n",
            "resetting env. episode 2924.000000, reward total was -21.000000. running mean: -19.560360\n",
            "resetting env. episode 2925.000000, reward total was -18.000000. running mean: -19.544757\n",
            "resetting env. episode 2926.000000, reward total was -20.000000. running mean: -19.549309\n",
            "resetting env. episode 2927.000000, reward total was -19.000000. running mean: -19.543816\n",
            "resetting env. episode 2928.000000, reward total was -20.000000. running mean: -19.548378\n",
            "resetting env. episode 2929.000000, reward total was -19.000000. running mean: -19.542894\n",
            "resetting env. episode 2930.000000, reward total was -20.000000. running mean: -19.547465\n",
            "resetting env. episode 2931.000000, reward total was -19.000000. running mean: -19.541991\n",
            "resetting env. episode 2932.000000, reward total was -20.000000. running mean: -19.546571\n",
            "resetting env. episode 2933.000000, reward total was -21.000000. running mean: -19.561105\n",
            "resetting env. episode 2934.000000, reward total was -20.000000. running mean: -19.565494\n",
            "resetting env. episode 2935.000000, reward total was -18.000000. running mean: -19.549839\n",
            "resetting env. episode 2936.000000, reward total was -20.000000. running mean: -19.554341\n",
            "resetting env. episode 2937.000000, reward total was -19.000000. running mean: -19.548797\n",
            "resetting env. episode 2938.000000, reward total was -21.000000. running mean: -19.563309\n",
            "resetting env. episode 2939.000000, reward total was -21.000000. running mean: -19.577676\n",
            "resetting env. episode 2940.000000, reward total was -20.000000. running mean: -19.581899\n",
            "resetting env. episode 2941.000000, reward total was -21.000000. running mean: -19.596080\n",
            "resetting env. episode 2942.000000, reward total was -21.000000. running mean: -19.610120\n",
            "resetting env. episode 2943.000000, reward total was -19.000000. running mean: -19.604018\n",
            "resetting env. episode 2944.000000, reward total was -19.000000. running mean: -19.597978\n",
            "resetting env. episode 2945.000000, reward total was -17.000000. running mean: -19.571998\n",
            "resetting env. episode 2946.000000, reward total was -19.000000. running mean: -19.566278\n",
            "resetting env. episode 2947.000000, reward total was -20.000000. running mean: -19.570616\n",
            "resetting env. episode 2948.000000, reward total was -21.000000. running mean: -19.584909\n",
            "resetting env. episode 2949.000000, reward total was -19.000000. running mean: -19.579060\n",
            "resetting env. episode 2950.000000, reward total was -19.000000. running mean: -19.573270\n",
            "resetting env. episode 2951.000000, reward total was -21.000000. running mean: -19.587537\n",
            "resetting env. episode 2952.000000, reward total was -20.000000. running mean: -19.591662\n",
            "resetting env. episode 2953.000000, reward total was -19.000000. running mean: -19.585745\n",
            "resetting env. episode 2954.000000, reward total was -19.000000. running mean: -19.579888\n",
            "resetting env. episode 2955.000000, reward total was -17.000000. running mean: -19.554089\n",
            "resetting env. episode 2956.000000, reward total was -19.000000. running mean: -19.548548\n",
            "resetting env. episode 2957.000000, reward total was -17.000000. running mean: -19.523062\n",
            "resetting env. episode 2958.000000, reward total was -20.000000. running mean: -19.527832\n",
            "resetting env. episode 2959.000000, reward total was -20.000000. running mean: -19.532553\n",
            "resetting env. episode 2960.000000, reward total was -20.000000. running mean: -19.537228\n",
            "resetting env. episode 2961.000000, reward total was -21.000000. running mean: -19.551856\n",
            "resetting env. episode 2962.000000, reward total was -21.000000. running mean: -19.566337\n",
            "resetting env. episode 2963.000000, reward total was -21.000000. running mean: -19.580674\n",
            "resetting env. episode 2964.000000, reward total was -20.000000. running mean: -19.584867\n",
            "resetting env. episode 2965.000000, reward total was -20.000000. running mean: -19.589018\n",
            "resetting env. episode 2966.000000, reward total was -21.000000. running mean: -19.603128\n",
            "resetting env. episode 2967.000000, reward total was -20.000000. running mean: -19.607097\n",
            "resetting env. episode 2968.000000, reward total was -20.000000. running mean: -19.611026\n",
            "resetting env. episode 2969.000000, reward total was -21.000000. running mean: -19.624916\n",
            "resetting env. episode 2970.000000, reward total was -21.000000. running mean: -19.638666\n",
            "resetting env. episode 2971.000000, reward total was -20.000000. running mean: -19.642280\n",
            "resetting env. episode 2972.000000, reward total was -21.000000. running mean: -19.655857\n",
            "resetting env. episode 2973.000000, reward total was -16.000000. running mean: -19.619298\n",
            "resetting env. episode 2974.000000, reward total was -19.000000. running mean: -19.613105\n",
            "resetting env. episode 2975.000000, reward total was -17.000000. running mean: -19.586974\n",
            "resetting env. episode 2976.000000, reward total was -20.000000. running mean: -19.591105\n",
            "resetting env. episode 2977.000000, reward total was -19.000000. running mean: -19.585194\n",
            "resetting env. episode 2978.000000, reward total was -21.000000. running mean: -19.599342\n",
            "resetting env. episode 2979.000000, reward total was -21.000000. running mean: -19.613348\n",
            "resetting env. episode 2980.000000, reward total was -20.000000. running mean: -19.617215\n",
            "resetting env. episode 2981.000000, reward total was -17.000000. running mean: -19.591043\n",
            "resetting env. episode 2982.000000, reward total was -18.000000. running mean: -19.575132\n",
            "resetting env. episode 2983.000000, reward total was -20.000000. running mean: -19.579381\n",
            "resetting env. episode 2984.000000, reward total was -17.000000. running mean: -19.553587\n",
            "resetting env. episode 2985.000000, reward total was -20.000000. running mean: -19.558051\n",
            "resetting env. episode 2986.000000, reward total was -21.000000. running mean: -19.572471\n",
            "resetting env. episode 2987.000000, reward total was -19.000000. running mean: -19.566746\n",
            "resetting env. episode 2988.000000, reward total was -18.000000. running mean: -19.551079\n",
            "resetting env. episode 2989.000000, reward total was -19.000000. running mean: -19.545568\n",
            "resetting env. episode 2990.000000, reward total was -19.000000. running mean: -19.540112\n",
            "resetting env. episode 2991.000000, reward total was -21.000000. running mean: -19.554711\n",
            "resetting env. episode 2992.000000, reward total was -19.000000. running mean: -19.549164\n",
            "resetting env. episode 2993.000000, reward total was -20.000000. running mean: -19.553672\n",
            "resetting env. episode 2994.000000, reward total was -16.000000. running mean: -19.518135\n",
            "resetting env. episode 2995.000000, reward total was -17.000000. running mean: -19.492954\n",
            "resetting env. episode 2996.000000, reward total was -21.000000. running mean: -19.508025\n",
            "resetting env. episode 2997.000000, reward total was -18.000000. running mean: -19.492944\n",
            "resetting env. episode 2998.000000, reward total was -20.000000. running mean: -19.498015\n",
            "resetting env. episode 2999.000000, reward total was -20.000000. running mean: -19.503035\n",
            "resetting env. episode 3000.000000, reward total was -18.000000. running mean: -19.488004\n",
            "resetting env. episode 3001.000000, reward total was -19.000000. running mean: -19.483124\n",
            "resetting env. episode 3002.000000, reward total was -20.000000. running mean: -19.488293\n",
            "resetting env. episode 3003.000000, reward total was -20.000000. running mean: -19.493410\n",
            "resetting env. episode 3004.000000, reward total was -17.000000. running mean: -19.468476\n",
            "resetting env. episode 3005.000000, reward total was -19.000000. running mean: -19.463791\n",
            "resetting env. episode 3006.000000, reward total was -20.000000. running mean: -19.469153\n",
            "resetting env. episode 3007.000000, reward total was -19.000000. running mean: -19.464462\n",
            "resetting env. episode 3008.000000, reward total was -17.000000. running mean: -19.439817\n",
            "resetting env. episode 3009.000000, reward total was -21.000000. running mean: -19.455419\n",
            "resetting env. episode 3010.000000, reward total was -17.000000. running mean: -19.430865\n",
            "resetting env. episode 3011.000000, reward total was -19.000000. running mean: -19.426556\n",
            "resetting env. episode 3012.000000, reward total was -19.000000. running mean: -19.422291\n",
            "resetting env. episode 3013.000000, reward total was -20.000000. running mean: -19.428068\n",
            "resetting env. episode 3014.000000, reward total was -19.000000. running mean: -19.423787\n",
            "resetting env. episode 3015.000000, reward total was -19.000000. running mean: -19.419549\n",
            "resetting env. episode 3016.000000, reward total was -21.000000. running mean: -19.435354\n",
            "resetting env. episode 3017.000000, reward total was -21.000000. running mean: -19.451000\n",
            "resetting env. episode 3018.000000, reward total was -21.000000. running mean: -19.466490\n",
            "resetting env. episode 3019.000000, reward total was -21.000000. running mean: -19.481825\n",
            "resetting env. episode 3020.000000, reward total was -20.000000. running mean: -19.487007\n",
            "resetting env. episode 3021.000000, reward total was -20.000000. running mean: -19.492137\n",
            "resetting env. episode 3022.000000, reward total was -20.000000. running mean: -19.497216\n",
            "resetting env. episode 3023.000000, reward total was -19.000000. running mean: -19.492243\n",
            "resetting env. episode 3024.000000, reward total was -19.000000. running mean: -19.487321\n",
            "resetting env. episode 3025.000000, reward total was -20.000000. running mean: -19.492448\n",
            "resetting env. episode 3026.000000, reward total was -17.000000. running mean: -19.467523\n",
            "resetting env. episode 3027.000000, reward total was -16.000000. running mean: -19.432848\n",
            "resetting env. episode 3028.000000, reward total was -20.000000. running mean: -19.438520\n",
            "resetting env. episode 3029.000000, reward total was -17.000000. running mean: -19.414134\n",
            "resetting env. episode 3030.000000, reward total was -19.000000. running mean: -19.409993\n",
            "resetting env. episode 3031.000000, reward total was -19.000000. running mean: -19.405893\n",
            "resetting env. episode 3032.000000, reward total was -17.000000. running mean: -19.381834\n",
            "resetting env. episode 3033.000000, reward total was -21.000000. running mean: -19.398016\n",
            "resetting env. episode 3034.000000, reward total was -19.000000. running mean: -19.394036\n",
            "resetting env. episode 3035.000000, reward total was -20.000000. running mean: -19.400095\n",
            "resetting env. episode 3036.000000, reward total was -19.000000. running mean: -19.396094\n",
            "resetting env. episode 3037.000000, reward total was -20.000000. running mean: -19.402133\n",
            "resetting env. episode 3038.000000, reward total was -20.000000. running mean: -19.408112\n",
            "resetting env. episode 3039.000000, reward total was -20.000000. running mean: -19.414031\n",
            "resetting env. episode 3040.000000, reward total was -21.000000. running mean: -19.429891\n",
            "resetting env. episode 3041.000000, reward total was -20.000000. running mean: -19.435592\n",
            "resetting env. episode 3042.000000, reward total was -19.000000. running mean: -19.431236\n",
            "resetting env. episode 3043.000000, reward total was -21.000000. running mean: -19.446923\n",
            "resetting env. episode 3044.000000, reward total was -19.000000. running mean: -19.442454\n",
            "resetting env. episode 3045.000000, reward total was -18.000000. running mean: -19.428030\n",
            "resetting env. episode 3046.000000, reward total was -19.000000. running mean: -19.423749\n",
            "resetting env. episode 3047.000000, reward total was -19.000000. running mean: -19.419512\n",
            "resetting env. episode 3048.000000, reward total was -19.000000. running mean: -19.415317\n",
            "resetting env. episode 3049.000000, reward total was -16.000000. running mean: -19.381164\n",
            "resetting env. episode 3050.000000, reward total was -19.000000. running mean: -19.377352\n",
            "resetting env. episode 3051.000000, reward total was -19.000000. running mean: -19.373578\n",
            "resetting env. episode 3052.000000, reward total was -18.000000. running mean: -19.359843\n",
            "resetting env. episode 3053.000000, reward total was -18.000000. running mean: -19.346244\n",
            "resetting env. episode 3054.000000, reward total was -17.000000. running mean: -19.322782\n",
            "resetting env. episode 3055.000000, reward total was -17.000000. running mean: -19.299554\n",
            "resetting env. episode 3056.000000, reward total was -19.000000. running mean: -19.296558\n",
            "resetting env. episode 3057.000000, reward total was -20.000000. running mean: -19.303593\n",
            "resetting env. episode 3058.000000, reward total was -18.000000. running mean: -19.290557\n",
            "resetting env. episode 3059.000000, reward total was -19.000000. running mean: -19.287651\n",
            "resetting env. episode 3060.000000, reward total was -20.000000. running mean: -19.294775\n",
            "resetting env. episode 3061.000000, reward total was -20.000000. running mean: -19.301827\n",
            "resetting env. episode 3062.000000, reward total was -20.000000. running mean: -19.308809\n",
            "resetting env. episode 3063.000000, reward total was -18.000000. running mean: -19.295721\n",
            "resetting env. episode 3064.000000, reward total was -20.000000. running mean: -19.302764\n",
            "resetting env. episode 3065.000000, reward total was -20.000000. running mean: -19.309736\n",
            "resetting env. episode 3066.000000, reward total was -20.000000. running mean: -19.316639\n",
            "resetting env. episode 3067.000000, reward total was -21.000000. running mean: -19.333472\n",
            "resetting env. episode 3068.000000, reward total was -19.000000. running mean: -19.330137\n",
            "resetting env. episode 3069.000000, reward total was -18.000000. running mean: -19.316836\n",
            "resetting env. episode 3070.000000, reward total was -20.000000. running mean: -19.323668\n",
            "resetting env. episode 3071.000000, reward total was -20.000000. running mean: -19.330431\n",
            "resetting env. episode 3072.000000, reward total was -20.000000. running mean: -19.337127\n",
            "resetting env. episode 3073.000000, reward total was -20.000000. running mean: -19.343755\n",
            "resetting env. episode 3074.000000, reward total was -20.000000. running mean: -19.350318\n",
            "resetting env. episode 3075.000000, reward total was -18.000000. running mean: -19.336815\n",
            "resetting env. episode 3076.000000, reward total was -18.000000. running mean: -19.323447\n",
            "resetting env. episode 3077.000000, reward total was -20.000000. running mean: -19.330212\n",
            "resetting env. episode 3078.000000, reward total was -19.000000. running mean: -19.326910\n",
            "resetting env. episode 3079.000000, reward total was -19.000000. running mean: -19.323641\n",
            "resetting env. episode 3080.000000, reward total was -20.000000. running mean: -19.330404\n",
            "resetting env. episode 3081.000000, reward total was -19.000000. running mean: -19.327100\n",
            "resetting env. episode 3082.000000, reward total was -19.000000. running mean: -19.323829\n",
            "resetting env. episode 3083.000000, reward total was -17.000000. running mean: -19.300591\n",
            "resetting env. episode 3084.000000, reward total was -19.000000. running mean: -19.297585\n",
            "resetting env. episode 3085.000000, reward total was -20.000000. running mean: -19.304609\n",
            "resetting env. episode 3086.000000, reward total was -20.000000. running mean: -19.311563\n",
            "resetting env. episode 3087.000000, reward total was -18.000000. running mean: -19.298448\n",
            "resetting env. episode 3088.000000, reward total was -18.000000. running mean: -19.285463\n",
            "resetting env. episode 3089.000000, reward total was -20.000000. running mean: -19.292609\n",
            "resetting env. episode 3090.000000, reward total was -20.000000. running mean: -19.299682\n",
            "resetting env. episode 3091.000000, reward total was -20.000000. running mean: -19.306686\n",
            "resetting env. episode 3092.000000, reward total was -20.000000. running mean: -19.313619\n",
            "resetting env. episode 3093.000000, reward total was -20.000000. running mean: -19.320483\n",
            "resetting env. episode 3094.000000, reward total was -21.000000. running mean: -19.337278\n",
            "resetting env. episode 3095.000000, reward total was -18.000000. running mean: -19.323905\n",
            "resetting env. episode 3096.000000, reward total was -19.000000. running mean: -19.320666\n",
            "resetting env. episode 3097.000000, reward total was -20.000000. running mean: -19.327459\n",
            "resetting env. episode 3098.000000, reward total was -19.000000. running mean: -19.324185\n",
            "resetting env. episode 3099.000000, reward total was -18.000000. running mean: -19.310943\n",
            "resetting env. episode 3100.000000, reward total was -19.000000. running mean: -19.307833\n",
            "resetting env. episode 3101.000000, reward total was -17.000000. running mean: -19.284755\n",
            "resetting env. episode 3102.000000, reward total was -19.000000. running mean: -19.281908\n",
            "resetting env. episode 3103.000000, reward total was -18.000000. running mean: -19.269088\n",
            "resetting env. episode 3104.000000, reward total was -21.000000. running mean: -19.286398\n",
            "resetting env. episode 3105.000000, reward total was -18.000000. running mean: -19.273534\n",
            "resetting env. episode 3106.000000, reward total was -17.000000. running mean: -19.250798\n",
            "resetting env. episode 3107.000000, reward total was -19.000000. running mean: -19.248290\n",
            "resetting env. episode 3108.000000, reward total was -21.000000. running mean: -19.265807\n",
            "resetting env. episode 3109.000000, reward total was -20.000000. running mean: -19.273149\n",
            "resetting env. episode 3110.000000, reward total was -21.000000. running mean: -19.290418\n",
            "resetting env. episode 3111.000000, reward total was -20.000000. running mean: -19.297514\n",
            "resetting env. episode 3112.000000, reward total was -21.000000. running mean: -19.314538\n",
            "resetting env. episode 3113.000000, reward total was -20.000000. running mean: -19.321393\n",
            "resetting env. episode 3114.000000, reward total was -20.000000. running mean: -19.328179\n",
            "resetting env. episode 3115.000000, reward total was -21.000000. running mean: -19.344897\n",
            "resetting env. episode 3116.000000, reward total was -19.000000. running mean: -19.341448\n",
            "resetting env. episode 3117.000000, reward total was -21.000000. running mean: -19.358034\n",
            "resetting env. episode 3118.000000, reward total was -17.000000. running mean: -19.334454\n",
            "resetting env. episode 3119.000000, reward total was -21.000000. running mean: -19.351109\n",
            "resetting env. episode 3120.000000, reward total was -20.000000. running mean: -19.357598\n",
            "resetting env. episode 3121.000000, reward total was -21.000000. running mean: -19.374022\n",
            "resetting env. episode 3122.000000, reward total was -19.000000. running mean: -19.370282\n",
            "resetting env. episode 3123.000000, reward total was -18.000000. running mean: -19.356579\n",
            "resetting env. episode 3124.000000, reward total was -19.000000. running mean: -19.353013\n",
            "resetting env. episode 3125.000000, reward total was -20.000000. running mean: -19.359483\n",
            "resetting env. episode 3126.000000, reward total was -18.000000. running mean: -19.345888\n",
            "resetting env. episode 3127.000000, reward total was -21.000000. running mean: -19.362429\n",
            "resetting env. episode 3128.000000, reward total was -20.000000. running mean: -19.368805\n",
            "resetting env. episode 3129.000000, reward total was -20.000000. running mean: -19.375117\n",
            "resetting env. episode 3130.000000, reward total was -17.000000. running mean: -19.351366\n",
            "resetting env. episode 3131.000000, reward total was -19.000000. running mean: -19.347852\n",
            "resetting env. episode 3132.000000, reward total was -21.000000. running mean: -19.364374\n",
            "resetting env. episode 3133.000000, reward total was -20.000000. running mean: -19.370730\n",
            "resetting env. episode 3134.000000, reward total was -18.000000. running mean: -19.357023\n",
            "resetting env. episode 3135.000000, reward total was -21.000000. running mean: -19.373452\n",
            "resetting env. episode 3136.000000, reward total was -18.000000. running mean: -19.359718\n",
            "resetting env. episode 3137.000000, reward total was -18.000000. running mean: -19.346121\n",
            "resetting env. episode 3138.000000, reward total was -19.000000. running mean: -19.342659\n",
            "resetting env. episode 3139.000000, reward total was -20.000000. running mean: -19.349233\n",
            "resetting env. episode 3140.000000, reward total was -21.000000. running mean: -19.365741\n",
            "resetting env. episode 3141.000000, reward total was -19.000000. running mean: -19.362083\n",
            "resetting env. episode 3142.000000, reward total was -18.000000. running mean: -19.348462\n",
            "resetting env. episode 3143.000000, reward total was -18.000000. running mean: -19.334978\n",
            "resetting env. episode 3144.000000, reward total was -20.000000. running mean: -19.341628\n",
            "resetting env. episode 3145.000000, reward total was -19.000000. running mean: -19.338212\n",
            "resetting env. episode 3146.000000, reward total was -17.000000. running mean: -19.314829\n",
            "resetting env. episode 3147.000000, reward total was -20.000000. running mean: -19.321681\n",
            "resetting env. episode 3148.000000, reward total was -18.000000. running mean: -19.308464\n",
            "resetting env. episode 3149.000000, reward total was -20.000000. running mean: -19.315380\n",
            "resetting env. episode 3150.000000, reward total was -20.000000. running mean: -19.322226\n",
            "resetting env. episode 3151.000000, reward total was -21.000000. running mean: -19.339004\n",
            "resetting env. episode 3152.000000, reward total was -20.000000. running mean: -19.345614\n",
            "resetting env. episode 3153.000000, reward total was -21.000000. running mean: -19.362158\n",
            "resetting env. episode 3154.000000, reward total was -19.000000. running mean: -19.358536\n",
            "resetting env. episode 3155.000000, reward total was -19.000000. running mean: -19.354951\n",
            "resetting env. episode 3156.000000, reward total was -18.000000. running mean: -19.341401\n",
            "resetting env. episode 3157.000000, reward total was -19.000000. running mean: -19.337987\n",
            "resetting env. episode 3158.000000, reward total was -21.000000. running mean: -19.354607\n",
            "resetting env. episode 3159.000000, reward total was -21.000000. running mean: -19.371061\n",
            "resetting env. episode 3160.000000, reward total was -20.000000. running mean: -19.377351\n",
            "resetting env. episode 3161.000000, reward total was -20.000000. running mean: -19.383577\n",
            "resetting env. episode 3162.000000, reward total was -18.000000. running mean: -19.369741\n",
            "resetting env. episode 3163.000000, reward total was -19.000000. running mean: -19.366044\n",
            "resetting env. episode 3164.000000, reward total was -20.000000. running mean: -19.372383\n",
            "resetting env. episode 3165.000000, reward total was -15.000000. running mean: -19.328660\n",
            "resetting env. episode 3166.000000, reward total was -18.000000. running mean: -19.315373\n",
            "resetting env. episode 3167.000000, reward total was -20.000000. running mean: -19.322219\n",
            "resetting env. episode 3168.000000, reward total was -18.000000. running mean: -19.308997\n",
            "resetting env. episode 3169.000000, reward total was -21.000000. running mean: -19.325907\n",
            "resetting env. episode 3170.000000, reward total was -17.000000. running mean: -19.302648\n",
            "resetting env. episode 3171.000000, reward total was -19.000000. running mean: -19.299622\n",
            "resetting env. episode 3172.000000, reward total was -21.000000. running mean: -19.316625\n",
            "resetting env. episode 3173.000000, reward total was -19.000000. running mean: -19.313459\n",
            "resetting env. episode 3174.000000, reward total was -21.000000. running mean: -19.330324\n",
            "resetting env. episode 3175.000000, reward total was -21.000000. running mean: -19.347021\n",
            "resetting env. episode 3176.000000, reward total was -20.000000. running mean: -19.353551\n",
            "resetting env. episode 3177.000000, reward total was -19.000000. running mean: -19.350015\n",
            "resetting env. episode 3178.000000, reward total was -18.000000. running mean: -19.336515\n",
            "resetting env. episode 3179.000000, reward total was -19.000000. running mean: -19.333150\n",
            "resetting env. episode 3180.000000, reward total was -21.000000. running mean: -19.349819\n",
            "resetting env. episode 3181.000000, reward total was -21.000000. running mean: -19.366320\n",
            "resetting env. episode 3182.000000, reward total was -21.000000. running mean: -19.382657\n",
            "resetting env. episode 3183.000000, reward total was -21.000000. running mean: -19.398831\n",
            "resetting env. episode 3184.000000, reward total was -19.000000. running mean: -19.394842\n",
            "resetting env. episode 3185.000000, reward total was -19.000000. running mean: -19.390894\n",
            "resetting env. episode 3186.000000, reward total was -21.000000. running mean: -19.406985\n",
            "resetting env. episode 3187.000000, reward total was -21.000000. running mean: -19.422915\n",
            "resetting env. episode 3188.000000, reward total was -19.000000. running mean: -19.418686\n",
            "resetting env. episode 3189.000000, reward total was -19.000000. running mean: -19.414499\n",
            "resetting env. episode 3190.000000, reward total was -21.000000. running mean: -19.430354\n",
            "resetting env. episode 3191.000000, reward total was -19.000000. running mean: -19.426051\n",
            "resetting env. episode 3192.000000, reward total was -18.000000. running mean: -19.411790\n",
            "resetting env. episode 3193.000000, reward total was -15.000000. running mean: -19.367672\n",
            "resetting env. episode 3194.000000, reward total was -20.000000. running mean: -19.373996\n",
            "resetting env. episode 3195.000000, reward total was -20.000000. running mean: -19.380256\n",
            "resetting env. episode 3196.000000, reward total was -18.000000. running mean: -19.366453\n",
            "resetting env. episode 3197.000000, reward total was -21.000000. running mean: -19.382788\n",
            "resetting env. episode 3198.000000, reward total was -20.000000. running mean: -19.388961\n",
            "resetting env. episode 3199.000000, reward total was -18.000000. running mean: -19.375071\n",
            "resetting env. episode 3200.000000, reward total was -19.000000. running mean: -19.371320\n",
            "resetting env. episode 3201.000000, reward total was -19.000000. running mean: -19.367607\n",
            "resetting env. episode 3202.000000, reward total was -20.000000. running mean: -19.373931\n",
            "resetting env. episode 3203.000000, reward total was -21.000000. running mean: -19.390192\n",
            "resetting env. episode 3204.000000, reward total was -21.000000. running mean: -19.406290\n",
            "resetting env. episode 3205.000000, reward total was -19.000000. running mean: -19.402227\n",
            "resetting env. episode 3206.000000, reward total was -19.000000. running mean: -19.398205\n",
            "resetting env. episode 3207.000000, reward total was -16.000000. running mean: -19.364223\n",
            "resetting env. episode 3208.000000, reward total was -21.000000. running mean: -19.380580\n",
            "resetting env. episode 3209.000000, reward total was -21.000000. running mean: -19.396775\n",
            "resetting env. episode 3210.000000, reward total was -20.000000. running mean: -19.402807\n",
            "resetting env. episode 3211.000000, reward total was -18.000000. running mean: -19.388779\n",
            "resetting env. episode 3212.000000, reward total was -21.000000. running mean: -19.404891\n",
            "resetting env. episode 3213.000000, reward total was -18.000000. running mean: -19.390842\n",
            "resetting env. episode 3214.000000, reward total was -19.000000. running mean: -19.386934\n",
            "resetting env. episode 3215.000000, reward total was -21.000000. running mean: -19.403064\n",
            "resetting env. episode 3216.000000, reward total was -19.000000. running mean: -19.399034\n",
            "resetting env. episode 3217.000000, reward total was -18.000000. running mean: -19.385043\n",
            "resetting env. episode 3218.000000, reward total was -20.000000. running mean: -19.391193\n",
            "resetting env. episode 3219.000000, reward total was -19.000000. running mean: -19.387281\n",
            "resetting env. episode 3220.000000, reward total was -18.000000. running mean: -19.373408\n",
            "resetting env. episode 3221.000000, reward total was -20.000000. running mean: -19.379674\n",
            "resetting env. episode 3222.000000, reward total was -20.000000. running mean: -19.385877\n",
            "resetting env. episode 3223.000000, reward total was -20.000000. running mean: -19.392019\n",
            "resetting env. episode 3224.000000, reward total was -18.000000. running mean: -19.378098\n",
            "resetting env. episode 3225.000000, reward total was -20.000000. running mean: -19.384317\n",
            "resetting env. episode 3226.000000, reward total was -19.000000. running mean: -19.380474\n",
            "resetting env. episode 3227.000000, reward total was -18.000000. running mean: -19.366669\n",
            "resetting env. episode 3228.000000, reward total was -18.000000. running mean: -19.353003\n",
            "resetting env. episode 3229.000000, reward total was -18.000000. running mean: -19.339473\n",
            "resetting env. episode 3230.000000, reward total was -17.000000. running mean: -19.316078\n",
            "resetting env. episode 3231.000000, reward total was -21.000000. running mean: -19.332917\n",
            "resetting env. episode 3232.000000, reward total was -21.000000. running mean: -19.349588\n",
            "resetting env. episode 3233.000000, reward total was -19.000000. running mean: -19.346092\n",
            "resetting env. episode 3234.000000, reward total was -19.000000. running mean: -19.342631\n",
            "resetting env. episode 3235.000000, reward total was -21.000000. running mean: -19.359205\n",
            "resetting env. episode 3236.000000, reward total was -21.000000. running mean: -19.375613\n",
            "resetting env. episode 3237.000000, reward total was -19.000000. running mean: -19.371857\n",
            "resetting env. episode 3238.000000, reward total was -20.000000. running mean: -19.378138\n",
            "resetting env. episode 3239.000000, reward total was -19.000000. running mean: -19.374357\n",
            "resetting env. episode 3240.000000, reward total was -19.000000. running mean: -19.370613\n",
            "resetting env. episode 3241.000000, reward total was -18.000000. running mean: -19.356907\n",
            "resetting env. episode 3242.000000, reward total was -19.000000. running mean: -19.353338\n",
            "resetting env. episode 3243.000000, reward total was -19.000000. running mean: -19.349805\n",
            "resetting env. episode 3244.000000, reward total was -21.000000. running mean: -19.366307\n",
            "resetting env. episode 3245.000000, reward total was -18.000000. running mean: -19.352644\n",
            "resetting env. episode 3246.000000, reward total was -18.000000. running mean: -19.339117\n",
            "resetting env. episode 3247.000000, reward total was -19.000000. running mean: -19.335726\n",
            "resetting env. episode 3248.000000, reward total was -18.000000. running mean: -19.322369\n",
            "resetting env. episode 3249.000000, reward total was -17.000000. running mean: -19.299145\n",
            "resetting env. episode 3250.000000, reward total was -19.000000. running mean: -19.296154\n",
            "resetting env. episode 3251.000000, reward total was -21.000000. running mean: -19.313192\n",
            "resetting env. episode 3252.000000, reward total was -20.000000. running mean: -19.320060\n",
            "resetting env. episode 3253.000000, reward total was -19.000000. running mean: -19.316859\n",
            "resetting env. episode 3254.000000, reward total was -17.000000. running mean: -19.293691\n",
            "resetting env. episode 3255.000000, reward total was -17.000000. running mean: -19.270754\n",
            "resetting env. episode 3256.000000, reward total was -19.000000. running mean: -19.268046\n",
            "resetting env. episode 3257.000000, reward total was -19.000000. running mean: -19.265366\n",
            "resetting env. episode 3258.000000, reward total was -20.000000. running mean: -19.272712\n",
            "resetting env. episode 3259.000000, reward total was -16.000000. running mean: -19.239985\n",
            "resetting env. episode 3260.000000, reward total was -21.000000. running mean: -19.257585\n",
            "resetting env. episode 3261.000000, reward total was -20.000000. running mean: -19.265009\n",
            "resetting env. episode 3262.000000, reward total was -19.000000. running mean: -19.262359\n",
            "resetting env. episode 3263.000000, reward total was -17.000000. running mean: -19.239736\n",
            "resetting env. episode 3264.000000, reward total was -19.000000. running mean: -19.237338\n",
            "resetting env. episode 3265.000000, reward total was -20.000000. running mean: -19.244965\n",
            "resetting env. episode 3266.000000, reward total was -19.000000. running mean: -19.242515\n",
            "resetting env. episode 3267.000000, reward total was -18.000000. running mean: -19.230090\n",
            "resetting env. episode 3268.000000, reward total was -21.000000. running mean: -19.247789\n",
            "resetting env. episode 3269.000000, reward total was -17.000000. running mean: -19.225311\n",
            "resetting env. episode 3270.000000, reward total was -21.000000. running mean: -19.243058\n",
            "resetting env. episode 3271.000000, reward total was -21.000000. running mean: -19.260628\n",
            "resetting env. episode 3272.000000, reward total was -21.000000. running mean: -19.278021\n",
            "resetting env. episode 3273.000000, reward total was -19.000000. running mean: -19.275241\n",
            "resetting env. episode 3274.000000, reward total was -21.000000. running mean: -19.292489\n",
            "resetting env. episode 3275.000000, reward total was -19.000000. running mean: -19.289564\n",
            "resetting env. episode 3276.000000, reward total was -20.000000. running mean: -19.296668\n",
            "resetting env. episode 3277.000000, reward total was -18.000000. running mean: -19.283702\n",
            "resetting env. episode 3278.000000, reward total was -17.000000. running mean: -19.260865\n",
            "resetting env. episode 3279.000000, reward total was -21.000000. running mean: -19.278256\n",
            "resetting env. episode 3280.000000, reward total was -20.000000. running mean: -19.285473\n",
            "resetting env. episode 3281.000000, reward total was -21.000000. running mean: -19.302619\n",
            "resetting env. episode 3282.000000, reward total was -19.000000. running mean: -19.299592\n",
            "resetting env. episode 3283.000000, reward total was -19.000000. running mean: -19.296597\n",
            "resetting env. episode 3284.000000, reward total was -20.000000. running mean: -19.303631\n",
            "resetting env. episode 3285.000000, reward total was -19.000000. running mean: -19.300594\n",
            "resetting env. episode 3286.000000, reward total was -19.000000. running mean: -19.297588\n",
            "resetting env. episode 3287.000000, reward total was -15.000000. running mean: -19.254612\n",
            "resetting env. episode 3288.000000, reward total was -18.000000. running mean: -19.242066\n",
            "resetting env. episode 3289.000000, reward total was -16.000000. running mean: -19.209646\n",
            "resetting env. episode 3290.000000, reward total was -18.000000. running mean: -19.197549\n",
            "resetting env. episode 3291.000000, reward total was -19.000000. running mean: -19.195574\n",
            "resetting env. episode 3292.000000, reward total was -21.000000. running mean: -19.213618\n",
            "resetting env. episode 3293.000000, reward total was -21.000000. running mean: -19.231482\n",
            "resetting env. episode 3294.000000, reward total was -17.000000. running mean: -19.209167\n",
            "resetting env. episode 3295.000000, reward total was -20.000000. running mean: -19.217075\n",
            "resetting env. episode 3296.000000, reward total was -19.000000. running mean: -19.214905\n",
            "resetting env. episode 3297.000000, reward total was -18.000000. running mean: -19.202756\n",
            "resetting env. episode 3298.000000, reward total was -19.000000. running mean: -19.200728\n",
            "resetting env. episode 3299.000000, reward total was -19.000000. running mean: -19.198721\n",
            "resetting env. episode 3300.000000, reward total was -20.000000. running mean: -19.206733\n",
            "resetting env. episode 3301.000000, reward total was -19.000000. running mean: -19.204666\n",
            "resetting env. episode 3302.000000, reward total was -15.000000. running mean: -19.162619\n",
            "resetting env. episode 3303.000000, reward total was -16.000000. running mean: -19.130993\n",
            "resetting env. episode 3304.000000, reward total was -20.000000. running mean: -19.139683\n",
            "resetting env. episode 3305.000000, reward total was -19.000000. running mean: -19.138287\n",
            "resetting env. episode 3306.000000, reward total was -18.000000. running mean: -19.126904\n",
            "resetting env. episode 3307.000000, reward total was -20.000000. running mean: -19.135635\n",
            "resetting env. episode 3308.000000, reward total was -20.000000. running mean: -19.144278\n",
            "resetting env. episode 3309.000000, reward total was -19.000000. running mean: -19.142835\n",
            "resetting env. episode 3310.000000, reward total was -19.000000. running mean: -19.141407\n",
            "resetting env. episode 3311.000000, reward total was -20.000000. running mean: -19.149993\n",
            "resetting env. episode 3312.000000, reward total was -16.000000. running mean: -19.118493\n",
            "resetting env. episode 3313.000000, reward total was -21.000000. running mean: -19.137308\n",
            "resetting env. episode 3314.000000, reward total was -19.000000. running mean: -19.135935\n",
            "resetting env. episode 3315.000000, reward total was -21.000000. running mean: -19.154576\n",
            "resetting env. episode 3316.000000, reward total was -19.000000. running mean: -19.153030\n",
            "resetting env. episode 3317.000000, reward total was -19.000000. running mean: -19.151500\n",
            "resetting env. episode 3318.000000, reward total was -20.000000. running mean: -19.159985\n",
            "resetting env. episode 3319.000000, reward total was -21.000000. running mean: -19.178385\n",
            "resetting env. episode 3320.000000, reward total was -19.000000. running mean: -19.176601\n",
            "resetting env. episode 3321.000000, reward total was -18.000000. running mean: -19.164835\n",
            "resetting env. episode 3322.000000, reward total was -21.000000. running mean: -19.183187\n",
            "resetting env. episode 3323.000000, reward total was -21.000000. running mean: -19.201355\n",
            "resetting env. episode 3324.000000, reward total was -18.000000. running mean: -19.189341\n",
            "resetting env. episode 3325.000000, reward total was -20.000000. running mean: -19.197448\n",
            "resetting env. episode 3326.000000, reward total was -21.000000. running mean: -19.215473\n",
            "resetting env. episode 3327.000000, reward total was -19.000000. running mean: -19.213319\n",
            "resetting env. episode 3328.000000, reward total was -18.000000. running mean: -19.201185\n",
            "resetting env. episode 3329.000000, reward total was -20.000000. running mean: -19.209174\n",
            "resetting env. episode 3330.000000, reward total was -20.000000. running mean: -19.217082\n",
            "resetting env. episode 3331.000000, reward total was -20.000000. running mean: -19.224911\n",
            "resetting env. episode 3332.000000, reward total was -17.000000. running mean: -19.202662\n",
            "resetting env. episode 3333.000000, reward total was -19.000000. running mean: -19.200635\n",
            "resetting env. episode 3334.000000, reward total was -21.000000. running mean: -19.218629\n",
            "resetting env. episode 3335.000000, reward total was -21.000000. running mean: -19.236443\n",
            "resetting env. episode 3336.000000, reward total was -21.000000. running mean: -19.254078\n",
            "resetting env. episode 3337.000000, reward total was -20.000000. running mean: -19.261537\n",
            "resetting env. episode 3338.000000, reward total was -21.000000. running mean: -19.278922\n",
            "resetting env. episode 3339.000000, reward total was -17.000000. running mean: -19.256133\n",
            "resetting env. episode 3340.000000, reward total was -20.000000. running mean: -19.263572\n",
            "resetting env. episode 3341.000000, reward total was -17.000000. running mean: -19.240936\n",
            "resetting env. episode 3342.000000, reward total was -18.000000. running mean: -19.228526\n",
            "resetting env. episode 3343.000000, reward total was -21.000000. running mean: -19.246241\n",
            "resetting env. episode 3344.000000, reward total was -21.000000. running mean: -19.263779\n",
            "resetting env. episode 3345.000000, reward total was -20.000000. running mean: -19.271141\n",
            "resetting env. episode 3346.000000, reward total was -20.000000. running mean: -19.278430\n",
            "resetting env. episode 3347.000000, reward total was -20.000000. running mean: -19.285645\n",
            "resetting env. episode 3348.000000, reward total was -20.000000. running mean: -19.292789\n",
            "resetting env. episode 3349.000000, reward total was -19.000000. running mean: -19.289861\n",
            "resetting env. episode 3350.000000, reward total was -20.000000. running mean: -19.296962\n",
            "resetting env. episode 3351.000000, reward total was -18.000000. running mean: -19.283993\n",
            "resetting env. episode 3352.000000, reward total was -15.000000. running mean: -19.241153\n",
            "resetting env. episode 3353.000000, reward total was -19.000000. running mean: -19.238741\n",
            "resetting env. episode 3354.000000, reward total was -19.000000. running mean: -19.236354\n",
            "resetting env. episode 3355.000000, reward total was -19.000000. running mean: -19.233990\n",
            "resetting env. episode 3356.000000, reward total was -20.000000. running mean: -19.241650\n",
            "resetting env. episode 3357.000000, reward total was -19.000000. running mean: -19.239234\n",
            "resetting env. episode 3358.000000, reward total was -20.000000. running mean: -19.246842\n",
            "resetting env. episode 3359.000000, reward total was -16.000000. running mean: -19.214373\n",
            "resetting env. episode 3360.000000, reward total was -20.000000. running mean: -19.222229\n",
            "resetting env. episode 3361.000000, reward total was -20.000000. running mean: -19.230007\n",
            "resetting env. episode 3362.000000, reward total was -21.000000. running mean: -19.247707\n",
            "resetting env. episode 3363.000000, reward total was -19.000000. running mean: -19.245230\n",
            "resetting env. episode 3364.000000, reward total was -21.000000. running mean: -19.262778\n",
            "resetting env. episode 3365.000000, reward total was -19.000000. running mean: -19.260150\n",
            "resetting env. episode 3366.000000, reward total was -19.000000. running mean: -19.257548\n",
            "resetting env. episode 3367.000000, reward total was -21.000000. running mean: -19.274973\n",
            "resetting env. episode 3368.000000, reward total was -17.000000. running mean: -19.252223\n",
            "resetting env. episode 3369.000000, reward total was -20.000000. running mean: -19.259701\n",
            "resetting env. episode 3370.000000, reward total was -20.000000. running mean: -19.267104\n",
            "resetting env. episode 3371.000000, reward total was -17.000000. running mean: -19.244433\n",
            "resetting env. episode 3372.000000, reward total was -20.000000. running mean: -19.251989\n",
            "resetting env. episode 3373.000000, reward total was -20.000000. running mean: -19.259469\n",
            "resetting env. episode 3374.000000, reward total was -18.000000. running mean: -19.246874\n",
            "resetting env. episode 3375.000000, reward total was -19.000000. running mean: -19.244405\n",
            "resetting env. episode 3376.000000, reward total was -21.000000. running mean: -19.261961\n",
            "resetting env. episode 3377.000000, reward total was -19.000000. running mean: -19.259342\n",
            "resetting env. episode 3378.000000, reward total was -21.000000. running mean: -19.276748\n",
            "resetting env. episode 3379.000000, reward total was -18.000000. running mean: -19.263981\n",
            "resetting env. episode 3380.000000, reward total was -20.000000. running mean: -19.271341\n",
            "resetting env. episode 3381.000000, reward total was -21.000000. running mean: -19.288627\n",
            "resetting env. episode 3382.000000, reward total was -20.000000. running mean: -19.295741\n",
            "resetting env. episode 3383.000000, reward total was -21.000000. running mean: -19.312784\n",
            "resetting env. episode 3384.000000, reward total was -18.000000. running mean: -19.299656\n",
            "resetting env. episode 3385.000000, reward total was -19.000000. running mean: -19.296659\n",
            "resetting env. episode 3386.000000, reward total was -19.000000. running mean: -19.293693\n",
            "resetting env. episode 3387.000000, reward total was -16.000000. running mean: -19.260756\n",
            "resetting env. episode 3388.000000, reward total was -19.000000. running mean: -19.258148\n",
            "resetting env. episode 3389.000000, reward total was -21.000000. running mean: -19.275567\n",
            "resetting env. episode 3390.000000, reward total was -19.000000. running mean: -19.272811\n",
            "resetting env. episode 3391.000000, reward total was -19.000000. running mean: -19.270083\n",
            "resetting env. episode 3392.000000, reward total was -19.000000. running mean: -19.267382\n",
            "resetting env. episode 3393.000000, reward total was -16.000000. running mean: -19.234708\n",
            "resetting env. episode 3394.000000, reward total was -21.000000. running mean: -19.252361\n",
            "resetting env. episode 3395.000000, reward total was -19.000000. running mean: -19.249838\n",
            "resetting env. episode 3396.000000, reward total was -17.000000. running mean: -19.227339\n",
            "resetting env. episode 3397.000000, reward total was -19.000000. running mean: -19.225066\n",
            "resetting env. episode 3398.000000, reward total was -20.000000. running mean: -19.232815\n",
            "resetting env. episode 3399.000000, reward total was -20.000000. running mean: -19.240487\n",
            "resetting env. episode 3400.000000, reward total was -19.000000. running mean: -19.238082\n",
            "resetting env. episode 3401.000000, reward total was -19.000000. running mean: -19.235701\n",
            "resetting env. episode 3402.000000, reward total was -19.000000. running mean: -19.233344\n",
            "resetting env. episode 3403.000000, reward total was -19.000000. running mean: -19.231011\n",
            "resetting env. episode 3404.000000, reward total was -19.000000. running mean: -19.228701\n",
            "resetting env. episode 3405.000000, reward total was -18.000000. running mean: -19.216414\n",
            "resetting env. episode 3406.000000, reward total was -21.000000. running mean: -19.234250\n",
            "resetting env. episode 3407.000000, reward total was -19.000000. running mean: -19.231907\n",
            "resetting env. episode 3408.000000, reward total was -21.000000. running mean: -19.249588\n",
            "resetting env. episode 3409.000000, reward total was -21.000000. running mean: -19.267092\n",
            "resetting env. episode 3410.000000, reward total was -18.000000. running mean: -19.254421\n",
            "resetting env. episode 3411.000000, reward total was -21.000000. running mean: -19.271877\n",
            "resetting env. episode 3412.000000, reward total was -20.000000. running mean: -19.279158\n",
            "resetting env. episode 3413.000000, reward total was -19.000000. running mean: -19.276367\n",
            "resetting env. episode 3414.000000, reward total was -20.000000. running mean: -19.283603\n",
            "resetting env. episode 3415.000000, reward total was -20.000000. running mean: -19.290767\n",
            "resetting env. episode 3416.000000, reward total was -17.000000. running mean: -19.267859\n",
            "resetting env. episode 3417.000000, reward total was -21.000000. running mean: -19.285181\n",
            "resetting env. episode 3418.000000, reward total was -21.000000. running mean: -19.302329\n",
            "resetting env. episode 3419.000000, reward total was -21.000000. running mean: -19.319306\n",
            "resetting env. episode 3420.000000, reward total was -18.000000. running mean: -19.306113\n",
            "resetting env. episode 3421.000000, reward total was -17.000000. running mean: -19.283052\n",
            "resetting env. episode 3422.000000, reward total was -20.000000. running mean: -19.290221\n",
            "resetting env. episode 3423.000000, reward total was -20.000000. running mean: -19.297319\n",
            "resetting env. episode 3424.000000, reward total was -20.000000. running mean: -19.304346\n",
            "resetting env. episode 3425.000000, reward total was -19.000000. running mean: -19.301302\n",
            "resetting env. episode 3426.000000, reward total was -18.000000. running mean: -19.288289\n",
            "resetting env. episode 3427.000000, reward total was -19.000000. running mean: -19.285406\n",
            "resetting env. episode 3428.000000, reward total was -21.000000. running mean: -19.302552\n",
            "resetting env. episode 3429.000000, reward total was -19.000000. running mean: -19.299527\n",
            "resetting env. episode 3430.000000, reward total was -19.000000. running mean: -19.296531\n",
            "resetting env. episode 3431.000000, reward total was -19.000000. running mean: -19.293566\n",
            "resetting env. episode 3432.000000, reward total was -20.000000. running mean: -19.300630\n",
            "resetting env. episode 3433.000000, reward total was -20.000000. running mean: -19.307624\n",
            "resetting env. episode 3434.000000, reward total was -21.000000. running mean: -19.324548\n",
            "resetting env. episode 3435.000000, reward total was -18.000000. running mean: -19.311302\n",
            "resetting env. episode 3436.000000, reward total was -19.000000. running mean: -19.308189\n",
            "resetting env. episode 3437.000000, reward total was -18.000000. running mean: -19.295107\n",
            "resetting env. episode 3438.000000, reward total was -17.000000. running mean: -19.272156\n",
            "resetting env. episode 3439.000000, reward total was -21.000000. running mean: -19.289435\n",
            "resetting env. episode 3440.000000, reward total was -16.000000. running mean: -19.256540\n",
            "resetting env. episode 3441.000000, reward total was -20.000000. running mean: -19.263975\n",
            "resetting env. episode 3442.000000, reward total was -20.000000. running mean: -19.271335\n",
            "resetting env. episode 3443.000000, reward total was -19.000000. running mean: -19.268622\n",
            "resetting env. episode 3444.000000, reward total was -20.000000. running mean: -19.275936\n",
            "resetting env. episode 3445.000000, reward total was -19.000000. running mean: -19.273176\n",
            "resetting env. episode 3446.000000, reward total was -21.000000. running mean: -19.290445\n",
            "resetting env. episode 3447.000000, reward total was -19.000000. running mean: -19.287540\n",
            "resetting env. episode 3448.000000, reward total was -19.000000. running mean: -19.284665\n",
            "resetting env. episode 3449.000000, reward total was -19.000000. running mean: -19.281818\n",
            "resetting env. episode 3450.000000, reward total was -21.000000. running mean: -19.299000\n",
            "resetting env. episode 3451.000000, reward total was -20.000000. running mean: -19.306010\n",
            "resetting env. episode 3452.000000, reward total was -20.000000. running mean: -19.312950\n",
            "resetting env. episode 3453.000000, reward total was -19.000000. running mean: -19.309820\n",
            "resetting env. episode 3454.000000, reward total was -21.000000. running mean: -19.326722\n",
            "resetting env. episode 3455.000000, reward total was -20.000000. running mean: -19.333455\n",
            "resetting env. episode 3456.000000, reward total was -20.000000. running mean: -19.340120\n",
            "resetting env. episode 3457.000000, reward total was -17.000000. running mean: -19.316719\n",
            "resetting env. episode 3458.000000, reward total was -19.000000. running mean: -19.313552\n",
            "resetting env. episode 3459.000000, reward total was -20.000000. running mean: -19.320416\n",
            "resetting env. episode 3460.000000, reward total was -20.000000. running mean: -19.327212\n",
            "resetting env. episode 3461.000000, reward total was -20.000000. running mean: -19.333940\n",
            "resetting env. episode 3462.000000, reward total was -16.000000. running mean: -19.300601\n",
            "resetting env. episode 3463.000000, reward total was -20.000000. running mean: -19.307595\n",
            "resetting env. episode 3464.000000, reward total was -20.000000. running mean: -19.314519\n",
            "resetting env. episode 3465.000000, reward total was -19.000000. running mean: -19.311374\n",
            "resetting env. episode 3466.000000, reward total was -21.000000. running mean: -19.328260\n",
            "resetting env. episode 3467.000000, reward total was -19.000000. running mean: -19.324977\n",
            "resetting env. episode 3468.000000, reward total was -20.000000. running mean: -19.331728\n",
            "resetting env. episode 3469.000000, reward total was -21.000000. running mean: -19.348410\n",
            "resetting env. episode 3470.000000, reward total was -20.000000. running mean: -19.354926\n",
            "resetting env. episode 3471.000000, reward total was -20.000000. running mean: -19.361377\n",
            "resetting env. episode 3472.000000, reward total was -20.000000. running mean: -19.367763\n",
            "resetting env. episode 3473.000000, reward total was -17.000000. running mean: -19.344085\n",
            "resetting env. episode 3474.000000, reward total was -17.000000. running mean: -19.320645\n",
            "resetting env. episode 3475.000000, reward total was -20.000000. running mean: -19.327438\n",
            "resetting env. episode 3476.000000, reward total was -19.000000. running mean: -19.324164\n",
            "resetting env. episode 3477.000000, reward total was -21.000000. running mean: -19.340922\n",
            "resetting env. episode 3478.000000, reward total was -19.000000. running mean: -19.337513\n",
            "resetting env. episode 3479.000000, reward total was -17.000000. running mean: -19.314138\n",
            "resetting env. episode 3480.000000, reward total was -19.000000. running mean: -19.310996\n",
            "resetting env. episode 3481.000000, reward total was -21.000000. running mean: -19.327886\n",
            "resetting env. episode 3482.000000, reward total was -20.000000. running mean: -19.334608\n",
            "resetting env. episode 3483.000000, reward total was -21.000000. running mean: -19.351262\n",
            "resetting env. episode 3484.000000, reward total was -20.000000. running mean: -19.357749\n",
            "resetting env. episode 3485.000000, reward total was -19.000000. running mean: -19.354171\n",
            "resetting env. episode 3486.000000, reward total was -19.000000. running mean: -19.350630\n",
            "resetting env. episode 3487.000000, reward total was -20.000000. running mean: -19.357123\n",
            "resetting env. episode 3488.000000, reward total was -17.000000. running mean: -19.333552\n",
            "resetting env. episode 3489.000000, reward total was -19.000000. running mean: -19.330217\n",
            "resetting env. episode 3490.000000, reward total was -21.000000. running mean: -19.346914\n",
            "resetting env. episode 3491.000000, reward total was -17.000000. running mean: -19.323445\n",
            "resetting env. episode 3492.000000, reward total was -18.000000. running mean: -19.310211\n",
            "resetting env. episode 3493.000000, reward total was -19.000000. running mean: -19.307109\n",
            "resetting env. episode 3494.000000, reward total was -20.000000. running mean: -19.314038\n",
            "resetting env. episode 3495.000000, reward total was -20.000000. running mean: -19.320897\n",
            "resetting env. episode 3496.000000, reward total was -20.000000. running mean: -19.327688\n",
            "resetting env. episode 3497.000000, reward total was -19.000000. running mean: -19.324411\n",
            "resetting env. episode 3498.000000, reward total was -19.000000. running mean: -19.321167\n",
            "resetting env. episode 3499.000000, reward total was -19.000000. running mean: -19.317956\n",
            "resetting env. episode 3500.000000, reward total was -21.000000. running mean: -19.334776\n",
            "resetting env. episode 3501.000000, reward total was -19.000000. running mean: -19.331428\n",
            "resetting env. episode 3502.000000, reward total was -18.000000. running mean: -19.318114\n",
            "resetting env. episode 3503.000000, reward total was -19.000000. running mean: -19.314933\n",
            "resetting env. episode 3504.000000, reward total was -19.000000. running mean: -19.311784\n",
            "resetting env. episode 3505.000000, reward total was -21.000000. running mean: -19.328666\n",
            "resetting env. episode 3506.000000, reward total was -20.000000. running mean: -19.335379\n",
            "resetting env. episode 3507.000000, reward total was -20.000000. running mean: -19.342025\n",
            "resetting env. episode 3508.000000, reward total was -21.000000. running mean: -19.358605\n",
            "resetting env. episode 3509.000000, reward total was -19.000000. running mean: -19.355019\n",
            "resetting env. episode 3510.000000, reward total was -16.000000. running mean: -19.321469\n",
            "resetting env. episode 3511.000000, reward total was -19.000000. running mean: -19.318254\n",
            "resetting env. episode 3512.000000, reward total was -19.000000. running mean: -19.315072\n",
            "resetting env. episode 3513.000000, reward total was -20.000000. running mean: -19.321921\n",
            "resetting env. episode 3514.000000, reward total was -21.000000. running mean: -19.338702\n",
            "resetting env. episode 3515.000000, reward total was -19.000000. running mean: -19.335315\n",
            "resetting env. episode 3516.000000, reward total was -17.000000. running mean: -19.311962\n",
            "resetting env. episode 3517.000000, reward total was -19.000000. running mean: -19.308842\n",
            "resetting env. episode 3518.000000, reward total was -21.000000. running mean: -19.325753\n",
            "resetting env. episode 3519.000000, reward total was -18.000000. running mean: -19.312496\n",
            "resetting env. episode 3520.000000, reward total was -16.000000. running mean: -19.279371\n",
            "resetting env. episode 3521.000000, reward total was -21.000000. running mean: -19.296577\n",
            "resetting env. episode 3522.000000, reward total was -21.000000. running mean: -19.313612\n",
            "resetting env. episode 3523.000000, reward total was -20.000000. running mean: -19.320475\n",
            "resetting env. episode 3524.000000, reward total was -19.000000. running mean: -19.317271\n",
            "resetting env. episode 3525.000000, reward total was -19.000000. running mean: -19.314098\n",
            "resetting env. episode 3526.000000, reward total was -19.000000. running mean: -19.310957\n",
            "resetting env. episode 3527.000000, reward total was -20.000000. running mean: -19.317847\n",
            "resetting env. episode 3528.000000, reward total was -21.000000. running mean: -19.334669\n",
            "resetting env. episode 3529.000000, reward total was -16.000000. running mean: -19.301322\n",
            "resetting env. episode 3530.000000, reward total was -19.000000. running mean: -19.298309\n",
            "resetting env. episode 3531.000000, reward total was -21.000000. running mean: -19.315326\n",
            "resetting env. episode 3532.000000, reward total was -21.000000. running mean: -19.332173\n",
            "resetting env. episode 3533.000000, reward total was -20.000000. running mean: -19.338851\n",
            "resetting env. episode 3534.000000, reward total was -21.000000. running mean: -19.355462\n",
            "resetting env. episode 3535.000000, reward total was -21.000000. running mean: -19.371908\n",
            "resetting env. episode 3536.000000, reward total was -16.000000. running mean: -19.338189\n",
            "resetting env. episode 3537.000000, reward total was -18.000000. running mean: -19.324807\n",
            "resetting env. episode 3538.000000, reward total was -17.000000. running mean: -19.301559\n",
            "resetting env. episode 3539.000000, reward total was -17.000000. running mean: -19.278543\n",
            "resetting env. episode 3540.000000, reward total was -21.000000. running mean: -19.295758\n",
            "resetting env. episode 3541.000000, reward total was -21.000000. running mean: -19.312800\n",
            "resetting env. episode 3542.000000, reward total was -21.000000. running mean: -19.329672\n",
            "resetting env. episode 3543.000000, reward total was -20.000000. running mean: -19.336375\n",
            "resetting env. episode 3544.000000, reward total was -19.000000. running mean: -19.333012\n",
            "resetting env. episode 3545.000000, reward total was -21.000000. running mean: -19.349682\n",
            "resetting env. episode 3546.000000, reward total was -19.000000. running mean: -19.346185\n",
            "resetting env. episode 3547.000000, reward total was -19.000000. running mean: -19.342723\n",
            "resetting env. episode 3548.000000, reward total was -19.000000. running mean: -19.339296\n",
            "resetting env. episode 3549.000000, reward total was -20.000000. running mean: -19.345903\n",
            "resetting env. episode 3550.000000, reward total was -18.000000. running mean: -19.332444\n",
            "resetting env. episode 3551.000000, reward total was -17.000000. running mean: -19.309119\n",
            "resetting env. episode 3552.000000, reward total was -19.000000. running mean: -19.306028\n",
            "resetting env. episode 3553.000000, reward total was -21.000000. running mean: -19.322968\n",
            "resetting env. episode 3554.000000, reward total was -20.000000. running mean: -19.329738\n",
            "resetting env. episode 3555.000000, reward total was -20.000000. running mean: -19.336441\n",
            "resetting env. episode 3556.000000, reward total was -18.000000. running mean: -19.323076\n",
            "resetting env. episode 3557.000000, reward total was -20.000000. running mean: -19.329846\n",
            "resetting env. episode 3558.000000, reward total was -18.000000. running mean: -19.316547\n",
            "resetting env. episode 3559.000000, reward total was -21.000000. running mean: -19.333382\n",
            "resetting env. episode 3560.000000, reward total was -18.000000. running mean: -19.320048\n",
            "resetting env. episode 3561.000000, reward total was -18.000000. running mean: -19.306847\n",
            "resetting env. episode 3562.000000, reward total was -19.000000. running mean: -19.303779\n",
            "resetting env. episode 3563.000000, reward total was -20.000000. running mean: -19.310741\n",
            "resetting env. episode 3564.000000, reward total was -20.000000. running mean: -19.317634\n",
            "resetting env. episode 3565.000000, reward total was -19.000000. running mean: -19.314457\n",
            "resetting env. episode 3566.000000, reward total was -20.000000. running mean: -19.321313\n",
            "resetting env. episode 3567.000000, reward total was -19.000000. running mean: -19.318100\n",
            "resetting env. episode 3568.000000, reward total was -16.000000. running mean: -19.284919\n",
            "resetting env. episode 3569.000000, reward total was -17.000000. running mean: -19.262069\n",
            "resetting env. episode 3570.000000, reward total was -21.000000. running mean: -19.279449\n",
            "resetting env. episode 3571.000000, reward total was -19.000000. running mean: -19.276654\n",
            "resetting env. episode 3572.000000, reward total was -19.000000. running mean: -19.273888\n",
            "resetting env. episode 3573.000000, reward total was -20.000000. running mean: -19.281149\n",
            "resetting env. episode 3574.000000, reward total was -18.000000. running mean: -19.268337\n",
            "resetting env. episode 3575.000000, reward total was -21.000000. running mean: -19.285654\n",
            "resetting env. episode 3576.000000, reward total was -21.000000. running mean: -19.302797\n",
            "resetting env. episode 3577.000000, reward total was -18.000000. running mean: -19.289769\n",
            "resetting env. episode 3578.000000, reward total was -15.000000. running mean: -19.246872\n",
            "resetting env. episode 3579.000000, reward total was -18.000000. running mean: -19.234403\n",
            "resetting env. episode 3580.000000, reward total was -20.000000. running mean: -19.242059\n",
            "resetting env. episode 3581.000000, reward total was -21.000000. running mean: -19.259638\n",
            "resetting env. episode 3582.000000, reward total was -15.000000. running mean: -19.217042\n",
            "resetting env. episode 3583.000000, reward total was -19.000000. running mean: -19.214872\n",
            "resetting env. episode 3584.000000, reward total was -21.000000. running mean: -19.232723\n",
            "resetting env. episode 3585.000000, reward total was -19.000000. running mean: -19.230396\n",
            "resetting env. episode 3586.000000, reward total was -20.000000. running mean: -19.238092\n",
            "resetting env. episode 3587.000000, reward total was -20.000000. running mean: -19.245711\n",
            "resetting env. episode 3588.000000, reward total was -20.000000. running mean: -19.253254\n",
            "resetting env. episode 3589.000000, reward total was -19.000000. running mean: -19.250721\n",
            "resetting env. episode 3590.000000, reward total was -19.000000. running mean: -19.248214\n",
            "resetting env. episode 3591.000000, reward total was -18.000000. running mean: -19.235732\n",
            "resetting env. episode 3592.000000, reward total was -19.000000. running mean: -19.233374\n",
            "resetting env. episode 3593.000000, reward total was -20.000000. running mean: -19.241041\n",
            "resetting env. episode 3594.000000, reward total was -20.000000. running mean: -19.248630\n",
            "resetting env. episode 3595.000000, reward total was -19.000000. running mean: -19.246144\n",
            "resetting env. episode 3596.000000, reward total was -20.000000. running mean: -19.253683\n",
            "resetting env. episode 3597.000000, reward total was -21.000000. running mean: -19.271146\n",
            "resetting env. episode 3598.000000, reward total was -19.000000. running mean: -19.268434\n",
            "resetting env. episode 3599.000000, reward total was -19.000000. running mean: -19.265750\n",
            "resetting env. episode 3600.000000, reward total was -19.000000. running mean: -19.263092\n",
            "resetting env. episode 3601.000000, reward total was -21.000000. running mean: -19.280462\n",
            "resetting env. episode 3602.000000, reward total was -19.000000. running mean: -19.277657\n",
            "resetting env. episode 3603.000000, reward total was -19.000000. running mean: -19.274880\n",
            "resetting env. episode 3604.000000, reward total was -19.000000. running mean: -19.272132\n",
            "resetting env. episode 3605.000000, reward total was -18.000000. running mean: -19.259410\n",
            "resetting env. episode 3606.000000, reward total was -19.000000. running mean: -19.256816\n",
            "resetting env. episode 3607.000000, reward total was -18.000000. running mean: -19.244248\n",
            "resetting env. episode 3608.000000, reward total was -21.000000. running mean: -19.261805\n",
            "resetting env. episode 3609.000000, reward total was -20.000000. running mean: -19.269187\n",
            "resetting env. episode 3610.000000, reward total was -19.000000. running mean: -19.266496\n",
            "resetting env. episode 3611.000000, reward total was -20.000000. running mean: -19.273831\n",
            "resetting env. episode 3612.000000, reward total was -17.000000. running mean: -19.251092\n",
            "resetting env. episode 3613.000000, reward total was -18.000000. running mean: -19.238581\n",
            "resetting env. episode 3614.000000, reward total was -21.000000. running mean: -19.256196\n",
            "resetting env. episode 3615.000000, reward total was -18.000000. running mean: -19.243634\n",
            "resetting env. episode 3616.000000, reward total was -16.000000. running mean: -19.211197\n",
            "resetting env. episode 3617.000000, reward total was -20.000000. running mean: -19.219085\n",
            "resetting env. episode 3618.000000, reward total was -19.000000. running mean: -19.216894\n",
            "resetting env. episode 3619.000000, reward total was -20.000000. running mean: -19.224726\n",
            "resetting env. episode 3620.000000, reward total was -19.000000. running mean: -19.222478\n",
            "resetting env. episode 3621.000000, reward total was -20.000000. running mean: -19.230253\n",
            "resetting env. episode 3622.000000, reward total was -18.000000. running mean: -19.217951\n",
            "resetting env. episode 3623.000000, reward total was -21.000000. running mean: -19.235771\n",
            "resetting env. episode 3624.000000, reward total was -17.000000. running mean: -19.213414\n",
            "resetting env. episode 3625.000000, reward total was -21.000000. running mean: -19.231280\n",
            "resetting env. episode 3626.000000, reward total was -20.000000. running mean: -19.238967\n",
            "resetting env. episode 3627.000000, reward total was -19.000000. running mean: -19.236577\n",
            "resetting env. episode 3628.000000, reward total was -17.000000. running mean: -19.214211\n",
            "resetting env. episode 3629.000000, reward total was -16.000000. running mean: -19.182069\n",
            "resetting env. episode 3630.000000, reward total was -20.000000. running mean: -19.190249\n",
            "resetting env. episode 3631.000000, reward total was -17.000000. running mean: -19.168346\n",
            "resetting env. episode 3632.000000, reward total was -18.000000. running mean: -19.156663\n",
            "resetting env. episode 3633.000000, reward total was -16.000000. running mean: -19.125096\n",
            "resetting env. episode 3634.000000, reward total was -21.000000. running mean: -19.143845\n",
            "resetting env. episode 3635.000000, reward total was -21.000000. running mean: -19.162407\n",
            "resetting env. episode 3636.000000, reward total was -19.000000. running mean: -19.160782\n",
            "resetting env. episode 3637.000000, reward total was -21.000000. running mean: -19.179175\n",
            "resetting env. episode 3638.000000, reward total was -21.000000. running mean: -19.197383\n",
            "resetting env. episode 3639.000000, reward total was -19.000000. running mean: -19.195409\n",
            "resetting env. episode 3640.000000, reward total was -21.000000. running mean: -19.213455\n",
            "resetting env. episode 3641.000000, reward total was -21.000000. running mean: -19.231320\n",
            "resetting env. episode 3642.000000, reward total was -21.000000. running mean: -19.249007\n",
            "resetting env. episode 3643.000000, reward total was -19.000000. running mean: -19.246517\n",
            "resetting env. episode 3644.000000, reward total was -21.000000. running mean: -19.264052\n",
            "resetting env. episode 3645.000000, reward total was -19.000000. running mean: -19.261411\n",
            "resetting env. episode 3646.000000, reward total was -21.000000. running mean: -19.278797\n",
            "resetting env. episode 3647.000000, reward total was -19.000000. running mean: -19.276009\n",
            "resetting env. episode 3648.000000, reward total was -18.000000. running mean: -19.263249\n",
            "resetting env. episode 3649.000000, reward total was -19.000000. running mean: -19.260617\n",
            "resetting env. episode 3650.000000, reward total was -16.000000. running mean: -19.228011\n",
            "resetting env. episode 3651.000000, reward total was -18.000000. running mean: -19.215731\n",
            "resetting env. episode 3652.000000, reward total was -20.000000. running mean: -19.223573\n",
            "resetting env. episode 3653.000000, reward total was -18.000000. running mean: -19.211337\n",
            "resetting env. episode 3654.000000, reward total was -18.000000. running mean: -19.199224\n",
            "resetting env. episode 3655.000000, reward total was -21.000000. running mean: -19.217232\n",
            "resetting env. episode 3656.000000, reward total was -15.000000. running mean: -19.175060\n",
            "resetting env. episode 3657.000000, reward total was -20.000000. running mean: -19.183309\n",
            "resetting env. episode 3658.000000, reward total was -20.000000. running mean: -19.191476\n",
            "resetting env. episode 3659.000000, reward total was -21.000000. running mean: -19.209561\n",
            "resetting env. episode 3660.000000, reward total was -21.000000. running mean: -19.227465\n",
            "resetting env. episode 3661.000000, reward total was -21.000000. running mean: -19.245191\n",
            "resetting env. episode 3662.000000, reward total was -21.000000. running mean: -19.262739\n",
            "resetting env. episode 3663.000000, reward total was -20.000000. running mean: -19.270112\n",
            "resetting env. episode 3664.000000, reward total was -20.000000. running mean: -19.277410\n",
            "resetting env. episode 3665.000000, reward total was -20.000000. running mean: -19.284636\n",
            "resetting env. episode 3666.000000, reward total was -21.000000. running mean: -19.301790\n",
            "resetting env. episode 3667.000000, reward total was -20.000000. running mean: -19.308772\n",
            "resetting env. episode 3668.000000, reward total was -21.000000. running mean: -19.325684\n",
            "resetting env. episode 3669.000000, reward total was -19.000000. running mean: -19.322427\n",
            "resetting env. episode 3670.000000, reward total was -21.000000. running mean: -19.339203\n",
            "resetting env. episode 3671.000000, reward total was -20.000000. running mean: -19.345811\n",
            "resetting env. episode 3672.000000, reward total was -20.000000. running mean: -19.352353\n",
            "resetting env. episode 3673.000000, reward total was -20.000000. running mean: -19.358830\n",
            "resetting env. episode 3674.000000, reward total was -21.000000. running mean: -19.375241\n",
            "resetting env. episode 3675.000000, reward total was -18.000000. running mean: -19.361489\n",
            "resetting env. episode 3676.000000, reward total was -17.000000. running mean: -19.337874\n",
            "resetting env. episode 3677.000000, reward total was -18.000000. running mean: -19.324495\n",
            "resetting env. episode 3678.000000, reward total was -21.000000. running mean: -19.341250\n",
            "resetting env. episode 3679.000000, reward total was -21.000000. running mean: -19.357838\n",
            "resetting env. episode 3680.000000, reward total was -20.000000. running mean: -19.364259\n",
            "resetting env. episode 3681.000000, reward total was -19.000000. running mean: -19.360617\n",
            "resetting env. episode 3682.000000, reward total was -18.000000. running mean: -19.347011\n",
            "resetting env. episode 3683.000000, reward total was -19.000000. running mean: -19.343541\n",
            "resetting env. episode 3684.000000, reward total was -18.000000. running mean: -19.330105\n",
            "resetting env. episode 3685.000000, reward total was -20.000000. running mean: -19.336804\n",
            "resetting env. episode 3686.000000, reward total was -19.000000. running mean: -19.333436\n",
            "resetting env. episode 3687.000000, reward total was -20.000000. running mean: -19.340102\n",
            "resetting env. episode 3688.000000, reward total was -18.000000. running mean: -19.326701\n",
            "resetting env. episode 3689.000000, reward total was -20.000000. running mean: -19.333434\n",
            "resetting env. episode 3690.000000, reward total was -21.000000. running mean: -19.350099\n",
            "resetting env. episode 3691.000000, reward total was -18.000000. running mean: -19.336598\n",
            "resetting env. episode 3692.000000, reward total was -20.000000. running mean: -19.343232\n",
            "resetting env. episode 3693.000000, reward total was -16.000000. running mean: -19.309800\n",
            "resetting env. episode 3694.000000, reward total was -20.000000. running mean: -19.316702\n",
            "resetting env. episode 3695.000000, reward total was -19.000000. running mean: -19.313535\n",
            "resetting env. episode 3696.000000, reward total was -18.000000. running mean: -19.300400\n",
            "resetting env. episode 3697.000000, reward total was -21.000000. running mean: -19.317396\n",
            "resetting env. episode 3698.000000, reward total was -18.000000. running mean: -19.304222\n",
            "resetting env. episode 3699.000000, reward total was -21.000000. running mean: -19.321179\n",
            "resetting env. episode 3700.000000, reward total was -21.000000. running mean: -19.337968\n",
            "resetting env. episode 3701.000000, reward total was -19.000000. running mean: -19.334588\n",
            "resetting env. episode 3702.000000, reward total was -18.000000. running mean: -19.321242\n",
            "resetting env. episode 3703.000000, reward total was -21.000000. running mean: -19.338030\n",
            "resetting env. episode 3704.000000, reward total was -16.000000. running mean: -19.304649\n",
            "resetting env. episode 3705.000000, reward total was -17.000000. running mean: -19.281603\n",
            "resetting env. episode 3706.000000, reward total was -18.000000. running mean: -19.268787\n",
            "resetting env. episode 3707.000000, reward total was -18.000000. running mean: -19.256099\n",
            "resetting env. episode 3708.000000, reward total was -19.000000. running mean: -19.253538\n",
            "resetting env. episode 3709.000000, reward total was -21.000000. running mean: -19.271003\n",
            "resetting env. episode 3710.000000, reward total was -15.000000. running mean: -19.228293\n",
            "resetting env. episode 3711.000000, reward total was -17.000000. running mean: -19.206010\n",
            "resetting env. episode 3712.000000, reward total was -19.000000. running mean: -19.203950\n",
            "resetting env. episode 3713.000000, reward total was -19.000000. running mean: -19.201910\n",
            "resetting env. episode 3714.000000, reward total was -19.000000. running mean: -19.199891\n",
            "resetting env. episode 3715.000000, reward total was -21.000000. running mean: -19.217892\n",
            "resetting env. episode 3716.000000, reward total was -19.000000. running mean: -19.215713\n",
            "resetting env. episode 3717.000000, reward total was -19.000000. running mean: -19.213556\n",
            "resetting env. episode 3718.000000, reward total was -18.000000. running mean: -19.201420\n",
            "resetting env. episode 3719.000000, reward total was -18.000000. running mean: -19.189406\n",
            "resetting env. episode 3720.000000, reward total was -20.000000. running mean: -19.197512\n",
            "resetting env. episode 3721.000000, reward total was -19.000000. running mean: -19.195537\n",
            "resetting env. episode 3722.000000, reward total was -17.000000. running mean: -19.173582\n",
            "resetting env. episode 3723.000000, reward total was -18.000000. running mean: -19.161846\n",
            "resetting env. episode 3724.000000, reward total was -16.000000. running mean: -19.130227\n",
            "resetting env. episode 3725.000000, reward total was -17.000000. running mean: -19.108925\n",
            "resetting env. episode 3726.000000, reward total was -19.000000. running mean: -19.107836\n",
            "resetting env. episode 3727.000000, reward total was -18.000000. running mean: -19.096758\n",
            "resetting env. episode 3728.000000, reward total was -18.000000. running mean: -19.085790\n",
            "resetting env. episode 3729.000000, reward total was -19.000000. running mean: -19.084932\n",
            "resetting env. episode 3730.000000, reward total was -21.000000. running mean: -19.104083\n",
            "resetting env. episode 3731.000000, reward total was -18.000000. running mean: -19.093042\n",
            "resetting env. episode 3732.000000, reward total was -19.000000. running mean: -19.092111\n",
            "resetting env. episode 3733.000000, reward total was -20.000000. running mean: -19.101190\n",
            "resetting env. episode 3734.000000, reward total was -17.000000. running mean: -19.080178\n",
            "resetting env. episode 3735.000000, reward total was -18.000000. running mean: -19.069377\n",
            "resetting env. episode 3736.000000, reward total was -14.000000. running mean: -19.018683\n",
            "resetting env. episode 3737.000000, reward total was -21.000000. running mean: -19.038496\n",
            "resetting env. episode 3738.000000, reward total was -17.000000. running mean: -19.018111\n",
            "resetting env. episode 3739.000000, reward total was -21.000000. running mean: -19.037930\n",
            "resetting env. episode 3740.000000, reward total was -17.000000. running mean: -19.017551\n",
            "resetting env. episode 3741.000000, reward total was -20.000000. running mean: -19.027375\n",
            "resetting env. episode 3742.000000, reward total was -19.000000. running mean: -19.027101\n",
            "resetting env. episode 3743.000000, reward total was -19.000000. running mean: -19.026830\n",
            "resetting env. episode 3744.000000, reward total was -20.000000. running mean: -19.036562\n",
            "resetting env. episode 3745.000000, reward total was -19.000000. running mean: -19.036197\n",
            "resetting env. episode 3746.000000, reward total was -19.000000. running mean: -19.035835\n",
            "resetting env. episode 3747.000000, reward total was -19.000000. running mean: -19.035476\n",
            "resetting env. episode 3748.000000, reward total was -21.000000. running mean: -19.055121\n",
            "resetting env. episode 3749.000000, reward total was -20.000000. running mean: -19.064570\n",
            "resetting env. episode 3750.000000, reward total was -18.000000. running mean: -19.053925\n",
            "resetting env. episode 3751.000000, reward total was -20.000000. running mean: -19.063385\n",
            "resetting env. episode 3752.000000, reward total was -16.000000. running mean: -19.032751\n",
            "resetting env. episode 3753.000000, reward total was -17.000000. running mean: -19.012424\n",
            "resetting env. episode 3754.000000, reward total was -20.000000. running mean: -19.022300\n",
            "resetting env. episode 3755.000000, reward total was -21.000000. running mean: -19.042077\n",
            "resetting env. episode 3756.000000, reward total was -17.000000. running mean: -19.021656\n",
            "resetting env. episode 3757.000000, reward total was -19.000000. running mean: -19.021439\n",
            "resetting env. episode 3758.000000, reward total was -20.000000. running mean: -19.031225\n",
            "resetting env. episode 3759.000000, reward total was -17.000000. running mean: -19.010913\n",
            "resetting env. episode 3760.000000, reward total was -20.000000. running mean: -19.020804\n",
            "resetting env. episode 3761.000000, reward total was -20.000000. running mean: -19.030596\n",
            "resetting env. episode 3762.000000, reward total was -19.000000. running mean: -19.030290\n",
            "resetting env. episode 3763.000000, reward total was -20.000000. running mean: -19.039987\n",
            "resetting env. episode 3764.000000, reward total was -19.000000. running mean: -19.039587\n",
            "resetting env. episode 3765.000000, reward total was -17.000000. running mean: -19.019191\n",
            "resetting env. episode 3766.000000, reward total was -21.000000. running mean: -19.038999\n",
            "resetting env. episode 3767.000000, reward total was -19.000000. running mean: -19.038609\n",
            "resetting env. episode 3768.000000, reward total was -21.000000. running mean: -19.058223\n",
            "resetting env. episode 3769.000000, reward total was -20.000000. running mean: -19.067641\n",
            "resetting env. episode 3770.000000, reward total was -21.000000. running mean: -19.086964\n",
            "resetting env. episode 3771.000000, reward total was -20.000000. running mean: -19.096095\n",
            "resetting env. episode 3772.000000, reward total was -14.000000. running mean: -19.045134\n",
            "resetting env. episode 3773.000000, reward total was -19.000000. running mean: -19.044682\n",
            "resetting env. episode 3774.000000, reward total was -19.000000. running mean: -19.044236\n",
            "resetting env. episode 3775.000000, reward total was -21.000000. running mean: -19.063793\n",
            "resetting env. episode 3776.000000, reward total was -21.000000. running mean: -19.083155\n",
            "resetting env. episode 3777.000000, reward total was -17.000000. running mean: -19.062324\n",
            "resetting env. episode 3778.000000, reward total was -19.000000. running mean: -19.061701\n",
            "resetting env. episode 3779.000000, reward total was -20.000000. running mean: -19.071084\n",
            "resetting env. episode 3780.000000, reward total was -18.000000. running mean: -19.060373\n",
            "resetting env. episode 3781.000000, reward total was -19.000000. running mean: -19.059769\n",
            "resetting env. episode 3782.000000, reward total was -20.000000. running mean: -19.069171\n",
            "resetting env. episode 3783.000000, reward total was -17.000000. running mean: -19.048480\n",
            "resetting env. episode 3784.000000, reward total was -19.000000. running mean: -19.047995\n",
            "resetting env. episode 3785.000000, reward total was -20.000000. running mean: -19.057515\n",
            "resetting env. episode 3786.000000, reward total was -21.000000. running mean: -19.076940\n",
            "resetting env. episode 3787.000000, reward total was -19.000000. running mean: -19.076170\n",
            "resetting env. episode 3788.000000, reward total was -17.000000. running mean: -19.055409\n",
            "resetting env. episode 3789.000000, reward total was -20.000000. running mean: -19.064854\n",
            "resetting env. episode 3790.000000, reward total was -19.000000. running mean: -19.064206\n",
            "resetting env. episode 3791.000000, reward total was -20.000000. running mean: -19.073564\n",
            "resetting env. episode 3792.000000, reward total was -21.000000. running mean: -19.092828\n",
            "resetting env. episode 3793.000000, reward total was -19.000000. running mean: -19.091900\n",
            "resetting env. episode 3794.000000, reward total was -21.000000. running mean: -19.110981\n",
            "resetting env. episode 3795.000000, reward total was -18.000000. running mean: -19.099871\n",
            "resetting env. episode 3796.000000, reward total was -21.000000. running mean: -19.118872\n",
            "resetting env. episode 3797.000000, reward total was -18.000000. running mean: -19.107684\n",
            "resetting env. episode 3798.000000, reward total was -19.000000. running mean: -19.106607\n",
            "resetting env. episode 3799.000000, reward total was -19.000000. running mean: -19.105541\n",
            "resetting env. episode 3800.000000, reward total was -19.000000. running mean: -19.104485\n",
            "resetting env. episode 3801.000000, reward total was -20.000000. running mean: -19.113441\n",
            "resetting env. episode 3802.000000, reward total was -18.000000. running mean: -19.102306\n",
            "resetting env. episode 3803.000000, reward total was -20.000000. running mean: -19.111283\n",
            "resetting env. episode 3804.000000, reward total was -19.000000. running mean: -19.110170\n",
            "resetting env. episode 3805.000000, reward total was -16.000000. running mean: -19.079069\n",
            "resetting env. episode 3806.000000, reward total was -19.000000. running mean: -19.078278\n",
            "resetting env. episode 3807.000000, reward total was -21.000000. running mean: -19.097495\n",
            "resetting env. episode 3808.000000, reward total was -17.000000. running mean: -19.076520\n",
            "resetting env. episode 3809.000000, reward total was -18.000000. running mean: -19.065755\n",
            "resetting env. episode 3810.000000, reward total was -20.000000. running mean: -19.075097\n",
            "resetting env. episode 3811.000000, reward total was -19.000000. running mean: -19.074346\n",
            "resetting env. episode 3812.000000, reward total was -17.000000. running mean: -19.053603\n",
            "resetting env. episode 3813.000000, reward total was -20.000000. running mean: -19.063067\n",
            "resetting env. episode 3814.000000, reward total was -19.000000. running mean: -19.062436\n",
            "resetting env. episode 3815.000000, reward total was -20.000000. running mean: -19.071812\n",
            "resetting env. episode 3816.000000, reward total was -17.000000. running mean: -19.051094\n",
            "resetting env. episode 3817.000000, reward total was -20.000000. running mean: -19.060583\n",
            "resetting env. episode 3818.000000, reward total was -20.000000. running mean: -19.069977\n",
            "resetting env. episode 3819.000000, reward total was -20.000000. running mean: -19.079277\n",
            "resetting env. episode 3820.000000, reward total was -20.000000. running mean: -19.088484\n",
            "resetting env. episode 3821.000000, reward total was -20.000000. running mean: -19.097600\n",
            "resetting env. episode 3822.000000, reward total was -18.000000. running mean: -19.086624\n",
            "resetting env. episode 3823.000000, reward total was -19.000000. running mean: -19.085757\n",
            "resetting env. episode 3824.000000, reward total was -20.000000. running mean: -19.094900\n",
            "resetting env. episode 3825.000000, reward total was -17.000000. running mean: -19.073951\n",
            "resetting env. episode 3826.000000, reward total was -21.000000. running mean: -19.093211\n",
            "resetting env. episode 3827.000000, reward total was -21.000000. running mean: -19.112279\n",
            "resetting env. episode 3828.000000, reward total was -19.000000. running mean: -19.111156\n",
            "resetting env. episode 3829.000000, reward total was -20.000000. running mean: -19.120045\n",
            "resetting env. episode 3830.000000, reward total was -19.000000. running mean: -19.118844\n",
            "resetting env. episode 3831.000000, reward total was -19.000000. running mean: -19.117656\n",
            "resetting env. episode 3832.000000, reward total was -19.000000. running mean: -19.116479\n",
            "resetting env. episode 3833.000000, reward total was -21.000000. running mean: -19.135315\n",
            "resetting env. episode 3834.000000, reward total was -18.000000. running mean: -19.123961\n",
            "resetting env. episode 3835.000000, reward total was -20.000000. running mean: -19.132722\n",
            "resetting env. episode 3836.000000, reward total was -21.000000. running mean: -19.151395\n",
            "resetting env. episode 3837.000000, reward total was -19.000000. running mean: -19.149881\n",
            "resetting env. episode 3838.000000, reward total was -19.000000. running mean: -19.148382\n",
            "resetting env. episode 3839.000000, reward total was -18.000000. running mean: -19.136898\n",
            "resetting env. episode 3840.000000, reward total was -21.000000. running mean: -19.155529\n",
            "resetting env. episode 3841.000000, reward total was -19.000000. running mean: -19.153974\n",
            "resetting env. episode 3842.000000, reward total was -20.000000. running mean: -19.162434\n",
            "resetting env. episode 3843.000000, reward total was -21.000000. running mean: -19.180810\n",
            "resetting env. episode 3844.000000, reward total was -19.000000. running mean: -19.179002\n",
            "resetting env. episode 3845.000000, reward total was -20.000000. running mean: -19.187212\n",
            "resetting env. episode 3846.000000, reward total was -18.000000. running mean: -19.175339\n",
            "resetting env. episode 3847.000000, reward total was -21.000000. running mean: -19.193586\n",
            "resetting env. episode 3848.000000, reward total was -21.000000. running mean: -19.211650\n",
            "resetting env. episode 3849.000000, reward total was -20.000000. running mean: -19.219534\n",
            "resetting env. episode 3850.000000, reward total was -20.000000. running mean: -19.227338\n",
            "resetting env. episode 3851.000000, reward total was -21.000000. running mean: -19.245065\n",
            "resetting env. episode 3852.000000, reward total was -19.000000. running mean: -19.242614\n",
            "resetting env. episode 3853.000000, reward total was -20.000000. running mean: -19.250188\n",
            "resetting env. episode 3854.000000, reward total was -19.000000. running mean: -19.247686\n",
            "resetting env. episode 3855.000000, reward total was -17.000000. running mean: -19.225209\n",
            "resetting env. episode 3856.000000, reward total was -18.000000. running mean: -19.212957\n",
            "resetting env. episode 3857.000000, reward total was -21.000000. running mean: -19.230828\n",
            "resetting env. episode 3858.000000, reward total was -21.000000. running mean: -19.248519\n",
            "resetting env. episode 3859.000000, reward total was -19.000000. running mean: -19.246034\n",
            "resetting env. episode 3860.000000, reward total was -18.000000. running mean: -19.233574\n",
            "resetting env. episode 3861.000000, reward total was -21.000000. running mean: -19.251238\n",
            "resetting env. episode 3862.000000, reward total was -19.000000. running mean: -19.248726\n",
            "resetting env. episode 3863.000000, reward total was -19.000000. running mean: -19.246239\n",
            "resetting env. episode 3864.000000, reward total was -20.000000. running mean: -19.253776\n",
            "resetting env. episode 3865.000000, reward total was -15.000000. running mean: -19.211238\n",
            "resetting env. episode 3866.000000, reward total was -20.000000. running mean: -19.219126\n",
            "resetting env. episode 3867.000000, reward total was -19.000000. running mean: -19.216935\n",
            "resetting env. episode 3868.000000, reward total was -19.000000. running mean: -19.214765\n",
            "resetting env. episode 3869.000000, reward total was -21.000000. running mean: -19.232618\n",
            "resetting env. episode 3870.000000, reward total was -18.000000. running mean: -19.220292\n",
            "resetting env. episode 3871.000000, reward total was -18.000000. running mean: -19.208089\n",
            "resetting env. episode 3872.000000, reward total was -20.000000. running mean: -19.216008\n",
            "resetting env. episode 3873.000000, reward total was -20.000000. running mean: -19.223848\n",
            "resetting env. episode 3874.000000, reward total was -19.000000. running mean: -19.221609\n",
            "resetting env. episode 3875.000000, reward total was -18.000000. running mean: -19.209393\n",
            "resetting env. episode 3876.000000, reward total was -17.000000. running mean: -19.187299\n",
            "resetting env. episode 3877.000000, reward total was -21.000000. running mean: -19.205426\n",
            "resetting env. episode 3878.000000, reward total was -19.000000. running mean: -19.203372\n",
            "resetting env. episode 3879.000000, reward total was -17.000000. running mean: -19.181338\n",
            "resetting env. episode 3880.000000, reward total was -20.000000. running mean: -19.189525\n",
            "resetting env. episode 3881.000000, reward total was -21.000000. running mean: -19.207630\n",
            "resetting env. episode 3882.000000, reward total was -19.000000. running mean: -19.205553\n",
            "resetting env. episode 3883.000000, reward total was -21.000000. running mean: -19.223498\n",
            "resetting env. episode 3884.000000, reward total was -18.000000. running mean: -19.211263\n",
            "resetting env. episode 3885.000000, reward total was -19.000000. running mean: -19.209150\n",
            "resetting env. episode 3886.000000, reward total was -19.000000. running mean: -19.207059\n",
            "resetting env. episode 3887.000000, reward total was -18.000000. running mean: -19.194988\n",
            "resetting env. episode 3888.000000, reward total was -20.000000. running mean: -19.203038\n",
            "resetting env. episode 3889.000000, reward total was -19.000000. running mean: -19.201008\n",
            "resetting env. episode 3890.000000, reward total was -20.000000. running mean: -19.208998\n",
            "resetting env. episode 3891.000000, reward total was -17.000000. running mean: -19.186908\n",
            "resetting env. episode 3892.000000, reward total was -18.000000. running mean: -19.175039\n",
            "resetting env. episode 3893.000000, reward total was -19.000000. running mean: -19.173288\n",
            "resetting env. episode 3894.000000, reward total was -14.000000. running mean: -19.121555\n",
            "resetting env. episode 3895.000000, reward total was -17.000000. running mean: -19.100340\n",
            "resetting env. episode 3896.000000, reward total was -17.000000. running mean: -19.079336\n",
            "resetting env. episode 3897.000000, reward total was -19.000000. running mean: -19.078543\n",
            "resetting env. episode 3898.000000, reward total was -20.000000. running mean: -19.087758\n",
            "resetting env. episode 3899.000000, reward total was -18.000000. running mean: -19.076880\n",
            "resetting env. episode 3900.000000, reward total was -19.000000. running mean: -19.076111\n",
            "resetting env. episode 3901.000000, reward total was -17.000000. running mean: -19.055350\n",
            "resetting env. episode 3902.000000, reward total was -16.000000. running mean: -19.024797\n",
            "resetting env. episode 3903.000000, reward total was -20.000000. running mean: -19.034549\n",
            "resetting env. episode 3904.000000, reward total was -20.000000. running mean: -19.044203\n",
            "resetting env. episode 3905.000000, reward total was -19.000000. running mean: -19.043761\n",
            "resetting env. episode 3906.000000, reward total was -19.000000. running mean: -19.043324\n",
            "resetting env. episode 3907.000000, reward total was -20.000000. running mean: -19.052890\n",
            "resetting env. episode 3908.000000, reward total was -18.000000. running mean: -19.042361\n",
            "resetting env. episode 3909.000000, reward total was -19.000000. running mean: -19.041938\n",
            "resetting env. episode 3910.000000, reward total was -18.000000. running mean: -19.031518\n",
            "resetting env. episode 3911.000000, reward total was -19.000000. running mean: -19.031203\n",
            "resetting env. episode 3912.000000, reward total was -19.000000. running mean: -19.030891\n",
            "resetting env. episode 3913.000000, reward total was -20.000000. running mean: -19.040582\n",
            "resetting env. episode 3914.000000, reward total was -20.000000. running mean: -19.050176\n",
            "resetting env. episode 3915.000000, reward total was -20.000000. running mean: -19.059675\n",
            "resetting env. episode 3916.000000, reward total was -20.000000. running mean: -19.069078\n",
            "resetting env. episode 3917.000000, reward total was -20.000000. running mean: -19.078387\n",
            "resetting env. episode 3918.000000, reward total was -19.000000. running mean: -19.077603\n",
            "resetting env. episode 3919.000000, reward total was -21.000000. running mean: -19.096827\n",
            "resetting env. episode 3920.000000, reward total was -20.000000. running mean: -19.105859\n",
            "resetting env. episode 3921.000000, reward total was -19.000000. running mean: -19.104800\n",
            "resetting env. episode 3922.000000, reward total was -19.000000. running mean: -19.103752\n",
            "resetting env. episode 3923.000000, reward total was -19.000000. running mean: -19.102715\n",
            "resetting env. episode 3924.000000, reward total was -19.000000. running mean: -19.101688\n",
            "resetting env. episode 3925.000000, reward total was -16.000000. running mean: -19.070671\n",
            "resetting env. episode 3926.000000, reward total was -19.000000. running mean: -19.069964\n",
            "resetting env. episode 3927.000000, reward total was -20.000000. running mean: -19.079265\n",
            "resetting env. episode 3928.000000, reward total was -19.000000. running mean: -19.078472\n",
            "resetting env. episode 3929.000000, reward total was -19.000000. running mean: -19.077687\n",
            "resetting env. episode 3930.000000, reward total was -18.000000. running mean: -19.066910\n",
            "resetting env. episode 3931.000000, reward total was -16.000000. running mean: -19.036241\n",
            "resetting env. episode 3932.000000, reward total was -17.000000. running mean: -19.015879\n",
            "resetting env. episode 3933.000000, reward total was -19.000000. running mean: -19.015720\n",
            "resetting env. episode 3934.000000, reward total was -16.000000. running mean: -18.985563\n",
            "resetting env. episode 3935.000000, reward total was -17.000000. running mean: -18.965707\n",
            "resetting env. episode 3936.000000, reward total was -18.000000. running mean: -18.956050\n",
            "resetting env. episode 3937.000000, reward total was -17.000000. running mean: -18.936490\n",
            "resetting env. episode 3938.000000, reward total was -21.000000. running mean: -18.957125\n",
            "resetting env. episode 3939.000000, reward total was -18.000000. running mean: -18.947553\n",
            "resetting env. episode 3940.000000, reward total was -19.000000. running mean: -18.948078\n",
            "resetting env. episode 3941.000000, reward total was -15.000000. running mean: -18.908597\n",
            "resetting env. episode 3942.000000, reward total was -20.000000. running mean: -18.919511\n",
            "resetting env. episode 3943.000000, reward total was -20.000000. running mean: -18.930316\n",
            "resetting env. episode 3944.000000, reward total was -17.000000. running mean: -18.911013\n",
            "resetting env. episode 3945.000000, reward total was -14.000000. running mean: -18.861903\n",
            "resetting env. episode 3946.000000, reward total was -19.000000. running mean: -18.863284\n",
            "resetting env. episode 3947.000000, reward total was -18.000000. running mean: -18.854651\n",
            "resetting env. episode 3948.000000, reward total was -16.000000. running mean: -18.826104\n",
            "resetting env. episode 3949.000000, reward total was -19.000000. running mean: -18.827843\n",
            "resetting env. episode 3950.000000, reward total was -17.000000. running mean: -18.809565\n",
            "resetting env. episode 3951.000000, reward total was -21.000000. running mean: -18.831469\n",
            "resetting env. episode 3952.000000, reward total was -20.000000. running mean: -18.843155\n",
            "resetting env. episode 3953.000000, reward total was -19.000000. running mean: -18.844723\n",
            "resetting env. episode 3954.000000, reward total was -19.000000. running mean: -18.846276\n",
            "resetting env. episode 3955.000000, reward total was -18.000000. running mean: -18.837813\n",
            "resetting env. episode 3956.000000, reward total was -18.000000. running mean: -18.829435\n",
            "resetting env. episode 3957.000000, reward total was -18.000000. running mean: -18.821141\n",
            "resetting env. episode 3958.000000, reward total was -20.000000. running mean: -18.832929\n",
            "resetting env. episode 3959.000000, reward total was -21.000000. running mean: -18.854600\n",
            "resetting env. episode 3960.000000, reward total was -21.000000. running mean: -18.876054\n",
            "resetting env. episode 3961.000000, reward total was -21.000000. running mean: -18.897293\n",
            "resetting env. episode 3962.000000, reward total was -20.000000. running mean: -18.908320\n",
            "resetting env. episode 3963.000000, reward total was -19.000000. running mean: -18.909237\n",
            "resetting env. episode 3964.000000, reward total was -19.000000. running mean: -18.910145\n",
            "resetting env. episode 3965.000000, reward total was -17.000000. running mean: -18.891043\n",
            "resetting env. episode 3966.000000, reward total was -17.000000. running mean: -18.872133\n",
            "resetting env. episode 3967.000000, reward total was -19.000000. running mean: -18.873412\n",
            "resetting env. episode 3968.000000, reward total was -19.000000. running mean: -18.874677\n",
            "resetting env. episode 3969.000000, reward total was -20.000000. running mean: -18.885931\n",
            "resetting env. episode 3970.000000, reward total was -19.000000. running mean: -18.887071\n",
            "resetting env. episode 3971.000000, reward total was -19.000000. running mean: -18.888201\n",
            "resetting env. episode 3972.000000, reward total was -15.000000. running mean: -18.849319\n",
            "resetting env. episode 3973.000000, reward total was -21.000000. running mean: -18.870825\n",
            "resetting env. episode 3974.000000, reward total was -21.000000. running mean: -18.892117\n",
            "resetting env. episode 3975.000000, reward total was -18.000000. running mean: -18.883196\n",
            "resetting env. episode 3976.000000, reward total was -21.000000. running mean: -18.904364\n",
            "resetting env. episode 3977.000000, reward total was -19.000000. running mean: -18.905320\n",
            "resetting env. episode 3978.000000, reward total was -19.000000. running mean: -18.906267\n",
            "resetting env. episode 3979.000000, reward total was -20.000000. running mean: -18.917205\n",
            "resetting env. episode 3980.000000, reward total was -17.000000. running mean: -18.898033\n",
            "resetting env. episode 3981.000000, reward total was -18.000000. running mean: -18.889052\n",
            "resetting env. episode 3982.000000, reward total was -20.000000. running mean: -18.900162\n",
            "resetting env. episode 3983.000000, reward total was -17.000000. running mean: -18.881160\n",
            "resetting env. episode 3984.000000, reward total was -19.000000. running mean: -18.882348\n",
            "resetting env. episode 3985.000000, reward total was -15.000000. running mean: -18.843525\n",
            "resetting env. episode 3986.000000, reward total was -21.000000. running mean: -18.865090\n",
            "resetting env. episode 3987.000000, reward total was -20.000000. running mean: -18.876439\n",
            "resetting env. episode 3988.000000, reward total was -19.000000. running mean: -18.877674\n",
            "resetting env. episode 3989.000000, reward total was -19.000000. running mean: -18.878898\n",
            "resetting env. episode 3990.000000, reward total was -18.000000. running mean: -18.870109\n",
            "resetting env. episode 3991.000000, reward total was -21.000000. running mean: -18.891408\n",
            "resetting env. episode 3992.000000, reward total was -21.000000. running mean: -18.912494\n",
            "resetting env. episode 3993.000000, reward total was -18.000000. running mean: -18.903369\n",
            "resetting env. episode 3994.000000, reward total was -20.000000. running mean: -18.914335\n",
            "resetting env. episode 3995.000000, reward total was -17.000000. running mean: -18.895192\n",
            "resetting env. episode 3996.000000, reward total was -15.000000. running mean: -18.856240\n",
            "resetting env. episode 3997.000000, reward total was -19.000000. running mean: -18.857677\n",
            "resetting env. episode 3998.000000, reward total was -20.000000. running mean: -18.869101\n",
            "resetting env. episode 3999.000000, reward total was -17.000000. running mean: -18.850410\n",
            "resetting env. episode 4000.000000, reward total was -19.000000. running mean: -18.851905\n",
            "CPU times: user 5h 33min 57s, sys: 1h 46min 38s, total: 7h 20min 36s\n",
            "Wall time: 3h 46min 54s\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "w2NblmwDsL3y",
        "outputId": "d02692d9-67a5-478e-b4fc-a345679c42a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        }
      },
      "cell_type": "code",
      "source": [
        "play_game(env, model)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gym/core.py:52: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
            "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
            "  \"The argument mode in render method is deprecated; \"\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode finished without success, accumulated reward = -5.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 320x420 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "ZYA0HgMoO77a"
      },
      "cell_type": "code",
      "source": [
        "# import pickle\n",
        "# pickle.dump(model, open('model.pkl', 'wb'))"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2Vu9PonFR5NA"
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}